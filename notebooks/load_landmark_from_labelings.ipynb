{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "sys.path.append(os.environ['GORDON_REPO_DIR'] + '/pipeline_scripts')\n",
    "\n",
    "from utilities2014 import *\n",
    "\n",
    "sys.path.append('/home/yuncong/project/opencv-2.4.9/release/lib/python2.7/site-packages')\n",
    "import cv2\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "from itertools import combinations, chain, product\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/oasis/projects/nsf/csd181/yuncong/virtualenv-1.9.1/yuncongve/lib/python2.7/site-packages/skimage/filter/__init__.py:6: skimage_deprecation: The `skimage.filter` module has been renamed to `skimage.filters`.  This placeholder module will be removed in v0.13.\n",
      "  warn(skimage_deprecation('The `skimage.filter` module has been renamed '\n"
     ]
    }
   ],
   "source": [
    "dm = DataManager(generate_hierarchy=False, stack='RS141', resol='x5', section=1)\n",
    "dm._load_image()\n",
    "\n",
    "texton_hists = dm.load_pipeline_result('texHist', 'npy')\n",
    "segmentation = dm.load_pipeline_result('segmentation', 'npy')\n",
    "n_superpixels = len(np.unique(segmentation)) - 1\n",
    "textonmap = dm.load_pipeline_result('texMap', 'npy')\n",
    "n_texton = len(np.unique(textonmap)) - 1\n",
    "neighbors = dm.load_pipeline_result('neighbors', 'pkl')\n",
    "sp_properties = dm.load_pipeline_result('spProps', 'npy')\n",
    "segmentation_vis = dm.load_pipeline_result('segmentationWithText', 'jpg')\n",
    "\n",
    "# texture_map = texton_hists[segmentation]\n",
    "# texture_map[~dm.mask] = np.nan * np.ones((n_texton,))\n",
    "# dm.save_pipeline_result(texture_map, 'textureMap', 'npy')\n",
    "texture_map = dm.load_pipeline_result('textureMap', 'npy')\n",
    "\n",
    "coherence_map = dm.load_pipeline_result('coherenceMap', 'npy')\n",
    "eigenvec_map = dm.load_pipeline_result('eigenvecMap', 'npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "from enum import Enum\n",
    "from itertools import groupby\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PolygonType(Enum):\n",
    "    CLOSED = 'closed'\n",
    "    OPEN = 'open'\n",
    "    TEXTURE = 'textured'\n",
    "    TEXTURE_WITH_CONTOUR = 'texture with contour'\n",
    "    DIRECTION = 'directionality'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(os.environ['GORDON_LABELING_DIR']+'/RS141_0001_yuncong_08142015182314.pkl') as f:\n",
    "    labelings = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thetas = np.linspace(-np.pi/4, np.pi/4, 9)\n",
    "n_theta = len(thetas)\n",
    "Rs = [np.array([[np.cos(theta), np.sin(theta)], [-np.sin(theta), np.cos(theta)]]) for theta in thetas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def vertices_to_normals(vertices):\n",
    "    \n",
    "    n = vertices.shape[0]\n",
    "\n",
    "    # compute normal direction of each vertex\n",
    "    D = cdist(vertices, vertices)\n",
    "    nn = D.argsort(axis=1)[:,:3]\n",
    "    vertice_normals = np.empty((n, 2))\n",
    "    for i, neighborhood in enumerate(nn):\n",
    "        X = vertices[neighborhood]\n",
    "        Xc = X - X.mean(axis=0)\n",
    "        U,S,V = np.linalg.svd(np.dot(Xc.T, Xc))\n",
    "        tangent_dir = U[:,0]\n",
    "        vertice_normals[i] = np.array([tangent_dir[1], -tangent_dir[0]])\n",
    "        if vertice_normals[i][0] < 0: # make sure x-component is positive, i.e. normal points rightwards\n",
    "            vertice_normals[i] = -vertice_normals[i]\n",
    "    return vertice_normals\n",
    "\n",
    "\n",
    "def find_in_polygon(vertices, x, y):\n",
    "\n",
    "    from matplotlib.path import Path\n",
    "\n",
    "    X, Y = np.meshgrid(x, y)  # X, Y are 2D ndarrays\n",
    "    XY = np.dstack((X, Y))\n",
    "    XY_flat = XY.reshape((-1, 2))\n",
    "\n",
    "    mpath = Path(vertices) # the vertices of the polygon\n",
    "    mask_flat = mpath.contains_points(XY_flat)\n",
    "    mask = mask_flat.reshape(X.shape)\n",
    "\n",
    "    return mask\n",
    "\n",
    "    \n",
    "def compute_landmark_descriptors(group):\n",
    "    \n",
    "    n_polygon = len(group)\n",
    "        \n",
    "    all_polygon_vertices = [vertices for _, _, vertices in group]\n",
    "    all_polygon_types = [polygon_type for _, polygon_type, _ in group]\n",
    "        \n",
    "    edge_indices = [i for i in range(n_polygon)\n",
    "                   if all_polygon_types[i] == PolygonType.TEXTURE_WITH_CONTOUR \\\n",
    "                            or all_polygon_types[i] == PolygonType.CLOSED\\\n",
    "                           or all_polygon_types[i] == PolygonType.OPEN]\n",
    "    texture_indices = [i for i in range(n_polygon)\n",
    "                   if all_polygon_types[i] == PolygonType.TEXTURE_WITH_CONTOUR \\\n",
    "                            or all_polygon_types[i] == PolygonType.TEXTURE]\n",
    "    \n",
    "    res = [dict([]) for _ in range(n_theta)]\n",
    "        \n",
    "    all_vertices = np.vstack(all_polygon_vertices)\n",
    "    \n",
    "    xmin, ymin = all_vertices.min(axis=0).astype(np.int)\n",
    "    xmax, ymax = all_vertices.max(axis=0).astype(np.int)\n",
    "    centroid_global = all_vertices.mean(axis=0).astype(np.int)\n",
    "    centroid_local = centroid_global - [xmin, ymin]\n",
    "    lm_texture_template = texture_map[ymin:ymax+1, xmin:xmax+1]\n",
    "\n",
    "    lm_box_shape = [xmax - xmin + 1, ymax - ymin + 1]\n",
    "\n",
    "    texture_sample_radius = 5\n",
    "    int_rs = np.arange(-texture_sample_radius, 0)\n",
    "    ext_rs = np.arange(1, texture_sample_radius+1)\n",
    "    \n",
    "    all_polygon_vertice_normals = map(vertices_to_normals, all_polygon_vertices)\n",
    "    \n",
    "    striation_indices = [i for i in range(n_polygon) if all_polygon_types[i] == PolygonType.DIRECTION]\n",
    "    if len(striation_indices) > 0:\n",
    "        striation_sample_points = np.vstack(all_polygon_vertices[i] for i in striation_indices).astype(np.int)\n",
    "        striation_sample_vecs = eigenvec_map[striation_sample_points[:,1], striation_sample_points[:,0]]\n",
    "    \n",
    "    for theta_i in range(n_theta):\n",
    "        \n",
    "#         print 'theta', theta_i\n",
    "        \n",
    "        all_polygon_vertices_rotated_global_list = []\n",
    "        \n",
    "        for vertices in all_polygon_vertices:\n",
    "            vertices_centered = vertices - centroid_global\n",
    "            vertices_centered_rotated = np.dot(Rs[theta_i], vertices_centered.T).astype(np.int).T\n",
    "            vertices_rotated_global = vertices_centered_rotated + centroid_global\n",
    "            all_polygon_vertices_rotated_global_list.append(vertices_rotated_global)\n",
    "            \n",
    "        all_polygon_vertices_rotated_global = np.vstack(all_polygon_vertices_rotated_global_list)\n",
    "        all_vertices_rotated_global_xmin, all_vertices_rotated_global_ymin = all_polygon_vertices_rotated_global.min(axis=0)\n",
    "        all_vertices_rotated_global_xmax, all_vertices_rotated_global_ymax = all_polygon_vertices_rotated_global.max(axis=0)\n",
    "        centroid_rotated_local = centroid_global - (all_vertices_rotated_global_xmin, all_vertices_rotated_global_ymin)\n",
    "        \n",
    "        rotated_bbox_shape = (all_vertices_rotated_global_xmax - all_vertices_rotated_global_xmin + 1, \n",
    "                                all_vertices_rotated_global_ymax - all_vertices_rotated_global_ymin + 1)\n",
    "\n",
    "        res[theta_i]['bbox'] = np.array([rotated_bbox_shape[0], rotated_bbox_shape[1], \n",
    "                                 centroid_rotated_local[0], centroid_rotated_local[1],\n",
    "                                        centroid_global[0], centroid_global[1],\n",
    "                                        xmin, ymin, xmax, ymax])\n",
    "        \n",
    "        all_polygon_vertices_rotated_local = [vertices_rotated_global - (all_vertices_rotated_global_xmin, all_vertices_rotated_global_ymin)\n",
    "                                  for vertices_rotated_global in all_polygon_vertices_rotated_global_list]\n",
    "        \n",
    "        \n",
    "        \n",
    "        res[theta_i]['vertices'] = np.vstack(all_polygon_vertices_rotated_local)\n",
    "        res[theta_i]['vertices_global'] = np.vstack(all_polygon_vertices_rotated_global_list)\n",
    "\n",
    "        \n",
    "        if len(edge_indices) > 0:\n",
    "            all_polygon_vertice_normals_rotated = []\n",
    "            for vertice_normals in all_polygon_vertice_normals:\n",
    "                vertice_normals_rotated = np.dot(Rs[theta_i], vertice_normals.T).T\n",
    "                all_polygon_vertice_normals_rotated.append(vertice_normals_rotated)\n",
    "            res[theta_i]['normal'] = np.vstack([all_polygon_vertice_normals_rotated[i] for i in edge_indices])\n",
    "        else:\n",
    "            res[theta_i]['normal'] = None\n",
    "\n",
    "        if len(edge_indices) > 0:\n",
    "\n",
    "            all_polygon_boundary_int_textures = []\n",
    "            all_polygon_boundary_ext_textures = []\n",
    "            for vertices, vertice_normals in zip(all_polygon_vertices, all_polygon_vertice_normals):\n",
    "\n",
    "                int_texture_sample_xs = (vertices[:,0][:,None] + np.outer(vertice_normals[:,0], int_rs)).astype(np.int)\n",
    "                int_texture_sample_ys = (vertices[:,1][:,None] + np.outer(vertice_normals[:,1], int_rs)).astype(np.int)\n",
    "                boundary_int_textures = texture_map[int_texture_sample_ys, int_texture_sample_xs].mean(axis=1)\n",
    "                all_polygon_boundary_int_textures.append(boundary_int_textures)\n",
    "\n",
    "                ext_texture_sample_xs = (vertices[:,0][:,None] + np.outer(vertice_normals[:,0], ext_rs)).astype(np.int)\n",
    "                ext_texture_sample_ys = (vertices[:,1][:,None] + np.outer(vertice_normals[:,1], ext_rs)).astype(np.int)\n",
    "                boundary_ext_textures = texture_map[ext_texture_sample_ys, ext_texture_sample_xs].mean(axis=1)\n",
    "                all_polygon_boundary_ext_textures.append(boundary_ext_textures)\n",
    "        \n",
    "            res[theta_i]['boundary_vertices'] = np.vstack(all_polygon_vertices_rotated_local[i] for i in edge_indices)\n",
    "            res[theta_i]['boundary_vertices_global'] = np.vstack(all_polygon_vertices_rotated_global_list[i] for i in edge_indices)\n",
    "            res[theta_i]['boundary_texture'] = np.c_[np.vstack(all_polygon_boundary_int_textures[i] for i in edge_indices), \n",
    "                                                     np.vstack(all_polygon_boundary_ext_textures[i] for i in edge_indices)]\n",
    "        \n",
    "        else:\n",
    "            res[theta_i]['boundary_vertices'] = None\n",
    "            res[theta_i]['boundary_vertices_global'] = None\n",
    "            res[theta_i]['boundary_texture'] = None\n",
    "            \n",
    "        \n",
    "        if len(striation_indices) > 0:\n",
    "            striation_sample_points_rotated_local = np.vstack(all_polygon_vertices_rotated_local[i] for i in striation_indices).astype(np.int)\n",
    "            striation_sample_vecs_rotated = np.dot(Rs[theta_i], striation_sample_vecs.T).T\n",
    "            res[theta_i]['striation'] = np.c_[striation_sample_points_rotated_local, striation_sample_vecs_rotated]\n",
    "            res[theta_i]['striation_points_global'] = np.vstack(all_polygon_vertices_rotated_global_list[i] for i in striation_indices)\n",
    "        else:\n",
    "            res[theta_i]['striation'] = None\n",
    "            res[theta_i]['striation_points_global'] = None\n",
    "            \n",
    "        # rotated templates\n",
    "        rotated_texTemplate = np.nan * np.ones((rotated_bbox_shape[1], rotated_bbox_shape[0], n_texton))\n",
    "                       \n",
    "#         for vertices in all_polygon_vertices_rotated_local:   \n",
    "#             mask = find_in_polygon(vertices, range(rotated_bbox_shape[0]), range(rotated_bbox_shape[1]))\n",
    "#             plt.imshow(mask)\n",
    "#             plt.show()\n",
    "                           \n",
    "        ys, xs = np.mgrid[:rotated_bbox_shape[1], :rotated_bbox_shape[0]]\n",
    "        a = np.dot(np.linalg.inv(Rs[theta_i]), (np.c_[xs.flat, ys.flat] - centroid_rotated_local).T).T\n",
    "\n",
    "        xss = (a[:,0] + centroid_local[0]).astype(np.int)\n",
    "        yss = (a[:,1] + centroid_local[1]).astype(np.int)\n",
    "        \n",
    "        valid = (yss < lm_texture_template.shape[0]) & (yss >= 0) & (xss < lm_texture_template.shape[1]) & (xss >= 0)\n",
    "        rotated_texTemplate[ys.flat[valid], xs.flat[valid]] = lm_texture_template[yss[valid], xss[valid]]\n",
    "\n",
    "        \n",
    "        if len(texture_indices) > 0:\n",
    "            all_polygon_masks = [find_in_polygon(all_polygon_vertices_rotated_local[i], range(rotated_bbox_shape[0]), range(rotated_bbox_shape[1]))\n",
    "                                 for i in texture_indices]\n",
    "            \n",
    "            if len(all_polygon_masks) == 1:\n",
    "                rotated_texTemplate[~all_polygon_masks[0]] = np.nan\n",
    "            else:\n",
    "                rotated_texTemplate[~np.bitwise_or(*all_polygon_masks)] = np.nan\n",
    "                \n",
    "            res[theta_i]['texture_template'] = rotated_texTemplate\n",
    "            \n",
    "            textured_ys, textured_xs = np.where(~np.isnan(rotated_texTemplate[:,:,0]))\n",
    "            textured_ys_global = textured_ys + all_vertices_rotated_global_ymin\n",
    "            textured_xs_global = textured_xs + all_vertices_rotated_global_xmin\n",
    "            res[theta_i]['texture_vertices_global'] = np.c_[textured_xs_global, textured_ys_global]\n",
    "        else:\n",
    "            res[theta_i]['texture_template'] = None\n",
    "            res[theta_i]['texture_vertices_global'] = None\n",
    "            \n",
    "    return res\n",
    "                    \n",
    "#         fig = plt.figure()\n",
    "#         ax = fig.add_subplot(111)\n",
    "# #             q = np.zeros_like(dm.image)\n",
    "# #             q[vertices_rotated_global[:,1], vertices_rotated_global[:,0]] = 1\n",
    "# #             plt.imshow(q)\n",
    "# #         all_polygon_vertices_rotated_global = np.vstack(all_polygon_vertices_rotated_global)\n",
    "\n",
    "#         ax.scatter(all_polygon_vertices_rotated_global[:,0], all_polygon_vertices_rotated_global[:,1])\n",
    "#         ax.set_aspect('equal')\n",
    "# #         ax.set_xlim([2800,3300])\n",
    "# #         ax.set_ylim([1900,2300])\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "landmark_descriptor = compute_landmark_descriptors([labelings['final_polygons'][5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def q(label, group):\n",
    "    descriptor = compute_landmark_descriptors(list(group))\n",
    "    with open('/home/yuncong/csd395/all_landmark_descriptors_%d.pkl'%label, 'w') as f:\n",
    "        pickle.dump(descriptor, f)\n",
    "    return label, descriptor\n",
    "    \n",
    "landmark_descriptors = dict(Parallel(n_jobs=16)(delayed(q)(label, list(group)) \n",
    "                        for label, group in groupby(labelings['final_polygons'], itemgetter(0))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "7\n",
      "5\n",
      "8\n",
      "6\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "# for label, group in groupby(labelings['final_polygons'], itemgetter(0)):\n",
    "#     print label\n",
    "#     descriptor = compute_landmark_descriptors(list(group))\n",
    "#     with open('/home/yuncong/csd395/all_landmark_descriptors_%d.pkl'%label, 'w') as f:\n",
    "#         pickle.dump(descriptor, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "from skimage.morphology import disk, binary_dilation\n",
    "\n",
    "viz_overlay = np.zeros_like(dm.image_rgb, np.uint8)\n",
    "\n",
    "for label, descriptor in landmark_descriptors.iteritems():\n",
    "    print label\n",
    "    \n",
    "    pts = descriptor[4]['boundary_vertices_global']\n",
    "#     c = (255,0,0)\n",
    "    if pts is not None:\n",
    "        overlay = np.zeros_like(dm.image, np.bool)\n",
    "        overlay[pts[:,1], pts[:,0]] = 1\n",
    "        overlay = binary_dilation(overlay, disk(10))\n",
    "#         viz[overlay] = c\n",
    "        viz_overlay[overlay] = (255,0,0)\n",
    "    \n",
    "    pts = descriptor[4]['texture_vertices_global']\n",
    "#     c = (0,255,0)\n",
    "    if pts is not None:\n",
    "#         viz[pts[:,1], pts[:,0]] = c\n",
    "        viz_overlay[pts[:,1], pts[:,0]] = (0,255,0)\n",
    "    \n",
    "    pts = descriptor[4]['striation_points_global']\n",
    "    if pts is not None:\n",
    "        vecs = descriptor[4]['striation'][:, 2:]\n",
    "        \n",
    "        overlay = np.zeros_like(dm.image, np.bool)\n",
    "        overlay[pts[:,1], pts[:,0]] = 1\n",
    "        overlay = binary_dilation(overlay, disk(5))\n",
    "#         c = (255,255,0)\n",
    "#         viz[overlay] = c\n",
    "        \n",
    "        length = 50.\n",
    "        ends = (pts + length * np.c_[vecs[:,1], -vecs[:,0]]).astype(np.int)\n",
    "        for end, (x,y) in zip(ends, pts):\n",
    "            cv2.line(viz_overlay, (x,y), tuple(end), (255,0,0), thickness=5, lineType=8, shift=0)\n",
    "        viz_overlay[overlay] = (255,255,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='tmp.jpg' target='_blank'>tmp.jpg</a><br>"
      ],
      "text/plain": [
       "/oasis/projects/nsf/csd395/yuncong/Brain/notebooks/tmp.jpg"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vis_overlay_alpha = np.ones(viz_overlay.shape[:2])\n",
    "vis_overlay_alpha[np.all(viz_overlay == 0, axis=-1)] = 0.\n",
    "\n",
    "viz = alpha_blending(dm.image_rgb, img_as_float(viz_overlay), .3, vis_overlay_alpha)\n",
    "# viz = alpha_blending(np.ones_like(dm.image_rgb), img_as_float(viz_overlay), .3, vis_overlay_alpha)\n",
    "display(viz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[array([397, 421, 193, 174]),\n",
       "  array([433, 375, 197, 155]),\n",
       "  array([460, 325, 200, 133]),\n",
       "  array([478, 286, 195, 121]),\n",
       "  array([479, 273, 184, 114]),\n",
       "  array([485, 277, 189, 105]),\n",
       "  array([475, 316, 189, 138]),\n",
       "  array([452, 361, 185, 174]),\n",
       "  array([421, 397, 174, 203])]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[rotated_version['bbox'] for rotated_version in all_landmark_descriptors[0]]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
