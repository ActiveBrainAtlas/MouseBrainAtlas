{
 "metadata": {
  "name": "",
  "signature": "sha256:fd75f4b374512d865a3ab9def421736fc163df827904a1e2f8e372c2a7408798"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%reload_ext autoreload\n",
      "%autoreload 2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "sys.path.append('/home/yuncong/Brain/pipeline_scripts')\n",
      "from utilities2014 import *\n",
      "import os\n",
      "\n",
      "from scipy.spatial.distance import cdist, pdist, squareform\n",
      "from joblib import Parallel, delayed\n",
      "from skimage.color import gray2rgb\n",
      "\n",
      "from networkx import from_dict_of_lists, Graph, adjacency_matrix\n",
      "from networkx.algorithms import node_connected_component\n",
      "\n",
      "%run grow_regions_common.ipynb\n",
      "\n",
      "os.environ['GORDON_DATA_DIR'] = '/home/yuncong/project/DavidData2014tif/'\n",
      "os.environ['GORDON_REPO_DIR'] = '/home/yuncong/Brain'\n",
      "os.environ['GORDON_RESULT_DIR'] = '/home/yuncong/project/DavidData2014results/'\n",
      "os.environ['GORDON_LABELING_DIR'] = '/home/yuncong/project/DavidData2014labelings/'\n",
      "\n",
      "dm = DataManager(data_dir=os.environ['GORDON_DATA_DIR'], \n",
      "  repo_dir=os.environ['GORDON_REPO_DIR'], \n",
      "  result_dir=os.environ['GORDON_RESULT_DIR'], \n",
      "  labeling_dir=os.environ['GORDON_LABELING_DIR'])\n",
      "\n",
      "dm.set_stack('RS141')\n",
      "dm.set_resol('x5')\n",
      "dm.set_gabor_params(gabor_params_id='blueNisslWide')\n",
      "dm.set_segmentation_params(segm_params_id='blueNisslRegular')\n",
      "dm.set_vq_params(vq_params_id='blueNissl')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dm.set_slice(7)\n",
      "dm._load_image()\n",
      "\n",
      "texton_hists = dm.load_pipeline_result('texHist', 'npy')\n",
      "segmentation = dm.load_pipeline_result('segmentation', 'npy')\n",
      "n_superpixels = len(unique(segmentation)) - 1\n",
      "textonmap = dm.load_pipeline_result('texMap', 'npy')\n",
      "n_texton = len(np.unique(textonmap)) - 1\n",
      "neighbors = dm.load_pipeline_result('neighbors', 'npy')\n",
      "sp_properties = dm.load_pipeline_result('spProps', 'npy')\n",
      "segmentation_vis = dm.load_pipeline_result('segmentationWithText', 'jpg')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "loaded /home/yuncong/project/DavidData2014results/RS141/0007/RS141_x5_0007_gabor-blueNisslWide-segm-blueNisslRegular-vq-blueNissl_texHist.npy\n",
        "loaded /home/yuncong/project/DavidData2014results/RS141/0007/RS141_x5_0007_segm-blueNisslRegular_segmentation.npy"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "loaded /home/yuncong/project/DavidData2014results/RS141/0007/RS141_x5_0007_gabor-blueNisslWide-vq-blueNissl_texMap.npy"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "loaded /home/yuncong/project/DavidData2014results/RS141/0007/RS141_x5_0007_segm-blueNisslRegular_neighbors.npy"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "loaded /home/yuncong/project/DavidData2014results/RS141/0007/RS141_x5_0007_segm-blueNisslRegular_spProps.npy\n",
        "loaded /home/yuncong/project/DavidData2014results/RS141/0007/RS141_x5_0007_segm-blueNisslRegular_segmentationWithText.jpg"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "try:\n",
      "    sp_sp_dists = dm.load_pipeline_result('texHistPairwiseDist', 'npy')\n",
      "    raise\n",
      "except:\n",
      "    def f(a):\n",
      "        sp_dists = cdist(a, texton_hists, metric=chi2)\n",
      "#         sp_dists = cdist(a, texton_hists, metric=js)\n",
      "        return sp_dists\n",
      "\n",
      "    sp_dists = Parallel(n_jobs=16)(delayed(f)(s) for s in np.array_split(texton_hists, 16))\n",
      "    sp_sp_dists = np.vstack(sp_dists)\n",
      "    \n",
      "    dm.save_pipeline_result(sp_sp_dists, 'texHistPairwiseDist', 'npy')\n",
      "\n",
      "center_dists = pdist(sp_properties[:, :2])\n",
      "center_dist_matrix = squareform(center_dists)\n",
      "\n",
      "# neighbor_dists = np.empty((n_superpixels, k))\n",
      "# for i in range(n_superpixels):\n",
      "# #     neighbor_dists[i] = np.squeeze(cdist(texton_hists[i][np.newaxis,:], texton_hists[k_neighbors[i]], chi2))\n",
      "#     neighbor_dists[i] = np.squeeze(cdist(texton_hists[i][np.newaxis,:], texton_hists[k_neighbors[i]], js))\n",
      "\n",
      "neighbors_dict = dict(zip(np.arange(n_superpixels), [list(i) for i in neighbors]))\n",
      "neighbor_graph = from_dict_of_lists(neighbors_dict)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "loaded /home/yuncong/project/DavidData2014results/RS141/0007/RS141_x5_0007_gabor-blueNisslWide-segm-blueNisslRegular-vq-blueNissl_texHistPairwiseDist.npy\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "saved /home/yuncong/project/DavidData2014results/RS141/0007/RS141_x5_0007_gabor-blueNisslWide-segm-blueNisslRegular-vq-blueNissl_texHistPairwiseDist.npy\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import heapq\n",
      "\n",
      "def grow_cluster3(seed, neighbors=neighbors, texton_hists=texton_hists, output=False, display_it=False):\n",
      "    \n",
      "    added_sp = []\n",
      "        \n",
      "    visited = set([])\n",
      "    curr_cluster = set([])\n",
      "                    \n",
      "    to_visit = [(0, seed)]\n",
      "        \n",
      "    c = 0\n",
      "        \n",
      "    while len(to_visit) > 0:\n",
      "\n",
      "#         if output:\n",
      "#             print 'iter', c        \n",
      "#             print 'to_visit', sorted(to_visit, key=lambda x:x[0])\n",
      "        \n",
      "        d, v = heapq.heappop(to_visit)\n",
      "        \n",
      "        if v in curr_cluster:\n",
      "            continue\n",
      "        \n",
      "        c += 1\n",
      "\n",
      "#         if output:\n",
      "#             print 'add', v       \n",
      "#             print \n",
      "        \n",
      "        curr_cluster.add(v)\n",
      "        \n",
      "        curr_avg = texton_hists[list(curr_cluster)].mean(axis=0)\n",
      "                    \n",
      "        if len(curr_cluster) > 1:\n",
      "#             dd = np.squeeze(cdist([curr_avg], texton_hists[list(curr_cluster)], js))\n",
      "            dd = np.squeeze(cdist([curr_avg], texton_hists[list(curr_cluster)], chi2))\n",
      "#             print c, np.max(dd)*10000, np.mean(dd)*10000\n",
      "#             print c, dd\n",
      "            dmean = np.mean(dd)*10000\n",
      "            dmax = np.max(dd)*10000\n",
      "        else:\n",
      "            dmean = 999\n",
      "            dmax = 999\n",
      "\n",
      "        compactness = len(find_boundaries([curr_cluster], \n",
      "                    neighbors=neighbors, \n",
      "                    mode='surrounds')[0])**2/float(len(curr_cluster))\n",
      "            \n",
      "        added_sp.append((d,dmean,dmax,compactness,v))\n",
      "\n",
      "        q = set([s for d,s in to_visit]) | (neighbors[v] - set([-1])) | (visited - curr_cluster)\n",
      "        to_visit_sps = list(q - curr_cluster)\n",
      "        assert len(to_visit_sps) == len(set(to_visit_sps)) and -1 not in to_visit_sps\n",
      "                \n",
      "        curr_cluster_list = list(curr_cluster)\n",
      "\n",
      "#         to_visit_dists = np.atleast_1d(np.squeeze(cdist([curr_avg], texton_hists[to_visit_sps], js)))\n",
      "        to_visit_dists = np.atleast_1d(np.squeeze(cdist([curr_avg], texton_hists[to_visit_sps], chi2)))\n",
      "\n",
      "        to_visit = zip((to_visit_dists*10000).astype(np.int), to_visit_sps)\n",
      "        heapq.heapify(to_visit)\n",
      "        \n",
      "        visited.add(v)\n",
      "                \n",
      "        if len(visited) > int(n_superpixels * 0.03):\n",
      "            break\n",
      "    \n",
      "    gaps, dmeans, dmaxs, compactnesses, added_sps = zip(*added_sp)\n",
      "    compactnesses = np.array(compactnesses)\n",
      "    gaps = np.array(gaps)\n",
      "        \n",
      "    min_size = 2\n",
      "    \n",
      "#     from collections import Counter \n",
      "#     from scipy.ndimage import maximum_filter1d\n",
      "        \n",
      "#     mf = maximum_filter1d(gaps[min_size:], 10)\n",
      "#     counter = Counter(mf)\n",
      "#     peaks = [k for k, v in counter.iteritems() if v > 5]\n",
      "\n",
      "#     peak_locs = np.array([where(gaps[min_size:]==p)[0][0]+min_size for p in peaks])\n",
      "#     peak_locs = peak_locs[peak_locs!=min_size]\n",
      "#     int_gaps_at_peaks = [dmaxs[l] for l in peak_locs]\n",
      "#     peak_locs_sorted = peak_locs[np.argsort(int_gaps_at_peaks)]\n",
      "#     cutoff = peak_locs_sorted[0]\n",
      "    \n",
      "    scores = gaps + dmeans - np.maximum(compactnesses-50,0)**2\n",
      "    \n",
      "#     gaps2 = gaps.copy()\n",
      "#     gaps2[compactnesses > 50] = 0\n",
      "    \n",
      "#     cutoff = np.argmax(gaps2[min_size:]) + min_size\n",
      "\n",
      "    cutoff = np.argmax(scores[min_size:]) + min_size\n",
      "        \n",
      "    if output:\n",
      "        \n",
      "        fig, axes = plt.subplots(4,1)\n",
      "\n",
      "        axes[0].plot(gaps)\n",
      "        axes[0].set_title('contrast')\n",
      "#         a = np.r_[0, np.diff(gaps)]\n",
      "#         a[a < 0] = 0\n",
      "#         plt.plot(a)\n",
      "#         plt.plot(dmaxs, 'r')\n",
      "#         plt.plot(dmeans, 'g')\n",
      "        axes[1].plot(dmeans)\n",
      "        axes[1].set_title('incoherence')\n",
      "        axes[2].plot(compactnesses, 'r')\n",
      "        axes[2].set_title('compactness')\n",
      "        axes[3].plot(scores, 'r')\n",
      "        axes[3].set_title('scores')\n",
      "        \n",
      "        plt.tight_layout()\n",
      "        plt.show()\n",
      "#         plt.plot(mf);\n",
      "        \n",
      "#         print 'peak_locs_sorted', peak_locs_sorted\n",
      "        \n",
      "        print 'cutoff', cutoff\n",
      "#         plt.figure(figsize=(10,10))\n",
      "        \n",
      "        if display_it:\n",
      "            vis = visualize_cluster(added_sps, segmentation=segmentation, segmentation_vis=segmentation_vis, text=True)\n",
      "            vi = display(vis)\n",
      "#         plt.imshow(vis)\n",
      "#         plt.axis('off')\n",
      "#         plt.show()\n",
      "\n",
      "    final_cluster = added_sps[:cutoff]\n",
      "#     final_score = gaps[cutoff]\n",
      "    final_score = scores[cutoff]\n",
      "    \n",
      "#     mean_score = np.mean(gaps[min_size:cutoff])\n",
      "\n",
      "#     return list(final_cluster), final_score, mean_score, gaps, internal_gaps, added_sps\n",
      "#     return list(final_cluster), final_score\n",
      "    if output:\n",
      "        if display_it:\n",
      "            return list(final_cluster), final_score, added_sps, vi\n",
      "        else:\n",
      "            return list(final_cluster), final_score, added_sps\n",
      "    else:\n",
      "        return list(final_cluster), final_score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import networkx\n",
      "\n",
      "def find_boundaries(clusters, neighbors, mode=None):\n",
      "            \n",
      "    border_sps = []\n",
      "    \n",
      "    for j, cluster in enumerate(clusters):\n",
      "        surrounds = set([i for i in set.union(*[neighbors[c] for c in cluster]) if i not in cluster and i != -1])\n",
      "        surrounds = set([i for i in surrounds if any([(n not in cluster) and (n not in surrounds) for n in neighbors[i]])])\n",
      "        if len(surrounds) == 0:\n",
      "            continue\n",
      "\n",
      "        if mode=='frontiers':\n",
      "            frontiers = set.union(*[neighbors[c] for c in surrounds]) & set(cluster)\n",
      "            border = frontiers\n",
      "        elif mode=='surrounds':\n",
      "            border = surrounds\n",
      "        elif mode=='both':\n",
      "            border = surrounds | frontiers\n",
      "         \n",
      "        boundary_subgraph = neighbor_graph.subgraph(border)\n",
      "        boundary_traversal = list(networkx.dfs_postorder_nodes(boundary_subgraph))\n",
      "        \n",
      "        border_sps.append(boundary_traversal)\n",
      "            \n",
      "    return border_sps"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "display(visualize_cluster(added_sps, segmentation=segmentation, segmentation_vis=segmentation_vis, text=True))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<a href='tmp.jpg' target='_blank'>tmp.jpg</a><br>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 248,
       "text": [
        "/oasis/projects/nsf/csd181/yuncong/Brain/notebooks/tmp.jpg"
       ]
      }
     ],
     "prompt_number": 248
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "try:\n",
      "    expansion_clusters_tuples = dm.load_pipeline_result('clusters', 'pkl')\n",
      "    raise\n",
      "except Exception as e:\n",
      "\n",
      "    import time\n",
      "    b = time.time()\n",
      "\n",
      "    expansion_clusters_tuples = Parallel(n_jobs=16)(delayed(grow_cluster3)(s) for s in range(n_superpixels))\n",
      "\n",
      "    print time.time() - b\n",
      "\n",
      "    dm.save_pipeline_result(expansion_clusters_tuples, 'clusters', 'pkl')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "loaded /home/yuncong/project/DavidData2014results/RS141/0006/RS141_x5_0006_gabor-blueNisslWide-segm-blueNisslRegular-vq-blueNissl_clusters.pkl\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "112.98576498\n",
        "saved /home/yuncong/project/DavidData2014results/RS141/0006/RS141_x5_0006_gabor-blueNisslWide-segm-blueNisslRegular-vq-blueNissl_clusters.pkl"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "expansion_clusters_tuples = dm.load_pipeline_result('clusters', 'pkl')\n",
      "expansion_clusters, expansion_cluster_scores = zip(*expansion_clusters_tuples)\n",
      "expansion_cluster_scores = np.array(expansion_cluster_scores)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "loaded /home/yuncong/project/DavidData2014results/RS141/0007/RS141_x5_0007_gabor-blueNisslWide-segm-blueNisslRegular-vq-blueNissl_clusters.pkl\n"
       ]
      }
     ],
     "prompt_number": 113
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Region Clustering Experiments"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def compute_overlap(c1, c2):\n",
      "#     return float(len(c1 & c2))/min(len(c1),len(c2))\n",
      "    return float(len(c1 & c2))/len(c1 | c2)\n",
      "\n",
      "def compute_overlap_partial(indices, sets):\n",
      "    n_sets = len(sets)\n",
      "    \n",
      "    overlap_matrix = np.zeros((len(indices), n_sets))\n",
      "        \n",
      "    for ii, i in enumerate(indices):\n",
      "        for j in range(n_sets):\n",
      "            c1 = set(sets[i])\n",
      "            c2 = set(sets[j])\n",
      "            overlap_matrix[ii, j] = compute_overlap(c1, c2)\n",
      "            \n",
      "    return overlap_matrix\n",
      "\n",
      "def set_pairwise_distances(sets):\n",
      "\n",
      "    partial_overlap_mat = Parallel(n_jobs=16, max_nbytes=1e6)(delayed(compute_overlap_partial)(s, sets) \n",
      "                                        for s in np.array_split(range(len(sets)), 16))\n",
      "    overlap_matrix = np.vstack(partial_overlap_mat)\n",
      "    distance_matrix = 1 - overlap_matrix\n",
      "    \n",
      "    return distance_matrix"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "try:\n",
      "    D = dm.load_pipeline_result('clusterPairwiseDist', 'npy')\n",
      "    raise\n",
      "except:\n",
      "    D = set_pairwise_distances(expansion_clusters)\n",
      "    dm.save_pipeline_result(D, 'clusterPairwiseDist', 'npy')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "loaded /home/yuncong/project/DavidData2014results/RS141/0007/RS141_x5_0007_gabor-blueNisslWide-segm-blueNisslRegular-vq-blueNissl_clusterPairwiseDist.npy\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "saved /home/yuncong/project/DavidData2014results/RS141/0007/RS141_x5_0007_gabor-blueNisslWide-segm-blueNisslRegular-vq-blueNissl_clusterPairwiseDist.npy\n"
       ]
      }
     ],
     "prompt_number": 114
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.spatial.distance import pdist, squareform\n",
      "from scipy.cluster.hierarchy import average, fcluster, leaders, complete, single, dendrogram\n",
      "\n",
      "def group_clusters(clusters=None, dist_thresh = 0.01, distance_matrix=None):\n",
      "\n",
      "    if distance_matrix is None:\n",
      "        assert clusters is not None\n",
      "        distance_matrix = set_pairwise_distances(clusters)\n",
      "\n",
      "    lk = complete(squareform(distance_matrix))\n",
      "#     lk = average(squareform(distance_matrix))\n",
      "#     lk = single(squareform(distance_matrix))\n",
      "\n",
      "    # T = fcluster(lk, 1.15, criterion='inconsistent')\n",
      "    T = fcluster(lk, dist_thresh, criterion='distance')\n",
      "\n",
      "    n_groups = len(set(T))    \n",
      "    groups = [None] * n_groups\n",
      "\n",
      "    for group_id in range(n_groups):\n",
      "        groups[group_id] = where(T == group_id)[0]\n",
      "        \n",
      "    return [g for g in groups if len(g) > 0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 83
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import time\n",
      "t = time.time()\n",
      "expansion_cluster_groups = group_clusters(expansion_clusters, dist_thresh=.5, distance_matrix=D)\n",
      "print len(expansion_cluster_groups), 'expansion cluster groups'\n",
      "print time.time() - t\n",
      "\n",
      "expansion_cluster_group_sizes = np.array(map(len, expansion_cluster_groups))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "382 expansion cluster groups\n",
        "32.893419981\n"
       ]
      }
     ],
     "prompt_number": 115
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "big_group_indices = np.where(expansion_cluster_group_sizes > 5)[0]\n",
      "n_big_groups = len(big_group_indices)\n",
      "print n_big_groups, 'big cluster groups'\n",
      "big_groups = [expansion_cluster_groups[i] for i in big_group_indices]\n",
      "\n",
      "# representative_cluster_indices = [g[np.argmax(expansion_cluster_scores[g])] for g in big_groups]\n",
      "# representative_cluster_scores = [expansion_cluster_scores[ind] for ind in representative_cluster_indices]\n",
      "\n",
      "# representative_cluster_scores_sorted, representative_cluster_indices_sorted_by_score, big_groups_sorted_by_score = map(list, \n",
      "#                                                                 zip(*sorted(zip(representative_cluster_scores, \n",
      "#                                                                     representative_cluster_indices,\n",
      "#                                                                     big_groups), reverse=True)))\n",
      "\n",
      "# representative_clusters_sorted_by_score = [expansion_clusters[i] for i in representative_cluster_indices_sorted_by_score]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "132 big cluster groups\n"
       ]
      }
     ],
     "prompt_number": 117
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import Counter\n",
      "\n",
      "representative_clusters = []\n",
      "representative_cluster_scores = []\n",
      "representative_cluster_indices = []\n",
      "\n",
      "big_groups_valid = []\n",
      "\n",
      "for g in big_groups:\n",
      "#     counter = Counter([frozenset(expansion_clusters[s]) for s in g])\n",
      "#     representative_cluster = counter.keys()[np.argmax(counter.values())]\n",
      "#     representative_clusters.append(representative_cluster)\n",
      "        \n",
      "#     cluster_indices_sorted_by_score = g[np.argsort(expansion_cluster_scores[g])[-1]]\n",
      "    for i in np.argsort(expansion_cluster_scores[g])[::-1]:\n",
      "        c = expansion_clusters[g[i]]\n",
      "        sc = expansion_cluster_scores[g[i]]\n",
      "        if len(c) > n_superpixels * .004:\n",
      "            representative_clusters.append(c)\n",
      "            representative_cluster_indices.append(g[i])\n",
      "            representative_cluster_scores.append(sc)\n",
      "            big_groups_valid.append(g)\n",
      "            break\n",
      "            \n",
      "#     score_counter = Counter(expansion_cluster_scores[g])\n",
      "#     representative_cluster_score = score_counter.keys()[np.argmax(score_counter.values())]\n",
      "#     representative_cluster_scores.append(representative_cluster_score)\n",
      "    \n",
      "# Note that representative_clusters and big_groups have different number of elements\n",
      "    \n",
      "print len(representative_clusters), 'representative clusters'\n",
      "    \n",
      "representative_cluster_scores_sorted, representative_clusters_sorted_by_score, \\\n",
      "representative_cluster_indices_sorted_by_score, \\\n",
      "big_groups_sorted_by_score = map(list, zip(*sorted(zip(representative_cluster_scores, \n",
      "                                                        representative_clusters,\n",
      "                                                        representative_cluster_indices,\n",
      "                                                        big_groups_valid), reverse=True)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "102 representative clusters\n"
       ]
      }
     ],
     "prompt_number": 118
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "representative_cluster_scores_sorted[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 121,
       "text": [
        "10392"
       ]
      }
     ],
     "prompt_number": 121
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "representative_cluster_scores_sorted[43]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 120,
       "text": [
        "2682"
       ]
      }
     ],
     "prompt_number": 120
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i, g in enumerate(big_groups_sorted_by_score):\n",
      "    if 3458 in g:\n",
      "        print i\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "43\n"
       ]
      }
     ],
     "prompt_number": 119
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for seed in set(big_groups_sorted_by_score[34]):\n",
      "    plt.imshow(visualize_cluster(expansion_clusters[seed], segmentation=segmentation, segmentation_vis=segmentation_vis))\n",
      "    plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "display(visualize_cluster(representative_clusters_sorted_by_score[34], \n",
      "                          segmentation=segmentation, \n",
      "                          segmentation_vis=segmentation_vis))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<a href='tmp.jpg' target='_blank'>tmp.jpg</a><br>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 125,
       "text": [
        "/oasis/projects/nsf/csd181/yuncong/Brain/notebooks/tmp.jpg"
       ]
      }
     ],
     "prompt_number": 125
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i, (c, s) in enumerate(zip(representative_clusters_sorted_by_score, \n",
      "                               representative_cluster_scores_sorted)[:30]):\n",
      "    vis = visualize_cluster(c, segmentation=segmentation, segmentation_vis=segmentation_vis)\n",
      "#     imsave('/tmp/repcl%d_score%d.jpg'%(i,s), vis)\n",
      "    \n",
      "    fig = plt.figure(figsize=(10,10))\n",
      "    plt.imshow(vis)\n",
      "    plt.title('sorted group ' + str(i) + ', score ' + str(s))\n",
      "    plt.axis('off')\n",
      "    plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "final_clusters_sorted_by_score = representative_clusters_sorted_by_score[:40]\n",
      "final_cluster_scores_sorted = representative_cluster_scores_sorted[:40]\n",
      "final_cluster_indices_sorted_by_score = representative_cluster_indices_sorted_by_score[:40]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 122
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "final_clusters_sorted_by_score = []\n",
      "final_cluster_scores_sorted = []\n",
      "final_cluster_indices_sorted_by_score = []\n",
      "\n",
      "covered = set([])\n",
      "\n",
      "for c, s, i in zip(representative_clusters_sorted_by_score, \n",
      "                   representative_cluster_scores_sorted, \n",
      "                   representative_cluster_indices_sorted_by_score)[:40]:\n",
      "        \n",
      "    if len(covered & set(c)) > 15:\n",
      "        print i, 'overlaps %d superpixels with previously selected regions' % len(covered & set(c))\n",
      "        continue\n",
      "\n",
      "    covered |= set(c)\n",
      "    final_clusters_sorted_by_score.append(c)\n",
      "    final_cluster_scores_sorted.append(s)\n",
      "    final_cluster_indices_sorted_by_score.append(i)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2777 overlaps with previously selected regions 19\n",
        "1211 overlaps with previously selected regions 40\n",
        "918 overlaps with previously selected regions 28\n",
        "919 overlaps with previously selected regions 19\n",
        "100 overlaps with previously selected regions 55\n",
        "273 overlaps with previously selected regions 31\n",
        "650 overlaps with previously selected regions 23\n",
        "2401 overlaps with previously selected regions 61\n",
        "1166 overlaps with previously selected regions 31\n",
        "1804 overlaps with previously selected regions 24\n",
        "2087 overlaps with previously selected regions 59\n",
        "1611 overlaps with previously selected regions 53\n",
        "3347 overlaps with previously selected regions 19\n",
        "2528 overlaps with previously selected regions 25\n"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vis = visualize_multiple_clusters(final_clusters_sorted_by_score[:10], segmentation=segmentation, segmentation_vis=segmentation_vis)\n",
      "dm.save_pipeline_result( vis, 'regionsTop10' , 'jpg')\n",
      "\n",
      "vis = visualize_multiple_clusters(final_clusters_sorted_by_score[10:20], segmentation=segmentation, segmentation_vis=segmentation_vis)\n",
      "dm.save_pipeline_result( vis, 'regionsTop10to20' , 'jpg')\n",
      "\n",
      "vis = visualize_multiple_clusters(final_clusters_sorted_by_score[20:30], segmentation=segmentation, segmentation_vis=segmentation_vis)\n",
      "dm.save_pipeline_result( vis, 'regionsTop20to30' , 'jpg')\n",
      "\n",
      "vis = visualize_multiple_clusters(final_clusters_sorted_by_score[30:], segmentation=segmentation, segmentation_vis=segmentation_vis)\n",
      "dm.save_pipeline_result( vis, 'regionsTop30to40' , 'jpg')\n",
      "\n",
      "#     fig = plt.figure(figsize=(10,10))\n",
      "#     plt.imshow(vis)\n",
      "#     plt.title('sorted group ' + str(i) + ', score ' + str(s))\n",
      "#     plt.axis('off')\n",
      "#     plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "saved /home/yuncong/project/DavidData2014results/RS141/0007/RS141_x5_0007_gabor-blueNisslWide-segm-blueNisslRegular-vq-blueNissl_regionsTop10.jpg\n",
        "saved /home/yuncong/project/DavidData2014results/RS141/0007/RS141_x5_0007_gabor-blueNisslWide-segm-blueNisslRegular-vq-blueNissl_regionsTop10to20.jpg"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "saved /home/yuncong/project/DavidData2014results/RS141/0007/RS141_x5_0007_gabor-blueNisslWide-segm-blueNisslRegular-vq-blueNissl_regionsTop20to30.jpg"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "saved /home/yuncong/project/DavidData2014results/RS141/0007/RS141_x5_0007_gabor-blueNisslWide-segm-blueNisslRegular-vq-blueNissl_regionsTop30to40.jpg"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 106
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def SaveFigureAsImage(fileName,fig=None,orig_size=None):\n",
      "\n",
      "    dpi = fig.get_dpi()\n",
      "    w,h = orig_size\n",
      "    fig.set_size_inches([float(w/dpi), float(h/dpi)])\n",
      "\n",
      "    a=fig.gca()\n",
      "    a.set_frame_on(False)\n",
      "    a.set_xticks([]); a.set_yticks([])\n",
      "    plt.axis('off')\n",
      "    plt.xlim(0,h); plt.ylim(w,0)\n",
      "    fig.savefig(fileName, transparent=True, bbox_inches='tight', \\\n",
      "                        pad_inches=0)\n",
      "    \n",
      "    \n",
      "def SaveFigureAsImage(fileName,fig=None,**kwargs):\n",
      "    ''' Save a Matplotlib figure as an image without borders or frames.\n",
      "       Args:\n",
      "            fileName (str): String that ends in .png etc.\n",
      "\n",
      "            fig (Matplotlib figure instance): figure you want to save as the image\n",
      "        Keyword Args:\n",
      "            orig_size (tuple): width, height of the original image used to maintain \n",
      "            aspect ratio.\n",
      "    '''\n",
      "    fig_size = fig.get_size_inches()\n",
      "    dpi = fig.get_dpi()\n",
      "    \n",
      "    fig.set_size_inches(dpi)\n",
      "    \n",
      "    w,h = fig_size[0], fig_size[1]\n",
      "    fig.patch.set_alpha(0)\n",
      "    if kwargs.has_key('orig_size'): # Aspect ratio scaling if required\n",
      "        w,h = kwargs['orig_size']\n",
      "        w2,h2 = fig_size[0],fig_size[1]\n",
      "        fig.set_size_inches([(w2/w)*w,(w2/w)*h])\n",
      "        fig.set_dpi((w2/w)*fig.get_dpi())\n",
      "    a=fig.gca()\n",
      "    a.set_frame_on(False)\n",
      "    a.set_xticks([]); a.set_yticks([])\n",
      "    plt.axis('off')\n",
      "    plt.xlim(0,h); plt.ylim(w,0)\n",
      "    fig.savefig(fileName, transparent=True, bbox_inches='tight', \\\n",
      "                        pad_inches=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 97
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from skimage.measure import find_contours\n",
      "import cv2\n",
      "from skimage.util import img_as_float\n",
      "\n",
      "colors = (np.loadtxt('../visualization/100colors.txt') * 255).astype(np.int)\n",
      "\n",
      "def visualize_contours(clusters):\n",
      "\n",
      "    vis = dm.image_rgb.copy()\n",
      "\n",
      "    for ci, c in enumerate(clusters):\n",
      "        q = np.zeros((n_superpixels,))\n",
      "        q[c] = 1.\n",
      "        v = q[segmentation]\n",
      "        contours = find_contours(img_as_float(v), 0.8)\n",
      "        contour = contours[np.argmax(map(len, contours))]\n",
      "        contour = np.round(contour[:,::-1].reshape((-1,1,2))).astype(np.int)\n",
      "        cv2.polylines(vis, [contour], isClosed=True, color=colors[ci%len(colors)], thickness=10) \n",
      "    #     cv2.polylines(vis, [contour], isClosed=True, color=[237,194,136], thickness=5) \n",
      "\n",
      "    #     ax.plot(contour[:,1], contour[:,0])\n",
      "\n",
      "    # fig.savefig('tmp.png', bbox_inches='tight', pad_inches=0)\n",
      "    # fig.savefig('tmp.png', pad_inches=0)\n",
      "    # SaveFigureAsImage('tmp.png', fig, orig_size=dm.image.shape[:2])\n",
      "    # FileLink('tmp.png')\n",
      "    return vis\n",
      "\n",
      "\n",
      "# dm.save_pipeline_result(representative_clusters_sorted_by_score, 'goodRegions', 'pkl')\n",
      "\n",
      "vis = visualize_contours(final_clusters_sorted_by_score[:10])\n",
      "dm.save_pipeline_result(np.uint8(vis), 'contoursTop10', 'jpg')\n",
      "\n",
      "vis = visualize_contours(final_clusters_sorted_by_score[10:20])\n",
      "dm.save_pipeline_result(np.uint8(vis), 'contoursTop10to20', 'jpg')\n",
      "\n",
      "vis = visualize_contours(final_clusters_sorted_by_score[20:30])\n",
      "dm.save_pipeline_result(np.uint8(vis), 'contoursTop20to30', 'jpg')\n",
      "\n",
      "vis = visualize_contours(final_clusters_sorted_by_score[30:])\n",
      "dm.save_pipeline_result(np.uint8(vis), 'contoursTop30to40', 'jpg')\n",
      "\n",
      "vis = visualize_contours(final_clusters_sorted_by_score)\n",
      "dm.save_pipeline_result(np.uint8(vis), 'contoursTopAll', 'jpg')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "saved /home/yuncong/project/DavidData2014results/RS141/0007/RS141_x5_0007_gabor-blueNisslWide-segm-blueNisslRegular-vq-blueNissl_contoursTop10.jpg\n",
        "saved /home/yuncong/project/DavidData2014results/RS141/0007/RS141_x5_0007_gabor-blueNisslWide-segm-blueNisslRegular-vq-blueNissl_contoursTop10to20.jpg"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "saved /home/yuncong/project/DavidData2014results/RS141/0007/RS141_x5_0007_gabor-blueNisslWide-segm-blueNisslRegular-vq-blueNissl_contoursTop20to30.jpg"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "saved /home/yuncong/project/DavidData2014results/RS141/0007/RS141_x5_0007_gabor-blueNisslWide-segm-blueNisslRegular-vq-blueNissl_contoursTop30to40.jpg"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "saved /home/yuncong/project/DavidData2014results/RS141/0007/RS141_x5_0007_gabor-blueNisslWide-segm-blueNisslRegular-vq-blueNissl_contoursTopAll.jpg"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 123
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "good_regions = zip(representative_cluster_scores_sorted, representative_clusters_sorted_by_score, \n",
      "                   representative_cluster_indices_sorted_by_score, \n",
      "                   big_groups_sorted_by_score)\n",
      "\n",
      "dm.save_pipeline_result(good_regions, 'goodRegions', 'pkl')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "saved /home/yuncong/project/DavidData2014results/RS141/0006/RS141_x5_0006_gabor-blueNisslWide-segm-blueNisslRegular-vq-blueNissl_goodRegions.pkl\n"
       ]
      }
     ],
     "prompt_number": 156
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "display(visualize_contours(representative_clusters_sorted_by_score[10:20]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<a href='tmp.jpg' target='_blank'>tmp.jpg</a><br>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 145,
       "text": [
        "/oasis/projects/nsf/csd181/yuncong/Brain/notebooks/tmp.jpg"
       ]
      }
     ],
     "prompt_number": 145
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Pairwise overlaps within each cluster group"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "group_ind = 11\n",
      "\n",
      "n = len(big_groups_sorted_by_score[group_ind])\n",
      "Q = np.zeros((n, n))\n",
      "for i, ci in enumerate(big_groups_sorted_by_score[group_ind]):\n",
      "    for j, cj in enumerate(big_groups_sorted_by_score[group_ind]):\n",
      "#         print i, j, ci, cj\n",
      "        Q[i,j] = compute_overlap(set(expansion_clusters[ci]), set(expansion_clusters[cj]))\n",
      "\n",
      "plt.matshow(Q, vmin=0, vmax=1.);\n",
      "plt.colorbar();"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Pairwise overlaps between two cluster groups"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "group_ind1 = 3\n",
      "group_ind2 = 14\n",
      "\n",
      "n1 = len(big_groups_sorted_by_score[group_ind1])\n",
      "n2 = len(big_groups_sorted_by_score[group_ind2])\n",
      "Q = np.zeros((n1, n2))\n",
      "for i, ci in enumerate(big_groups_sorted_by_score[group_ind1]):\n",
      "    for j, cj in enumerate(big_groups_sorted_by_score[group_ind2]):\n",
      "        Q[i,j] = compute_overlap(set(expansion_clusters[ci]), set(expansion_clusters[cj]))\n",
      "\n",
      "plt.matshow(Q, vmin=0, vmax=1.);\n",
      "plt.colorbar();\n",
      "print Q.max()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Max pairwise overlaps between any groups. If hierarchical clusternig uses single linkage, then printed values should all be smaller than _dist_thresh_ in _group_clusters()_."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for group_ind1, group_ind2 in itertools.product(range(n_big_groups), range(n_big_groups)):\n",
      "\n",
      "#     print group_ind1, group_ind2\n",
      "\n",
      "    if group_ind1 >= group_ind2: continue\n",
      "\n",
      "    n1 = len(big_groups_sorted_by_score[group_ind1])\n",
      "    n2 = len(big_groups_sorted_by_score[group_ind2])\n",
      "    Q = np.zeros((n1, n2))\n",
      "    for i, ci in enumerate(big_groups_sorted_by_score[group_ind1]):\n",
      "        for j, cj in enumerate(big_groups_sorted_by_score[group_ind2]):\n",
      "            Q[i,j] = compute_overlap(set(expansion_clusters[ci]), set(expansion_clusters[cj]))\n",
      "\n",
      "#     plt.matshow(Q, vmin=0, vmax=1.);\n",
      "#     plt.colorbar();\n",
      "#     print Q.max()\n",
      "    if Q.max() > .5:\n",
      "        print group_ind1, group_ind2, Q.max()\n",
      "        \n",
      "# ASSERT THESE VALUES ARE ALL SMALLER THAN THRESH DISTANCE OF HIERARCHICAL CLUSTERING !!!"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Old"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sp_votes = np.zeros((n_superpixels,))\n",
      "surrounds_sps = []\n",
      "for j, cluster in enumerate(cluster_sps):\n",
      "    surrounds = set([i for i in set.union(*[neighbors[c] for c in cluster]) if i not in cluster and i != -1])        \n",
      "    frontiers = set.union(*[neighbors[c] for c in surrounds]) & set(cluster)\n",
      "    surrounds_sps.append(surrounds | frontiers)\n",
      "#     print cluster, surrounds, frontiers\n",
      "#     weight = 1./len(cluster)\n",
      "    weight = 1\n",
      "    for sp in surrounds:\n",
      "        sp_votes[sp] += weight"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.hist(sp_votes);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from itertools import chain\n",
      "sp_votes = np.bincount(list(chain(*surrounds_sps)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
      "\n",
      "votemap = sp_votes[segmentation]\n",
      "\n",
      "plt.figure(figsize=(20,8))\n",
      "\n",
      "plt.subplot(121)\n",
      "plt.imshow(dm.image, aspect='equal', cmap=plt.cm.gray)\n",
      "plt.axis('off')\n",
      "\n",
      "ax = plt.subplot(122)\n",
      "\n",
      "plt.axis('off')\n",
      "votemap_im = ax.imshow(votemap, aspect='equal')\n",
      "divider = make_axes_locatable(ax)\n",
      "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
      "plt.colorbar(votemap_im, cax=cax);\n",
      "\n",
      "plt.tight_layout()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "highvote_sps = np.where(sp_votes>20)[0]\n",
      "print len(highvote_sps)\n",
      "\n",
      "vis = visualize_cluster(highvote_sps)\n",
      "display(vis)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "highlighted_sps = np.where((cluster_size_sps < 200) & (cluster_size_sps > 4))[0]\n",
      "n_highlights = len(highlighted_sps)\n",
      "print n_highlights\n",
      "highlighted_clusters = [cluster_sps[s] for s in highlighted_sps]\n",
      "highlighted_scores = [cluster_score_sps[s] for s in highlighted_sps]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.spatial.distance import pdist, squareform\n",
      "from scipy.cluster.hierarchy import average, fcluster, leaders, complete, single, dendrogram\n",
      "\n",
      "def group_clusters(clusters, dist_thresh = 0.1):\n",
      "\n",
      "    n_clusters = len(clusters)\n",
      "    \n",
      "    overlap_matrix = np.zeros((n_clusters, n_clusters))\n",
      "    \n",
      "    for i in range(n_clusters):\n",
      "        for j in range(n_clusters):\n",
      "            if i == j:\n",
      "                overlap_matrix[i, j] = 1\n",
      "            else:\n",
      "                c1 = set(clusters[i])\n",
      "                c2 = set(clusters[j])\n",
      "                overlap_matrix[i, j] = float(len(c1 & c2))/min(len(c1),len(c2))\n",
      "\n",
      "    distance_matrix = 1 - overlap_matrix\n",
      "    \n",
      "#     lk = average(squareform(distance_matrix))\n",
      "    lk = single(squareform(distance_matrix))\n",
      "\n",
      "    # T = fcluster(lk, 1.15, criterion='inconsistent')\n",
      "    T = fcluster(lk, dist_thresh, criterion='distance')\n",
      "\n",
      "    n_groups = len(set(T))\n",
      "    print n_groups, 'groups'\n",
      "    \n",
      "    groups = [None] * n_groups\n",
      "\n",
      "    for group_id in range(n_groups):\n",
      "        groups[group_id] = where(T == group_id)[0]\n",
      "    \n",
      "        \n",
      "    return groups"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "highlighted_groups = group_clusters(highlighted_clusters)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sp_groups = [ [highlighted_sps[i] for i in group] for group in highlighted_groups if len(group) > 1]\n",
      "union_clusters = [cluster_sps[g[np.argmax(cluster_score_sps[g])]] for g in sp_groups]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "union_cluster_groups = group_clusters(union_clusters, dist_thresh=0.5)\n",
      "union_cluster_groups = [u for u in union_cluster_groups if len(u) > 0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# union_cluster_union_clusters = [set.union(*[set(union_clusters[i]) for i in g]) for g in union_cluster_groups]\n",
      "# union_cluster_union_clusters = [set.intersection(*[set(union_clusters[i]) for i in g]) for g in union_cluster_groups]\n",
      "union_cluster_union_clusters = [union_clusters[g[np.argmax([compute_cluster_score(union_clusters[i])[0] for i in g])]] \n",
      "                                for g in union_cluster_groups]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filtered_group_scores = np.array([compute_cluster_score(g)[0] for g in union_clusters])\n",
      "# filtered_group_scores = np.array([compute_cluster_score(g)[0] for g in union_cluter_union_clusters])\n",
      "# filtered_group_scores = [cluster_score_sps[list(g)].max() for g in filtered_groups]\n",
      "\n",
      "arg_score_sorted = np.argsort(filtered_group_scores)[::-1]\n",
      "\n",
      "union_cluster_union_clusters_sorted = [union_clusters[i] for i in arg_score_sorted]\n",
      "\n",
      "print len(union_cluster_union_clusters_sorted)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dm.save_pipeline_result(union_cluster_union_clusters_sorted, 'groups', 'pkl')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# for i, (g, s) in enumerate(zip(union_cluster_union_clusters_sorted, filtered_group_scores[arg_score_sorted])):\n",
      "#     print i, g, s"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def display(vis, filename='tmp.jpg'):\n",
      "    \n",
      "    if vis.dtype != np.uint8:\n",
      "        imsave(filename, img_as_ubyte(vis))\n",
      "    else:\n",
      "        imsave(filename, vis)\n",
      "            \n",
      "    from IPython.display import FileLink\n",
      "    return FileLink(filename)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vis = visualize_multiple_clusters(union_cluster_union_clusters_sorted[:10])\n",
      "display(vis)\n",
      "# dm.save_pipeline_result(vis, 'groupsTop10Vis', 'jpg', is_rgb=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vis = visualize_multiple_clusters(union_cluster_union_clusters_sorted[10:20])\n",
      "display(vis)\n",
      "# dm.save_pipeline_result(vis, 'groupsTop10to20Vis', 'jpg', is_rgb=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vis = visualize_multiple_clusters(union_cluster_union_clusters_sorted[20:30])\n",
      "display(vis)\n",
      "# dm.save_pipeline_result(vis, 'groupsTop20to30Vis', 'jpg', is_rgb=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}