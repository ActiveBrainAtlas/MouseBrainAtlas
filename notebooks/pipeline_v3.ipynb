{
 "metadata": {
  "name": "",
  "signature": "sha256:d763ccc1bf51b3983c04e783df3a76e2d64507cee13c5a4a60e80a293197aab7"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import cv2\n",
      "\n",
      "import matplotlib\n",
      "# Force matplotlib to not use any Xwindows backend.\n",
      "matplotlib.use('Agg')\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "import random, itertools, sys, os\n",
      "from multiprocessing import Pool\n",
      "import json\n",
      "\n",
      "from skimage.segmentation import slic, mark_boundaries\n",
      "from skimage.measure import regionprops\n",
      "from skimage.util import img_as_ubyte\n",
      "from skimage.color import hsv2rgb, label2rgb, gray2rgb\n",
      "from skimage.morphology import disk\n",
      "from skimage.filter.rank import gradient\n",
      "from skimage.filter import gabor_kernel\n",
      "from skimage.transform import rescale, resize\n",
      "\n",
      "from scipy.ndimage import gaussian_filter, measurements\n",
      "from scipy.sparse import coo_matrix\n",
      "from scipy.spatial.distance import pdist, squareform, euclidean, cdist\n",
      "from scipy.signal import fftconvolve\n",
      "\n",
      "from IPython.display import FileLink, Image, FileLinks\n",
      "\n",
      "import utilities\n",
      "from utilities import chi2\n",
      "\n",
      "import glob, re, os, sys, subprocess, argparse\n",
      "import pprint"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# parse arguments\n",
      "parser = argparse.ArgumentParser(\n",
      "formatter_class=argparse.RawDescriptionHelpFormatter,\n",
      "description='Execute feature extraction pipeline',\n",
      "epilog=\"\"\"\n",
      "The following command processes image PMD1305_region0_reduce2_0244.tif using the parameter id nissl324.\n",
      "python %s ../ParthaData/PMD1305_region0_reduce2/PMD1305_region0_reduce2_0244.tif nissl324\n",
      "\n",
      "This script loads the parameters in params_dir. \n",
      "Results are stored in a sub-directory named <result name>_param_<parameter id>, under output_dir.\n",
      "Details are in the GitHub README (https://github.com/mistycheney/BrainSaliencyDetection/blob/master/README.md)\n",
      "\"\"\"%(os.path.basename(sys.argv[0]), ))\n",
      "\n",
      "parser.add_argument(\"img_file\", type=str, help=\"path to image file\")\n",
      "parser.add_argument(\"param_id\", type=str, help=\"parameter identification name\")\n",
      "parser.add_argument(\"-o\", \"--output_dir\", type=str, help=\"output directory (default: %(default)s)\", default='/oasis/scratch/csd181/yuncong/output')\n",
      "parser.add_argument(\"-p\", \"--params_dir\", type=str, help=\"directory containing csv parameter files %(default)s)\", default='/oasis/projects/nsf/csd181/yuncong/Brain/params')\n",
      "args = parser.parse_args()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load_array(suffix):\n",
      "    return utilities.load_array(suffix, img_name, param['param_id'], args.output_dir)\n",
      "\n",
      "def save_array(arr, suffix):\n",
      "    utilities.save_array(arr, suffix, img_name, param['param_id'], args.output_dir)\n",
      "        \n",
      "def save_img(img, suffix):\n",
      "    utilities.save_img(img, suffix, img_name, param['param_id'], args.output_dir, overwrite=True)\n",
      "\n",
      "def get_img_filename(suffix, ext='png'):\n",
      "    return utilities.get_img_filename(suffix, img_name, param['param_id'], args.output_dir, ext=ext)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# load parameter settings\n",
      "params_dir = os.path.realpath(args.params_dir)\n",
      "param_file = os.path.join(params_dir, 'param_%s.json'%args.param_id)\n",
      "param_default_file = os.path.join(params_dir, 'param_default.json')\n",
      "param = json.load(open(param_file, 'r'))\n",
      "param_default = json.load(open(param_default_file, 'r'))\n",
      "\n",
      "for k, v in param_default.iteritems():\n",
      "    if not isinstance(param[k], basestring):\n",
      "        if np.isnan(param[k]):\n",
      "            param[k] = v\n",
      "\n",
      "pprint.pprint(param)\n",
      "\n",
      "# set image paths\n",
      "img_file = os.path.realpath(args.img_file)\n",
      "img_path, ext = os.path.splitext(img_file)\n",
      "img_dir, img_name = os.path.split(img_path)\n",
      "\n",
      "print img_file\n",
      "img = cv2.imread(img_file, 0)\n",
      "im_height, im_width = img.shape[:2]\n",
      "\n",
      "# set output paths\n",
      "output_dir = os.path.realpath(args.output_dir)\n",
      "\n",
      "result_name = img_name + '_param_' + str(param['param_id'])\n",
      "result_dir = os.path.join(output_dir, result_name)\n",
      "if not os.path.exists(result_dir):\n",
      "    os.makedirs(result_dir)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Find foreground mask\n",
      "\n",
      "print '=== finding foreground mask ==='\n",
      "mask = utilities.foreground_mask(img, min_size=2500)\n",
      "mask = mask > .5\n",
      "# plt.imshow(mask, cmap=plt.cm.Greys_r);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Generate Gabor filter kernels\n",
      "\n",
      "theta_interval = param['theta_interval']\n",
      "n_angle = int(180/theta_interval)\n",
      "freq_step = param['freq_step']\n",
      "freq_max = 1./param['min_wavelen']\n",
      "freq_min = 1./param['max_wavelen']\n",
      "bandwidth = param['bandwidth']\n",
      "n_freq = int(np.log(freq_max/freq_min)/np.log(freq_step)) + 1\n",
      "frequencies = freq_max/freq_step**np.arange(n_freq)\n",
      "\n",
      "kernels = [gabor_kernel(f, theta=t, bandwidth=bandwidth) for f in frequencies \n",
      "          for t in np.arange(0, n_angle)*np.deg2rad(theta_interval)]\n",
      "kernels = map(np.real, kernels)\n",
      "\n",
      "n_kernel = len(kernels)\n",
      "\n",
      "print '=== filter using Gabor filters ==='\n",
      "print 'num. of kernels: %d' % (n_kernel)\n",
      "print 'frequencies:', frequencies\n",
      "print 'wavelength (pixels):', 1/frequencies\n",
      "\n",
      "max_kern_size = np.max([kern.shape[0] for kern in kernels])\n",
      "print 'max kernel matrix size:', max_kern_size"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Process the image using Gabor filters\n",
      "\n",
      "try:\n",
      "#     raise IOError\n",
      "    features = load_array('features')\n",
      "except IOError:\n",
      "    \n",
      "    def convolve_per_proc(i):\n",
      "        return fftconvolve(img, kernels[i], 'same').astype(np.half)\n",
      "    \n",
      "    filtered = Parallel(n_jobs=16)(delayed(convolve_per_proc)(i) \n",
      "                            for i in range(n_kernel))\n",
      "\n",
      "    features = np.empty((im_height, im_width, n_kernel), dtype=np.half)\n",
      "    for i in range(n_kernel):\n",
      "        features[...,i] = filtered[i]\n",
      "\n",
      "    del filtered\n",
      "    \n",
      "    save_array(features, 'features')\n",
      "\n",
      "n_feature = features.shape[-1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Crop image border where filters show border effects\n",
      "\n",
      "features = features[max_kern_size/2:-max_kern_size/2, max_kern_size/2:-max_kern_size/2, :]\n",
      "img = img[max_kern_size/2:-max_kern_size/2, max_kern_size/2:-max_kern_size/2]\n",
      "mask = mask[max_kern_size/2:-max_kern_size/2, max_kern_size/2:-max_kern_size/2]\n",
      "im_height, im_width = img.shape[:2]\n",
      "\n",
      "save_img(img, 'cropImg')\n",
      "\n",
      "save_array(mask, 'mask')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Compute rotation-invariant texton map using K-Means\n",
      "\n",
      "print '=== compute rotation-invariant texton map using K-Means ==='\n",
      "\n",
      "n_texton = int(param['n_texton'])\n",
      "\n",
      "try: \n",
      "#     raise IOError\n",
      "    textonmap = load_array('textonmap')\n",
      "except IOError:\n",
      "    \n",
      "    X = features.reshape(-1, n_feature)\n",
      "    n_data = X.shape[0]\n",
      "    n_splits = 1000\n",
      "    n_sample = int(param['n_sample'])\n",
      "    centroids = np.array(random.sample(X, n_texton))\n",
      "    \n",
      "    n_iter = int(param['n_iter'])\n",
      "\n",
      "    def compute_dist_per_proc(X_partial, c_all_rot):\n",
      "        D = cdist(X_partial, c_all_rot, 'sqeuclidean')\n",
      "        ci, ri = np.unravel_index(D.argmin(axis=1), (n_texton, n_angle))\n",
      "        return np.c_[ci, ri]\n",
      "\n",
      "    for iteration in range(n_iter):\n",
      "        \n",
      "        data = random.sample(X, n_sample)\n",
      "        \n",
      "        print 'iteration', iteration\n",
      "        centroid_all_rotations = np.vstack([np.concatenate(np.roll(np.split(c, n_freq), i)) \n",
      "                                for c,i in itertools.product(centroids, range(n_angle))])\n",
      "\n",
      "        r = Parallel(n_jobs=16)(delayed(compute_dist_per_proc)(x,c) \n",
      "                        for x, c in zip(np.array_split(data, n_splits, axis=0), \n",
      "                                        itertools.repeat(centroid_all_rotations, n_splits)))\n",
      "        res = np.vstack(r)        \n",
      "\n",
      "        labels = res[:,0]\n",
      "        rotations = res[:,1]\n",
      "\n",
      "        centroids_new = np.zeros((n_texton, n_feature))\n",
      "        for d, l, r in itertools.izip(data, labels, rotations):\n",
      "            rot = np.concatenate(np.roll(np.split(d, n_freq), i))\n",
      "            centroids_new[l] += rot\n",
      "\n",
      "        counts = np.bincount(labels, minlength=n_texton)\n",
      "        centroids_new /= counts[:, np.newaxis]\n",
      "        centroids_new[counts==0] = centroids[counts==0]\n",
      "        print np.sqrt(np.sum((centroids - centroids_new)**2, axis=1)).mean()\n",
      "\n",
      "        centroids = centroids_new\n",
      "\n",
      "    print 'kmeans completes'\n",
      "    centroid_all_rotations = np.vstack([np.concatenate(np.roll(np.split(c, n_freq), i)) \n",
      "                                for c,i in itertools.product(centroids, range(n_angle))])\n",
      "\n",
      "    r = Parallel(n_jobs=16)(delayed(compute_dist_per_proc)(x,c) \n",
      "                            for x, c in zip(np.array_split(X, n_splits, axis=0), \n",
      "                                            itertools.repeat(centroid_all_rotations, n_splits)))\n",
      "    res = np.vstack(r)\n",
      "    \n",
      "    labels = res[:,0]\n",
      "    rotations = res[:,1]\n",
      "\n",
      "    textonmap = labels.reshape(features.shape[:2])\n",
      "    textonmap[~mask] = -1\n",
      "    \n",
      "    save_array(textonmap, 'textonmap')\n",
      "    \n",
      "textonmap_rgb = label2rgb(textonmap, image=None, colors=None, alpha=0.3, image_alpha=1)\n",
      "save_img(textonmap_rgb, 'textonmap')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Over-segment the image into superpixels using SLIC (http://ivrg.epfl.ch/research/superpixels)\n",
      "\n",
      "print '=== over-segment the image into superpixels based on color information ==='\n",
      "\n",
      "img_rgb = gray2rgb(img)\n",
      "\n",
      "try:\n",
      "#     raise IOError\n",
      "    segmentation = load_array('segmentation')\n",
      "    \n",
      "except IOError:\n",
      "    segmentation = slic(img_rgb, n_segments=int(param['n_superpixels']), \n",
      "                        max_iter=10, \n",
      "                        compactness=float(param['slic_compactness']), \n",
      "                        sigma=float(param['slic_sigma']), \n",
      "                        enforce_connectivity=True)\n",
      "    print 'segmentation computed'\n",
      "    \n",
      "    save_array(segmentation, 'segmentation')\n",
      "    \n",
      "sp_props = regionprops(segmentation+1, intensity_image=img, cache=True)\n",
      "\n",
      "def obtain_props_worker(i):\n",
      "    return sp_props[i].centroid, sp_props[i].area, sp_props[i].mean_intensity\n",
      "\n",
      "r = Parallel(n_jobs=16)(delayed(obtain_props_worker)(i) for i in range(len(sp_props)))\n",
      "sp_centroids = np.array([s[0] for s in r])\n",
      "sp_areas = np.array([s[1] for s in r])\n",
      "sp_mean_intensity = np.array([s[2] for s in r])\n",
      "\n",
      "n_superpixels = len(np.unique(segmentation))\n",
      "\n",
      "img_superpixelized = mark_boundaries(img_rgb, segmentation)\n",
      "sptext = img_as_ubyte(img_superpixelized)\n",
      "for s in range(n_superpixels):\n",
      "    sptext = cv2.putText(sptext, str(s), \n",
      "                      tuple(np.floor(sp_centroids[s][::-1]).astype(np.int)), \n",
      "                      cv2.FONT_HERSHEY_COMPLEX_SMALL,\n",
      "                      .5, ((255,0,255)), 1)\n",
      "save_img(sptext, 'segmentation')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Determine which superpixels are mostly background\n",
      "\n",
      "def count_fg_worker(i):\n",
      "    return np.count_nonzero(mask[segmentation==i])\n",
      "\n",
      "r = Parallel(n_jobs=16)(delayed(count_fg_worker)(i) for i in range(n_superpixels))\n",
      "superpixels_fg_count = np.array(r)\n",
      "bg_superpixels = np.nonzero((superpixels_fg_count/sp_areas) < 0.3)[0]\n",
      "# bg_superpixels = np.array(list(set(bg_superpixels.tolist()\n",
      "#                           +[0,1,2,3,4,5,6,7,119,78,135,82,89,187,174,242,289]\n",
      "#                           +[50,51,56,57,58,59,60,61,62,63,64,65,115,73,88,109,99,91,122,110,151,192,165,158,254,207,236,306]\n",
      "#                           )))\n",
      "fg_superpixels = np.array([i for i in range(n_superpixels) if i not in bg_superpixels])\n",
      "print '%d background superpixels'%len(bg_superpixels)\n",
      "\n",
      "save_array(fg_superpixels, 'fg')\n",
      "save_array(bg_superpixels, 'bg')\n",
      "\n",
      "# a = np.zeros((n_superpixels,), dtype=np.bool)\n",
      "# a[fg_superpixels] = True\n",
      "# plt.imshow(a[segmentation], cmap=plt.cm.Greys_r)\n",
      "# plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Compute neighbor lists and connectivity matrix\n",
      "\n",
      "from skimage.morphology import disk\n",
      "from skimage.filter.rank import gradient\n",
      "from scipy.sparse import coo_matrix\n",
      "\n",
      "edge_map = gradient(segmentation.astype(np.uint8), disk(3))\n",
      "neighbors = [set() for i in range(n_superpixels)]\n",
      "\n",
      "for y,x in zip(*np.nonzero(edge_map)):\n",
      "    neighbors[segmentation[y,x]] |= set(segmentation[y-2:y+2,x-2:x+2].ravel())\n",
      "\n",
      "for i in range(n_superpixels):\n",
      "    neighbors[i] -= set([i])\n",
      "    \n",
      "rows = np.hstack([s*np.ones((len(neighbors[s]),), dtype=np.int) for s in range(n_superpixels)])\n",
      "cols = np.hstack([list(neighbors[s]) for s in range(n_superpixels)])\n",
      "data = np.ones((cols.size, ), dtype=np.bool)\n",
      "connectivity_matrix = coo_matrix((data, (rows, cols)), shape=(n_superpixels,n_superpixels))\n",
      "connectivity_matrix = connectivity_matrix.transpose() * connectivity_matrix"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# compute texton histogram of every superpixel\n",
      "print '=== compute texton histogram of each superpixel ==='\n",
      "\n",
      "try:\n",
      "#     raise IOError\n",
      "    sp_texton_hist_normalized = load_array('texHist')\n",
      "except IOError:\n",
      "    def texton_histogram_worker(i):\n",
      "        return np.bincount(textonmap[(segmentation == i)&(textonmap != -1)], minlength=n_texton)\n",
      "\n",
      "    r = Parallel(n_jobs=16)(delayed(texton_histogram_worker)(i) for i in range(n_superpixels))\n",
      "    sp_texton_hist = np.array(r)\n",
      "    sp_texton_hist_normalized = sp_texton_hist.astype(np.float) / sp_texton_hist.sum(axis=1)[:, np.newaxis]\n",
      "    save_array(sp_texton_hist_normalized, 'texHist')\n",
      "\n",
      "# compute the null texton histogram\n",
      "overall_texton_hist = np.bincount(textonmap[mask].flat)\n",
      "overall_texton_hist_normalized = overall_texton_hist.astype(np.float) / overall_texton_hist.sum()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# compute directionality histogram of every superpixel\n",
      "print '=== compute directionality histogram of each superpixel ==='\n",
      "\n",
      "try:\n",
      "#     raise IOError\n",
      "    sp_dir_hist_normalized = load_array('dirHist')\n",
      "except IOError:\n",
      "    f = np.reshape(features, (features.shape[0], features.shape[1], n_freq, n_angle))\n",
      "    dir_energy = np.sum(abs(f), axis=2)\n",
      "\n",
      "    def dir_histogram_worker(i):\n",
      "        segment_dir_energies = dir_energy[segmentation == i].astype(np.float_).mean(axis=0)\n",
      "        return segment_dir_energies    \n",
      "\n",
      "    r = Parallel(n_jobs=16)(delayed(dir_histogram_worker)(i) for i in range(n_superpixels))\n",
      "    \n",
      "    sp_dir_hist = np.vstack(r)\n",
      "    sp_dir_hist_normalized = sp_dir_hist/sp_dir_hist.sum(axis=1)[:,np.newaxis]\n",
      "    save_array(sp_dir_hist_normalized, 'dirHist')\n",
      "\n",
      "# compute the null directionality histogram\n",
      "overall_dir_hist = sp_dir_hist_normalized[fg_superpixels].mean(axis=0)\n",
      "overall_dir_hist_normalized = overall_dir_hist.astype(np.float) / overall_dir_hist.sum()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# compute distance between every superpixel and the null\n",
      "D_texton_null = np.squeeze(cdist(sp_texton_hist_normalized, [overall_texton_hist_normalized], chi2))\n",
      "D_dir_null = np.squeeze(cdist(sp_dir_hist_normalized, [overall_dir_hist_normalized], chi2))\n",
      "\n",
      "p = sp_texton_hist_normalized\n",
      "q = sp_dir_hist_normalized"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "re_thresh_min = 0.01\n",
      "re_thresh_max = 0.8\n",
      "\n",
      "def grow_cluster_relative_entropy(seed, debug=False, \n",
      "                                  frontier_contrast_diff_thresh = 0.1,\n",
      "                                  max_cluster_size = 100):\n",
      "    '''\n",
      "    find the connected cluster of superpixels that have similar texture, starting from a superpixel as seed\n",
      "    '''\n",
      "    \n",
      "    bg_set = set(bg_superpixels.tolist())\n",
      "    \n",
      "    if seed in bg_set:\n",
      "        return [], -1\n",
      "\n",
      "    prev_frontier_contrast = np.inf\n",
      "    for re_thresh in np.arange(re_thresh_min, re_thresh_max, .01):\n",
      "    \n",
      "        curr_cluster = set([seed])\n",
      "        frontier = [seed]\n",
      "\n",
      "        while len(frontier) > 0:\n",
      "            u = frontier.pop(-1)\n",
      "            for v in neighbors[u]:\n",
      "                if v in bg_superpixels or v in curr_cluster: \n",
      "                    continue\n",
      "\n",
      "                if chi2(p[v], p[seed]) < re_thresh:\n",
      "                    curr_cluster.add(v)\n",
      "                    frontier.append(v)\n",
      "        \n",
      "        surround = set.union(*[neighbors[i] for i in curr_cluster]) - set.union(curr_cluster, bg_set)\n",
      "        if len(surround) == 0:\n",
      "            return curr_cluster, re_thresh\n",
      "\n",
      "        frontier_in_cluster = set.intersection(set.union(*[neighbors[i] for i in surround]), curr_cluster)\n",
      "        frontier_contrasts = [np.nanmax([chi2(p[i], p[j]) for j in neighbors[i] if j not in bg_set]) for i in frontier_in_cluster]\n",
      "        frontier_contrast = np.max(frontier_contrasts)\n",
      "        \n",
      "        if debug:\n",
      "            print 'frontier_contrast=', frontier_contrast, 'prev_frontier_contrast=', prev_frontier_contrast, 'diff=', frontier_contrast - prev_frontier_contrast\n",
      "        \n",
      "        if len(curr_cluster) > max_cluster_size or \\\n",
      "        frontier_contrast - prev_frontier_contrast > frontier_contrast_diff_thresh:\n",
      "            return curr_cluster, re_thresh\n",
      "        \n",
      "        prev_frontier_contrast = frontier_contrast\n",
      "        prev_cluster = curr_cluster\n",
      "        prev_re_thresh = re_thresh\n",
      "                                \n",
      "    return curr_cluster, re_thresh\n",
      "    \n",
      "\n",
      "def grow_cluster_likelihood_ratio(seed, texton_model, dir_model, debug=False, lr_grow_thresh = 0.1):\n",
      "    '''\n",
      "    find the connected cluster of superpixels that are more likely to be explained by given model than by null, \n",
      "    starting from a superpixel as seed\n",
      "    '''\n",
      "    \n",
      "    if seed in bg_superpixels:\n",
      "        return [], -1\n",
      "\n",
      "    curr_cluster = set([seed])\n",
      "    frontier = [seed]\n",
      "        \n",
      "    while len(frontier) > 0:\n",
      "        u = frontier.pop(-1)\n",
      "        for v in neighbors[u]:\n",
      "            if v in bg_superpixels or v in curr_cluster: \n",
      "                continue\n",
      "            \n",
      "            ratio_v = D_texton_null[v] - chi2(p[v], texton_model) +\\\n",
      "                        D_dir_null[v] - chi2(q[v], dir_model)\n",
      "            if debug:  \n",
      "                print 'u=', u, 'v=',v, 'ratio_v = ', ratio_v\n",
      "                print D_texton_null[v],  chi2(p[v], texton_model), \\\n",
      "                        D_dir_null[v], chi2(q[v], dir_model)\n",
      "            \n",
      "            if ratio_v > lr_grow_thresh:\n",
      "                curr_cluster.add(v)\n",
      "                frontier.append(v)\n",
      "                                \n",
      "    return curr_cluster, lr_grow_thresh\n",
      "\n",
      "def grow_cluster_likelihood_ratio_precomputed(seed, D_texton_model, D_dir_model, debug=False, lr_grow_thresh = 0.1):\n",
      "    '''\n",
      "    find the connected cluster of superpixels that are more likely to be explained by given model than by null, \n",
      "    starting from a superpixel as seed\n",
      "    using pre-computed distances between model and superpixels\n",
      "    '''\n",
      "\n",
      "    if seed in bg_superpixels:\n",
      "        return [], -1\n",
      "\n",
      "    curr_cluster = set([seed])\n",
      "    frontier = [seed]\n",
      "        \n",
      "    while len(frontier) > 0:\n",
      "        u = frontier.pop(-1)\n",
      "        for v in neighbors[u]:\n",
      "            if v in bg_superpixels or v in curr_cluster: \n",
      "                continue\n",
      "            \n",
      "            ratio_v = D_texton_null[v] - D_texton_model[v] +\\\n",
      "                        D_dir_null[v] - D_dir_model[v]\n",
      "            if debug:  \n",
      "                print 'u=', u, 'v=',v, 'ratio_v = ', ratio_v\n",
      "                print D_texton_null[v],  D_texton_model[v], \\\n",
      "                        D_dir_null[v], D_dir_model[v]\n",
      "            \n",
      "            if ratio_v > lr_grow_thresh:\n",
      "                curr_cluster.add(v)\n",
      "                frontier.append(v)\n",
      "                                \n",
      "    return curr_cluster, lr_grow_thresh\n",
      "\n",
      "\n",
      "def visualize_cluster(scores, cluster='all', title='', filename=None):\n",
      "    '''\n",
      "    Generate black and white image with the cluster of superpixels highlighted\n",
      "    '''\n",
      "    \n",
      "    vis = scores[segmentation]\n",
      "    if cluster != 'all':\n",
      "        cluster_selection = np.equal.outer(segmentation, cluster).any(axis=2)\n",
      "        vis[~cluster_selection] = 0\n",
      "    \n",
      "    plt.matshow(vis, cmap=plt.cm.Greys_r);\n",
      "    plt.axis('off');\n",
      "    plt.title(title)\n",
      "    if filename is not None:\n",
      "        plt.savefig(os.path.join(result_dir, 'stages', filename + '.png'), bbox_inches='tight')\n",
      "#     plt.show()\n",
      "    plt.close();\n",
      "    \n",
      "    \n",
      "def paint_cluster_on_img(cluster, title, filename=None):\n",
      "    '''\n",
      "    Highlight a cluster of superpixels on the real image\n",
      "    '''    \n",
      "\n",
      "    cluster_map = -1*np.ones_like(segmentation)\n",
      "    for s in cluster:\n",
      "        cluster_map[segmentation==s] = 1\n",
      "    vis = label2rgb(cluster_map, image=img)\n",
      "    plt.imshow(vis, cmap=plt.cm.Greys_r);\n",
      "    plt.axis('off');\n",
      "    plt.title(title)\n",
      "    if filename is not None:\n",
      "        plt.savefig(os.path.join(result_dir, 'stages', filename + '.png'), bbox_inches='tight')\n",
      "#     plt.show()\n",
      "    plt.close();\n",
      "\n",
      "def paint_clusters_on_img(clusters, title, filename=None):\n",
      "    '''\n",
      "    Highlight multiple clusters with different colors on the real image\n",
      "    '''\n",
      "    \n",
      "    cluster_map = -1*np.ones_like(segmentation)\n",
      "    for i, cluster in enumerate(clusters):\n",
      "        for j in cluster:\n",
      "            cluster_map[segmentation==j] = i\n",
      "    vis = label2rgb(cluster_map, image=img)\n",
      "    plt.imshow(vis, cmap=plt.cm.Greys_r);\n",
      "    plt.axis('off');\n",
      "    plt.title(title)\n",
      "    if filename is not None:\n",
      "        plt.savefig(os.path.join(result_dir, 'stages', filename + '.png'), bbox_inches='tight')\n",
      "#     plt.show()\n",
      "    plt.close();"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# set up sigboost parameters\n",
      "\n",
      "n_models = param['n_models']\n",
      "frontier_contrast_diff_thresh = param['frontier_contrast_diff_thresh']\n",
      "lr_grow_thresh = param['lr_grow_thresh']\n",
      "beta = param['beta']\n",
      "lr_decision_thresh = param['lr_decision_thresh']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# compute RE-clusters of every superpixel\n",
      "r = Parallel(n_jobs=16)(delayed(grow_cluster_relative_entropy)(i, frontier_contrast_diff_thresh=frontier_contrast_diff_thresh) \n",
      "                        for i in range(n_superpixels))\n",
      "clusters = [list(c) for c, t in r]\n",
      "print 'clusters computed'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# create output directory\n",
      "f = os.path.join(result_dir, 'stages')\n",
      "if not os.path.exists(f):\n",
      "    os.makedirs(f)\n",
      "\n",
      "# initialize models\n",
      "texton_models = np.zeros((n_models, n_texton))\n",
      "dir_models = np.zeros((n_models, n_angle))\n",
      "\n",
      "seed_indices = np.zeros((n_models,))\n",
      "\n",
      "weights = np.ones((n_superpixels, ))/n_superpixels\n",
      "weights[bg_superpixels] = 0\n",
      "\n",
      "# begin boosting loop; learn one model at each iteration\n",
      "for t in range(n_models):\n",
      "    \n",
      "    print 'model %d' % (t)\n",
      "    \n",
      "    # Compute significance scores for every superpixel;\n",
      "    # the significance score is defined as the average log likelihood ratio in a superpixel's RE-cluster\n",
      "    sig_score = np.zeros((n_superpixels, ))\n",
      "    for i in fg_superpixels:\n",
      "        cluster = clusters[i]\n",
      "        sig_score[i] = np.mean(weights[cluster] * \\\n",
      "                               (D_texton_null[cluster] - np.array([chi2(p[j], p[i]) for j in cluster]) +\\\n",
      "                               D_dir_null[cluster] - np.array([chi2(q[j], q[i]) for j in cluster])))\n",
      " \n",
      "    # Pick the most significant superpixel\n",
      "    seed_sp = sig_score.argsort()[-1]\n",
      "    print \"most significant superpixel\", seed_sp\n",
      "    \n",
      "    visualize_cluster(sig_score, 'all', title='significance score for each superpixel', filename='sigscore%d'%t)\n",
      "    \n",
      "    curr_cluster = clusters[seed_sp]\n",
      "    visualize_cluster(sig_score, curr_cluster, title='distance cluster', filename='curr_cluster%d'%t)\n",
      "\n",
      "    # models are the average of the distributions in the chosen superpixel's RE-cluster\n",
      "    model_texton = sp_texton_hist_normalized[curr_cluster].mean(axis=0)\n",
      "    model_dir = sp_dir_hist_normalized[curr_cluster].mean(axis=0)\n",
      "    \n",
      "    # Compute log likelihood ratio of this model against the null, for every superpixel\n",
      "    \n",
      "    # RE(pj|pm)\n",
      "    D_texton_model = np.empty((n_superpixels,))\n",
      "    D_texton_model[fg_superpixels] = np.array([chi2(sp_texton_hist_normalized[i], model_texton) for i in fg_superpixels])\n",
      "    D_texton_model[bg_superpixels] = np.nan\n",
      "    \n",
      "    # RE(qj|qm)\n",
      "    D_dir_model = np.empty((n_superpixels,)) \n",
      "    D_dir_model[fg_superpixels] = np.array([chi2(sp_dir_hist_normalized[i], model_dir) for i in fg_superpixels])\n",
      "    D_dir_model[bg_superpixels] = np.nan\n",
      "    \n",
      "    # RE(pj|p0)-RE(pj|pm) + RE(qj|q0)-RE(qj|qm)\n",
      "    match_scores = np.empty((n_superpixels,))\n",
      "    match_scores[fg_superpixels] = D_texton_null[fg_superpixels] - D_texton_model[fg_superpixels] +\\\n",
      "                                    D_dir_model[fg_superpixels] - D_dir_model[fg_superpixels]\n",
      "    match_scores[bg_superpixels] = 0\n",
      "\n",
      "    visualize_cluster(match_scores, 'all', title='match score', filename='grow%d'%t)\n",
      "\n",
      "    # Find the cluster growed from seed based on log likelihood ratio. Refer to this cluster as the LR-cluster\n",
      "    matched, _ = grow_cluster_likelihood_ratio(seed_sp, model_texton, model_dir)\n",
      "    matched = list(matched)\n",
      "\n",
      "    visualize_cluster(match_scores, matched, title='growed cluster', filename='grow%d'%t)\n",
      "\n",
      "    # Reduce the weights of superpixels in LR-cluster\n",
      "    weights[matched] = weights[matched] * np.exp(-5*(D_texton_null[matched] - D_texton_model[matched] +\\\n",
      "                                                   D_dir_null[matched] - D_dir_model[matched])**beta)\n",
      "    weights[bg_superpixels] = 0\n",
      "    weights = weights/weights.sum()\n",
      "    visualize_cluster((weights - weights.min())/(weights.max()-weights.min()), 'all', \n",
      "                      title='updated superpixel weights', filename='weight%d'%t)\n",
      "    \n",
      "    labels = -1*np.ones_like(segmentation)\n",
      "    for i in matched:\n",
      "        labels[segmentation == i] = 1\n",
      "    real_image = label2rgb(labels, img)\n",
      "    save_img(real_image, os.path.join('stage', 'real_image_model%d'%t))\n",
      "\n",
      "    # record the model found at this round\n",
      "    seed_indices[t] = seed_sp\n",
      "    texton_models[t] = model_texton\n",
      "    dir_models[t] = model_dir"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Compute the distances between every model and every superpixel\n",
      "D_texton_model = -1*np.ones((n_models, n_superpixels))\n",
      "D_dir_model = -1*np.ones((n_models, n_superpixels))\n",
      "D_texton_model[:, fg_superpixels] = cdist(sp_texton_hist_normalized[fg_superpixels], texton_models, chi2).T\n",
      "D_dir_model[:, fg_superpixels] = cdist(sp_dir_hist_normalized[fg_superpixels], dir_models, chi2).T"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def find_best_model_per_proc(i):\n",
      "    '''\n",
      "    Worker function for finding the best models for every superpixel on the current image.\n",
      "    Best model is the one with the highest likelihood ratio against the null distribution.\n",
      "    '''\n",
      "    \n",
      "    model_score = np.empty((n_models, ))\n",
      "\n",
      "    if i in bg_superpixels:\n",
      "        return -1\n",
      "    else:\n",
      "        for m in range(n_models):\n",
      "            matched, _ = grow_cluster_likelihood_ratio_precomputed(i, D_texton_model[m], D_dir_model[m], \n",
      "                                                                   lr_grow_thresh=lr_grow_thresh)\n",
      "            matched = list(matched)\n",
      "            model_score[m] = np.mean(D_texton_null[matched] - D_texton_model[m, matched] +\\\n",
      "                                     D_dir_null[matched] - D_dir_model[m, matched])\n",
      "\n",
      "        best_sig = model_score.max()\n",
      "        if best_sig > lr_decision_thresh: # sp whose sig is smaller than this is assigned null\n",
      "          return model_score.argmax()    \n",
      "    return -1\n",
      "\n",
      "\n",
      "# Compute the likelihood ratio for every model on every superpixel, and return the model with the highest ratio\n",
      "best_model = Parallel(n_jobs=16)(delayed(find_best_model_per_proc)(i) for i in range(n_superpixels))\n",
      "labels = np.array(best_model, dtype=np.int)\n",
      "save_array(labels, 'labels')\n",
      "\n",
      "labelmap = labels[segmentation]\n",
      "save_array(labelmap, 'labelmap')\n",
      "\n",
      "labelmap_rgb = label2rgb(labelmap.astype(np.int), image=img)\n",
      "save_img(labelmap_rgb, 'labelmap')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}