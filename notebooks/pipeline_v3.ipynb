{
 "metadata": {
  "name": "",
  "signature": "sha256:79a749cf923cf1c3d905be895e456db5eebc2d3ed375e5550793d4e44a433486"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import cv2\n",
      "\n",
      "import matplotlib\n",
      "# Force matplotlib to not use any Xwindows backend.\n",
      "matplotlib.use('Agg')\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "import random, itertools, sys, os\n",
      "from multiprocessing import Pool\n",
      "import json\n",
      "\n",
      "from skimage.segmentation import slic, mark_boundaries\n",
      "from skimage.measure import regionprops\n",
      "from skimage.util import img_as_ubyte\n",
      "from skimage.color import hsv2rgb, label2rgb, gray2rgb\n",
      "from skimage.morphology import disk\n",
      "from skimage.filter.rank import gradient\n",
      "from skimage.filter import gabor_kernel\n",
      "from skimage.transform import rescale, resize\n",
      "\n",
      "from scipy.ndimage import gaussian_filter, measurements\n",
      "from scipy.sparse import coo_matrix\n",
      "from scipy.spatial.distance import pdist, squareform, euclidean, cdist\n",
      "from scipy.signal import fftconvolve\n",
      "\n",
      "from IPython.display import FileLink, Image, FileLinks\n",
      "\n",
      "import utilities\n",
      "from utilities import chi2\n",
      "\n",
      "from joblib import Parallel, delayed\n",
      "\n",
      "import cPickle as pickle\n",
      "\n",
      "import glob, re, os, sys, subprocess, argparse\n",
      "import pprint"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# # parse arguments\n",
      "# parser = argparse.ArgumentParser(\n",
      "# formatter_class=argparse.RawDescriptionHelpFormatter,\n",
      "# description='Execute feature extraction pipeline',\n",
      "# epilog=\"\"\"\n",
      "# The following command processes image PMD1305_region0_reduce2_0244.tif using the parameter id nissl324.\n",
      "# python %s ../ParthaData/PMD1305_region0_reduce2/PMD1305_region0_reduce2_0244.tif nissl324\n",
      "\n",
      "# This script loads the parameters in params_dir. \n",
      "# Results are stored in a sub-directory named <result name>_param_<parameter id>, under output_dir.\n",
      "# Details are in the GitHub README (https://github.com/mistycheney/BrainSaliencyDetection/blob/master/README.md)\n",
      "# \"\"\"%(os.path.basename(sys.argv[0]), ))\n",
      "\n",
      "# parser.add_argument(\"img_file\", type=str, help=\"path to image file\")\n",
      "# parser.add_argument(\"param_id\", type=str, help=\"parameter identification name\")\n",
      "# # parser.add_argument(\"-o\", \"--output_dir\", type=str, help=\"output directory (default: %(default)s)\", default='/oasis/projects/nsf/csd181/yuncong/DavidData2014v2')\n",
      "# # parser.add_argument(\"-p\", \"--params_dir\", type=str, help=\"directory containing csv parameter files %(default)s)\", default='/oasis/projects/nsf/csd181/yuncong/Brain/params')\n",
      "# args = parser.parse_args()\n",
      "\n",
      "parser = argparse.ArgumentParser(\n",
      "formatter_class=argparse.RawDescriptionHelpFormatter,\n",
      "description='Execute feature processing pipeline',\n",
      "epilog=\"\"\"%s\n",
      "\"\"\"%(os.path.basename(sys.argv[0]), ))\n",
      "\n",
      "parser.add_argument(\"img_file\", type=str, help=\"path to image file\")\n",
      "parser.add_argument(\"param_id\", type=str, help=\"parameter identification name\")\n",
      "parser.add_argument(\"-t\", \"--textons_file\", type=str, help=\"pre-computed textons\", default=None)\n",
      "args = parser.parse_args()\n",
      "\n",
      "data_dir = '/oasis/projects/nsf/csd181/yuncong/DavidData2014v2'\n",
      "repo_dir = '/oasis/projects/nsf/csd181/yuncong/Brain/'\n",
      "params_dir = os.path.join(repo_dir, 'params')\n",
      "\n",
      "# class args:\n",
      "#     img_file = os.path.join(data_dir, 'RS141', 'x5', '0001', 'RS141_x5_0001.tif')\n",
      "#     param_id = 'redNissl'\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# load parameter settings\n",
      "# params_dir = os.path.realpath(params_dir)\n",
      "\n",
      "param_file = os.path.join(params_dir, 'param_%s.json'%args.param_id)\n",
      "param_default_file = os.path.join(params_dir, 'param_default.json')\n",
      "param = json.load(open(param_file, 'r'))\n",
      "param_default = json.load(open(param_default_file, 'r'))\n",
      "\n",
      "for k, v in param_default.iteritems():\n",
      "    if not isinstance(param[k], basestring):\n",
      "        if np.isnan(param[k]):\n",
      "            param[k] = v\n",
      "\n",
      "pprint.pprint(param)\n",
      "\n",
      "# set image paths\n",
      "img_file = os.path.realpath(args.img_file)\n",
      "img_path, ext = os.path.splitext(img_file)\n",
      "img_dir, img_name = os.path.split(img_path)\n",
      "\n",
      "stack, resol, slice = img_name.split('_')\n",
      "\n",
      "img = cv2.imread(img_file, 0)\n",
      "print img_file\n",
      "im_height, im_width = img.shape[:2]\n",
      "\n",
      "# set output paths\n",
      "# data_dir = os.path.realpath(data_dir)\n",
      "\n",
      "instance_name = img_name + '_' + str(param['param_id'])\n",
      "\n",
      "results_dir = os.path.join(data_dir, stack, resol, slice, args.param_id+'_pipelineResults')\n",
      "if not os.path.exists(results_dir):\n",
      "    os.makedirs(results_dir)\n",
      "    \n",
      "textons_file = os.path.realpath(args.textons_file)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# def load_array(suffix):\n",
      "#     return utilities.load_array(suffix, img_name, param['param_id'], args.output_dir)\n",
      "\n",
      "# def save_array(arr, suffix):\n",
      "#     utilities.save_array(arr, suffix, img_name, param['param_id'], args.output_dir)\n",
      "        \n",
      "# def save_img(img, suffix):\n",
      "#     utilities.save_img(img, suffix, img_name, param['param_id'], args.output_dir, overwrite=True)\n",
      "\n",
      "# def get_img_filename(suffix, ext='png'):\n",
      "#     return utilities.get_img_filename(suffix, img_name, param['param_id'], args.output_dir, ext=ext)\n",
      "\n",
      "def load_array(suffix):\n",
      "    return utilities.load_array(suffix, instance_name=instance_name, results_dir=results_dir)\n",
      "\n",
      "def save_array(arr, suffix):\n",
      "    utilities.save_array(arr, suffix, instance_name=instance_name, results_dir=results_dir)\n",
      "        \n",
      "def save_image(img, suffix):\n",
      "    utilities.save_image(img, suffix, instance_name=instance_name, results_dir=results_dir, overwrite=True)\n",
      "\n",
      "def load_image(suffix):\n",
      "    return utilities.load_array(suffix, instance_name=instance_name, results_dir=results_dir)\n",
      "\n",
      "    \n",
      "# def get_img_filename(suffix, ext='png'):\n",
      "#     return utilities.get_img_filename(suffix, img_name, param['param_id'], args.output_dir, ext=ext)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Find foreground mask\n",
      "\n",
      "print '=== finding foreground mask ==='\n",
      "\n",
      "try:\n",
      "    \n",
      "    mask_fn = os.path.join(img_dir, '_'.join([stack, resol, slice, '_mask.png']))\n",
      "    mask = cv2.imread(mask_fn, 0) > 0\n",
      "    print 'loaded mask from', mask_fn\n",
      "    \n",
      "#     mask = load_array('uncropMask')\n",
      "\n",
      "except:\n",
      "\n",
      "    mask = utilities.foreground_mask(img, min_size=2500)\n",
      "    mask = mask > .5\n",
      "    # plt.imshow(mask, cmap=plt.cm.Greys_r);\n",
      "\n",
      "    save_array(mask, 'uncropMask')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Generate Gabor filter kernels\n",
      "\n",
      "theta_interval = param['theta_interval']\n",
      "n_angle = int(180/theta_interval)\n",
      "freq_step = param['freq_step']\n",
      "freq_max = 1./param['min_wavelen']\n",
      "freq_min = 1./param['max_wavelen']\n",
      "bandwidth = param['bandwidth']\n",
      "n_freq = int(np.log(freq_max/freq_min)/np.log(freq_step)) + 1\n",
      "frequencies = freq_max/freq_step**np.arange(n_freq)\n",
      "\n",
      "kernels = [gabor_kernel(f, theta=t, bandwidth=bandwidth) for f in frequencies \n",
      "          for t in np.arange(0, n_angle)*np.deg2rad(theta_interval)]\n",
      "kernels = map(np.real, kernels)\n",
      "\n",
      "n_kernel = len(kernels)\n",
      "\n",
      "print '=== filter using Gabor filters ==='\n",
      "print 'num. of kernels: %d' % (n_kernel)\n",
      "print 'frequencies:', frequencies\n",
      "print 'wavelength (pixels):', 1/frequencies\n",
      "\n",
      "max_kern_size = np.max([kern.shape[0] for kern in kernels])\n",
      "print 'max kernel matrix size:', max_kern_size"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Process the image using Gabor filters\n",
      "\n",
      "try:\n",
      "#     raise IOError\n",
      "    features = load_array('features')\n",
      "except IOError:\n",
      "    \n",
      "    def convolve_per_proc(i):\n",
      "        return fftconvolve(img, kernels[i], 'same').astype(np.half)\n",
      "    \n",
      "    filtered = Parallel(n_jobs=16)(delayed(convolve_per_proc)(i) \n",
      "                            for i in range(n_kernel))\n",
      "\n",
      "    features = np.empty((im_height, im_width, n_kernel), dtype=np.half)\n",
      "    for i in range(n_kernel):\n",
      "        features[...,i] = filtered[i]\n",
      "\n",
      "    del filtered\n",
      "    \n",
      "    save_array(features, 'features')\n",
      "\n",
      "n_feature = features.shape[-1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Crop image border where filters show border effects\n",
      "\n",
      "features = features[max_kern_size/2:-max_kern_size/2, max_kern_size/2:-max_kern_size/2, :]\n",
      "img = img[max_kern_size/2:-max_kern_size/2, max_kern_size/2:-max_kern_size/2]\n",
      "mask = mask[max_kern_size/2:-max_kern_size/2, max_kern_size/2:-max_kern_size/2]\n",
      "im_height, im_width = img.shape[:2]\n",
      "\n",
      "save_image(img, 'cropImg')\n",
      "\n",
      "save_array(mask, 'cropMask')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Compute rotation-invariant texton map using K-Means\n",
      "\n",
      "print '=== compute rotation-invariant texton map using K-Means ==='\n",
      "\n",
      "n_texton = int(param['n_texton'])\n",
      "\n",
      "def compute_dist_per_proc(X_partial, c_all_rot):\n",
      "    D = cdist(X_partial, c_all_rot, 'sqeuclidean')\n",
      "    ci, ri = np.unravel_index(D.argmin(axis=1), (n_texton, n_angle))\n",
      "    return np.c_[ci, ri]\n",
      "\n",
      "try: \n",
      "#     raise IOError\n",
      "    textonmap = load_array('texMap')\n",
      "except IOError:\n",
      "    \n",
      "    X = features.reshape(-1, n_feature)\n",
      "    n_data = X.shape[0]\n",
      "    n_splits = 1000\n",
      "    n_sample = int(param['n_sample'])\n",
      "    \n",
      "    try:\n",
      "#         centroids = load_array('centroids')\n",
      "\n",
      "        if textons_file is None:\n",
      "            raise IOError\n",
      "\n",
      "        centroids = np.load(textons_file)\n",
      "        print 'loading textons from', textons_file\n",
      "    \n",
      "    except IOError:\n",
      "        \n",
      "        centroids = np.array(random.sample(X, n_texton))\n",
      "\n",
      "        n_iter = int(param['n_iter'])\n",
      "\n",
      "        for iteration in range(n_iter):\n",
      "\n",
      "            data = random.sample(X, n_sample)\n",
      "\n",
      "            print 'iteration', iteration\n",
      "            centroid_all_rotations = np.vstack([np.concatenate(np.roll(np.split(c, n_freq), i)) \n",
      "                                    for c,i in itertools.product(centroids, range(n_angle))])\n",
      "\n",
      "            r = Parallel(n_jobs=16)(delayed(compute_dist_per_proc)(x,c) \n",
      "                            for x, c in zip(np.array_split(data, n_splits, axis=0), \n",
      "                                            itertools.repeat(centroid_all_rotations, n_splits)))\n",
      "            res = np.vstack(r)\n",
      "\n",
      "            labels = res[:,0]\n",
      "            rotations = res[:,1]\n",
      "\n",
      "            centroids_new = np.zeros((n_texton, n_feature))\n",
      "            for d, l, r in itertools.izip(data, labels, rotations):\n",
      "                rot = np.concatenate(np.roll(np.split(d, n_freq), i))\n",
      "                centroids_new[l] += rot\n",
      "\n",
      "            counts = np.bincount(labels, minlength=n_texton)\n",
      "            centroids_new /= counts[:, np.newaxis] # denominator might be zero\n",
      "            centroids_new[counts==0] = centroids[counts==0]\n",
      "            print np.sqrt(np.sum((centroids - centroids_new)**2, axis=1)).mean()\n",
      "\n",
      "            centroids = centroids_new\n",
      "\n",
      "        print centroids.shape\n",
      "        save_array(centroids, 'centroids')\n",
      "    \n",
      "    print 'kmeans completes'\n",
      "    centroid_all_rotations = np.vstack([np.concatenate(np.roll(np.split(c, n_freq), i)) \n",
      "                                for c,i in itertools.product(centroids, range(n_angle))])\n",
      "\n",
      "    r = Parallel(n_jobs=16)(delayed(compute_dist_per_proc)(x,c) \n",
      "                            for x, c in zip(np.array_split(X, n_splits, axis=0), \n",
      "                                            itertools.repeat(centroid_all_rotations, n_splits)))\n",
      "    res = np.vstack(r)\n",
      "    \n",
      "    labels = res[:,0]\n",
      "    rotations = res[:,1]\n",
      "\n",
      "    textonmap = labels.reshape(features.shape[:2])\n",
      "    textonmap[~mask] = -1\n",
      "    \n",
      "#     save_array(textonmap, 'texMap')\n",
      "    save_array(textonmap.astype(np.int16), 'texMap')\n",
      "    \n",
      "textonmap_rgb = label2rgb(textonmap, image=None, colors=None, alpha=0.3, image_alpha=1)\n",
      "save_image(textonmap_rgb, 'texMap')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Over-segment the image into superpixels using SLIC (http://ivrg.epfl.ch/research/superpixels)\n",
      "\n",
      "print '=== over-segment the image into superpixels based on color information ==='\n",
      "\n",
      "img_rgb = gray2rgb(img)\n",
      "\n",
      "try:\n",
      "#     raise IOError\n",
      "    segmentation = load_array('segmentation')\n",
      "    \n",
      "except IOError:\n",
      "    segmentation = slic(img_rgb, n_segments=int(param['n_superpixels']), \n",
      "                        max_iter=10, \n",
      "                        compactness=float(param['slic_compactness']), \n",
      "                        sigma=float(param['slic_sigma']), \n",
      "                        enforce_connectivity=True)\n",
      "    print 'segmentation computed'\n",
      "    \n",
      "    save_array(segmentation.astype(np.int16), 'segmentation')\n",
      "    \n",
      "sp_props = regionprops(segmentation+1, intensity_image=img, cache=True)\n",
      "\n",
      "def obtain_props_worker(i):\n",
      "    return sp_props[i].centroid, sp_props[i].area, sp_props[i].mean_intensity\n",
      "\n",
      "r = Parallel(n_jobs=16)(delayed(obtain_props_worker)(i) for i in range(len(sp_props)))\n",
      "sp_centroids = np.array([s[0] for s in r])\n",
      "sp_areas = np.array([s[1] for s in r])\n",
      "sp_mean_intensity = np.array([s[2] for s in r])\n",
      "\n",
      "n_superpixels = len(np.unique(segmentation))\n",
      "\n",
      "img_superpixelized = mark_boundaries(img_rgb, segmentation)\n",
      "sptext = img_as_ubyte(img_superpixelized)\n",
      "for s in range(n_superpixels):\n",
      "    sptext = cv2.putText(sptext, str(s), \n",
      "                      tuple(np.floor(sp_centroids[s][::-1]).astype(np.int)), \n",
      "                      cv2.FONT_HERSHEY_COMPLEX_SMALL,\n",
      "                      .5, ((255,0,255)), 1)\n",
      "save_image(sptext, 'segmentation')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Determine which superpixels are mostly background\n",
      "\n",
      "def count_fg_worker(i):\n",
      "    return np.count_nonzero(mask[segmentation==i])\n",
      "\n",
      "r = Parallel(n_jobs=16)(delayed(count_fg_worker)(i) for i in range(n_superpixels))\n",
      "superpixels_fg_count = np.array(r)\n",
      "bg_superpixels = np.nonzero((superpixels_fg_count/sp_areas) < 0.3)[0]\n",
      "# bg_superpixels = np.array(list(set(bg_superpixels.tolist()\n",
      "#                           +[0,1,2,3,4,5,6,7,119,78,135,82,89,187,174,242,289]\n",
      "#                           +[50,51,56,57,58,59,60,61,62,63,64,65,115,73,88,109,99,91,122,110,151,192,165,158,254,207,236,306]\n",
      "#                           )))\n",
      "fg_superpixels = np.array([i for i in range(n_superpixels) if i not in bg_superpixels])\n",
      "print '%d background superpixels'%len(bg_superpixels)\n",
      "\n",
      "save_array(fg_superpixels, 'fg')\n",
      "save_array(bg_superpixels, 'bg')\n",
      "\n",
      "# a = np.zeros((n_superpixels,), dtype=np.bool)\n",
      "# a[fg_superpixels] = True\n",
      "# plt.imshow(a[segmentation], cmap=plt.cm.Greys_r)\n",
      "# plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Compute neighbor lists and connectivity matrix\n",
      "\n",
      "from skimage.morphology import disk\n",
      "from skimage.filter.rank import gradient\n",
      "from scipy.sparse import coo_matrix\n",
      "\n",
      "edge_map = gradient(segmentation.astype(np.uint8), disk(3))\n",
      "neighbors = [set() for i in range(n_superpixels)]\n",
      "\n",
      "for y,x in zip(*np.nonzero(edge_map)):\n",
      "    neighbors[segmentation[y,x]] |= set(segmentation[y-2:y+2,x-2:x+2].ravel())\n",
      "\n",
      "for i in range(n_superpixels):\n",
      "    neighbors[i] -= set([i])\n",
      "    \n",
      "rows = np.hstack([s*np.ones((len(neighbors[s]),), dtype=np.int) for s in range(n_superpixels)])\n",
      "cols = np.hstack([list(neighbors[s]) for s in range(n_superpixels)])\n",
      "data = np.ones((cols.size, ), dtype=np.bool)\n",
      "connectivity_matrix = coo_matrix((data, (rows, cols)), shape=(n_superpixels,n_superpixels))\n",
      "connectivity_matrix = connectivity_matrix.transpose() * connectivity_matrix\n",
      "\n",
      "save_array(neighbors, 'neighbors')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# compute texton histogram of every superpixel\n",
      "print '=== compute texton histogram of each superpixel ==='\n",
      "\n",
      "try:\n",
      "#     raise IOError\n",
      "    sp_texton_hist_normalized = load_array('texHist')\n",
      "except IOError:\n",
      "    def texton_histogram_worker(i):\n",
      "        return np.bincount(textonmap[(segmentation == i)&(textonmap != -1)], minlength=n_texton)\n",
      "\n",
      "    r = Parallel(n_jobs=16)(delayed(texton_histogram_worker)(i) for i in range(n_superpixels))\n",
      "    sp_texton_hist = np.array(r)\n",
      "    sp_texton_hist_normalized = sp_texton_hist.astype(np.float) / sp_texton_hist.sum(axis=1)[:, np.newaxis] # denom might be invalid\n",
      "    save_array(sp_texton_hist_normalized, 'texHist')\n",
      "\n",
      "# compute the null texton histogram\n",
      "overall_texton_hist = np.bincount(textonmap[mask].flat)\n",
      "overall_texton_hist_normalized = overall_texton_hist.astype(np.float) / overall_texton_hist.sum()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# compute directionality histogram of every superpixel\n",
      "print '=== compute directionality histogram of each superpixel ==='\n",
      "\n",
      "try:\n",
      "#     raise IOError\n",
      "    sp_dir_hist_normalized = load_array('dirHist')\n",
      "except IOError:\n",
      "    f = np.reshape(features, (features.shape[0], features.shape[1], n_freq, n_angle))\n",
      "    dir_energy = np.sum(abs(f), axis=2)\n",
      "\n",
      "    def dir_histogram_worker(i):\n",
      "        segment_dir_energies = dir_energy[segmentation == i].astype(np.float_).mean(axis=0)\n",
      "        return segment_dir_energies    \n",
      "\n",
      "    r = Parallel(n_jobs=16)(delayed(dir_histogram_worker)(i) for i in range(n_superpixels))\n",
      "    \n",
      "    sp_dir_hist = np.vstack(r)\n",
      "    sp_dir_hist_normalized = sp_dir_hist/sp_dir_hist.sum(axis=1)[:,np.newaxis]\n",
      "    save_array(sp_dir_hist_normalized, 'dirHist')\n",
      "\n",
      "# compute the null directionality histogram\n",
      "overall_dir_hist = sp_dir_hist_normalized[fg_superpixels].mean(axis=0)\n",
      "overall_dir_hist_normalized = overall_dir_hist.astype(np.float) / overall_dir_hist.sum()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}