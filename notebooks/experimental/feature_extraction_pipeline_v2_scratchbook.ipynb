{
 "metadata": {
  "name": "",
  "signature": "sha256:896f8f73170246b26464b596c8b5d9394179e58c5d1066a63c60a0f45b57130d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext autoreload\n",
      "%autoreload 2\n",
      "\n",
      "import numpy as np\n",
      "import cv2\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "import random, itertools, sys, os\n",
      "from multiprocessing import Pool\n",
      "import json\n",
      "\n",
      "from skimage.segmentation import slic, mark_boundaries\n",
      "from skimage.measure import regionprops\n",
      "from skimage.util import img_as_ubyte\n",
      "from skimage.color import hsv2rgb, label2rgb, gray2rgb\n",
      "from skimage.morphology import disk\n",
      "from skimage.filter.rank import gradient\n",
      "from skimage.filter import gabor_kernel\n",
      "from skimage.transform import rescale, resize\n",
      "\n",
      "from scipy.ndimage import gaussian_filter, measurements\n",
      "from scipy.sparse import coo_matrix\n",
      "from scipy.spatial.distance import pdist, squareform, euclidean, cdist\n",
      "from scipy.signal import fftconvolve\n",
      "\n",
      "from IPython.display import FileLink, Image, FileLinks\n",
      "\n",
      "import utilities\n",
      "\n",
      "from joblib import Parallel, delayed\n",
      "\n",
      "import glob, re, os, sys, subprocess, argparse\n",
      "import pprint\n",
      "\n",
      "%autosave 60"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# parser = argparse.ArgumentParser(\n",
      "# formatter_class=argparse.RawDescriptionHelpFormatter,\n",
      "# description='Execute feature extraction pipeline',\n",
      "# epilog=\"\"\"\n",
      "# The following command processes image PMD1305_region0_reduce2_0244.tif using the parameter setting number 10.\n",
      "# python %s ../data/PMD1305_region0_reduce2/PMD1305_region0_reduce2_0244.tif 10\n",
      "\n",
      "# This script loads the parameters in ../params. \n",
      "# The meanings of all parameters are explained in GitHub README.\n",
      "\n",
      "# The results are stored in a sub-directory under the output directory. \n",
      "# The sub-directory is named <dataset name>_reduce<reduce level>_<image index>_param<parameter id>.\n",
      "# The content of this sub-directory are the .npy files or image files with different _<suffix>. See GitHub README for details of these files.\n",
      "\n",
      "# * GitHub README *\n",
      "# https://github.com/mistycheney/BrainSaliencyDetection/blob/master/README.md\n",
      "# \"\"\"%(os.path.basename(sys.argv[0]), ))\n",
      "\n",
      "# parser.add_argument(\"img_file\", type=str, help=\"path to image file\")\n",
      "# parser.add_argument(\"param_id\", type=str, help=\"parameter identification name\")\n",
      "# parser.add_argument(\"-o\", \"--output_dir\", type=str, help=\"output directory (default: %(default)s)\", default='/oasis/scratch/csd181/yuncong/output')\n",
      "# parser.add_argument(\"-p\", \"--params_dir\", type=str, help=\"directory containing csv parameter files %(default)s)\", default='/oasis/projects/nsf/csd181/yuncong/Brain/params')\n",
      "# args = parser.parse_args()\n",
      "\n",
      "class args:\n",
      "#     param_id = 'nissl324'\n",
      "    param_id = 'redNissl'\n",
      "#     img_file = '../ParthaData/PMD1305_region0_reduce2/PMD1305_region0_reduce2_0244.tif'\n",
      "    img_file = '../DavidData/RS141_x5/RS141_x5_0000.tif'\n",
      "    output_dir = '/oasis/scratch/csd181/yuncong/output'\n",
      "#     params_dir = '/oasis/projects/nsf/csd181/yuncong/Brain/params'\n",
      "    params_dir = '/home/yfreund/brainRegistration/params/'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load_array(suffix):\n",
      "    return utilities.load_array(suffix, img_name, param['param_id'], args.output_dir)\n",
      "\n",
      "def save_array(arr, suffix):\n",
      "    utilities.save_array(arr, suffix, img_name, param['param_id'], args.output_dir)\n",
      "        \n",
      "def save_img(img, suffix):\n",
      "    utilities.save_img(img, suffix, img_name, param['param_id'], args.output_dir, overwrite=True)\n",
      "\n",
      "def get_img_filename(suffix, ext='png'):\n",
      "    return utilities.get_img_filename(suffix, img_name, param['param_id'], args.output_dir, ext=ext)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "params_dir = os.path.realpath(args.params_dir)\n",
      "param_file = os.path.join(params_dir, 'param_%s.json'%args.param_id)\n",
      "param_default_file = os.path.join(params_dir, 'param_default.json')\n",
      "param = json.load(open(param_file, 'r'))\n",
      "param_default = json.load(open(param_default_file, 'r'))\n",
      "\n",
      "for k, v in param_default.iteritems():\n",
      "    if not isinstance(param[k], basestring):\n",
      "        if np.isnan(param[k]):\n",
      "            param[k] = v\n",
      "\n",
      "pprint.pprint(param)\n",
      "\n",
      "img_file = os.path.realpath(args.img_file)\n",
      "img_path, ext = os.path.splitext(img_file)\n",
      "img_dir, img_name = os.path.split(img_path)\n",
      "\n",
      "img = cv2.imread(img_file, 0)\n",
      "im_height, im_width = img.shape[:2]\n",
      "\n",
      "output_dir = os.path.realpath(args.output_dir)\n",
      "\n",
      "result_name = img_name + '_param_' + str(param['param_id'])\n",
      "result_dir = os.path.join(output_dir, result_name)\n",
      "if not os.path.exists(result_dir):\n",
      "    os.makedirs(result_dir)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print '=== finding foreground mask ==='\n",
      "mask = utilities.foreground_mask(img, min_size=2500)\n",
      "mask = mask > .5\n",
      "plt.imshow(mask, cmap=plt.cm.Greys_r);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.arange(0, np.pi, np.deg2rad(theta_interval))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "theta_interval = param['theta_interval']\n",
      "n_angle = int(180/theta_interval)\n",
      "freq_step = param['freq_step']\n",
      "freq_max = 1./param['min_wavelen']\n",
      "freq_min = 1./param['max_wavelen']\n",
      "bandwidth = param['bandwidth']\n",
      "n_freq = int(np.log(freq_max/freq_min)/np.log(freq_step)) + 1\n",
      "frequencies = freq_max/freq_step**np.arange(n_freq)\n",
      "\n",
      "kernels = [gabor_kernel(f, theta=t, bandwidth=bandwidth) for f in frequencies \n",
      "          for t in np.arange(0, n_angle)*np.deg2rad(theta_interval)]\n",
      "kernels = map(np.real, kernels)\n",
      "\n",
      "# for i, k in enumerate(kernels):\n",
      "#     np.savetxt('kernels/kernel%d.txt'%i, k)\n",
      "\n",
      "n_kernel = len(kernels)\n",
      "\n",
      "print '=== filter using Gabor filters ==='\n",
      "print 'num. of kernels: %d' % (n_kernel)\n",
      "print 'frequencies:', frequencies\n",
      "print 'wavelength (pixels):', 1/frequencies\n",
      "\n",
      "max_kern_size = np.max([kern.shape[0] for kern in kernels])\n",
      "print 'max kernel matrix size:', max_kern_size"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "try:\n",
      "    raise IOError\n",
      "    features = load_array('features')\n",
      "except IOError:\n",
      "    def convolve_per_proc(i):\n",
      "        return fftconvolve(img, kernels[i], 'same').astype(np.half)\n",
      "    \n",
      "    filtered = Parallel(n_jobs=16)(delayed(convolve_per_proc)(i) \n",
      "                            for i in range(n_kernel))\n",
      "\n",
      "    features = np.empty((im_height, im_width, n_kernel), dtype=np.half)\n",
      "    for i in range(n_kernel):\n",
      "        features[...,i] = filtered[i]\n",
      "\n",
      "    del filtered\n",
      "    \n",
      "    save_array(features, 'features')\n",
      "\n",
      "n_feature = features.shape[-1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'crop border where filters show border effects'\n",
      "features = features[max_kern_size/2:-max_kern_size/2, max_kern_size/2:-max_kern_size/2, :]\n",
      "img = img[max_kern_size/2:-max_kern_size/2, max_kern_size/2:-max_kern_size/2]\n",
      "mask = mask[max_kern_size/2:-max_kern_size/2, max_kern_size/2:-max_kern_size/2]\n",
      "im_height, im_width = img.shape[:2]\n",
      "\n",
      "save_img(img, 'img_cropped')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print '=== compute rotation-invariant texton map using K-Means ==='\n",
      "\n",
      "n_texton = int(param['n_texton'])\n",
      "\n",
      "try: \n",
      "    raise IOError\n",
      "    textonmap = load_array('textonmap')\n",
      "except IOError:\n",
      "    \n",
      "    X = features.reshape(-1, n_feature)\n",
      "    n_data = X.shape[0]\n",
      "    n_splits = 1000\n",
      "    n_sample = int(param['n_sample'])\n",
      "    centroids = np.array(random.sample(X, n_texton))\n",
      "    \n",
      "    n_iter = int(param['n_iter'])\n",
      "\n",
      "    def compute_dist_per_proc(X_partial, c_all_rot):\n",
      "        D = cdist(X_partial, c_all_rot, 'sqeuclidean')\n",
      "        ci, ri = np.unravel_index(D.argmin(axis=1), (n_texton, n_angle))\n",
      "        return np.c_[ci, ri]\n",
      "\n",
      "    for iteration in range(n_iter):\n",
      "        \n",
      "        data = random.sample(X, n_sample)\n",
      "        \n",
      "        print 'iteration', iteration\n",
      "        centroid_all_rotations = np.vstack([np.concatenate(np.roll(np.split(c, n_freq), i)) \n",
      "                                for c,i in itertools.product(centroids, range(n_angle))])\n",
      "\n",
      "        r = Parallel(n_jobs=16)(delayed(compute_dist_per_proc)(x,c) \n",
      "                        for x, c in zip(np.array_split(data, n_splits, axis=0), \n",
      "                                        itertools.repeat(centroid_all_rotations, n_splits)))\n",
      "        res = np.vstack(r)        \n",
      "\n",
      "        labels = res[:,0]\n",
      "        rotations = res[:,1]\n",
      "\n",
      "        centroids_new = np.zeros((n_texton, n_feature))\n",
      "        for d, l, r in itertools.izip(data, labels, rotations):\n",
      "            rot = np.concatenate(np.roll(np.split(d, n_freq), i))\n",
      "            centroids_new[l] += rot\n",
      "\n",
      "        counts = np.bincount(labels, minlength=n_texton)\n",
      "        centroids_new /= counts[:, np.newaxis]\n",
      "        centroids_new[counts==0] = centroids[counts==0]\n",
      "        print np.sqrt(np.sum((centroids - centroids_new)**2, axis=1)).mean()\n",
      "\n",
      "        centroids = centroids_new\n",
      "\n",
      "    print 'kmeans completes'\n",
      "    centroid_all_rotations = np.vstack([np.concatenate(np.roll(np.split(c, n_freq), i)) \n",
      "                                for c,i in itertools.product(centroids, range(n_angle))])\n",
      "\n",
      "    r = Parallel(n_jobs=16)(delayed(compute_dist_per_proc)(x,c) \n",
      "                            for x, c in zip(np.array_split(X, n_splits, axis=0), \n",
      "                                            itertools.repeat(centroid_all_rotations, n_splits)))\n",
      "    res = np.vstack(r)\n",
      "    \n",
      "    labels = res[:,0]\n",
      "    rotations = res[:,1]\n",
      "\n",
      "    textonmap = labels.reshape(features.shape[:2])\n",
      "    textonmap[~mask] = -1\n",
      "    \n",
      "    save_array(textonmap, 'textonmap')\n",
      "    \n",
      "textonmap_rgb = label2rgb(textonmap, image=None, colors=None, alpha=0.3, image_alpha=1)\n",
      "save_img(textonmap_rgb, 'textonmap')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print '=== over-segment the image into superpixels based on color information ==='\n",
      "\n",
      "img_rgb = gray2rgb(img)\n",
      "\n",
      "try:\n",
      "    raise IOError\n",
      "    segmentation = load_array('segmentation')\n",
      "    \n",
      "except IOError:\n",
      "    segmentation = slic(img_rgb, n_segments=int(param['n_superpixels']), \n",
      "                        max_iter=10, \n",
      "                        compactness=float(param['slic_compactness']), \n",
      "                        sigma=float(param['slic_sigma']), \n",
      "                        enforce_connectivity=True)\n",
      "    print 'segmentation computed'\n",
      "    \n",
      "    save_array(segmentation, 'segmentation')\n",
      "    \n",
      "sp_props = regionprops(segmentation+1, intensity_image=img, cache=True)\n",
      "\n",
      "def foo2(i):\n",
      "    return sp_props[i].centroid, sp_props[i].area, sp_props[i].mean_intensity\n",
      "\n",
      "r = Parallel(n_jobs=16)(delayed(foo2)(i) for i in range(len(sp_props)))\n",
      "sp_centroids = np.array([s[0] for s in r])\n",
      "sp_areas = np.array([s[1] for s in r])\n",
      "sp_mean_intensity = np.array([s[2] for s in r])\n",
      "\n",
      "n_superpixels = len(np.unique(segmentation))\n",
      "\n",
      "img_superpixelized = mark_boundaries(img_rgb, segmentation)\n",
      "sptext = img_as_ubyte(img_superpixelized)\n",
      "for s in range(n_superpixels):\n",
      "    sptext = cv2.putText(sptext, str(s), \n",
      "                      tuple(np.floor(sp_centroids[s][::-1]).astype(np.int)), \n",
      "                      cv2.FONT_HERSHEY_COMPLEX_SMALL,\n",
      "                      .5, ((255,0,255)), 1)\n",
      "save_img(sptext, 'segmentation')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "FileLink(get_img_filename('segmentation')[30:])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "FileLink(get_img_filename('textonmap')[30:])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def foo(i):\n",
      "    return np.count_nonzero(mask[segmentation==i])\n",
      "\n",
      "r = Parallel(n_jobs=16)(delayed(foo)(i) for i in range(n_superpixels))\n",
      "superpixels_fg_count = np.array(r)\n",
      "bg_superpixels = np.nonzero((superpixels_fg_count/sp_areas) < 0.3)[0]\n",
      "# bg_superpixels = np.array(list(set(bg_superpixels.tolist()\n",
      "#                           +[0,1,2,3,4,5,6,7,119,78,135,82,89,187,174,242,289]\n",
      "#                           +[50,51,56,57,58,59,60,61,62,63,64,65,115,73,88,109,99,91,122,110,151,192,165,158,254,207,236,306]\n",
      "#                           )))\n",
      "\n",
      "# bg_superpixels = np.array(list(set(bg_superpixels.tolist()+range(47,72)\n",
      "#                           +[76,105,108,151,142,187,218,188,122,84,171,202,265,106,152,119,78,79,152,158,202,285,209,310,323,253]\n",
      "#                           +[0,1,2,3,4,5,6,7,8,15,80,100,174,153,162,75])))\n",
      "\n",
      "fg_superpixels = np.array([i for i in range(n_superpixels) if i not in bg_superpixels])\n",
      "print '%d background superpixels'%len(bg_superpixels)\n",
      "\n",
      "a = np.zeros((n_superpixels,), dtype=np.bool)\n",
      "a[fg_superpixels] = True\n",
      "plt.imshow(a[segmentation], cmap=plt.cm.Greys_r)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from skimage.morphology import disk\n",
      "from skimage.filter.rank import gradient\n",
      "from scipy.sparse import coo_matrix\n",
      "\n",
      "edge_map = gradient(segmentation.astype(np.uint8), disk(3))\n",
      "neighbors = [set() for i in range(n_superpixels)]\n",
      "\n",
      "for y,x in zip(*np.nonzero(edge_map)):\n",
      "    neighbors[segmentation[y,x]] |= set(segmentation[y-2:y+2,x-2:x+2].ravel())\n",
      "\n",
      "for i in range(n_superpixels):\n",
      "    neighbors[i] -= set([i])\n",
      "    \n",
      "rows = np.hstack([s*np.ones((len(neighbors[s]),), dtype=np.int) for s in range(n_superpixels)])\n",
      "cols = np.hstack([list(neighbors[s]) for s in range(n_superpixels)])\n",
      "data = np.ones((cols.size, ), dtype=np.bool)\n",
      "connectivity_matrix = coo_matrix((data, (rows, cols)), shape=(n_superpixels,n_superpixels))\n",
      "connectivity_matrix = connectivity_matrix.transpose() * connectivity_matrix"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print '=== compute texton histogram of each superpixel ==='\n",
      "\n",
      "try:\n",
      "    raise IOError\n",
      "    sp_texton_hist_normalized = load_array('sp_texton_hist_normalized')\n",
      "except IOError:\n",
      "    def bar(i):\n",
      "        return np.bincount(textonmap[(segmentation == i)&(textonmap != -1)], minlength=n_texton)\n",
      "\n",
      "    r = Parallel(n_jobs=16)(delayed(bar)(i) for i in range(n_superpixels))\n",
      "    sp_texton_hist = np.array(r)\n",
      "    sp_texton_hist_normalized = sp_texton_hist.astype(np.float) / sp_texton_hist.sum(axis=1)[:, np.newaxis]\n",
      "    save_array(sp_texton_hist_normalized, 'sp_texton_hist_normalized')\n",
      "    \n",
      "overall_texton_hist = np.bincount(textonmap[mask].flat)\n",
      "overall_texton_hist_normalized = overall_texton_hist.astype(np.float) / overall_texton_hist.sum()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print '=== compute directionality histogram of each superpixel ==='\n",
      "\n",
      "try:\n",
      "    raise IOError\n",
      "    sp_dir_hist_normalized = load_array('sp_dir_hist_normalized')\n",
      "except IOError:\n",
      "    f = np.reshape(features, (features.shape[0], features.shape[1], n_freq, n_angle))\n",
      "    dir_energy = np.sum(abs(f), axis=2)\n",
      "\n",
      "    def bar2(i):\n",
      "        segment_dir_energies = dir_energy[segmentation == i].astype(np.float_).mean(axis=0)\n",
      "        return segment_dir_energies    \n",
      "\n",
      "    r = Parallel(n_jobs=16)(delayed(bar2)(i) for i in range(n_superpixels))\n",
      "    \n",
      "    sp_dir_hist = np.vstack(r)\n",
      "    sp_dir_hist_normalized = sp_dir_hist/sp_dir_hist.sum(axis=1)[:,np.newaxis]\n",
      "    save_array(sp_dir_hist_normalized, 'sp_dir_hist_normalized')\n",
      "    \n",
      "overall_dir_hist = sp_dir_hist_normalized[fg_superpixels].mean(axis=0)\n",
      "overall_dir_hist_normalized = overall_dir_hist.astype(np.float) / overall_dir_hist.sum()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def chi2(u,v):\n",
      "    r = np.nansum((u-v)**2/(u+v))\n",
      "    return r\n",
      "\n",
      "D_texton_null = np.squeeze(cdist(sp_texton_hist_normalized, [overall_texton_hist_normalized], chi2))\n",
      "D_dir_null = np.squeeze(cdist(sp_dir_hist_normalized, [overall_dir_hist_normalized], chi2))\n",
      "p = sp_texton_hist_normalized\n",
      "q = sp_dir_hist_normalized"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "re_thresh_min = 0.01\n",
      "re_thresh_max = 0.8\n",
      "\n",
      "def grow_cluster_relative_entropy(seed, debug=False, \n",
      "                                  frontier_contrast_diff_thresh = 0.1,\n",
      "                                  max_cluster_size = 100):\n",
      "    \n",
      "    bg_set = set(bg_superpixels.tolist())\n",
      "    \n",
      "    if seed in bg_set:\n",
      "        return [], -1\n",
      "\n",
      "    prev_frontier_contrast = np.inf\n",
      "    for re_thresh in np.arange(re_thresh_min, re_thresh_max, .01):\n",
      "    \n",
      "        curr_cluster = set([seed])\n",
      "        frontier = [seed]\n",
      "\n",
      "        while len(frontier) > 0:\n",
      "            u = frontier.pop(-1)\n",
      "            for v in neighbors[u]:\n",
      "                if v in bg_superpixels or v in curr_cluster: \n",
      "                    continue\n",
      "\n",
      "                if chi2(p[v], p[seed]) < re_thresh:\n",
      "                    curr_cluster.add(v)\n",
      "                    frontier.append(v)\n",
      "        \n",
      "        surround = set.union(*[neighbors[i] for i in curr_cluster]) - set.union(curr_cluster, bg_set)\n",
      "        if len(surround) == 0:\n",
      "            return curr_cluster, re_thresh\n",
      "\n",
      "        frontier_in_cluster = set.intersection(set.union(*[neighbors[i] for i in surround]), curr_cluster)\n",
      "        frontier_contrasts = [np.nanmax([chi2(p[i], p[j]) for j in neighbors[i] if j not in bg_set]) for i in frontier_in_cluster]\n",
      "        frontier_contrast = np.max(frontier_contrasts)\n",
      "        \n",
      "        if debug:\n",
      "            print 'frontier_contrast=', frontier_contrast, 'prev_frontier_contrast=', prev_frontier_contrast, 'diff=', frontier_contrast - prev_frontier_contrast\n",
      "        \n",
      "        if len(curr_cluster) > max_cluster_size or \\\n",
      "        frontier_contrast - prev_frontier_contrast > frontier_contrast_diff_thresh:\n",
      "            return curr_cluster, re_thresh\n",
      "        \n",
      "        prev_frontier_contrast = frontier_contrast\n",
      "        prev_cluster = curr_cluster\n",
      "        prev_re_thresh = re_thresh\n",
      "                                \n",
      "    return curr_cluster, re_thresh\n",
      "    \n",
      "\n",
      "def grow_cluster_likelihood_ratio(seed, texton_model, dir_model, debug=False, lr_grow_thresh = 0.1):\n",
      "    \n",
      "    if seed in bg_superpixels:\n",
      "        return [], -1\n",
      "\n",
      "    curr_cluster = set([seed])\n",
      "    frontier = [seed]\n",
      "        \n",
      "    while len(frontier) > 0:\n",
      "        u = frontier.pop(-1)\n",
      "        for v in neighbors[u]:\n",
      "            if v in bg_superpixels or v in curr_cluster: \n",
      "                continue\n",
      "            \n",
      "            ratio_v = D_texton_null[v] - chi2(p[v], texton_model) +\\\n",
      "                        D_dir_null[v] - chi2(q[v], dir_model)\n",
      "            if debug:  \n",
      "                print 'u=', u, 'v=',v, 'ratio_v = ', ratio_v\n",
      "                print D_texton_null[v],  chi2(p[v], texton_model), \\\n",
      "                        D_dir_null[v], chi2(q[v], dir_model)\n",
      "            \n",
      "            if ratio_v > lr_grow_thresh:\n",
      "                curr_cluster.add(v)\n",
      "                frontier.append(v)\n",
      "                                \n",
      "    return curr_cluster, lr_grow_thresh\n",
      "\n",
      "def grow_cluster_likelihood_ratio_precomputed(seed, D_texton_model, D_dir_model, debug=False, lr_grow_thresh = 0.1):\n",
      "    \n",
      "    if seed in bg_superpixels:\n",
      "        return [], -1\n",
      "\n",
      "    curr_cluster = set([seed])\n",
      "    frontier = [seed]\n",
      "        \n",
      "    while len(frontier) > 0:\n",
      "        u = frontier.pop(-1)\n",
      "        for v in neighbors[u]:\n",
      "            if v in bg_superpixels or v in curr_cluster: \n",
      "                continue\n",
      "            \n",
      "            ratio_v = D_texton_null[v] - D_texton_model[v] +\\\n",
      "                        D_dir_null[v] - D_dir_model[v]\n",
      "            if debug:  \n",
      "                print 'u=', u, 'v=',v, 'ratio_v = ', ratio_v\n",
      "                print D_texton_null[v],  D_texton_model[v], \\\n",
      "                        D_dir_null[v], D_dir_model[v]\n",
      "            \n",
      "            if ratio_v > lr_grow_thresh:\n",
      "                curr_cluster.add(v)\n",
      "                frontier.append(v)\n",
      "                                \n",
      "    return curr_cluster, lr_grow_thresh\n",
      "\n",
      "\n",
      "def visualize_cluster(scores, cluster='all', title='', filename=None):\n",
      "    vis = scores[segmentation]\n",
      "    if cluster != 'all':\n",
      "        cluster_selection = np.equal.outer(segmentation, cluster).any(axis=2)\n",
      "        vis[~cluster_selection] = 0\n",
      "    \n",
      "    plt.matshow(vis, cmap=plt.cm.Greys_r);\n",
      "    plt.axis('off');\n",
      "    plt.title(title)\n",
      "    if filename is not None:\n",
      "        plt.savefig(os.path.join(result_dir, 'stages', filename + '.png'), bbox_inches='tight')\n",
      "#     plt.show()\n",
      "    plt.close();\n",
      "    \n",
      "    \n",
      "def paint_cluster_on_img(cluster, title, filename=None):\n",
      "    cluster_map = -1*np.ones_like(segmentation)\n",
      "    for s in cluster:\n",
      "        cluster_map[segmentation==s] = 1\n",
      "    vis = label2rgb(cluster_map, image=img)\n",
      "    plt.imshow(vis, cmap=plt.cm.Greys_r);\n",
      "    plt.axis('off');\n",
      "    plt.title(title)\n",
      "    if filename is not None:\n",
      "        plt.savefig(os.path.join(result_dir, 'stages', filename + '.png'), bbox_inches='tight')\n",
      "#     plt.show()\n",
      "    plt.close();\n",
      "\n",
      "def paint_clusters_on_img(clusters, title, filename=None):\n",
      "    cluster_map = -1*np.ones_like(segmentation)\n",
      "    for i, cluster in enumerate(clusters):\n",
      "        for j in cluster:\n",
      "            cluster_map[segmentation==j] = i\n",
      "    vis = label2rgb(cluster_map, image=img)\n",
      "    plt.imshow(vis, cmap=plt.cm.Greys_r);\n",
      "    plt.axis('off');\n",
      "    plt.title(title)\n",
      "    if filename is not None:\n",
      "        plt.savefig(os.path.join(result_dir, 'stages', filename + '.png'), bbox_inches='tight')\n",
      "#     plt.show()\n",
      "    plt.close();"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "frontier_contrast_diff_thresh = param['frontier_contrast_diff_thresh']\n",
      "lr_grow_thresh = param['lr_grow_thresh']\n",
      "beta = param['beta']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "seed = 1273\n",
      "c, _ = grow_cluster_relative_entropy(seed, frontier_contrast_diff_thresh=frontier_contrast_diff_thresh)\n",
      "# c, _ = grow_cluster_likelihood_ratio(i, p[i], q[i], debug=False)\n",
      "paint_cluster_on_img(c, title='relative entropy-growed from seed %d'%seed)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r = Parallel(n_jobs=16)(delayed(grow_cluster_relative_entropy)(i, frontier_contrast_diff_thresh=frontier_contrast_diff_thresh, debug=False) \n",
      "                        for i in range(n_superpixels))\n",
      "clusters = [list(c) for c, t in r]\n",
      "print 'clusters computed'\n",
      "\n",
      "plt.hist([len(c) for c in clusters], bins=200);\n",
      "plt.title('distribution of cluster sizes')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = os.path.join(result_dir, 'stages')\n",
      "if not os.path.exists(f):\n",
      "    os.makedirs(f)\n",
      "\n",
      "n_models = param['n_models']\n",
      "\n",
      "    \n",
      "texton_models = np.zeros((n_models, n_texton))\n",
      "dir_models = np.zeros((n_models, n_angle))\n",
      "\n",
      "seed_indices = np.zeros((n_models,))\n",
      "\n",
      "weights = np.ones((n_superpixels, ))/n_superpixels\n",
      "weights[bg_superpixels] = 0\n",
      "\n",
      "for t in range(n_models):\n",
      "    \n",
      "    print 'model %d' % (t)\n",
      "    \n",
      "    sig_score = np.zeros((n_superpixels, ))\n",
      "    for i in fg_superpixels:\n",
      "        cluster = clusters[i]\n",
      "        sig_score[i] = np.mean(weights[cluster] * \\\n",
      "                               (D_texton_null[cluster] - np.array([chi2(p[j], p[i]) for j in cluster]) +\\\n",
      "                               D_dir_null[cluster] - np.array([chi2(q[j], q[i]) for j in cluster])))\n",
      " \n",
      "    seed_sp = sig_score.argsort()[-1]\n",
      "#     seed_sp = 1622\n",
      "    print \"most significant superpixel\", seed_sp\n",
      "    \n",
      "    visualize_cluster(sig_score, 'all', title='significance score for each superpixel', filename='sigscore%d'%t)\n",
      "    \n",
      "    curr_cluster = clusters[seed_sp]\n",
      "    visualize_cluster(sig_score, curr_cluster, title='distance cluster', filename='curr_cluster%d'%t)\n",
      "    \n",
      "    model_texton = sp_texton_hist_normalized[curr_cluster].mean(axis=0)\n",
      "    model_dir = sp_dir_hist_normalized[curr_cluster].mean(axis=0)\n",
      "    \n",
      "    # RE(pj|pm)\n",
      "    D_texton_model = np.empty((n_superpixels,))\n",
      "    D_texton_model[fg_superpixels] = np.array([chi2(sp_texton_hist_normalized[i], model_texton) for i in fg_superpixels])\n",
      "    D_texton_model[bg_superpixels] = np.nan\n",
      "    \n",
      "    # RE(qj|qm)\n",
      "    D_dir_model = np.empty((n_superpixels,)) \n",
      "    D_dir_model[fg_superpixels] = np.array([chi2(sp_dir_hist_normalized[i], model_dir) for i in fg_superpixels])\n",
      "    D_dir_model[bg_superpixels] = np.nan\n",
      "    \n",
      "    # RE(pj|p0)-RE(pj|pm) + RE(qj|q0)-RE(qj|qm)\n",
      "    match_scores = np.empty((n_superpixels,))\n",
      "    match_scores[fg_superpixels] = D_texton_null[fg_superpixels] - D_texton_model[fg_superpixels] +\\\n",
      "                                    D_dir_model[fg_superpixels] - D_dir_model[fg_superpixels]\n",
      "    match_scores[bg_superpixels] = 0\n",
      "\n",
      "    visualize_cluster(match_scores, 'all', title='match score', filename='grow%d'%t)\n",
      "\n",
      "    \n",
      "    matched, _ = grow_cluster_likelihood_ratio(seed_sp, model_texton, model_dir, debug=False)\n",
      "    matched = list(matched)\n",
      "\n",
      "    visualize_cluster(match_scores, matched, title='growed cluster', filename='grow%d'%t)\n",
      "    \n",
      "    weights[matched] = weights[matched] * np.exp(-5*(D_texton_null[matched] - D_texton_model[matched] +\\\n",
      "                                                   D_dir_null[matched] - D_dir_model[matched])**beta)\n",
      "    weights[bg_superpixels] = 0\n",
      "    weights = weights/weights.sum()\n",
      "    visualize_cluster((weights - weights.min())/(weights.max()-weights.min()), 'all', title='updated superpixel weights', filename='weight%d'%t)\n",
      "    \n",
      "    labels = -1*np.ones_like(segmentation)\n",
      "    for i in matched:\n",
      "        labels[segmentation == i] = 1\n",
      "    real_image = label2rgb(labels, img)\n",
      "    plt.imshow(real_image, cmap=plt.cm.Greys_r)\n",
      "    plt.axis('off')\n",
      "    plt.show()\n",
      "        \n",
      "    seed_indices[t] = seed_sp\n",
      "    texton_models[t] = model_texton\n",
      "    dir_models[t] = model_dir"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "D_texton_model = -1*np.ones((n_models, n_superpixels))\n",
      "D_dir_model = -1*np.ones((n_models, n_superpixels))\n",
      "D_texton_model[:, fg_superpixels] = cdist(sp_texton_hist_normalized[fg_superpixels], texton_models, chi2).T\n",
      "D_dir_model[:, fg_superpixels] = cdist(sp_dir_hist_normalized[fg_superpixels], dir_models, chi2).T"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lr_decision_thresh = param['lr_decision_thresh']\n",
      "\n",
      "def f(i):\n",
      "    model_score = np.empty((n_models, ))\n",
      "\n",
      "    if i in bg_superpixels:\n",
      "        return -1\n",
      "    else:\n",
      "        for m in range(n_models):\n",
      "            matched, _ = grow_cluster_likelihood_ratio_precomputed(i, D_texton_model[m], D_dir_model[m], \n",
      "                                                                   lr_grow_thresh=lr_grow_thresh)\n",
      "            matched = list(matched)\n",
      "            model_score[m] = np.mean(D_texton_null[matched] - D_texton_model[m, matched] +\\\n",
      "                                     D_dir_null[matched] - D_dir_model[m, matched])\n",
      "\n",
      "        best_sig = model_score.max()\n",
      "        if best_sig > lr_decision_thresh: # sp whose sig is smaller than this is assigned null\n",
      "          return model_score.argmax()    \n",
      "    return -1\n",
      "\n",
      "r = Parallel(n_jobs=16)(delayed(f)(i) for i in range(n_superpixels))\n",
      "labels = np.array(r, dtype=np.int)\n",
      "save_array(labels, 'labels')\n",
      "\n",
      "labelmap = labels[segmentation]\n",
      "save_array(labelmap, 'labelmap')\n",
      "\n",
      "labelmap_rgb = label2rgb(labelmap.astype(np.int), image=img)\n",
      "save_img(labelmap_rgb, 'labelmap')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "FileLinks(result_dir)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "i = 618\n",
      "T = 0.3\n",
      "\n",
      "model_score = np.empty((n_models, ))\n",
      "\n",
      "if i in bg_superpixels:\n",
      "    print -1\n",
      "else:\n",
      "    for m in range(n_models):\n",
      "        matched, _ = grow_cluster_likelihood_ratio_precomputed(i, D_texton_model[m], D_dir_model[m], debug=False, grow_thresh=0.1)\n",
      "        matched = list(matched)\n",
      "        print 'model', m\n",
      "        print 'matched', matched\n",
      "#         print 'D_texton_null', D_texton_null[matched]\n",
      "#         print 'D_texton_model', D_texton_model[m, matched]\n",
      "#         print 'D_dir_null', D_dir_null[matched]\n",
      "#         print 'D_dir_model', D_dir_model[m, matched]\n",
      "        assert (D_texton_null[matched] >= 0).any()\n",
      "        assert (D_texton_model[m, matched] >= 0).any()\n",
      "        assert (D_dir_null[matched] >= 0).any()\n",
      "        assert (D_dir_model[m, matched] >= 0).any()\n",
      "        model_score[m] = np.mean(D_texton_null[matched] - D_texton_model[m, matched] +\\\n",
      "                                 D_dir_null[matched] - D_dir_model[m, matched])\n",
      "        \n",
      "    best_sig = model_score.max()\n",
      "    print 'model_score', model_score\n",
      "    if best_sig > T: # sp whose sig is smaller than this is assigned null\n",
      "      print model_score.argmax()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}