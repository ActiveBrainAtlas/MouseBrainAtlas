{
 "metadata": {
  "name": "",
  "signature": "sha256:58c5cfa7d351dd6091fd09a3c0d4d9e12396d2de938ee13d99e9ed48c6ca9fa9"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import cv2\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "import random, itertools, sys, os\n",
      "from multiprocessing import Pool\n",
      "import json\n",
      "\n",
      "from skimage.segmentation import slic, mark_boundaries\n",
      "from skimage.measure import regionprops\n",
      "from skimage.util import img_as_ubyte\n",
      "from skimage.color import hsv2rgb, label2rgb, gray2rgb\n",
      "from skimage.morphology import disk\n",
      "from skimage.filter.rank import gradient\n",
      "from skimage.filter import gabor_kernel\n",
      "from skimage.transform import rescale, resize\n",
      "\n",
      "from scipy.ndimage import gaussian_filter, measurements\n",
      "from scipy.sparse import coo_matrix\n",
      "from scipy.spatial.distance import pdist, squareform, euclidean, cdist\n",
      "from scipy.signal import fftconvolve\n",
      "\n",
      "from IPython.display import FileLink, Image, FileLinks\n",
      "\n",
      "from utilities import *\n",
      "import manager_utilities\n",
      "\n",
      "from joblib import Parallel, delayed\n",
      "\n",
      "import glob, re, os, sys, subprocess, argparse"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "parser = argparse.ArgumentParser()\n",
      "parser.add_argument(\"param_file\", type=str, help=\"parameter file name\")\n",
      "parser.add_argument(\"img_file\", type=str, help=\"path to image file\")\n",
      "parser.add_argument(\"output_dir\", type=str, help=\"directory to store outputs\")\n",
      "args = parser.parse_args()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load_array(suffix):\n",
      "    return manager_utilities.load_array(suffix, img_name, \n",
      "                                 params['param_id'], args.output_dir)\n",
      "\n",
      "def save_array(arr, suffix):\n",
      "    manager_utilities.save_array(arr, suffix, img_name, \n",
      "                                 params['param_id'], args.output_dir)\n",
      "        \n",
      "def save_img(img, suffix):\n",
      "    manager_utilities.save_img(img, suffix, img_name, params['param_id'], \n",
      "                               args.output_dir, overwrite=True)\n",
      "\n",
      "def get_img_filename(suffix, ext='tif'):\n",
      "    return manager_utilities.get_img_filename(suffix, img_name, params['param_id'], args.output_dir, ext=ext)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "params = json.load(open(args.param_file))\n",
      "\n",
      "p, ext = os.path.splitext(args.img_file)\n",
      "img_dir, img_name = os.path.split(p)\n",
      "img = cv2.imread(args.img_file, 0)\n",
      "im_height, im_width = img.shape[:2]\n",
      "\n",
      "print 'read %s' % args.img_file\n",
      "\n",
      "result_name = img_name + '_param' + str(params['param_id'])\n",
      "result_dir = os.path.join(args.output_dir, result_name)\n",
      "if not os.path.exists(result_dir):\n",
      "    os.makedirs(result_dir)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print '=== finding foreground mask ==='\n",
      "mask = foreground_mask(rescale(img, .5**3), min_size=100)\n",
      "mask = resize(mask, img.shape) > .5"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "theta_interval = params['theta_interval'] #10\n",
      "n_angle = 180/theta_interval\n",
      "freq_step = params['freq_step']\n",
      "freq_max = 1./params['min_wavelen'] #1./5.\n",
      "freq_min = 1./params['max_wavelen']\n",
      "n_freq = int(np.log(freq_max/freq_min)/np.log(freq_step)) + 1\n",
      "frequencies = freq_max/freq_step**np.arange(n_freq)\n",
      "\n",
      "kernels = [gabor_kernel(f, theta=t, bandwidth=1.) for f in frequencies \n",
      "          for t in np.arange(0, np.pi, np.deg2rad(theta_interval))]\n",
      "kernels = map(np.real, kernels)\n",
      "n_kernel = len(kernels)\n",
      "\n",
      "print '=== filter using Gabor filters ==='\n",
      "print 'num. of kernels: %d' % (n_kernel)\n",
      "print 'frequencies:', frequencies\n",
      "print 'wavelength (pixels):', 1/frequencies\n",
      "\n",
      "max_kern_size = np.max([kern.shape[0] for kern in kernels])\n",
      "print 'max kernel matrix size:', max_kern_size"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "try:\n",
      "    features = load_array('features')\n",
      "except IOError:\n",
      "    def convolve_per_proc(i):\n",
      "        return fftconvolve(img, kernels[i], 'same').astype(np.half)\n",
      "    \n",
      "    filtered = Parallel(n_jobs=16)(delayed(convolve_per_proc)(i) \n",
      "                            for i in range(n_kernel))\n",
      "\n",
      "    features = np.empty((im_height, im_width, n_kernel), dtype=np.half)\n",
      "    for i in range(n_kernel):\n",
      "        features[...,i] = filtered[i]\n",
      "\n",
      "    del filtered\n",
      "    \n",
      "    save_array(features, 'features')\n",
      "\n",
      "n_feature = features.shape[-1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'crop border where filters show border effects'\n",
      "features = features[max_kern_size:-max_kern_size, max_kern_size:-max_kern_size, :]\n",
      "img = img[max_kern_size:-max_kern_size, max_kern_size:-max_kern_size]\n",
      "mask = mask[max_kern_size:-max_kern_size, max_kern_size:-max_kern_size]\n",
      "im_height, im_width = img.shape[:2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print '=== compute rotation-invariant texton map using K-Means ==='\n",
      "\n",
      "n_texton = params['n_texton']\n",
      "\n",
      "try: \n",
      "    textonmap = load_array('textonmap')\n",
      "except IOError:\n",
      "    \n",
      "    X = features.reshape(-1, n_feature)\n",
      "    n_data = X.shape[0]\n",
      "    n_splits = 1000\n",
      "    n_sample = 10000\n",
      "    centroids = random.sample(X, n_texton)\n",
      "    \n",
      "    n_iter = 5\n",
      "\n",
      "    def compute_dist_per_proc(X_partial, c_all_rot):\n",
      "        D = cdist(X_partial, c_all_rot, 'sqeuclidean')\n",
      "        ci, ri = np.unravel_index(D.argmin(axis=1), (n_texton, n_angle))\n",
      "        return np.c_[ci, ri]\n",
      "\n",
      "    for iteration in range(n_iter):\n",
      "        \n",
      "        data = random.sample(X, n_sample)\n",
      "        \n",
      "        print 'iteration', iteration\n",
      "        centroid_all_rotations = np.vstack([np.concatenate(np.roll(np.split(c, n_freq), i)) \n",
      "                                for c,i in itertools.product(centroids, range(n_angle))])\n",
      "\n",
      "        r = Parallel(n_jobs=16)(delayed(compute_dist_per_proc)(x,c) \n",
      "                        for x, c in zip(np.array_split(data, n_splits, axis=0), \n",
      "                                        itertools.repeat(centroid_all_rotations, n_splits)))\n",
      "        res = np.vstack(r)        \n",
      "\n",
      "        labels = res[:,0]\n",
      "        rotations = res[:,1]\n",
      "\n",
      "        centroids_new = np.zeros((n_texton, n_feature))\n",
      "        for d, l, r in itertools.izip(data, labels, rotations):\n",
      "            rot = np.concatenate(np.roll(np.split(d, n_freq), i))\n",
      "            centroids_new[l] += rot\n",
      "\n",
      "        counts = np.bincount(labels)\n",
      "        centroids_new /= counts[:, np.newaxis]\n",
      "        print np.sqrt(np.sum((centroids - centroids_new)**2, axis=1)).mean()\n",
      "\n",
      "        centroids = centroids_new\n",
      "\n",
      "    print 'kmeans completes'\n",
      "    centroid_all_rotations = np.vstack([np.concatenate(np.roll(np.split(c, n_freq), i)) \n",
      "                                for c,i in itertools.product(centroids, range(n_angle))])\n",
      "\n",
      "    r = Parallel(n_jobs=16)(delayed(compute_dist_per_proc)(x,c) \n",
      "                            for x, c in zip(np.array_split(X, n_splits, axis=0), \n",
      "                                            itertools.repeat(centroid_all_rotations, n_splits)))\n",
      "    res = np.vstack(r)\n",
      "    \n",
      "    labels = res[:,0]\n",
      "    rotations = res[:,1]\n",
      "\n",
      "    textonmap = labels.reshape(features.shape[:2])\n",
      "    textonmap[~mask] = -1\n",
      "    \n",
      "    save_array(textonmap, 'textonmap')\n",
      "    \n",
      "    textonmap_rgb = label2rgb(textonmap, image=None, colors=None, alpha=0.3, image_alpha=1)\n",
      "    save_img(textonmap_rgb, 'textonmap')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print '=== over-segment the image into superpixels based on color information ==='\n",
      "\n",
      "img_rgb = gray2rgb(img)\n",
      "\n",
      "try:\n",
      "    segmentation = load_array('segmentation')\n",
      "    \n",
      "except IOError:\n",
      "    segmentation = slic(img_rgb, n_segments=params['n_superpixels'], max_iter=10, \n",
      "                        compactness=params['slic_compactness'], \n",
      "                        sigma=params['slic_sigma'], enforce_connectivity=True)\n",
      "    print 'segmentation computed'\n",
      "    \n",
      "    save_array(segmentation, 'segmentation')\n",
      "    \n",
      "sp_props = regionprops(segmentation+1, intensity_image=img, cache=True)\n",
      "\n",
      "def foo2(i):\n",
      "    return sp_props[i].centroid, sp_props[i].area, sp_props[i].mean_intensity\n",
      "\n",
      "r = Parallel(n_jobs=16)(delayed(foo2)(i) for i in range(len(sp_props)))\n",
      "sp_centroids_areas_meanintensitys = np.array(r)\n",
      "\n",
      "sp_centroids = sp_centroids_areas_meanintensitys[:,0]\n",
      "sp_areas = sp_centroids_areas_meanintensitys[:,1]\n",
      "sp_mean_intensity = sp_centroids_areas_meanintensitys[:,2]\n",
      "\n",
      "n_superpixels = len(np.unique(segmentation))\n",
      "\n",
      "img_superpixelized = mark_boundaries(img_rgb, segmentation)\n",
      "sptext = img_as_ubyte(img_superpixelized)\n",
      "for s in range(n_superpixels):\n",
      "    sptext = cv2.putText(sptext, str(s), \n",
      "                      tuple(np.floor(sp_centroids[s][::-1]).astype(np.int)), \n",
      "                      cv2.FONT_HERSHEY_COMPLEX_SMALL,\n",
      "                      .5, ((255,0,255)), 1)\n",
      "save_img(sptext, 'segmentation')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def foo(i):\n",
      "    return np.count_nonzero(mask[segmentation==i])\n",
      "\n",
      "r = Parallel(n_jobs=16)(delayed(foo)(i) for i in range(n_superpixels))\n",
      "superpixels_fg_count = np.array(r)\n",
      "bg_superpixels = np.nonzero((superpixels_fg_count/sp_areas) < 0.3)[0]\n",
      "print '%d background superpixels'%len(bg_superpixels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print '=== compute texton and directionality histogram of each superpixel ==='\n",
      "\n",
      "try:\n",
      "    sp_texton_hist_normalized = load_array('sp_texton_hist_normalized')\n",
      "except IOError:\n",
      "    def bar(i):\n",
      "        return np.bincount(textonmap[(segmentation == i)&(textonmap != -1)], minlength=n_texton)\n",
      "\n",
      "    r = Parallel(n_jobs=16)(delayed(bar)(i) for i in range(n_superpixels))\n",
      "    sp_texton_hist = np.array(r)\n",
      "    sp_texton_hist_normalized = sp_texton_hist.astype(np.float) / sp_texton_hist.sum(axis=1)[:, np.newaxis]\n",
      "    save_array(sp_texton_hist_normalized, 'sp_texton_hist_normalized')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "try:\n",
      "    sp_dir_hist_normalized = load_array('sp_dir_hist_normalized')\n",
      "except IOError:\n",
      "    f = np.reshape(features, (features.shape[0], features.shape[1], n_freq, n_angle))\n",
      "    dir_energy = np.sum(abs(f), axis=2)\n",
      "\n",
      "    def bar2(i):\n",
      "        segment_dir_energies = dir_energy[segmentation == i].astype(np.float_).sum(axis=0)\n",
      "        return segment_dir_energies/segment_dir_energies.sum()    \n",
      "\n",
      "    r = Parallel(n_jobs=16)(delayed(bar2)(i) for i in range(n_superpixels))\n",
      "    sp_dir_hist_normalized = np.vstack(r)\n",
      "    save_array(sp_dir_hist_normalized, 'sp_dir_hist_normalized')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def chi2(u,v):\n",
      "    return np.sum(np.where(u+v!=0, (u-v)**2/(u+v), 0))\n",
      "\n",
      "print '=== compute significance of each superpixel ==='\n",
      "\n",
      "overall_texton_hist = np.bincount(textonmap[mask].flat)\n",
      "overall_texton_hist_normalized = overall_texton_hist.astype(np.float) / overall_texton_hist.sum()\n",
      "\n",
      "individual_texton_saliency_score = np.array([chi2(sp_hist, overall_texton_hist_normalized) \n",
      "                                             if sp_hist not in bg_superpixels else 0 \n",
      "                                             for sp_hist in sp_texton_hist_normalized])\n",
      "\n",
      "texton_saliency_score = np.zeros((n_superpixels,))\n",
      "for i, sp_hist in enumerate(sp_texton_hist_normalized):\n",
      "    if i not in bg_superpixels:\n",
      "        texton_saliency_score[i] = individual_texton_saliency_score[i]\n",
      "        \n",
      "texton_saliency_map = texton_saliency_score[segmentation]\n",
      "\n",
      "save_img(texton_saliency_map, 'texton_saliencymap')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}