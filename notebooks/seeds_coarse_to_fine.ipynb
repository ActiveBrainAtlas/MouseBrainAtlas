{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from utilities2015 import *\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.cluster.hierarchy import average, fcluster, single, complete\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from skimage.color import gray2rgb\n",
    "from skimage.measure import find_contours\n",
    "from skimage.util import img_as_float\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from networkx import from_dict_of_lists, Graph, adjacency_matrix, connected_components\n",
    "from networkx.algorithms import node_connected_component, dfs_successors, dfs_postorder_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack_name = 'MD593'\n",
    "# section_id = 138\n",
    "# dm = DataManager(stack=stack_name, section=section_id, segm_params_id='gridsize200')\n",
    "dms = dict([(section_id, DataManager(stack=stack_name, section=section_id, segm_params_id='tSLIC200')) \n",
    "            for section_id in [138,139,140]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def obtain_props_worker(spp):\n",
    "    return spp.centroid, spp.area, spp.bbox, spp.coords\n",
    "    # (row, col), a, (min_row, min_col, max_row, max_col),(rows, cols)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/oasis/projects/nsf/csd181/yuncong/virtualenv-1.9.1/yuncongve/lib/python2.7/site-packages/PIL/Image.py:2261: DecompressionBombWarning: Image size (203470848 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning)\n",
      "/oasis/projects/nsf/csd181/yuncong/virtualenv-1.9.1/yuncongve/lib/python2.7/site-packages/skimage/util/dtype.py:111: UserWarning: Possible precision loss when converting from float64 to uint8\n",
      "  \"%s to %s\" % (dtypeobj_in, dtypeobj))\n"
     ]
    }
   ],
   "source": [
    "from skimage.segmentation import mark_boundaries, relabel_sequential\n",
    "\n",
    "grid_size = 200\n",
    "\n",
    "for si, dm in dms.iteritems():\n",
    "    \n",
    "    segmentation = np.zeros((dm.image_height, dm.image_width), np.int16)\n",
    "    rss, css = np.mgrid[0:dm.image_height:grid_size, 0:dm.image_width:grid_size]\n",
    "    for gi, (rs, cs) in enumerate(zip(rss.flat, css.flat)):\n",
    "        segmentation[rs:rs+grid_size, cs:cs+grid_size] = gi\n",
    "    \n",
    "    segmentation[~dm.mask] = -1\n",
    "\n",
    "    # segmentation starts from 0\n",
    "    masked_segmentation_relabeled, _, _ = relabel_sequential(segmentation + 1)\n",
    "\n",
    "    # make background label -1\n",
    "    dm.segmentation = masked_segmentation_relabeled - 1\n",
    "    \n",
    "    dm.n_superpixels = dm.segmentation.max() + 1\n",
    "    \n",
    "    sp_all_props = regionprops(dm.segmentation + 1, cache=True)\n",
    "    sp_props = Parallel(n_jobs=16)(delayed(obtain_props_worker)(spp) for spp in sp_all_props)\n",
    "    dm.sp_centroids, dm.sp_areas, dm.sp_bbox, dm.sp_coords = map(np.asarray, zip(*sp_props))\n",
    "    \n",
    "    dm._load_image(versions=['rgb-jpg'])\n",
    "    segViz = mark_boundaries(dm.image_rgb_jpg[dm.ymin:dm.ymax+1, dm.xmin:dm.xmax+1], \n",
    "                             dm.segmentation[dm.ymin:dm.ymax+1, dm.xmin:dm.xmax+1], \n",
    "                             color=(1,0,0))\n",
    "    \n",
    "    dm.segVizText = img_as_ubyte(segViz)\n",
    "    \n",
    "    for s in range(dm.n_superpixels):\n",
    "        cv2.putText(dm.segVizText, str(s), \n",
    "                    tuple(dm.sp_centroids[s][::-1].astype(np.int) - (dm.xmin, dm.ymin) - (10,-10)), \n",
    "                    cv2.FONT_HERSHEY_DUPLEX, .5, ((255,0,255)), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='tmp.jpg' target='_blank'>tmp.jpg</a><br>"
      ],
      "text/plain": [
       "/oasis/projects/nsf/csd395/yuncong/Brain/notebooks/tmp.jpg"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(dms[140].segVizText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for si, dm in dms.iteritems():\n",
    "    dm.load_multiple_results(['texMap'])\n",
    "    \n",
    "    hs = np.array([np.bincount(dm.textonmap[dm.sp_coords[i][:,0], dm.sp_coords[i][:,1]], \n",
    "                                     minlength=dm.n_texton)\n",
    "                         for i in range(dm.n_superpixels)])\n",
    "    dm.texton_hists = hs/hs.sum(axis=1)[:,None].astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_cluster_score(self, cluster, seed=None, seed_weight=0, verbose=False, method='rc-mean', thresh=.2):\n",
    "\n",
    "    cluster_list = list(cluster)\n",
    "    cluster_avg = self.texton_hists[cluster_list].mean(axis=0)\n",
    "\n",
    "    surrounds = set([i for i in set.union(*[self.neighbors[c] for c in cluster]) if i not in cluster and i != -1])\n",
    "\n",
    "    if len(surrounds) == 0: # single sp on background\n",
    "        return np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan\n",
    "\n",
    "    surrounds_list = list(surrounds)\n",
    "\n",
    "    # if verbose:\n",
    "    #     print 'min', surrounds_list[ds.argmin()]\n",
    "\n",
    "    ds = np.atleast_1d(np.squeeze(chi2s([cluster_avg], self.texton_hists[surrounds_list])))\n",
    "\n",
    "    if method == 'min':\n",
    "        surround_dist = ds.min()\n",
    "        if verbose:\n",
    "            print 'min', surrounds_list[ds.argmin()]\n",
    "        score = surround_dist\n",
    "\n",
    "    elif method == 'mean':\n",
    "        surround_dist = ds.mean()\n",
    "        score = surround_dist\n",
    "\n",
    "    elif method == 'percentage':\n",
    "        surround_dist = np.count_nonzero(ds > thresh) / float(len(ds)) # hard\n",
    "        score = surround_dist\n",
    "\n",
    "    elif method == 'percentage-soft':        \n",
    "        sigma = .01\n",
    "        surround_dist = np.sum(1./(1+np.exp((thresh - ds)/sigma)))/len(ds); #soft        \n",
    "        if verbose:\n",
    "            for t in sorted(zip(surrounds_list, ds), key=itemgetter(1)):\n",
    "                print t\n",
    "            plt.hist(ds, bins=np.linspace(0,1,50));\n",
    "            plt.show();\n",
    "\n",
    "        score = surround_dist\n",
    "\n",
    "    elif method == 'rc-min' or method == 'rc-mean':\n",
    "\n",
    "        sigs_front = []\n",
    "        if len(cluster) > 1:\n",
    "\n",
    "            # frontiers = set.union(*[set(self.neighbors[s]) for s in surrounds_list]) & set(cluster_list)\n",
    "            frontiers = cluster\n",
    "            for f in frontiers:\n",
    "                if len(surrounds & set(self.neighbors[f])) > 0:\n",
    "                    alternative_sps = list((surrounds & set(self.neighbors[f])) - {-1})\n",
    "                else:\n",
    "                    q = list(surrounds-{-1})\n",
    "                    alternative_sps = [q[np.squeeze(cdist([self.sp_centroids[f]], self.sp_centroids[q])).argmin()]]\n",
    "\n",
    "                # alternative_dist = np.atleast_1d(np.squeeze(chi2s([self.texton_hists[f]], \n",
    "                #                                 self.texton_hists[alternative_sps+[f]].mean(axis=0)))).min()\n",
    "                # alternative_dist = np.min([chi2(self.texton_hists[f], self.texton_hists[[s,f]].mean(axis=0)) for s in alternative_sps])\n",
    "                alternative_dist = np.mean([chi2(self.texton_hists[f], self.texton_hists[[s,f]].mean(axis=0)) for s in alternative_sps])\n",
    "\n",
    "                # interior_neighbors = list((set(cluster_list) & set(self.neighbors[f])) - {-1})\n",
    "                # interior_avg = self.texton_hists[interior_neighbors + [f]].mean(axis=0)\n",
    "                # curr_dist = .5 * chi2(self.texton_hists[f], interior_avg) + .5 * chi2(self.texton_hists[f], cluster_avg)\n",
    "\n",
    "                if seed is not None:\n",
    "                    curr_dist = chi2(self.texton_hists[f], seed_weight*self.texton_hists[seed]+(1.-seed_weight)*self.texton_hists[cluster_list].mean(axis=0))                        \n",
    "                else:\n",
    "                    curr_dist = chi2(self.texton_hists[f], self.texton_hists[cluster_list].mean(axis=0))\n",
    "\n",
    "                sig = alternative_dist - curr_dist\n",
    "                sigs_front.append(sig)\n",
    "\n",
    "            if verbose:\n",
    "                print 'frontiers advantages'\n",
    "                print zip(list(frontiers), sigs_front)\n",
    "\n",
    "        sigs_sur = []\n",
    "        for s in surrounds:\n",
    "            sur_neighbors = self.neighbors[s] - set(cluster)\n",
    "            alternative_dist = np.mean([chi2(self.texton_hists[s], self.texton_hists[[s,n]].mean(axis=0)) for n in sur_neighbors])\n",
    "\n",
    "            if seed is not None:\n",
    "                curr_dist = chi2(self.texton_hists[s], seed_weight*self.texton_hists[seed]+(1.-seed_weight)*self.texton_hists[cluster_list+[s]].mean(axis=0))\n",
    "            else:\n",
    "                curr_dist = chi2(self.texton_hists[s], self.texton_hists[cluster_list+[s]].mean(axis=0))\n",
    "\n",
    "            sig = curr_dist - alternative_dist\n",
    "            sigs_sur.append(sig)\n",
    "\n",
    "        if verbose:\n",
    "            print 'surround advantages'\n",
    "            print zip(list(surrounds), sigs_sur)\n",
    "\n",
    "        # sigs_sur = np.array(sigs_sur)\n",
    "        # sigs_front = np.array(sigs_front)\n",
    "\n",
    "        # thresh = .2\n",
    "        # # sig = int(sig > thresh)\n",
    "        # sigma = .025\n",
    "        # sigs = 1./(1+np.exp((thresh - sigs)/sigma)); #soft\n",
    "\n",
    "        if method == 'rc-min':\n",
    "            if len(sigs_front) > 0:\n",
    "                score = min(np.min(sigs_sur), np.min(sigs_front))\n",
    "                s1_max = np.max(sigs_sur)\n",
    "                s1_min = np.min(sigs_sur)\n",
    "                s2_max = np.max(sigs_front)\n",
    "                s2_min = np.min(sigs_front)\n",
    "            else:\n",
    "                score = np.min(sigs_sur)\n",
    "                s1_max = np.max(sigs_sur)\n",
    "                s1_min = np.min(sigs_sur)\n",
    "                s2_max = np.nan\n",
    "                s2_min = np.nan\n",
    "\n",
    "            # score = .5*np.min(sigs_sur)+.5*np.min(sigs_front) if len(sigs_front) > 0 else 0                \n",
    "        elif method == 'rc-mean':\n",
    "            if len(sigs_front) > 0:\n",
    "                # print np.mean(sigs_sur), np.mean(sigs_front)\n",
    "                score = .5*np.mean(sigs_sur)+.5*np.mean(sigs_front)\n",
    "                # score = max(np.mean(sigs_sur), np.mean(sigs_front))\n",
    "                s1_max = np.max(sigs_sur)\n",
    "                s1_min = np.min(sigs_sur)\n",
    "                s2_max = np.max(sigs_front)\n",
    "                s2_min = np.min(sigs_front)\n",
    "            else:\n",
    "                score = np.mean(sigs_sur)\n",
    "                s1_max = np.max(sigs_sur)\n",
    "                s1_min = np.min(sigs_sur)\n",
    "                s2_max = np.nan\n",
    "                s2_min = np.nan\n",
    "\n",
    "    else:\n",
    "        raise 'unrecognized method'\n",
    "            # print list(frontiers)[np.argmin(sigs)]\n",
    "\n",
    "\n",
    "    inter_sp_dists = np.squeeze(pdist(self.texton_hists[list(cluster)], chi2))\n",
    "    inter_sp_dist = inter_sp_dists.mean()\n",
    "\n",
    "    if seed is not None:\n",
    "        seed_dist = chi2(cluster_avg, self.texton_hists[seed])\n",
    "    else:\n",
    "        seed_dist = np.nan\n",
    "\n",
    "    if method == 'rc-min' or method == 'rc-mean':\n",
    "        return score,  np.mean(sigs_sur),  np.mean(sigs_front), inter_sp_dist, seed_dist, s1_max, s1_min, s2_max, s2_min\n",
    "    else:\n",
    "        return score,  np.nan, np.nan, inter_sp_dist, seed_dist, np.nan, np.nan, np.nan, np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grow_cluster(self, seed, seed_weight=.5,\n",
    "                verbose=False, all_history=True, \n",
    "                 num_sp_percentage_limit=0.05,\n",
    "                 min_size=1, min_distance=3, thresh=.4,\n",
    "                 threshold_abs=-0.05, threshold_rel=.4,\n",
    "                 peakedness_limit=0.001, method='rc-min'):\n",
    "\n",
    "    from networkx import from_dict_of_lists, Graph, adjacency_matrix, connected_components\n",
    "\n",
    "    from itertools import chain\n",
    "    from skimage.feature import peak_local_max\n",
    "    from scipy.spatial import ConvexHull\n",
    "    from matplotlib.path import Path\n",
    "\n",
    "    # self.load_multiple_results(['neighbors', 'texHist', 'segmentation'])\n",
    "\n",
    "    neighbor_long_graph = from_dict_of_lists(dict(enumerate(self.neighbors)))\n",
    "\n",
    "    visited = set([])\n",
    "    curr_cluster = set([])\n",
    "\n",
    "    candidate_scores = [0]\n",
    "    candidate_sps = [seed]\n",
    "\n",
    "    score_tuples = []\n",
    "    added_sps = []\n",
    "    n_sps = []\n",
    "\n",
    "    cluster_list = []\n",
    "    addorder_list = []\n",
    "\n",
    "    iter_ind = 0\n",
    "\n",
    "    hull_begin = False\n",
    "\n",
    "    nearest_surrounds = []\n",
    "    toadd_list = []\n",
    "\n",
    "    while len(candidate_sps) > 0:\n",
    "\n",
    "        if verbose:\n",
    "            print '\\niter', iter_ind\n",
    "\n",
    "        best_ind = np.argmax(candidate_scores)\n",
    "\n",
    "        just_added_score = candidate_scores[best_ind]\n",
    "        sp = candidate_sps[best_ind]\n",
    "\n",
    "        del candidate_scores[best_ind]\n",
    "        del candidate_sps[best_ind]\n",
    "\n",
    "        if sp in curr_cluster:\n",
    "            continue\n",
    "\n",
    "        curr_cluster.add(sp)\n",
    "        added_sps.append(sp)\n",
    "\n",
    "        extra_sps = []\n",
    "\n",
    "        sg = neighbor_long_graph.subgraph(list(set(range(self.n_superpixels)) - curr_cluster))\n",
    "        for c in connected_components(sg):\n",
    "            if len(c) < 10: # holes\n",
    "                extra_sps.append(c)\n",
    "\n",
    "        extra_sps = list(chain(*extra_sps))\n",
    "        curr_cluster |= set(extra_sps)\n",
    "        added_sps += extra_sps\n",
    "\n",
    "        tt = self.compute_cluster_score(curr_cluster, seed=seed, seed_weight=seed_weight, verbose=verbose, thresh=thresh, method=method)\n",
    "\n",
    "        # nearest_surround = compute_nearest_surround(curr_cluster, neighbors, texton_hists)\n",
    "        # nearest_surrounds.append(nearest_surround)\n",
    "\n",
    "        tot, s1, s2, inter_sp_dist, seed_dist, s1_max, s1_min, s2_max, s2_min = tt\n",
    "\n",
    "        cluster_avg = self.texton_hists[list(curr_cluster)].mean(axis=0)\n",
    "\n",
    "        if (len(curr_cluster) > 5 and (seed_dist > .2 or inter_sp_dist > .3)) or (len(curr_cluster) > int(self.n_superpixels * num_sp_percentage_limit)):\n",
    "            # if verbose:\n",
    "            print 'terminate', seed_dist, inter_sp_dist\n",
    "            break\n",
    "\n",
    "        if np.isnan(tot):\n",
    "            return [seed], -np.inf\n",
    "        score_tuples.append(np.r_[just_added_score, tt])\n",
    "\n",
    "        n_sps.append(len(curr_cluster))\n",
    "\n",
    "        # just_added_score, curr_total_score, exterior_score, interior_score, compactness_score, surround_pval,\n",
    "        # interior_pval, size_prior\n",
    "\n",
    "        if verbose:\n",
    "            print 'add', sp\n",
    "            print 'extra', extra_sps\n",
    "            print 'added_sps', added_sps\n",
    "            print 'curr_cluster', curr_cluster\n",
    "            print 'n_sps', n_sps\n",
    "            print 'tt', tot\n",
    "            if len(curr_cluster) != len(added_sps):\n",
    "                print len(curr_cluster), len(added_sps)\n",
    "                raise\n",
    "\n",
    "        cluster_list.append(curr_cluster.copy())\n",
    "        addorder_list.append(added_sps[:])\n",
    "        candidate_sps = (set(candidate_sps) | \\\n",
    "                         (set.union(*[self.neighbors[i] for i in list(extra_sps)+[sp]]) - {-1})) - curr_cluster\n",
    "        candidate_sps = list(candidate_sps)\n",
    "\n",
    "        # for c in candidate_sps:\n",
    "        #     int_dist = chi2(self.texton_hists[c], self.texton_hists[list(curr_cluster)+[c]].mean(axis=0))\n",
    "        #     ext_neighbors = self.neighbors[c] - set(curr_cluster)\n",
    "        #     chi2(self.texton_hists[c], self.texton_hists[s+[c]]) for s in ext_neighbors\n",
    "\n",
    "        candidate_scores = []\n",
    "        for c in candidate_sps:\n",
    "            int_neighbors = list(set(curr_cluster) & self.neighbors[c])\n",
    "            int_dist = chi2(self.texton_hists[c], self.texton_hists[int_neighbors + [c]].mean(axis=0))\n",
    "            curr_dist = chi2(self.texton_hists[c], self.texton_hists[list(curr_cluster)+[c]].mean(axis=0))\n",
    "            seed_dist = chi2(self.texton_hists[c], self.texton_hists[seed])\n",
    "            sc = .1 * int_dist + .3* curr_dist + .6*seed_dist\n",
    "            candidate_scores.append(-sc)\n",
    "\n",
    "        # h_avg = self.texton_hists[list(curr_cluster)].mean(axis=0)\n",
    "        # candidate_scores = -.5*chi2s([h_avg], self.texton_hists[candidate_sps])-\\\n",
    "        #                 .5*chi2s([self.texton_hists[seed]], self.texton_hists[candidate_sps])\n",
    "\n",
    "        # candidate_scores = candidate_scores.tolist()\n",
    "\n",
    "        if verbose:\n",
    "#                 print 'candidate', candidate_sps\n",
    "            print 'candidate\\n'\n",
    "\n",
    "            for i,j in sorted(zip(candidate_scores, candidate_sps), reverse=True):\n",
    "                print i, j\n",
    "            print 'best', candidate_sps[np.argmax(candidate_scores)]\n",
    "\n",
    "        toadd_list.append(candidate_sps[np.argmax(candidate_scores)])\n",
    "\n",
    "        iter_ind += 1\n",
    "\n",
    "    score_tuples = np.array(score_tuples)\n",
    "\n",
    "    # peaks_sorted, peakedness_sorted = find_score_peaks(score_tuples[:,1], min_size=min_size, min_distance=min_distance,\n",
    "    #                                                     threshold_abs=threshold_abs, threshold_rel=threshold_rel, \n",
    "    #                                                     peakedness_lim=peakedness_limit,\n",
    "    #                                                     verbose=verbose)\n",
    "\n",
    "    peaks_sorted1, peakedness_sorted1 = find_score_peaks(score_tuples[:,2], min_size=min_size, min_distance=min_distance,\n",
    "                                                        threshold_abs=threshold_abs, threshold_rel=threshold_rel, \n",
    "                                                        peakedness_lim=peakedness_limit,\n",
    "                                                        verbose=verbose)\n",
    "\n",
    "    peaks_sorted2, peakedness_sorted2 = find_score_peaks(score_tuples[:,3], min_size=min_size, min_distance=min_distance,\n",
    "                                                        threshold_abs=threshold_abs, threshold_rel=threshold_rel, \n",
    "                                                        peakedness_lim=peakedness_limit,\n",
    "                                                        verbose=verbose)\n",
    "\n",
    "    peaks_sorted = np.unique(np.r_[peaks_sorted1, peaks_sorted2])\n",
    "    peakedness_sorted = np.unique(np.r_[peakedness_sorted1, peakedness_sorted2])\n",
    "\n",
    "    if all_history:\n",
    "        # return addorder_list, score_tuples, peaks_sorted, peakedness_sorted, nearest_surrounds, toadd_list\n",
    "        return addorder_list, score_tuples, peaks_sorted, peakedness_sorted, toadd_list, peaks_sorted1, peaks_sorted2\n",
    "    else:\n",
    "        return [addorder_list[i] for i in peaks_sorted], score_tuples[peaks_sorted, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " computing neighbors ... done in 46.3716528416 seconds\n",
      "compute edge info ..."
     ]
    },
    {
     "ename": "NameError",
     "evalue": "global name 'cdist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-ff6105452435>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mdm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0medge_neighbors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdedge_neighbors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mneighbors_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msegmentation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msp_centroids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/oasis/projects/nsf/csd395/yuncong/Brain/notebooks/neighbors.py\u001b[0m in \u001b[0;36mneighbors_info\u001b[1;34m(segmentation, sp_centroids)\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m         \u001b[0medge_midpoints\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcdist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# closest point to the centroid\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m         \u001b[0mXc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[0mU\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mV\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msvd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: global name 'cdist' is not defined"
     ]
    }
   ],
   "source": [
    "from neighbors import *\n",
    "\n",
    "for si, dm in dms.iteritems():\n",
    "    dm.neighbors, dm.edge_neighbors, dm.dedge_neighbors = neighbors_info(dm.segmentation, dm.sp_centroids)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataManager' object has no attribute 'neighbors'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-91602587f5b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclusters_allhistory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore_tuples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpeaks_sorted\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpeaks1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpeaks2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrow_cluster\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m140\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m962\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-d939beacd3f9>\u001b[0m in \u001b[0;36mgrow_cluster\u001b[1;34m(self, seed, seed_weight, verbose, all_history, num_sp_percentage_limit, min_size, min_distance, thresh, threshold_abs, threshold_rel, peakedness_limit, method)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;31m# self.load_multiple_results(['neighbors', 'texHist', 'segmentation'])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mneighbor_long_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfrom_dict_of_lists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mvisited\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataManager' object has no attribute 'neighbors'"
     ]
    }
   ],
   "source": [
    "clusters_allhistory, score_tuples, peaks_sorted, _, _, peaks1, peaks2 = grow_cluster(dms[140], 962)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "ERROR:tornado.general:Uncaught exception, closing connection.\n",
      "Traceback (most recent call last):\n",
      "  File \"/oasis/projects/nsf/csd181/yuncong/virtualenv-1.9.1/yuncongve/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 407, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/oasis/projects/nsf/csd181/yuncong/virtualenv-1.9.1/yuncongve/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/oasis/projects/nsf/csd181/yuncong/virtualenv-1.9.1/yuncongve/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 252, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/oasis/projects/nsf/csd181/yuncong/virtualenv-1.9.1/yuncongve/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 213, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/oasis/projects/nsf/csd181/yuncong/virtualenv-1.9.1/yuncongve/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 362, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/oasis/projects/nsf/csd181/yuncong/virtualenv-1.9.1/yuncongve/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 185, in do_execute\n",
      "    tb_list = traceback.format_exception(etype, evalue, tb)\n",
      "  File \"/opt/python/lib/python2.7/traceback.py\", line 141, in format_exception\n",
      "    list = list + format_tb(tb, limit)\n",
      "  File \"/opt/python/lib/python2.7/traceback.py\", line 76, in format_tb\n",
      "    return format_list(extract_tb(tb, limit))\n",
      "  File \"/opt/python/lib/python2.7/traceback.py\", line 101, in extract_tb\n",
      "    line = linecache.getline(filename, lineno, f.f_globals)\n",
      "  File \"/oasis/projects/nsf/csd181/yuncong/virtualenv-1.9.1/yuncongve/lib/python2.7/linecache.py\", line 14, in getline\n",
      "    lines = getlines(filename, module_globals)\n",
      "  File \"/oasis/projects/nsf/csd181/yuncong/virtualenv-1.9.1/yuncongve/lib/python2.7/linecache.py\", line 40, in getlines\n",
      "    return updatecache(filename, module_globals)\n",
      "  File \"/oasis/projects/nsf/csd181/yuncong/virtualenv-1.9.1/yuncongve/lib/python2.7/linecache.py\", line 128, in updatecache\n",
      "    lines = fp.readlines()\n",
      "KeyboardInterrupt\n",
      "ERROR:tornado.general:Uncaught exception, closing connection.\n",
      "Traceback (most recent call last):\n",
      "  File \"/oasis/projects/nsf/csd181/yuncong/virtualenv-1.9.1/yuncongve/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 433, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/oasis/projects/nsf/csd181/yuncong/virtualenv-1.9.1/yuncongve/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 465, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/oasis/projects/nsf/csd181/yuncong/virtualenv-1.9.1/yuncongve/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 407, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/oasis/projects/nsf/csd181/yuncong/virtualenv-1.9.1/yuncongve/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/oasis/projects/nsf/csd181/yuncong/virtualenv-1.9.1/yuncongve/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 252, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/oasis/projects/nsf/csd181/yuncong/virtualenv-1.9.1/yuncongve/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 213, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/oasis/projects/nsf/csd181/yuncong/virtualenv-1.9.1/yuncongve/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 362, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/oasis/projects/nsf/csd181/yuncong/virtualenv-1.9.1/yuncongve/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 185, in do_execute\n",
      "    tb_list = traceback.format_exception(etype, evalue, tb)\n",
      "  File \"/opt/python/lib/python2.7/traceback.py\", line 141, in format_exception\n",
      "    list = list + format_tb(tb, limit)\n",
      "  File \"/opt/python/lib/python2.7/traceback.py\", line 76, in format_tb\n",
      "    return format_list(extract_tb(tb, limit))\n",
      "  File \"/opt/python/lib/python2.7/traceback.py\", line 101, in extract_tb\n",
      "    line = linecache.getline(filename, lineno, f.f_globals)\n",
      "  File \"/oasis/projects/nsf/csd181/yuncong/virtualenv-1.9.1/yuncongve/lib/python2.7/linecache.py\", line 14, in getline\n",
      "    lines = getlines(filename, module_globals)\n",
      "  File \"/oasis/projects/nsf/csd181/yuncong/virtualenv-1.9.1/yuncongve/lib/python2.7/linecache.py\", line 40, in getlines\n",
      "    return updatecache(filename, module_globals)\n",
      "  File \"/oasis/projects/nsf/csd181/yuncong/virtualenv-1.9.1/yuncongve/lib/python2.7/linecache.py\", line 128, in updatecache\n",
      "    lines = fp.readlines()\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "dms[140].plot_scores(peaks1, peaks2, clusters_allhistory, score_tuples, visualize_peaks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for si, dm in dms.iteritems():\n",
    "    dm.load_multiple_results(['texMap'])\n",
    "    \n",
    "    hs = np.array([np.bincount(dm.textonmap[dm.ymin+dm.sp_coords2[i][:,0], dm.xmin+dm.sp_coords2[i][:,1]], \n",
    "                                     minlength=dm.n_texton)\n",
    "                         for i in range(dm.n_superpixels2)])\n",
    "    dm.sp_hists2 = hs/hs.sum(axis=1)[:,None].astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for si, dm in dms.iteritems():\n",
    "    dm.neighbors2, _, _ = neighbors_info(dm.segmentation2, dm.sp_centroids2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_contains = {}\n",
    "for s in range(dm.n_superpixels):\n",
    "    label_contains[s] = np.unique(dm.segmentation2[dm.sp_coords[s][:,0], dm.sp_coords[s][:,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sp_label = {}\n",
    "for s, cs in label_contains.iteritems():\n",
    "    for c in cs:\n",
    "        sp_label[c] = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_contains[37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[sp_label[n] for n in dm.neighbors2[135]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display(dm.segVizText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display(dm.segVizText2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_contains_new = label_contains.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_contains_new[37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_contains_new[38] = set(label_contains_new[38]) | {135,156}\n",
    "label_contains_new[37] = set(label_contains_new[37]) - {135,156}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_sur = np.zeros((dm.n_superpixels,))\n",
    "\n",
    "for l, sps in label_contains.iteritems():\n",
    "    \n",
    "    cl = list(sps)\n",
    "    \n",
    "    surrounds = set.union(*[dm.neighbors2[i] for i in cl]) - set(cl)\n",
    "    surrounds_twohop = (set.union(*[dm.neighbors2[i] for i in surrounds]) - set(cl)) - surrounds\n",
    "    h_cl = dm.sp_hists2[cl].mean(axis=0)\n",
    "    h_sur = dm.sp_hists2[list(surrounds)].mean(axis=0)\n",
    "    h_sur2 = dm.sp_hists2[list(surrounds_twohop)].mean(axis=0)\n",
    "        \n",
    "    if h_cl[3] < 0.3:\n",
    "        d_sur[l] = chi2(h_cl, h_sur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d_sur_new = np.zeros((dm.n_superpixels,))\n",
    "\n",
    "for l, sps in label_contains_new.iteritems():\n",
    "    \n",
    "    cl = list(sps)\n",
    "    \n",
    "    surrounds = set.union(*[dm.neighbors2[i] for i in cl]) - set(cl)\n",
    "    surrounds_twohop = (set.union(*[dm.neighbors2[i] for i in surrounds]) - set(cl)) - surrounds\n",
    "    h_cl = dm.sp_hists2[cl].mean(axis=0)\n",
    "    h_sur = dm.sp_hists2[list(surrounds)].mean(axis=0)\n",
    "    h_sur2 = dm.sp_hists2[list(surrounds_twohop)].mean(axis=0)\n",
    "        \n",
    "    if h_cl[3] < 0.3:\n",
    "        d_sur_new[l] = chi2(h_cl, h_sur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d_sur_new - d_sur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dm = dms[139]\n",
    "d_sur = np.zeros((dm.n_superpixels,))\n",
    "d_sur2 = np.zeros((dm.n_superpixels,))\n",
    "for s in range(dm.n_superpixels):\n",
    "    cl = [s]\n",
    "    surrounds = set.union(*[dm.neighbors[i] for i in cl]) - set(cl)\n",
    "    surrounds_twohop = (set.union(*[dm.neighbors[i] for i in surrounds]) - set(cl)) - surrounds\n",
    "    h_cl = dm.sp_hists[cl].mean(axis=0)\n",
    "    h_sur = dm.sp_hists[list(surrounds)].mean(axis=0)\n",
    "    h_sur2 = dm.sp_hists[list(surrounds_twohop)].mean(axis=0)\n",
    "    \n",
    "    if dm.sp_hists[s,3] < 0.3:\n",
    "        d_sur[s] = chi2(h_cl, h_sur)\n",
    "        d_sur2[s] = chi2(h_cl, h_sur2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d_sur_map = d_sur[dm.segmentation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_sur_overlay = plt.cm.jet(d_sur_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d_sur_viz = alpha_blending(dm.image_rgb_jpg[dm.ymin:dm.ymax+1, dm.xmin:dm.xmax+1],\n",
    "                          d_sur_overlay[...,:3], .1, .9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display(d_sur_viz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.matshow(d_sur_map);\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d_sur2_map = d_sur2[dm.segmentation]\n",
    "plt.matshow(d_sur2_map, cmap=plt.cm.RdBu_r);\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display(dms[140].segVizText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display(dm.segVizText)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
