{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/oasis/projects/nsf/csd181/yuncong/virtualenv-1.9.1/yuncongve/lib/python2.7/site-packages/PIL/Image.py:2261: DecompressionBombWarning: Image size (167881728 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning)\n",
      "/oasis/projects/nsf/csd181/yuncong/virtualenv-1.9.1/yuncongve/lib/python2.7/site-packages/skimage/filter/__init__.py:6: skimage_deprecation: The `skimage.filter` module has been renamed to `skimage.filters`.  This placeholder module will be removed in v0.13.\n",
      "  warn(skimage_deprecation('The `skimage.filter` module has been renamed '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading image ... done in 4.32109379768 seconds\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "sys.path.append(os.path.join(os.environ['GORDON_REPO_DIR'], 'utilities'))\n",
    "from utilities2015 import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.signal import fftconvolve\n",
    "\n",
    "import bloscpack as bp\n",
    "import blosc\n",
    "\n",
    "dm = DataManager(stack='MD592',\n",
    "                 section=46)\n",
    "\n",
    "print 'reading image ...',\n",
    "t = time.time()\n",
    "dm._load_image(versions=['gray'])\n",
    "dm._generate_kernels()\n",
    "print 'done in', time.time() - t, 'seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert dm.ymin-dm.max_kern_size >= 0 and dm.xmin-dm.max_kern_size >= 0 and \\\n",
    "        dm.ymax+1+dm.max_kern_size <= dm.image_height and dm.xmax+1+dm.max_kern_size <= dm.image_width, \\\n",
    "        'Not all pixels within the mask have value from the largest kernel'\n",
    "\n",
    "def convolve_per_proc(i):\n",
    "    pf = fftconvolve(dm.image[dm.ymin-dm.max_kern_size : dm.ymax+1+dm.max_kern_size, \n",
    "                              dm.xmin-dm.max_kern_size : dm.xmax+1+dm.max_kern_size], \n",
    "                     dm.kernels[i], 'same').astype(np.half)\n",
    "    sys.stderr.write('filtered kernel %d\\n'%i)\n",
    "\n",
    "#     bp.pack_ndarray_file(pf[dm.max_kern_size:-dm.max_kern_size, dm.max_kern_size:-dm.max_kern_size].copy(), \n",
    "#                          os.environ['GORDON_RESULT_DIR']+'/feature_%03d.bp'%i)\n",
    "    \n",
    "#     return pf[dm.max_kern_size:-dm.max_kern_size, dm.max_kern_size:-dm.max_kern_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_0 = pf[dm.max_kern_size:-dm.max_kern_size, dm.max_kern_size:-dm.max_kern_size]\n",
    "plt.matshow(feature_0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# with open('/home/yuncong/CSHL_data_results/feature_000.bp', 'wb') as f:\n",
    "#     f.write(blosc.pack_array(feature_0))\n",
    "\n",
    "t = time.time()\n",
    "# features_0_load = bp.unpack_ndarray_str(bp.pack_ndarray_str(feature_0.copy()))\n",
    "features_0_load = blosc.unpack_array(blosc.pack_array(feature_0))\n",
    "print time.time() - t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# with open('/home/yuncong/CSHL_data_results/feature_000.bp', 'rb') as f:\n",
    "#     s = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "filtered kernel 0\n",
      "filtered kernel 1\n",
      "filtered kernel 2\n",
      "filtered kernel 3\n",
      "filtered kernel 4\n",
      "filtered kernel 5\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "print 'gabor filtering...',\n",
    "\n",
    "for i in range(dm.n_kernel):\n",
    "    convolve_per_proc(i)\n",
    "\n",
    "print 'done in', time.time() - t, 'seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "print 'gabor filtering...',\n",
    "\n",
    "# filtered = Parallel(n_jobs=4)(delayed(convolve_per_proc)(i) for i in range(dm.n_kernel))\n",
    "# features = np.asarray(filtered)\n",
    "# del filtered\n",
    "\n",
    "Parallel(n_jobs=4)(delayed(convolve_per_proc)(i) for i in range(dm.n_kernel))\n",
    "\n",
    "print 'done in', time.time() - t, 'seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dm.save_pipeline_result(features, 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "print 'load filtered values ...',\n",
    "\n",
    "features = []\n",
    "for i in range(dm.n_kernel):\n",
    "    a = bp.unpack_ndarray_file(os.environ['GORDON_RESULT_DIR']+'/feature_%03d.bp'%i).reshape((-1,)) \n",
    "    features.append(a)\n",
    "    \n",
    "print 'done in', time.time() - t, 'seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "print 'load filtered values ...',\n",
    "\n",
    "features = [bp.unpack_ndarray_file(os.environ['GORDON_RESULT_DIR']+'/feature_%03d.bp'%i).reshape((-1,)) \n",
    "                     for i in range(dm.n_kernel)]\n",
    "\n",
    "print 'done in', time.time() - t, 'seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = features.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rotate_features(fs, j):\n",
    "    features_tabular = fs.reshape((fs.shape[0], dm.n_freq, dm.n_angle))\n",
    "    max_angle_indices = features_tabular.max(axis=1).argmax(axis=-1)\n",
    "    features_rotated = np.reshape([np.roll(features_tabular[i], -ai, axis=-1) \n",
    "                               for i, ai in enumerate(max_angle_indices)], (fs.shape[0], dm.n_freq * dm.n_angle))\n",
    "\n",
    "    del features_tabular, max_angle_indices\n",
    "    \n",
    "#     print features_rotated.shape\n",
    "#     bp.pack_ndarray_file(features_rotated, os.environ['GORDON_RESULT_DIR']+'/featureRotated_batch_%03d.bp'%j)\n",
    "\n",
    "    return features_rotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "print 'rotating features ...',\n",
    "\n",
    "items_per_job = 100\n",
    "features_rotated = Parallel(n_jobs=8)(delayed(rotate_features)(fs, i) \n",
    "                   for i, fs in enumerate(np.array_split(features, features.shape[0]/items_per_job)))\n",
    "\n",
    "print 'done in', time.time() - t, 'seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del features_rotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_rotated = np.vstack(features_rotated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_rotated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "print 'load filtered values ...',\n",
    "\n",
    "items_per_job = 100\n",
    "features_rotated = Parallel(n_jobs=8)(delayed(rotate_features)(fs, i) \n",
    "                   for i, fs in enumerate(np.array_split(features[:10000000], 10000000/items_per_job)))\n",
    "# features_rotated = np.vstack(features_rotated)\n",
    "\n",
    "print 'done in', time.time() - t, 'seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_rotated = np.vstack(features_rotated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_rotated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage.util import pad\n",
    "\n",
    "approx_bg_intensity = dm.image[10:20, 10:20].mean()\n",
    "# approx_bg_intensity = 0\n",
    "\n",
    "masked_image = dm.image.copy()\n",
    "masked_image[~dm.mask] = approx_bg_intensity\n",
    "\n",
    "# padded_image = pad(masked_image, max_kern_size, 'constant', constant_values=approx_bg_intensity)\n",
    "padded_image = pad(masked_image, dm.max_kern_size, 'linear_ramp', end_values=approx_bg_intensity)\n",
    "\n",
    "# plt.imshow(padded_image, cm.Greys_r)\n",
    "# plt.show()\n",
    "\n",
    "# display(padded_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "b = time.time()\n",
    "\n",
    "# try:\n",
    "#     features = dm.load_pipeline_result('features', 'npy')\n",
    "    \n",
    "# except Exception as e:\n",
    "\n",
    "def convolve_per_proc(i):\n",
    "    return fftconvolve(padded_image, dm.kernels[i], 'same').astype(np.half)\n",
    "\n",
    "padded_filtered = Parallel(n_jobs=16)(delayed(convolve_per_proc)(i) \n",
    "                        for i in range(dm.n_kernel))\n",
    "\n",
    "filtered = [f[dm.max_kern_size:-dm.max_kern_size, dm.max_kern_size:-dm.max_kern_size] for f in padded_filtered]\n",
    "\n",
    "#     features = np.empty((dm.image_height, dm.image_width, n_kernel), dtype=np.half)\n",
    "#     for i in range(n_kernel):\n",
    "#         features[...,i] = filtered[i]\n",
    "\n",
    "features = np.empty((dm.n_kernel, dm.image_height, dm.image_width), dtype=np.half)\n",
    "for i in range(dm.n_kernel):\n",
    "    features[i, ...] = filtered[i]\n",
    "\n",
    "del filtered\n",
    "\n",
    "dm.save_pipeline_result(features, 'features', 'npy')\n",
    "\n",
    "print 'gabor filtering', time.time() - b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # visualize a slice of feature responses\n",
    "\n",
    "# cropped_response = features[-1]\n",
    "# plt.matshow(cropped_response, cmap=cm.coolwarm)\n",
    "# plt.colorbar()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from skimage.exposure import rescale_intensity\n",
    "# cropped_response_vis = rescale_intensity(cropped_response, out_range=(0, 255))\n",
    "# cropped_response_vis[~dm.mask] = 127\n",
    "# display(cropped_response_vis.astype(np.uint8))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
