{
 "metadata": {
  "name": "",
  "signature": "sha256:3cf683016fc71dc9f2cbb13ae591348238c1e7296eb71e27bbbb41aacb5a6cd5"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%reload_ext autoreload\n",
      "%autoreload 2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%run preamble.ipynb"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "defaultdict(<type 'list'>, {})\n"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sys.path.append('/home/yuncong/Brain/pipeline_scripts')\n",
      "from utilities import *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.spatial.distance import cdist, pdist, squareform\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "texton_hists = dm.load_pipeline_result('texHist', 'npy')\n",
      "\n",
      "segmentation = dm.load_pipeline_result('segmentation', 'npy')\n",
      "n_superpixels = len(unique(segmentation)) - 1\n",
      "\n",
      "textonmap = dm.load_pipeline_result('texMap', 'npy')\n",
      "n_texton = len(np.unique(textonmap)) - 1\n",
      "\n",
      "neighbors = dm.load_pipeline_result('neighbors', 'npy')\n",
      "\n",
      "sp_properties = dm.load_pipeline_result('spProps', 'npy')\n",
      "\n",
      "segmentation_vis = dm.load_pipeline_result('segmentationWithText', 'jpg')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/yuncong/project/DavidData2014results/RS141/0028/RS141_x5_0028_gabor-blueNisslWide-segm-blueNisslRegular-vq-blueNissl_texHist.npy\n",
        "loaded /home/yuncong/project/DavidData2014results/RS141/0028/RS141_x5_0028_gabor-blueNisslWide-segm-blueNisslRegular-vq-blueNissl_texHist.npy\n",
        "/home/yuncong/project/DavidData2014results/RS141/0028/RS141_x5_0028_segm-blueNisslRegular_segmentation.npy\n",
        "loaded /home/yuncong/project/DavidData2014results/RS141/0028/RS141_x5_0028_segm-blueNisslRegular_segmentation.npy"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "/home/yuncong/project/DavidData2014results/RS141/0028/RS141_x5_0028_gabor-blueNisslWide-vq-blueNissl_texMap.npy"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "loaded /home/yuncong/project/DavidData2014results/RS141/0028/RS141_x5_0028_gabor-blueNisslWide-vq-blueNissl_texMap.npy"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "/home/yuncong/project/DavidData2014results/RS141/0028/RS141_x5_0028_segm-blueNisslRegular_neighbors.npy"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "loaded /home/yuncong/project/DavidData2014results/RS141/0028/RS141_x5_0028_segm-blueNisslRegular_neighbors.npy"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "/home/yuncong/project/DavidData2014results/RS141/0028/RS141_x5_0028_segm-blueNisslRegular_spProps.npy\n",
        "loaded /home/yuncong/project/DavidData2014results/RS141/0028/RS141_x5_0028_segm-blueNisslRegular_spProps.npy\n",
        "/home/yuncong/project/DavidData2014results/RS141/0028/RS141_x5_0028_segm-blueNisslRegular_segmentationWithText.jpg\n",
        "loaded /home/yuncong/project/DavidData2014results/RS141/0028/RS141_x5_0028_segm-blueNisslRegular_segmentationWithText.jpg"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def compute_cluster_score(cluster, texton_hists=texton_hists, neighbors=neighbors, output=False):\n",
      "    \n",
      "    cluster_list = list(cluster)\n",
      "    hists_cluster = texton_hists[cluster_list]\n",
      "\n",
      "    cluster_avg = hists_cluster.mean(axis=0)\n",
      "    \n",
      "    surrounds = set([i for i in set.union(*[neighbors[c] for c in cluster]) if i not in cluster and i != -1])\n",
      "    \n",
      "    surrounds_list = list(surrounds)\n",
      "    \n",
      "    hists_surround = texton_hists[surrounds_list]\n",
      "    \n",
      "    avg_dists = np.atleast_1d(np.squeeze(cdist(np.atleast_2d(cluster_avg), hists_cluster, js)))\n",
      "            \n",
      "    surround_dists = np.empty((len(cluster_list), ))\n",
      "    closest_neighboring_surround_sps = np.empty((len(cluster_list), ), dtype=np.int)\n",
      "    for ind, i in enumerate(cluster_list):\n",
      "        neighboring_surround_sps = list(neighbors[i] & surrounds)\n",
      "        if len(neighboring_surround_sps) > 0:\n",
      "            ds = sp_sp_dists[i, neighboring_surround_sps]\n",
      "            surround_dists[ind] = np.min(ds)\n",
      "            closest_neighboring_surround_sps[ind] = neighboring_surround_sps[np.argmin(ds)]\n",
      "        else:\n",
      "            surround_dists[ind] = np.nan\n",
      "            closest_neighboring_surround_sps[ind] = -1\n",
      "        \n",
      "#     surround_dists = np.array([sp_sp_dists[i, cluster_list] for i in surrounds_list])\n",
      "    \n",
      "    avg_dist = np.mean(avg_dists) / np.sqrt(len(cluster_list))\n",
      "#     avg_dist = np.max(avg_dists)\n",
      "#     surround_dist = np.min(np.atleast_2d(surround_dists), axis=0).mean()\n",
      "#     surround_dist = np.min(np.atleast_2d(surround_dists), axis=0).min()\n",
      "    surround_dist = np.nanmin(surround_dists)\n",
      "#     surround_dist = np.nanmean(surround_dists)\n",
      "\n",
      "    score = surround_dist\n",
      "\n",
      "#     score = (1 + 10 * np.log(len(cluster_list))) * (surround_dist - avg_dist)\n",
      "#     if len(cluster_list) == 1:\n",
      "#         score = 0\n",
      "#     score = (1 + np.log(len(cluster_list) + 1)) * (surround_dist - .01 * avg_dist)\n",
      "#     score = (1 + .01 * len(cluster_list)) * (surround_dist - .01 * avg_dist)\n",
      "#     score = (1 + .03 * np.log(10 * len(cluster_list) + 1)) * (surround_dist - .15 * avg_dist)\n",
      "#     score = (1 + .01 * np.log(10 * len(cluster_list) + 1)) * (surround_dist - .8 * avg_dist)\n",
      "\n",
      "    if output:\n",
      "        print 'cluster', cluster_list\n",
      "        #     print 'surrounds_list', surrounds_list\n",
      "        #     argmins = np.array(surrounds_list)[np.argmin(np.atleast_2d(surround_dists), axis=0)]\n",
      "        mins = np.min(np.atleast_2d(surround_dists), axis=0)\n",
      "        adv = mins - avg_dists\n",
      "        print 'surrounds'\n",
      "        for t in zip(cluster_list, closest_neighboring_surround_sps, mins, avg_dists, adv):\n",
      "            print t\n",
      "\n",
      "        print 'sig:', score, ', surround:', surround_dist, ', model:', avg_dist\n",
      "        print \n",
      "    \n",
      "    return score, surround_dist, avg_dist"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# import cv2\n",
      "\n",
      "def visualize_cluster(cluster, segmentation=segmentation, segmentation_vis=segmentation_vis):\n",
      "\n",
      "    a = -1*np.ones_like(segmentation)\n",
      "    \n",
      "    for c in cluster:\n",
      "        a[segmentation == c] = 0\n",
      "        \n",
      "    vis = label2rgb(a, image=segmentation_vis)\n",
      "\n",
      "    vis = img_as_ubyte(vis[...,::-1])\n",
      "\n",
      "#     for i, sp in enumerate(cluster):\n",
      "#         vis = cv2.putText(vis, str(i), \n",
      "#                           tuple(np.floor(sp_properties[sp, [1,0]] - np.array([10,-10])).astype(np.int)), \n",
      "#                           cv2.FONT_HERSHEY_DUPLEX,\n",
      "#                           1., ((0,255,255)), 1)\n",
      "\n",
      "    return vis.copy()\n",
      "\n",
      "def visualize_multiple_clusters(clusters, segmentation=segmentation, segmentation_vis=segmentation_vis):\n",
      "\n",
      "    n = len(clusters)\n",
      "    m = -1*np.ones((n_superpixels,), dtype=np.int)\n",
      "    \n",
      "    for ci, c in enumerate(clusters):\n",
      "        m[list(c)] = ci\n",
      "        \n",
      "    a = m[segmentation]\n",
      "    a[~dm.mask] = -1\n",
      "    \n",
      "#     a = -1*np.ones_like(segmentation)\n",
      "#     for ci, c in enumerate(clusters):\n",
      "#         for i in c:\n",
      "#             a[segmentation == i] = ci\n",
      "\n",
      "    vis = label2rgb(a, image=segmentation_vis)\n",
      "\n",
      "    vis = img_as_ubyte(vis[...,::-1])\n",
      "\n",
      "#     for ci, c in enumerate(clusters):\n",
      "#         for i, sp in enumerate(c):\n",
      "#             vis = cv2.putText(vis, str(i), \n",
      "#                               tuple(np.floor(sp_properties[sp, [1,0]] - np.array([10,-10])).astype(np.int)), \n",
      "#                               cv2.FONT_HERSHEY_DUPLEX,\n",
      "#                               1., ((0,255,255)), 1)\n",
      "    \n",
      "    return vis.copy()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def grow_cluster(seed, output=False):\n",
      "\n",
      "#     seed = 3767\n",
      "    # null_seed = 3066\n",
      "\n",
      "    all_distances = np.atleast_1d(np.squeeze(cdist(texton_hists[seed][np.newaxis, :], texton_hists, js)))\n",
      "    # null_distances = np.atleast_1d(np.squeeze(cdist(texton_hists[null_seed][np.newaxis, :], texton_hists, js)))\n",
      "\n",
      "    ss = []\n",
      "    cc = []\n",
      "\n",
      "    # for i in np.arange(.01,null_distances[seed],.01):\n",
      "\n",
      "    for i in np.arange(.01, 0.3, .01):\n",
      "\n",
      "    #     similar_nodes = np.where(all_distances < .1)[0]\n",
      "        similar_nodes = np.where(all_distances < i)[0]\n",
      "    #     similar_nodes = np.where(all_distances < null_distances - i)[0]\n",
      "        similar_graph = neighbor_graph.subgraph(similar_nodes)\n",
      "\n",
      "        curr_cluster = node_connected_component(similar_graph, seed)\n",
      "\n",
      "        if len(curr_cluster) > int(n_superpixels * 0.05):\n",
      "            break\n",
      "            \n",
      "        cc.append(curr_cluster)\n",
      "\n",
      "        s, _, _ = compute_cluster_score(curr_cluster)\n",
      "        ss.append(s)\n",
      "        \n",
      "        if output:\n",
      "            print i, curr_cluster, s\n",
      "\n",
      "    curr_cluster = cc[np.argmax(ss)]\n",
      "    score = np.max(ss)\n",
      "    \n",
      "    return curr_cluster, score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "try:\n",
      "    sp_sp_dists = dm.load_pipeline_result('texHistPairwiseDist', 'npy')\n",
      "\n",
      "except:\n",
      "    def f(a):\n",
      "        sp_dists = cdist(a, texton_hists, metric=js)\n",
      "        return sp_dists\n",
      "\n",
      "    sp_dists = Parallel(n_jobs=16)(delayed(f)(s) for s in np.array_split(texton_hists, 16))\n",
      "    sp_sp_dists = np.vstack(sp_dists)\n",
      "    \n",
      "    dm.save_pipeline_result(sp_sp_dists, 'texHistPairwiseDist', 'npy')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/yuncong/project/DavidData2014results/RS141/0028/RS141_x5_0028_gabor-blueNisslWide-segm-blueNisslRegular-vq-blueNissl_texHistPairwiseDist.npy\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "saved /home/yuncong/project/DavidData2014results/RS141/0028/RS141_x5_0028_gabor-blueNisslWide-segm-blueNisslRegular-vq-blueNissl_texHistPairwiseDist.npy\n"
       ]
      }
     ],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.spatial.distance import cdist, pdist, squareform\n",
      "\n",
      "center_dists = pdist(sp_properties[:, :2])\n",
      "center_dist_matrix = squareform(center_dists)\n",
      "\n",
      "# k = 200\n",
      "# k_neighbors = np.argsort(center_dist_matrix, axis=1)[:, 1:k+1]\n",
      "\n",
      "# neighbor_dists = np.empty((n_superpixels, k))\n",
      "# for i in range(n_superpixels):\n",
      "# #     neighbor_dists[i] = np.squeeze(cdist(texton_hists[i][np.newaxis,:], texton_hists[k_neighbors[i]], chi2))\n",
      "#     neighbor_dists[i] = np.squeeze(cdist(texton_hists[i][np.newaxis,:], texton_hists[k_neighbors[i]], js))\n",
      "    \n",
      "# sp_sp_dists = np.nan * np.ones((n_superpixels, n_superpixels))\n",
      "# for i in range(n_superpixels):\n",
      "#     sp_sp_dists[i, k_neighbors[i]] = neighbor_dists[i]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import networkx\n",
      "from networkx.algorithms import node_connected_component\n",
      "\n",
      "neighbors_dict = dict(zip(np.arange(n_superpixels), [list(i) for i in neighbors]))\n",
      "neighbor_graph = networkx.from_dict_of_lists(neighbors_dict)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "try:\n",
      "    clusters = dm.load_pipeline_result('clusters', 'pkl')\n",
      "    \n",
      "except Exception as e:\n",
      "\n",
      "    import time\n",
      "    b = time.time()\n",
      "\n",
      "    clusters = Parallel(n_jobs=16)(delayed(grow_cluster)(s) for s in range(n_superpixels))\n",
      "\n",
      "    print time.time() - b\n",
      "\n",
      "    dm.save_pipeline_result(clusters, 'clusters', 'pkl')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/yuncong/project/DavidData2014results/RS141/0028/RS141_x5_0028_gabor-blueNisslWide-segm-blueNisslRegular-vq-blueNissl_clusters.pkl\n",
        "loaded /home/yuncong/project/DavidData2014results/RS141/0028/RS141_x5_0028_gabor-blueNisslWide-segm-blueNisslRegular-vq-blueNissl_clusters.pkl"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cluster_sps, cluster_score_sps = zip(*clusters)\n",
      "cluster_size_sps = np.array([len(c) for c in cluster_sps])\n",
      "cluster_score_sps = np.array(cluster_score_sps)\n",
      "# cluster_bounding_boxes = Parallel(n_jobs=16)(delayed(compute_bounding_box)(c) for c in cluster_sps)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "highlighted_sps = np.where((cluster_size_sps < 200) & (cluster_size_sps > 4))[0]\n",
      "n_highlights = len(highlighted_sps)\n",
      "print n_highlights\n",
      "highlighted_clusters = [cluster_sps[s] for s in highlighted_sps]\n",
      "highlighted_scores = [cluster_score_sps[s] for s in highlighted_sps]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1591\n"
       ]
      }
     ],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.spatial.distance import pdist, squareform\n",
      "from scipy.cluster.hierarchy import average, fcluster, leaders, complete, single, dendrogram\n",
      "\n",
      "def group_clusters(clusters, dist_thresh = 0.1):\n",
      "\n",
      "    n_clusters = len(clusters)\n",
      "    \n",
      "    overlap_matrix = np.zeros((n_clusters, n_clusters))\n",
      "    \n",
      "    for i in range(n_clusters):\n",
      "        for j in range(n_clusters):\n",
      "            if i == j:\n",
      "                overlap_matrix[i, j] = 1\n",
      "            else:\n",
      "                c1 = set(clusters[i])\n",
      "                c2 = set(clusters[j])\n",
      "                overlap_matrix[i, j] = float(len(c1 & c2))/min(len(c1),len(c2))\n",
      "\n",
      "    distance_matrix = 1 - overlap_matrix\n",
      "    \n",
      "#     lk = average(squareform(distance_matrix))\n",
      "    lk = single(squareform(distance_matrix))\n",
      "\n",
      "    # T = fcluster(lk, 1.15, criterion='inconsistent')\n",
      "    T = fcluster(lk, dist_thresh, criterion='distance')\n",
      "\n",
      "    n_groups = len(set(T))\n",
      "    print n_groups, 'groups'\n",
      "    \n",
      "    groups = [None] * n_groups\n",
      "\n",
      "    for group_id in range(n_groups):\n",
      "        groups[group_id] = where(T == group_id)[0]\n",
      "    \n",
      "        \n",
      "    return groups"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "highlighted_groups = group_clusters(highlighted_clusters)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "133 groups\n"
       ]
      }
     ],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sp_groups = [ [highlighted_sps[i] for i in group] for group in highlighted_groups if len(group) > 1]\n",
      "union_clusters = [cluster_sps[g[np.argmax(cluster_score_sps[g])]] for g in sp_groups]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "union_cluster_groups = group_clusters(union_clusters, dist_thresh=0.5)\n",
      "union_cluster_groups = [u for u in union_cluster_groups if len(u) > 0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# union_cluster_union_clusters = [set.union(*[set(union_clusters[i]) for i in g]) for g in union_cluster_groups]\n",
      "# union_cluster_union_clusters = [set.intersection(*[set(union_clusters[i]) for i in g]) for g in union_cluster_groups]\n",
      "union_cluster_union_clusters = [union_clusters[g[np.argmax([compute_cluster_score(union_clusters[i])[0] for i in g])]] \n",
      "                                for g in union_cluster_groups]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filtered_group_scores = np.array([compute_cluster_score(g)[0] for g in union_clusters])\n",
      "# filtered_group_scores = np.array([compute_cluster_score(g)[0] for g in union_cluter_union_clusters])\n",
      "# filtered_group_scores = [cluster_score_sps[list(g)].max() for g in filtered_groups]\n",
      "\n",
      "arg_score_sorted = np.argsort(filtered_group_scores)[::-1]\n",
      "\n",
      "union_cluster_union_clusters_sorted = [union_clusters[i] for i in arg_score_sorted]\n",
      "\n",
      "print len(union_cluster_union_clusters_sorted)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "84\n"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dm.save_pipeline_result(union_cluster_union_clusters_sorted, 'groups', 'pkl')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# for i, (g, s) in enumerate(zip(union_cluster_union_clusters_sorted, filtered_group_scores[arg_score_sorted])):\n",
      "#     print i, g, s"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def display(vis, filename='tmp.jpg'):\n",
      "    \n",
      "    if vis.dtype != np.uint8:\n",
      "        imsave(filename, img_as_ubyte(vis))\n",
      "    else:\n",
      "        imsave(filename, vis)\n",
      "            \n",
      "    from IPython.display import FileLink\n",
      "    return FileLink(filename)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vis = visualize_multiple_clusters(union_cluster_union_clusters_sorted[:10])\n",
      "display(vis)\n",
      "# dm.save_pipeline_result(vis, 'groupsTop10Vis', 'jpg', is_rgb=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<a href='tmp.jpg' target='_blank'>tmp.jpg</a><br>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 44,
       "text": [
        "/oasis/projects/nsf/csd181/yuncong/Brain/notebooks/tmp.jpg"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vis = visualize_multiple_clusters(union_cluster_union_clusters_sorted[10:20])\n",
      "display(vis)\n",
      "# dm.save_pipeline_result(vis, 'groupsTop10to20Vis', 'jpg', is_rgb=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<a href='tmp.jpg' target='_blank'>tmp.jpg</a><br>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "/oasis/projects/nsf/csd181/yuncong/Brain/notebooks/tmp.jpg"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vis = visualize_multiple_clusters(union_cluster_union_clusters_sorted[20:30])\n",
      "display(vis)\n",
      "# dm.save_pipeline_result(vis, 'groupsTop20to30Vis', 'jpg', is_rgb=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<a href='tmp.jpg' target='_blank'>tmp.jpg</a><br>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "/oasis/projects/nsf/csd181/yuncong/Brain/notebooks/tmp.jpg"
       ]
      }
     ],
     "prompt_number": 24
    }
   ],
   "metadata": {}
  }
 ]
}