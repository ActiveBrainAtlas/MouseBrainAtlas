{
 "metadata": {
  "name": "",
  "signature": "sha256:a00741f997a137b777e0e5c29c1cfb628faa69f7e5a8b812ed63f36c2027b973"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "sys.path.append('/home/yuncong/Brain/pipeline_scripts')\n",
      "from utilities2014 import *\n",
      "import os\n",
      "\n",
      "from scipy.spatial.distance import cdist, pdist, squareform\n",
      "from joblib import Parallel, delayed\n",
      "from skimage.color import gray2rgb\n",
      "\n",
      "import networkx\n",
      "from networkx.algorithms import node_connected_component\n",
      "\n",
      "%run grow_regions_common.ipynb\n",
      "\n",
      "os.environ['GORDON_DATA_DIR'] = '/home/yuncong/project/DavidData2014tif/'\n",
      "os.environ['GORDON_REPO_DIR'] = '/home/yuncong/Brain'\n",
      "os.environ['GORDON_RESULT_DIR'] = '/home/yuncong/project/DavidData2014results/'\n",
      "os.environ['GORDON_LABELING_DIR'] = '/home/yuncong/project/DavidData2014labelings/'\n",
      "\n",
      "dm = DataManager(data_dir=os.environ['GORDON_DATA_DIR'], \n",
      "  repo_dir=os.environ['GORDON_REPO_DIR'], \n",
      "  result_dir=os.environ['GORDON_RESULT_DIR'], \n",
      "  labeling_dir=os.environ['GORDON_LABELING_DIR'])\n",
      "\n",
      "dm.set_stack('RS141')\n",
      "dm.set_resol('x5')\n",
      "dm.set_gabor_params(gabor_params_id='blueNisslWide')\n",
      "dm.set_segmentation_params(segm_params_id='blueNisslRegular')\n",
      "dm.set_vq_params(vq_params_id='blueNissl')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def alpha_blending(src_rgb, dst_rgb, src_alpha, dst_alpha):\n",
      "    \n",
      "    out_alpha = src_alpha + dst_alpha * (1. - src_alpha)\n",
      "    out_rgb = (src_rgb * src_alpha[..., None] +\n",
      "               dst_rgb * dst_alpha[..., None] * (1. - src_alpha[..., None])) / out_alpha[..., None]\n",
      "    \n",
      "    out = np.zeros((src_rgb.shape[0], src_rgb.shape[1], 4))\n",
      "        \n",
      "    out[..., :3] = out_rgb\n",
      "    out[..., 3] = out_alpha\n",
      "    \n",
      "    return out"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def compute_boundariness_vote(clusters, neighbors, mode=None):\n",
      "\n",
      "    cluster_sps, cluster_score_sps = zip(*clusters)\n",
      "    cluster_size_sps = np.array([len(c) for c in cluster_sps])\n",
      "    cluster_score_sps = np.array(cluster_score_sps)\n",
      "    # cluster_bounding_boxes = Parallel(n_jobs=16)(delayed(compute_bounding_box)(c) for c in cluster_sps)\n",
      "    \n",
      "    sp_votes = np.zeros((n_superpixels,), dtype=np.float)\n",
      "\n",
      "    border_sps = []\n",
      "\n",
      "    for j, cluster in enumerate(cluster_sps):\n",
      "        surrounds = set([i for i in set.union(*[neighbors[c] for c in cluster]) if i not in cluster and i != -1])        \n",
      "        if len(surrounds) == 0:\n",
      "            continue\n",
      "\n",
      "        if mode=='frontiers':\n",
      "            frontiers = set.union(*[neighbors[c] for c in surrounds]) & set(cluster)\n",
      "            border = frontiers\n",
      "        elif mode=='surrounds':\n",
      "            border = surrounds\n",
      "        elif mode=='both':\n",
      "            border = surrounds | frontiers\n",
      "        \n",
      "        border_sps.append(border)\n",
      "\n",
      "    #     weight = 1./np.sqrt(len(cluster))\n",
      "        weight = 1.\n",
      "        sp_votes[list(surrounds)] += weight\n",
      "    \n",
      "    return sp_votes, border_sps"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def show_votemap(section_ind):\n",
      "\n",
      "    sp_votes = compute_boundariness_vote(section_ind)\n",
      "    \n",
      "    votemap = sp_votes[segmentation]\n",
      "    votemap[~dm.mask] = 0\n",
      "\n",
      "#     from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
      "\n",
      "#     fig = plt.figure(figsize=(20,20))\n",
      "\n",
      "#     ax1 = fig.add_subplot(211)\n",
      "#     ax1.imshow(dm.image, aspect='equal', cmap=plt.cm.gray)\n",
      "#     ax1.axis('off')\n",
      "\n",
      "#     ax2 = fig.add_subplot(212)\n",
      "#     votemap_im = ax2.imshow(votemap, aspect='equal')\n",
      "#     ax2.axis('off')\n",
      "#     divider = make_axes_locatable(ax2)\n",
      "#     cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
      "#     plt.colorbar(votemap_im, cax=cax);\n",
      "\n",
      "#     plt.tight_layout()\n",
      "#     plt.show()\n",
      "\n",
      "#     return votemap\n",
      "\n",
      "    votemap_normalized = (votemap-votemap.min())/(votemap.max()-votemap.min())\n",
      "    votemap_vis = plt.cm.Reds(votemap_normalized)[..., :3]\n",
      "\n",
      "    \n",
      "    vis = alpha_blending(votemap_vis, gray2rgb(dm.image), .5 * np.ones_like(dm.image),\n",
      "                          1. * np.ones_like(dm.image))\n",
      "    \n",
      "\n",
      "    dm.save_pipeline_result(votemap_vis, 'votemap', 'jpg')\n",
      "    dm.save_pipeline_result(vis, 'votemapOverlaid', 'jpg')\n",
      "    \n",
      "    return votemap_normalized, votemap_vis\n",
      "    \n",
      "#     return vis\n",
      "#     plt.imshow(vis)\n",
      "            \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.spatial.distance import pdist, squareform\n",
      "from scipy.cluster.hierarchy import average, fcluster, leaders, complete, single, dendrogram\n",
      "\n",
      "def f(indices, sets):\n",
      "    n_sets = len(sets)\n",
      "    \n",
      "    overlap_matrix = np.zeros((len(indices), n_sets))\n",
      "        \n",
      "    for ii, i in enumerate(indices):\n",
      "        for j in range(n_sets):\n",
      "            c1 = set(sets[i])\n",
      "            c2 = set(sets[j])\n",
      "            overlap_matrix[ii, j] = float(len(c1 & c2))/min(len(c1),len(c2))\n",
      "\n",
      "    return overlap_matrix\n",
      "\n",
      "def set_pairwise_distances(sets):\n",
      "\n",
      "    partial_overlap_mat = Parallel(n_jobs=16, max_nbytes=1e6)(delayed(f)(s, sets) \n",
      "                                        for s in np.array_split(range(len(sets)), 16))\n",
      "    overlap_matrix = np.vstack(partial_overlap_mat)\n",
      "    distance_matrix = 1 - overlap_matrix\n",
      "    \n",
      "    return distance_matrix\n",
      "\n",
      "def group_clusters(clusters=None, dist_thresh = 0.1, distance_matrix=None):\n",
      "\n",
      "    if distance_matrix is None:\n",
      "        assert clusters is not None\n",
      "        distance_matrix = set_pairwise_distances(clusters)\n",
      "        \n",
      "    lk = average(squareform(distance_matrix))\n",
      "#     lk = single(squareform(distance_matrix))\n",
      "\n",
      "    # T = fcluster(lk, 1.15, criterion='inconsistent')\n",
      "    T = fcluster(lk, dist_thresh, criterion='distance')\n",
      "\n",
      "    n_groups = len(set(T))\n",
      "    print n_groups, 'groups'\n",
      "    \n",
      "    groups = [None] * n_groups\n",
      "\n",
      "    for group_id in range(n_groups):\n",
      "        groups[group_id] = where(T == group_id)[0]\n",
      "        \n",
      "    return groups"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}