{
 "metadata": {
  "name": "",
  "signature": "sha256:8ac2dee33170ce8fb79ff0facc7319ea4b15626ba8a6874cf107fab2a8b9a612"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext autoreload\n",
      "%autoreload 2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from utilities import *\n",
      "\n",
      "if 'SSH_CONNECTION' in os.environ:\n",
      "    DATA_DIR = '/home/yuncong/DavidData'\n",
      "    REPO_DIR = '/home/yuncong/Brain'\n",
      "else:\n",
      "    DATA_DIR = '/home/yuncong/BrainLocal/DavidData_v4'\n",
      "    REPO_DIR = '/home/yuncong/Brain'\n",
      "\n",
      "dm = DataManager(DATA_DIR, REPO_DIR)\n",
      "\n",
      "# import argparse\n",
      "# import sys\n",
      "\n",
      "# parser = argparse.ArgumentParser(\n",
      "# formatter_class=argparse.RawDescriptionHelpFormatter,\n",
      "# description='Execute feature extraction pipeline',\n",
      "# epilog=\"\"\"\n",
      "# The following command processes image RS141_x5_0001.tif using blueNissl for both gabor parameters and segmentation parameters.\n",
      "# python %s RS141 x5 1 -g blueNissl -s blueNissl\n",
      "# \"\"\"%(os.path.basename(sys.argv[0]), ))\n",
      "\n",
      "# parser.add_argument(\"stack_name\", type=str, help=\"stack name\")\n",
      "# parser.add_argument(\"resolution\", type=str, help=\"resolution string\")\n",
      "# parser.add_argument(\"slice_ind\", type=int, help=\"slice index\")\n",
      "# parser.add_argument(\"-g\", \"--gabor_params_id\", type=str, help=\"gabor filter parameters id (default: %(default)s)\", default='blueNissl')\n",
      "# parser.add_argument(\"-s\", \"--segm_params_id\", type=str, help=\"segmentation parameters id (default: %(default)s)\", default='blueNissl')\n",
      "# args = parser.parse_args()\n",
      "\n",
      "class args:\n",
      "    stack_name = 'RS141'\n",
      "    resolution = 'x5'\n",
      "    slice_ind = 1\n",
      "    gabor_params_id = 'blueNisslWide'\n",
      "    segm_params_id = 'blueNissl'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dm.set_image(args.stack_name, args.resolution, args.slice_ind)\n",
      "dm.set_gabor_params(gabor_params_id=args.gabor_params_id)\n",
      "dm.set_segmentation_params(segm_params_id=args.segm_params_id)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# @timeit\n",
      "# def build_gabor_kernels(gabor_params):\n",
      "#     \"\"\"\n",
      "#     Generate the Gabor kernels\n",
      "#     \"\"\"\n",
      "\n",
      "from skimage.filter import gabor_kernel\n",
      "\n",
      "theta_interval = dm.gabor_params['theta_interval']\n",
      "n_angle = int(180/theta_interval)\n",
      "freq_step = dm.gabor_params['freq_step']\n",
      "freq_max = 1./dm.gabor_params['min_wavelen']\n",
      "freq_min = 1./dm.gabor_params['max_wavelen']\n",
      "bandwidth = dm.gabor_params['bandwidth']\n",
      "n_freq = int(np.log(freq_max/freq_min)/np.log(freq_step)) + 1\n",
      "frequencies = freq_max/freq_step**np.arange(n_freq)\n",
      "angles = np.arange(0, n_angle)*np.deg2rad(theta_interval)\n",
      "\n",
      "kernels = [gabor_kernel(f, theta=t, bandwidth=bandwidth) for f in frequencies for t in angles]\n",
      "kernels = map(np.real, kernels)\n",
      "\n",
      "n_kernel = len(kernels)\n",
      "\n",
      "print 'num. of kernels: %d' % (n_kernel)\n",
      "print 'frequencies:', frequencies\n",
      "print 'wavelength (pixels):', 1/frequencies\n",
      "\n",
      "max_kern_size = np.max([kern.shape[0] for kern in kernels])\n",
      "print 'max kernel matrix size:', max_kern_size"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "biases = np.array([k.sum() for k in kernels])\n",
      "mean_bias = biases.mean()\n",
      "kernels = [k/k.sum()*mean_bias for k in kernels]\n",
      "\n",
      "# dm.save_pipeline_result(kernels, 'kernels', 'pkl')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def crop_borders(data):\n",
      "    cropped_data = data[max_kern_size/2:-max_kern_size/2, max_kern_size/2:-max_kern_size/2, ...].copy()\n",
      "    return cropped_data\n",
      "\n",
      "# crop borders\n",
      "\n",
      "try:\n",
      "    cropped_features = dm.load_pipeline_result('cropFeatures', 'npy')\n",
      "except:\n",
      "    cropped_features = crop_borders(features)\n",
      "    dm.save_pipeline_result(cropped_features, 'cropFeatures', 'npy')\n",
      "\n",
      "try:\n",
      "    cropped_img = dm.load_pipeline_result('cropImg', 'tif')    \n",
      "except:\n",
      "    cropped_img = crop_borders(dm.image)\n",
      "    dm.save_pipeline_result(cropped_img, 'cropImg', 'tif')\n",
      "\n",
      "try:\n",
      "    cropped_mask = dm.load_pipeline_result('cropMask', 'npy')\n",
      "except:\n",
      "    cropped_mask = crop_borders(dm.mask)\n",
      "    dm.save_pipeline_result(cropped_mask, 'cropMask', 'npy')\n",
      "    dm.save_pipeline_result(cropped_mask, 'cropMask', 'tif')\n",
      "\n",
      "cropped_height, cropped_width = cropped_img.shape[:2]\n",
      "print cropped_height, cropped_width"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "valid_features = cropped_features[cropped_mask]\n",
      "n_valid = len(valid_features)\n",
      "\n",
      "# del cropped_features"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def rotate_features(fs):\n",
      "    features_tabular = fs.reshape((fs.shape[0], n_freq, n_angle))\n",
      "    max_angle_indices = features_tabular.max(axis=1).argmax(axis=-1)\n",
      "    features_rotated = np.reshape([np.roll(features_tabular[i], -ai, axis=-1) \n",
      "                               for i, ai in enumerate(max_angle_indices)], (fs.shape[0], n_freq * n_angle))\n",
      "    \n",
      "    return features_rotated\n",
      "\n",
      "from joblib import Parallel, delayed\n",
      "\n",
      "n_splits = 1000\n",
      "features_rotated_list = Parallel(n_jobs=16)(delayed(rotate_features)(fs) for fs in np.array_split(valid_features, n_splits))\n",
      "features_rotated = np.vstack(features_rotated_list)\n",
      "\n",
      "del valid_features"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dm.save_pipeline_result(features_rotated, 'features_rotated', 'npy')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "b = time.time()\n",
      "\n",
      "n_components = 5\n",
      "\n",
      "from sklearn.decomposition import RandomizedPCA \n",
      "pca = RandomizedPCA(n_components=n_components, whiten=True)\n",
      "# pca = PCA(n_components=n_components, whiten=True)\n",
      "pca.fit(features_rotated)\n",
      "print(pca.explained_variance_ratio_)\n",
      "\n",
      "features_rotated_pca = pca.transform(features_rotated)\n",
      "\n",
      "print time.time() - b"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dm.save_pipeline_result(features_rotated_pca, 'features_rotated_pca', 'npy')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# n_texton = 100\n",
      "n_texton = 10\n",
      "\n",
      "from sklearn.cluster import MiniBatchKMeans\n",
      "kmeans = MiniBatchKMeans(n_clusters=n_texton, batch_size=1000)\n",
      "kmeans.fit(features_rotated_pca)\n",
      "# kmeans.fit(features_rotated)\n",
      "centroids = kmeans.cluster_centers_\n",
      "labels = kmeans.labels_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = np.random.choice(features_rotated_pca.shape[0], 1000)\n",
      "\n",
      "plt.scatter(features_rotated_pca[a, 0], features_rotated_pca[a, 1], c='r')\n",
      "\n",
      "plt.scatter(centroids[:, 0], centroids[:, 1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# from scipy.spatial.distance import pdist, squareform\n",
      "\n",
      "# D = squareform(pdist(centroids))\n",
      "# Dmin = D[D > 0].min()\n",
      "# Dmax = D.max()\n",
      "# plt.matshow(D, vmin=Dmin, vmax=Dmax)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# hc_colors = np.loadtxt('hc_colors.txt', delimiter=',')/ 255.\n",
      "# hc_colors = np.loadtxt('../visualization/high_contrast_colors.txt')/ 255.\n",
      "\n",
      "hc_colors = np.loadtxt('../visualization/100colors.txt')\n",
      "\n",
      "# hc_colors = np.random.random((n_texton, 3))\n",
      "# np.savetxt('../visualization/100colors.txt', hc_colors)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Visualize textons and color codes (in original space)\n",
      "\n",
      "n_cols = 10\n",
      "n_rows = int(np.ceil(n_texton/n_cols))\n",
      "\n",
      "fig, axes = plt.subplots(2*n_rows, n_cols, figsize=(20,5), facecolor='white')\n",
      "axes = np.atleast_2d(axes)\n",
      "\n",
      "vmin = centroids.min()\n",
      "vmax = centroids.max()\n",
      "\n",
      "for i in range(n_rows):\n",
      "    for j in range(n_cols):\n",
      "        axes[2*i, j].set_title('texton %d'%(i*10+j))\n",
      "        axes[2*i, j].matshow(centroids[i*10+j].reshape(n_freq, n_angle), vmin=vmin, vmax=vmax)\n",
      "        axes[2*i, j].set_xticks([])\n",
      "        axes[2*i, j].set_yticks([])\n",
      "        \n",
      "        cbox = np.ones((3,10,3))\n",
      "        cbox[:,:,:] = hc_colors[i*10+j]\n",
      "        axes[2*i+1, j].imshow(cbox)\n",
      "        axes[2*i+1, j].set_xticks([])\n",
      "        axes[2*i+1, j].set_yticks([])\n",
      "        \n",
      "# plt.tight_layout()\n",
      "\n",
      "plt.subplots_adjust(left=0, right=1., top=1, bottom=0., wspace=0.1, hspace=0)\n",
      "\n",
      "# plt.savefig('textons2.png', bbox_inches='tight')\n",
      "# plt.close(fig)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Visualize textons (in original space)\n",
      "\n",
      "n_cols = 10\n",
      "n_rows = int(np.ceil(n_texton/n_cols))\n",
      "\n",
      "fig, axes = plt.subplots(n_rows, n_cols, figsize=(20,20), facecolor='white')\n",
      "axes = np.atleast_2d(axes)\n",
      "\n",
      "vmin = centroids.min()\n",
      "vmax = centroids.max()\n",
      "\n",
      "for i in range(n_rows):\n",
      "    for j in range(n_cols):\n",
      "        axes[i, j].set_title('texton %d'%(i*10+j))\n",
      "        axes[i, j].matshow(centroids[i*10+j].reshape(n_freq, n_angle), vmin=vmin, vmax=vmax)\n",
      "        axes[i, j].set_xticks([])\n",
      "        axes[i, j].set_yticks([])\n",
      "        \n",
      "plt.tight_layout()\n",
      "\n",
      "# plt.savefig('textons2.png', bbox_inches='tight')\n",
      "# plt.close(fig)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Visualize color codes (in original space)\n",
      "\n",
      "n_cols = 10\n",
      "n_rows = int(np.ceil(n_texton/n_cols))\n",
      "\n",
      "fig, axes = plt.subplots(n_rows, n_cols, figsize=(20,20), facecolor='white')\n",
      "axes = np.atleast_2d(axes)\n",
      "\n",
      "for i in range(n_rows):\n",
      "    for j in range(n_cols):\n",
      "        axes[i, j].set_title('texton %d'%(i*10+j))\n",
      "        cbox = np.ones((10,10,3))\n",
      "        cbox[:,:,:] = hc_colors[i*10+j]\n",
      "        axes[i, j].imshow(cbox)\n",
      "        axes[i, j].set_xticks([])\n",
      "        axes[i, j].set_yticks([])\n",
      "        \n",
      "plt.tight_layout()\n",
      "\n",
      "# plt.savefig('textons2.png', bbox_inches='tight')\n",
      "# plt.close(fig)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# a = np.random.choice(features_rotated.shape[0], 10000)\n",
      "# plt.scatter(features_rotated[a, 0], features_rotated[a, 1], c='r', s=.1)\n",
      "# plt.scatter(centroids[:, 0], centroids[:, 1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "textonmap = -1 * np.ones_like(cropped_img, dtype=np.int)\n",
      "textonmap[cropped_mask] = labels\n",
      "# vis = label2rgb(textonmap, image=cropped_img)\n",
      "vis = label2rgb(textonmap, colors=hc_colors, alpha=1.)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.hist(textonmap.flat, bins=np.arange(n_texton+1))\n",
      "plt.xlabel('texton')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cv2.imwrite('textonmap2.png', img_as_ubyte(vis)[..., ::-1])\n",
      "from IPython.display import FileLink\n",
      "FileLink('textonmap2.png')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for s in range(n_texton):\n",
      "    print s\n",
      "    overlayed = overlay_labels(cropped_img, textonmap, [s])\n",
      "    cv2.imwrite('overlayed_pca_texton%d.png'%s, img_as_ubyte(overlayed)[..., ::-1])\n",
      "#     from IPython.display import FileLink\n",
      "#     FileLink('overlayed.png')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def overlay_labels(image, lbp, labels):\n",
      "    mask = np.logical_or.reduce([lbp == each for each in labels])\n",
      "    return label2rgb(mask, image=image, bg_label=0, alpha=0.5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Visualize textons\n",
      "\n",
      "n_cols = 10\n",
      "n_rows = int(np.ceil(n_texton/n_cols))\n",
      "\n",
      "fig, axes = plt.subplots(n_rows, n_cols, figsize=(20,5), facecolor='white', sharey=True)\n",
      "axes = np.atleast_2d(axes)\n",
      "\n",
      "for i in range(n_rows):\n",
      "    for j in range(n_cols):\n",
      "        axes[i, j].set_title('texton %d'%(i*10+j))\n",
      "        axes[i, j].bar(np.arange(n_components), centroids[i*10+j])\n",
      "        axes[i, j].set_xticks([])\n",
      "        axes[i, j].set_yticks([])\n",
      "        \n",
      "plt.tight_layout()\n",
      "\n",
      "# plt.savefig('textons2.png', bbox_inches='tight')\n",
      "# plt.close(fig)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Over-segment the image into superpixels using SLIC (http://ivrg.epfl.ch/research/superpixels)\n",
      "\n",
      "from skimage.segmentation import slic, mark_boundaries\n",
      "from skimage.util import img_as_ubyte\n",
      "\n",
      "img_rgb = gray2rgb(dm.image)\n",
      "\n",
      "try:\n",
      "    segmentation = dm.load_pipeline_result('segmentation', 'npy')\n",
      "    \n",
      "except Exception as e:\n",
      "    segmentation = slic(img_rgb, n_segments=int(dm.segm_params['n_superpixels']), \n",
      "                        max_iter=10, \n",
      "                        compactness=float(dm.segm_params['slic_compactness']), \n",
      "                        sigma=float(dm.segm_params['slic_sigma']), \n",
      "                        enforce_connectivity=True)\n",
      "    print 'segmentation computed'\n",
      "    \n",
      "    dm.save_pipeline_result(segmentation.astype(np.int16), 'segmentation', 'npy')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from skimage.segmentation import relabel_sequential\n",
      "\n",
      "try:\n",
      "    cropped_segmentation_relabeled = dm.load_pipeline_result('cropSegmentation', 'npy')\n",
      "except:\n",
      "    # segmentation starts from 0\n",
      "    cropped_segmentation = crop_borders(segmentation)\n",
      "    n_superpixels = len(np.unique(cropped_segmentation))\n",
      "    cropped_segmentation[~cropped_mask] = -1\n",
      "    cropped_segmentation_relabeled, fw, inv = relabel_sequential(cropped_segmentation + 1)\n",
      "\n",
      "    # make background label -1\n",
      "    cropped_segmentation_relabeled -= 1\n",
      "    dm.save_pipeline_result(cropped_segmentation_relabeled, 'cropSegmentation', 'npy')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sp_props = regionprops(cropped_segmentation_relabeled + 1, intensity_image=cropped_img, cache=True)\n",
      "\n",
      "def obtain_props_worker(i):\n",
      "    return sp_props[i].centroid, sp_props[i].area, sp_props[i].mean_intensity, sp_props[i].bbox\n",
      "\n",
      "r = Parallel(n_jobs=16)(delayed(obtain_props_worker)(i) for i in range(len(sp_props)))\n",
      "sp_centroids = np.array([s[0] for s in r])\n",
      "sp_areas = np.array([s[1] for s in r])\n",
      "sp_mean_intensity = np.array([s[2] for s in r])\n",
      "sp_bbox = np.array([s[3] for s in r])\n",
      "\n",
      "sp_properties = np.column_stack([sp_centroids, sp_areas, sp_mean_intensity, sp_bbox])\n",
      "\n",
      "dm.save_pipeline_result(sp_properties, 'cropSpProps', 'npy')\n",
      "\n",
      "n_superpixels = len(np.unique(cropped_segmentation_relabeled))\n",
      "\n",
      "img_superpixelized = mark_boundaries(gray2rgb(cropped_img), cropped_segmentation_relabeled)\n",
      "img_superpixelized_text = img_as_ubyte(img_superpixelized)\n",
      "\n",
      "# background label (-1) is not displayed\n",
      "for s in range(n_superpixels - 1):\n",
      "    img_superpixelized_text = cv2.putText(img_superpixelized_text, str(s), \n",
      "                      tuple(np.floor(sp_centroids[s][::-1]).astype(np.int)), \n",
      "                      cv2.FONT_HERSHEY_COMPLEX_SMALL,\n",
      "                      .5, ((255,0,255)), 1)\n",
      "\n",
      "dm.save_pipeline_result(img_superpixelized_text, 'cropSegmentation', 'tif')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Compute neighbor lists and connectivity matrix\n",
      "\n",
      "from skimage.morphology import disk\n",
      "from skimage.filter.rank import gradient\n",
      "# from scipy.sparse import coo_matrix\n",
      "\n",
      "try:\n",
      "    neighbors = dm.load_pipeline_result('neighbors', 'npy')\n",
      "\n",
      "except:\n",
      "\n",
      "    edge_map = gradient(cropped_segmentation_relabeled.astype(np.uint8), disk(3))\n",
      "    neighbors = [set() for i in range(n_superpixels)]\n",
      "\n",
      "    for y,x in zip(*np.nonzero(edge_map)):\n",
      "        neighbors[cropped_segmentation_relabeled[y,x]] |= set(cropped_segmentation_relabeled[y-2:y+2,x-2:x+2].ravel())\n",
      "\n",
      "    for i in range(n_superpixels):\n",
      "        neighbors[i] -= set([i])\n",
      "\n",
      "    dm.save_pipeline_result(neighbors, 'neighbors', 'npy')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}