{
 "metadata": {
  "name": "",
  "signature": "sha256:09413524da7aa5d973d4456d00d4e179862535180cf5416f16f83a3f91410cd4"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import glob, re, os, sys, subprocess, argparse\n",
      "\n",
      "parser = argparse.ArgumentParser(\n",
      "formatter_class=argparse.RawDescriptionHelpFormatter,\n",
      "description=\"Dataset creation utility\",\n",
      "epilog=\"\"\"\n",
      "For example, the following command generates images for dataset PMD1305_region0 that are 4 times smaller in each dimension than the full resolution:\n",
      "\n",
      "python %s ../dataset_defs/PMD1305_region0_reduce2.txt\n",
      "\n",
      "A dataset definition file contains a single integer at the first row, which specifies the reduce level (0 being the full resolution).\n",
      "Below this are multiple rows of comma separated values. Each row specifies:\n",
      "stack_name, image_index, [top, left, height, width]\n",
      "\n",
      "Here stack_name is a string such as PMD1305, image_index is an integer. \n",
      "The last four parameters specify a bounding box, and are optional. If specified, they must be float-point numbers between 0 and 1, not integers. If not specified, a bounding box is automatically computed for each image. The sizes and positions of the bounding boxes may differ for different images in the dataset.\n",
      "For an example of a dataset definition file, see ../dataset_defs/PMD1305_region0_reduce2.txt, which specifies a particular brainstem regions in stack PMD1305.\n",
      "\n",
      "By default, the script will create a sub-directory under the data directory, with the same name as the datasest definition file, to store the output tif files. The tif files are named <dataset_name>_reduce<reduce_level>_<image_index>.tif\n",
      "\"\"\"%(os.path.basename(sys.argv[0]))\n",
      ")\n",
      "\n",
      "parser.add_argument(\"dataset_def\", type=str, help=\"dataset definition file\")\n",
      "parser.add_argument(\"-i\", \"--data_dir\", type=str, help=\"data directory (default: %(default)s)\", default='/oasis/projects/nsf/csd181/yuncong/ParthaData')\n",
      "parser.add_argument(\"-o\", \"--out_dir\", type=str, help=\"output directory\")\n",
      "args = parser.parse_args()\n",
      "\n",
      "import cv2\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "\n",
      "from skimage.filter import threshold_otsu, gaussian_filter\n",
      "from skimage.measure import regionprops, label\n",
      "\n",
      "data_dir = os.path.realpath(args.data_dir)\n",
      "\n",
      "dataset_path = os.path.realpath(args.dataset_def)\n",
      "dataset_dir, dataset_fn = os.path.split(dataset_path)\n",
      "dataset_name, _ = os.path.splitext(dataset_fn)\n",
      "    \n",
      "dataset_mat = np.genfromtxt(dataset_path, delimiter=',', filling_values=-1, dtype=None, skip_header=1)\n",
      "\n",
      "n_images = dataset_mat.shape[0]\n",
      "stack_names = dataset_mat['f0']\n",
      "image_indices = dataset_mat['f1']\n",
      "if len(dataset_mat.dtype.names) > 2:\n",
      "    bounding_boxes = dataset_mat[['f2','f3','f4','f5']].view((float, 4))\n",
      "else:\n",
      "    bounding_boxes = -1*np.ones((n_images, 4), dtype=np.float)\n",
      "\n",
      "with open(dataset_path, 'r') as f:\n",
      "    level = int(f.readline()[0])\n",
      "    \n",
      "# uncompress tarball, if not having done so\n",
      "os.chdir(data_dir)\n",
      "for stack_name in set(stack_names):\n",
      "    if not os.path.exists(stack_name):\n",
      "        if os.path.exists(stack_name+'.tar.gz'):\n",
      "            return_code = subprocess.call('tar xfz %s.tar.gz'%stack_name, shell=True)\n",
      "        elif os.path.exists(stack_name+'.tar'):\n",
      "            return_code = subprocess.call('tar xf %s.tar'%stack_name, shell=True)\n",
      "\n",
      "# if bounding boxes are not specified, compute them for all images, using the lowest level versions\n",
      "os.chdir(data_dir)\n",
      "for s, i, bb in zip(stack_names, image_indices, bounding_boxes):\n",
      "    if bb[0] == -1: # meaning the bb is not specified\n",
      "        margin = 0 # at lowest level, image dimension is 120 by 90\n",
      "        fn = glob.glob(os.path.join(s, '*_%04d.jpg'%i))[0]\n",
      "        img = cv2.imread(fn, 0)\n",
      "        blurred = gaussian_filter(img, 2)\n",
      "        thresholded = blurred < threshold_otsu(blurred) + 10./255.\n",
      "        labelmap, n_components = label(thresholded, background=0, return_num=True)    \n",
      "        component_props = regionprops(labelmap+1, cache=True)\n",
      "        major_comp_prop = sorted(component_props, key=lambda x: x.area, reverse=True)[0]\n",
      "        y1, x1, y2, x2 = major_comp_prop.bbox\n",
      "        bb[:] = [float(y1)/img.shape[0], float(x1)/img.shape[1], \n",
      "              float(y2-y1)/img.shape[0], float(x2-x1)/img.shape[1]]\n",
      "        \n",
      "# create output dir\n",
      "if args.out_dir is None:\n",
      "    output_dir = os.path.join(data_dir, dataset_name)\n",
      "else:\n",
      "    output_dir = os.path.realpath(args.out_dir)\n",
      "    \n",
      "if not os.path.exists(output_dir):\n",
      "    os.mkdir(output_dir)\n",
      "\n",
      "# extract the bounding box at the specified reduce level\n",
      "os.chdir(data_dir)\n",
      "for sn, i, bb in zip(stack_names, image_indices, bounding_boxes):\n",
      "    in_fn = glob.glob(os.path.join(sn, '*_%04d.jp2'%i))[0]\n",
      "    out_name = '%s_%04d.tif'%(dataset_name, i)\n",
      "    out_fn = os.path.join(output_dir, out_name)\n",
      "    top,left,height,width = bb\n",
      "    command = \"kdu_expand -i '%s' -o '%s' -reduce %d -region '{%f,%f},{%f,%f}'\"%(in_fn, out_fn, level, \n",
      "                                                                                 top, left, height, width)\n",
      "    return_code = subprocess.call(command, shell=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}