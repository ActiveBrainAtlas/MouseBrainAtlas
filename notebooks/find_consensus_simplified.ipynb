{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "sys.path.append('../utilities')\n",
    "from utilities2015 import *\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from clustering import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# surround_high_contrast_thresh = .1\n",
    "coherence_limit = .25\n",
    "# significance_limit = .8\n",
    "area_limit = 60000\n",
    "nonoverlapping_area_limit = 2.\n",
    "bg_texton = 3\n",
    "bg_texton_percentage = .2\n",
    "# significance_limit = -0.81\n",
    "significance_limit = 0.05\n",
    "consensus_limit = -20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dm = DataManager(stack='MD593', section=140, segm_params_id='tSLIC200')\n",
    "# dm._load_image(format='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dm.load_multiple_results(results=['texHist', 'segmentation', 'texMap', 'neighbors', \n",
    "                                  'edgeCoords', 'spCentroids', 'edgeNeighbors', 'dedgeNeighbors',\n",
    "                                  'spCoords', 'edgeMidpoints', 'spAreas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_seed_cluster_score_dedge_tuples = dm.load_pipeline_result('allSeedClusterScoreDedgeTuples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_seeds, all_clusters, all_cluster_scores, all_cluster_dedges = zip(*all_seed_cluster_score_dedge_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3822 proposals"
     ]
    }
   ],
   "source": [
    "sys.stderr.write('%d proposals'%len(all_clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_clusters_unique_dict = {}\n",
    "for i, cl in enumerate(all_clusters):\n",
    "    all_clusters_unique_dict[frozenset(cl)] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_unique_cluster_indices = all_clusters_unique_dict.values()\n",
    "all_unique_clusters = [all_clusters[i] for i in all_unique_cluster_indices]\n",
    "all_unique_dedges = [all_cluster_dedges[i] for i in all_unique_cluster_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_unique_cluster_scores = [all_cluster_scores[i] for i in all_unique_cluster_indices]\n",
    "all_unique_seeds = [all_seeds[i] for i in all_unique_cluster_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3208 unique proposals"
     ]
    }
   ],
   "source": [
    "sys.stderr.write('%d unique proposals'%len(all_unique_clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_cluster_coherence_score(cluster, verbose=False):\n",
    "    \n",
    "    if len(cluster) > 1:\n",
    "        cluster_avg = dm.texton_hists[cluster].mean(axis=0)\n",
    "        ds = np.squeeze(chi2s([cluster_avg], dm.texton_hists[list(cluster)]))\n",
    "        var = ds.mean()\n",
    "    else:\n",
    "        var = 0\n",
    "    \n",
    "    return var\n",
    "\n",
    "def compute_cluster_significance_score(*args, **kwargs):\n",
    "    return dm.compute_cluster_score(*args, **kwargs)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f(se, cl):\n",
    "    diff_sizes = [np.min([len((set(cl2)|set(cl))-(set(cl2)&set(cl))) for cl2 in growed_from[s]]) \n",
    "                  for s in cl if s != se and len(growed_from[s]) > 0]\n",
    "    if len(diff_sizes) > 0:\n",
    "        mean_diff = np.mean(diff_sizes)\n",
    "        return -mean_diff\n",
    "    else:\n",
    "        return -np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "growed_from = defaultdict(list)\n",
    "for se, cl in zip(all_seeds, all_clusters):\n",
    "    growed_from[se].append(cl)\n",
    "    \n",
    "all_cluster_consensus = Parallel(n_jobs=16)(delayed(f)(se, cl) \n",
    "                                                for se, cl in zip(all_unique_seeds, all_unique_clusters))\n",
    "all_cluster_consensus = np.array(all_cluster_consensus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# all_cluster_sigs = np.array([compute_cluster_significance_score(cl, method='rc-mean') for cl in all_clusters])\n",
    "all_cluster_sigs = np.array(all_unique_cluster_scores)\n",
    "all_cluster_coherences = np.array([compute_cluster_coherence_score(cl) for cl in all_unique_clusters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# all_cluster_sigs_perc = np.array(Parallel(n_jobs=16)(delayed(compute_cluster_significance_score)(cl, method='percentage-soft',\n",
    "#                                 thresh=surround_high_contrast_thresh) for cl in all_unique_clusters))\n",
    "\n",
    "# # all_cluster_sigs_perc = np.array([compute_cluster_significance_score(cl, method='percentage-soft',\n",
    "# #                                                                thresh=surround_high_contrast_thresh) \n",
    "# #                              for cl in all_clusters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_cluster_hists = [dm.texton_hists[cl].mean(axis=0) for cl in all_unique_clusters]\n",
    "all_cluster_entropy = np.nan_to_num([-np.sum(hist[hist!=0]*np.log(hist[hist!=0])) for hist in all_cluster_hists])\n",
    "\n",
    "all_cluster_centroids = np.array([dm.sp_centroids[cl, ::-1].mean(axis=0) for cl in all_unique_clusters])\n",
    "\n",
    "# all_cluster_compactness = np.array([len(eds)**2/float(len(cl)) for cl, eds in zip(all_unique_clusters, all_cluster_dedges)])\n",
    "# all_cluster_compactness = .001 * np.maximum(all_cluster_compactness-40,0)**2\n",
    "\n",
    "all_cluster_area = np.array([dm.sp_areas[cl].sum() for cl in all_unique_clusters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 2, squeeze=True, figsize=(20,10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "h = axes[0].hist(all_cluster_sigs, bins=100);\n",
    "axes[0].set_xlabel('contrast');\n",
    "axes[0].set_ylabel('number of clusters');\n",
    "axes[0].vlines(significance_limit, 0, h[0].max(), color='r');\n",
    "\n",
    "h = axes[1].hist(all_cluster_coherences, bins=100);\n",
    "axes[1].set_xlabel('conherence');\n",
    "axes[1].set_ylabel('number of clusters');\n",
    "axes[1].vlines(coherence_limit, 0, h[0].max(), color='r');\n",
    "# h = axes[2].hist(all_cluster_compactness, bins=100);\n",
    "# axes[2].set_xlabel('compactness');\n",
    "# axes[2].set_ylabel('number of clusters');\n",
    "# axes[2].vlines(50, 0, h[0].max(), color='r');\n",
    "\n",
    "h = axes[3].hist(all_cluster_area, bins=100);\n",
    "axes[3].set_xlabel('area');\n",
    "axes[3].set_ylabel('number of clusters');\n",
    "axes[3].vlines(area_limit, 0, h[0].max(), color='r');\n",
    "\n",
    "# h = axes[4].hist(all_cluster_consensus[all_cluster_consensus!=-np.inf], bins=100);\n",
    "# axes[4].set_xlabel('consensus');\n",
    "# axes[4].set_ylabel('number of clusters');\n",
    "# axes[4].vlines(consensus_limit, 0, h[0].max(), color='r');\n",
    "\n",
    "h = axes[5].hist([hist[bg_texton] for hist in all_cluster_hists], bins=100);\n",
    "axes[5].set_xlabel('background texton proportion');\n",
    "axes[5].set_ylabel('number of clusters');\n",
    "axes[5].vlines(bg_texton_percentage, 0, h[0].max(), color='r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "remaining_cluster_indices = [i for i, (cl, coh, sig, ent, cent, area, cons, hist) in enumerate(zip(all_clusters, \n",
    "                                                                                      all_cluster_coherences, \n",
    "                                                                                      all_cluster_sigs,\n",
    "#                                                                                     all_cluster_sigs_perc,\n",
    "                                                                                      all_cluster_entropy,\n",
    "                                                                                      all_cluster_centroids,\n",
    "#                                                                                       all_cluster_compactness,\n",
    "                                                                                      all_cluster_area,\n",
    "                                                                                    all_cluster_consensus,\n",
    "                                                                                    all_cluster_hists)) \n",
    "            if coh < coherence_limit and sig > significance_limit and \\\n",
    "                area > area_limit and cons > consensus_limit and \\\n",
    "#                  comp < 50 and \\\n",
    "             ((ent > 1.5 and hist[bg_texton] < bg_texton_percentage) or \\\n",
    "              (cent[0] - dm.xmin > 800 and \\\n",
    "               dm.xmax - cent[0] > 800 and \\\n",
    "               cent[1] - dm.ymin > 800 and \\\n",
    "               dm.ymax - cent[1] > 800)\n",
    "             )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "remaining_cluster_indices = 429\n"
     ]
    }
   ],
   "source": [
    "sys.stderr.write('remaining_cluster_indices = %d\\n'%len(remaining_cluster_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_remaining_seeds = [all_unique_seeds[i] for i in remaining_cluster_indices]\n",
    "all_remaining_clusters = [all_unique_clusters[i] for i in remaining_cluster_indices]\n",
    "all_remaining_cluster_dedges = [all_unique_dedges[i] for i in remaining_cluster_indices]\n",
    "all_remaining_cluster_sigs = [all_cluster_sigs[i] for i in remaining_cluster_indices]\n",
    "all_remaining_cluster_hists = [all_cluster_hists[i] for i in remaining_cluster_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# nonoverlapping_area_limit = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_remaining_overlap_mat = compute_pairwise_distances(all_remaining_clusters, metric='overlap-size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# all_remaining_da_mat = compute_pairwise_distances(all_remaining_clusters, metric='nonoverlap-area', \n",
    "#                                                       sp_areas=dm.sp_areas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_remaining_histdist_mat = compute_pairwise_distances(all_remaining_cluster_hists, chi2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all_remaining_hist_distmat = pdist(all_remaining_cluster_hists, chi2)\n",
    "# all_remaining_hist_distmat = squareform(all_remaining_hist_distmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# all_remaining_distmat = (all_remaining_da_distmat > nonoverlapping_area_limit) | (all_remaining_hist_distmat > .2)\n",
    "all_remaining_distmat = ~((all_remaining_overlap_mat > 0) & (all_remaining_histdist_mat < .2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0245001316071\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "\n",
    "all_remaining_cluster_tuples = zip(all_remaining_seeds, all_remaining_clusters, all_remaining_cluster_dedges,\n",
    "                                   all_remaining_cluster_hists, all_remaining_cluster_sigs)\n",
    "\n",
    "cluster_indices_grouped, tuples_grouped, _ = group_tuples(all_remaining_cluster_tuples, \n",
    "                                                        val_ind = 1,\n",
    "                                                        distance_matrix=all_remaining_distmat,\n",
    "                                                       dist_thresh=.00001,\n",
    "                                                       linkage='complete')\n",
    "\n",
    "print time.time() - t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "77 groups\n"
     ]
    }
   ],
   "source": [
    "n_group = len(cluster_indices_grouped)\n",
    "sys.stderr.write('%d groups\\n'%n_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "group_internal_order = [np.argsort(map(itemgetter(4), tuple_group))[::-1] for tuple_group in tuples_grouped]\n",
    "cluster_indices_grouped = [[ci_group[i] for i in order] for order, ci_group in zip(group_internal_order, cluster_indices_grouped)]\n",
    "tuples_grouped = [[tuple_group[i] for i in order] for order, tuple_group in zip(group_internal_order, tuples_grouped)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_seeds_grouped, all_clusters_grouped, all_dedges_grouped, \\\n",
    "all_hists_grouped, all_sigs_grouped = [list(map(list, lst)) for lst in zip(*[zip(*g) for g in tuples_grouped])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reps = [g[0] for g in cluster_indices_grouped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_reps_overlap_mat = compute_pairwise_distances([all_remaining_clusters[i] for i in reps], \n",
    "                                                       metric='overlap-size')\n",
    "all_reps_histdist_mat = compute_pairwise_distances([all_remaining_cluster_hists[i] for i in reps], chi2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_reps_distmat = ~((all_reps_overlap_mat > 0) & (all_reps_histdist_mat < .1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.matshow(all_reps_distmat);\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_, repind_clusters_grouped, _ = group_tuples([(i, all_remaining_clusters[i]) for i in reps], \n",
    "                                              val_ind = 1, distance_matrix=all_reps_distmat,\n",
    "                                              dist_thresh=.00001, linkage='single')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reps_grouped = [map(itemgetter(0), grp) for grp in repind_clusters_grouped]\n",
    "clusters_grouped = [map(itemgetter(1), grp) for grp in repind_clusters_grouped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sys.stderr.write('%d nonoverlapping groups\\n' % len(clusters_grouped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visu(i, cl_grp):\n",
    "    dm.visualize_clusters_in_subplots(cl_grp, fname='group%02d.jpg'%i,\n",
    "                                     titles=['%.3f'%all_remaining_cluster_sigs[rep] for rep in reps_grouped[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_ = Parallel(n_jobs=16)(delayed(visu)(i, cl_grp) for i, cl_grp in enumerate(clusters_grouped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i, cl_grp in enumerate(clusters_grouped):\n",
    "#     print i\n",
    "#     dm.visualize_clusters_in_subplots(cl_grp, fname='group%02d.jpg'%i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# all_scores_grouped = [[compute_cluster_significance_score(g, method='percentage') for g in cg] \n",
    "#                           for cg in all_clusters_grouped]\n",
    "\n",
    "# all_cluster_grouped_union = [set.union(*map(set, cls)) for cls in all_clusters_grouped]\n",
    "# # all_cluster_grouped_union = [smart_union(cls) for cls in all_clusters_grouped]\n",
    "# # all_scores_grouped = np.array([len(seeds) / float(len(union_cl)) for seeds, union_cl in zip(all_seeds_grouped,\n",
    "# #                                                                                   all_cluster_grouped_union)])\n",
    "# all_scores_grouped = np.array([-dm.sp_areas[list(set(union_cl)-set(seeds))].sum()\n",
    "#                                for seeds, union_cl in zip(all_seeds_grouped, all_cluster_grouped_union)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dedges missing 42 89%\n",
      "dedges missing 13 54%\n"
     ]
    }
   ],
   "source": [
    "group_rep_indices = map(np.argmax, all_sigs_grouped)\n",
    "\n",
    "group_rep_clusters = [cls[rep] for cls, rep in zip(all_clusters_grouped, group_rep_indices)]\n",
    "\n",
    "group_contrasts = [compute_cluster_significance_score(cl, method='rc-mean') for cl in group_rep_clusters]\n",
    "\n",
    "group_size = [len(g) for g in all_clusters_grouped]\n",
    "\n",
    "def scores_to_vote(scores):\n",
    "    vals = np.unique(scores)\n",
    "    d = dict(zip(vals, np.linspace(0, 1, len(vals))))\n",
    "    votes = np.array([d[s] for s in scores])\n",
    "    votes = votes/votes.sum()\n",
    "    return votes\n",
    "\n",
    "d1 = scores_to_vote(group_contrasts)\n",
    "d3 = scores_to_vote(group_size)\n",
    "group_indices_ranked = np.argsort(.5*d1 + 0*d3)[::-1]\n",
    "\n",
    "rep_contrast_ranked = [group_contrasts[i] for i in group_indices_ranked]\n",
    "rep_clusters_ranked = [all_clusters_grouped[i][group_rep_indices[i]] for i in group_indices_ranked]\n",
    "rep_dedges_ranked = [dm.find_boundary_dedges_ordered(cl) for cl in rep_clusters_ranked]\n",
    "\n",
    "good_clusters = rep_clusters_ranked\n",
    "good_dedges = rep_dedges_ranked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[(rank, group_contrasts[i], len(all_clusters_grouped[i]), i) for rank, i in enumerate(group_indices_ranked)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "research_sp = 961\n",
    "\n",
    "gs_all = [gi for gi, cl in enumerate(all_remaining_clusters) if research_sp in cl]\n",
    "print gs_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gs = [(gi, [remaining_cluster_indices[i] for i in inds]) \n",
    "      for gi, (cls, inds) in enumerate(zip(all_clusters_grouped, cluster_indices_grouped)) if any(research_sp in cl\n",
    "      for cl in cls)]\n",
    "\n",
    "print gs\n",
    "print 'group id / group size / rank'\n",
    "for x in sorted([(i, len(all_clusters_grouped[i]), group_indices_ranked.tolist().index(i) )\n",
    "                     for i, inds in gs], key=itemgetter(2)):\n",
    "    print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gi = 21\n",
    "dm.visualize_clusters_in_subplots(all_clusters_grouped[gi], \n",
    "                                  titles=['lr %.3f, %d'%(all_remaining_cluster_sigs[i], i)\n",
    "                                          for i in cluster_indices_grouped[gi]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(0, min(100, len(good_dedges)), 10):\n",
    "    viz = dm.visualize_edge_sets(good_dedges[i:i+10], show_set_index=True)\n",
    "    try:\n",
    "        dm.save_pipeline_result(viz, 'landmarks%dViz'%(i+10))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sp_covered_by = defaultdict(set)\n",
    "for i, cl in enumerate(good_clusters):\n",
    "    for s in cl:\n",
    "        sp_covered_by[s].add(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /oasis/projects/nsf/csd395/yuncong/CSHL_data_results/MD593/0140/MD593_0140_lossless_gabor-blueNisslWide-segm-tSLIC200-vq-blueNissl_spCoveredByProposals.pkl\n"
     ]
    }
   ],
   "source": [
    "dm.save_pipeline_result(sp_covered_by, 'spCoveredByProposals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_ellipse_to_points(pts):\n",
    "\n",
    "    pts = np.array(list(pts) if isinstance(pts, set) else pts)\n",
    "\n",
    "    c0 = pts.mean(axis=0)\n",
    "\n",
    "    coords0 = pts - c0\n",
    "\n",
    "    U,S,V = np.linalg.svd(np.dot(coords0.T, coords0)/coords0.shape[0])\n",
    "    v1 = U[:,0]\n",
    "    v2 = U[:,1]\n",
    "    s1 = np.sqrt(S[0])\n",
    "    s2 = np.sqrt(S[1])\n",
    "\n",
    "    return v1, v2, s1, s2, c0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "boundary_models = []\n",
    "\n",
    "for i, (cl, dedges, sig) in enumerate(zip(good_clusters, good_dedges, rep_contrast_ranked)[:100]):\n",
    "\n",
    "    dedge_list = list(dedges)\n",
    "\n",
    "    interior_texture = dm.texton_hists[list(cl)].mean(axis=0)\n",
    "    exterior_textures = []\n",
    "    \n",
    "    cluster_coords = np.vstack([dm.sp_coords[s] for s in cl])\n",
    "    ell = fit_ellipse_to_points(cluster_coords)\n",
    "    \n",
    "    edge_points = []\n",
    "    \n",
    "    for e in dedge_list:\n",
    "        pts_e = dm.edge_coords[frozenset(e)]\n",
    "        sample_indices = np.arange(20, len(pts_e)-20, 200)\n",
    "\n",
    "        if len(sample_indices) > 0:\n",
    "            sample_pts_e = pts_e[sample_indices]\n",
    "            edge_points.append(sample_pts_e)\n",
    "            surr = e[0]\n",
    "            ext_tex = dm.texton_hists[surr] if surr != -1 else np.nan * np.ones((dm.n_texton,))\n",
    "            exterior_textures.append([ext_tex for _ in sample_indices])\n",
    "    \n",
    "    edge_points = np.vstack(edge_points)\n",
    "    exterior_textures = np.vstack(exterior_textures)\n",
    "\n",
    "    center = np.mean([dm.edge_midpoints[frozenset(e)] for e in dedge_list], axis=0)\n",
    "\n",
    "    boundary_models.append((cl, dedge_list, sig, interior_texture, exterior_textures, edge_points, center) +\\\n",
    "                           ell)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /oasis/projects/nsf/csd395/yuncong/CSHL_data_results/MD593/0140/MD593_0140_lossless_gabor-blueNisslWide-segm-tSLIC200-vq-blueNissl_boundaryModels.pkl\n"
     ]
    }
   ],
   "source": [
    "dm.save_pipeline_result(boundary_models, 'boundaryModels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "barray((10944, 18592), int16)\n",
       "  nbytes: 388.09 MB; cbytes: 3.78 MB; ratio: 102.75\n",
       "  bparams := bparams(clevel=5, shuffle=True, cname=blosclz)\n",
       "  rootdir := 'seg'\n",
       "[[-1 -1 -1 ..., -1 -1 -1]\n",
       " [-1 -1 -1 ..., -1 -1 -1]\n",
       " [-1 -1 -1 ..., -1 -1 -1]\n",
       " ..., \n",
       " [-1 -1 -1 ..., -1 -1 -1]\n",
       " [-1 -1 -1 ..., -1 -1 -1]\n",
       " [-1 -1 -1 ..., -1 -1 -1]]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import blz\n",
    "blz.barray(dm.segmentation, rootdir='seg') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seg = blz.open('seg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seg = seg[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bloscpack as bp\n",
    "bp.pack_ndarray_file(dm.segmentation, 'seg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = bp.unpack_ndarray_file('seg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.8391931057\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "from skimage.segmentation import mark_boundaries\n",
    "\n",
    "emptycanvas_superpixelized_mask = mark_boundaries(np.ones((dm.h, dm.w)), dm.segmentation[dm.ymin:dm.ymax+1,\n",
    "                                                                                   dm.xmin:dm.xmax+1], \n",
    "                                             color=(0,0,0), outline_color=None)\n",
    "\n",
    "emptycanvas_superpixelized = np.ones((dm.image_height, dm.image_width, 3))\n",
    "emptycanvas_superpixelized[dm.ymin:dm.ymax+1, dm.xmin:dm.xmax+1] = emptycanvas_superpixelized_mask\n",
    "\n",
    "# emptycanvas_superpixelized = mark_boundaries(np.ones((dm.image_height, dm.image_width)), dm.segmentation, \n",
    "#                                              color=(0,0,0), outline_color=None)\n",
    "print time.time()-t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/oasis/projects/nsf/csd181/yuncong/virtualenv-1.9.1/yuncongve/lib/python2.7/site-packages/skimage/util/dtype.py:111: UserWarning: Possible precision loss when converting from float64 to uint8\n",
      "  \"%s to %s\" % (dtypeobj_in, dtypeobj))\n",
      "/oasis/projects/nsf/csd181/yuncong/virtualenv-1.9.1/yuncongve/lib/python2.7/site-packages/skimage/io/_io.py:159: UserWarning: /oasis/projects/nsf/csd395/yuncong/CSHL_data_results/MD593/0140/MD593_0140_lossless_segm-tSLIC200_segmentationTransparent.png is a low contrast image\n",
      "  warnings.warn('%s is a low contrast image' % fname)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /oasis/projects/nsf/csd395/yuncong/CSHL_data_results/MD593/0140/MD593_0140_lossless_segm-tSLIC200_segmentationTransparent.png\n"
     ]
    }
   ],
   "source": [
    "alpha_channel = ~ emptycanvas_superpixelized.all(axis=2)\n",
    "rgba = np.dstack([emptycanvas_superpixelized, alpha_channel])\n",
    "\n",
    "dm.save_pipeline_result(rgba, 'segmentationTransparent', is_rgb=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
