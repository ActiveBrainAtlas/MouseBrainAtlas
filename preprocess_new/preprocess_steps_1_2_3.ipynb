{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup and Imports\n",
    "\n",
    "# %reload_ext : Reloads an IPython extension by its module name.\n",
    "%reload_ext autoreload\n",
    "# %autoreload 2 : Reloads all modules (except those excluded by %aimport)  \n",
    "#  every time before executing the Python code typed.\n",
    "%autoreload 2\n",
    "\n",
    "# %TEXT : code in this format is called a \"magic function\" \n",
    "#  https://stackoverflow.com/questions/43027980/purpose-of-matplotlib-inline/43028034\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# Sets backend of matplotlib to the 'inline' backend\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(os.path.join(os.environ['REPO_DIR'], 'utilities'))\n",
    "from utilities2015 import *\n",
    "from metadata import *\n",
    "from data_manager import *\n",
    "from learning_utilities import *\n",
    "\n",
    "\n",
    "stack = 'MD662'\n",
    "print('testing metadata: ',metadata_cache['valid_filenames_all'][stack][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 1\n",
    "### raw (.jp2) -> raw_Ntb (.tif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "in_dir = '/media/alexn/BstemAtlasDataBackup/MD662/'\n",
    "output_dir = create_if_not_exists(DataManager.get_image_dir_v2(stack=stack, prep_id=None, resol='raw'))\n",
    "\n",
    "# INPUT TEST\n",
    "in_list = [os.path.join(in_dir, img_name + '_lossless.jp2') \n",
    "                                       for img_name in list(image_names_all_data_dirs_flattened)]\n",
    "# OUTPUT TEST\n",
    "out_list = [DataManager.get_image_filepath_v2(stack=stack, prep_id=None, \n",
    "                                        resol='raw', version=None, fn=img_name) \n",
    "                                        for img_name in list(image_names_all_data_dirs_flattened)]\n",
    "\n",
    "print('first input file: ',in_list[0])\n",
    "print('first output file: ',out_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Multiple core processing on every individual file (takes about 4 minutes each)\n",
    "# In total will take about 30 hours\n",
    "# Creates new files at /CSHL_data_processed/MD662/MD662_raw/*_raw.tif\n",
    "t = time.time()\n",
    "\n",
    "run_distributed('export LD_LIBRARY_PATH=%(kdu_dir)s:$LD_LIBRARY_PATH; %(kdu_bin)s -i \\\"%%(in_fp)s\\\" -o \\\"%%(out_fp)s\\\"' % \\\n",
    "                {'kdu_bin': KDU_EXPAND_BIN, 'kdu_dir': os.path.dirname(KDU_EXPAND_BIN)},\n",
    "                kwargs_list={'in_fp': [os.path.join(in_dir, img_name + '_lossless.jp2') \n",
    "                                       for img_name in list(image_names_all_data_dirs_flattened)], \n",
    "                             'out_fp': [DataManager.get_image_filepath_v2(stack=stack, prep_id=None, \n",
    "                                        resol='raw', version=None, fn=img_name) \n",
    "                                        for img_name in list(image_names_all_data_dirs_flattened)]},\n",
    "                argument_type='single',\n",
    "                jobs_per_node=1, # Use single process\n",
    "                local_only=True, # Run local\n",
    "                use_aws=False)   # Run local\n",
    "print 'done in', time.time() - t, 'seconds' # 2252 seconds full stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 2\n",
    "### raw_Ntb -> thumbnail_Ntb\n",
    "rescale\n",
    "\n",
    "# & STEP 3\n",
    "### thumbnail_Ntb -> thumbnail_NtbNormalized\n",
    "normalize_intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create_if_not_exists(DataManager.get_image_dir_v2(stack=stack, prep_id=None, resol='raw', version='Ntb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# raw -> raw_Ntb\n",
    "# Multiple core processing on every individual file (takes about 4 minutes each)\n",
    "# In total will take about 20 hours\n",
    "# Creates new files at CSHL_data_processed/MD662/MD662_raw_Ntb/*_raw_Ntb.tif\n",
    "t = time.time()\n",
    "run_distributed('convert \\\"%(in_fp)s\\\" -channel B -separate \\\"%(out_fp)s\\\"',\n",
    "                kwargs_list={'in_fp': [DataManager.get_image_filepath_v2(stack=stack, prep_id=None, \n",
    "                                        resol='raw', version=None, fn=img_name) \n",
    "                                       for img_name in list(image_names_all_data_dirs_flattened)], \n",
    "                             'out_fp': [DataManager.get_image_filepath_v2(stack=stack, prep_id=None, \n",
    "                                        resol='raw', version='Ntb', fn=img_name) \n",
    "                                        for img_name in list(image_names_all_data_dirs_flattened)]},\n",
    "                argument_type='single',\n",
    "                jobs_per_node=1,\n",
    "                local_only=True,\n",
    "               use_aws=False)\n",
    "print('finished generating raw_Ntb files')\n",
    "print 'done in', time.time() - t, 'seconds' # 2252 seconds full stack\n",
    "\n",
    "thumbnail_downscale_factor = 32\n",
    "tb_resol = 'thumbnail'\n",
    "\n",
    "# Takes about 1 minute per file, in total about 8-10 hours\n",
    "\n",
    "# Will create new files at the filepaths /CSHL_data_processed/MD662/MD662_thumbnail_Ntb/*_thumbnail_Ntb.tif\n",
    "#  and /CSHL_data_processed/MD662/MD662_thumbnail_NtbNormalized/*_thumbnail_NtbNormalized.tif\n",
    "# Only 108 files in each directory though?\n",
    "i = 0\n",
    "\n",
    "for img_name in metadata_cache['valid_filenames_all'][stack]:\n",
    "    i = i+1\n",
    "    print '\\n\\n'+img_name+'\\n'\n",
    "\n",
    "    t = time.time()\n",
    "\n",
    "    in_fp = DataManager.get_image_filepath_v2(stack=stack, prep_id=None, resol='raw', version='Ntb', \\\n",
    "                                              fn=img_name)\n",
    "    out_fp = DataManager.get_image_filepath_v2(stack=stack, prep_id=None, resol=tb_resol, version='Ntb', \\\n",
    "                                              fn=img_name)\n",
    "    create_parent_dir_if_not_exists(out_fp)\n",
    "    \n",
    "  #  if os.path.isfile(out_fp):\n",
    "  #      print('SKIPPING NeurotraceB: '+out_fp)\n",
    "  #      #continue\n",
    "  #  else:\n",
    "    \n",
    "    try:\n",
    "        img = imread(in_fp)\n",
    "    except IndexError:\n",
    "        print('Problematic file detected\\n\\n'+out_fp+'\\n\\n')\n",
    "        \n",
    "    print(out_fp)\n",
    "    img_tb = img[::thumbnail_downscale_factor, ::thumbnail_downscale_factor]\n",
    "    imsave(out_fp, img_tb)\n",
    "    \n",
    "    \n",
    "    # Alternative: ImageMagick introduces an artificial noisy stripe in the output image.\n",
    "#     cmd = 'convert %(in_fp)s -scale 3.125%% %(out_fp)s' % {'in_fp': in_fp, 'out_fp': out_fp}\n",
    "#     execute_command(cmd)\n",
    "        \n",
    "    sys.stderr.write(\"Rescale: %.2f seconds.\\n\" % (time.time() - t)) # ~20s / image\n",
    "    \n",
    "    t = time.time()\n",
    "\n",
    "    in_fp = DataManager.get_image_filepath_v2(stack=stack, prep_id=None, resol=tb_resol, version='Ntb', \\\n",
    "                                              fn=img_name)\n",
    "    out_fp = DataManager.get_image_filepath_v2(stack=stack, prep_id=None, resol=tb_resol, version='NtbNormalized',\\\n",
    "                                               fn=img_name)\n",
    "    create_parent_dir_if_not_exists(out_fp)\n",
    "    \n",
    "  #  if os.path.isfile(out_fp):\n",
    "  #      print('SKIPPING Ntb Normalized: '+out_fp)\n",
    "  #      continue\n",
    "  #  else:\n",
    "    print(out_fp)\n",
    "    cmd = \"\"\"convert \"%(in_fp)s\" -normalize -depth 8 \"%(out_fp)s\" \"\"\" % {'in_fp': in_fp, 'out_fp': out_fp}\n",
    "    execute_command(cmd)\n",
    "  #  try:\n",
    "  #      img = imread(in_fp)\n",
    "  #  except IndexError:\n",
    "  #      print('Problematic file detected\\n\\n'+out_fp+'\\n\\n')\n",
    "    \n",
    "    \n",
    "    sys.stderr.write(\"Intensity normalize: %.2f seconds.\\n\" % (time.time() - t))\n",
    "print i"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
