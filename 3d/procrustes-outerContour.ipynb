{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/pkg_resources.py:1031: UserWarning: /home/yuncong/.python-eggs is writable by group/others and vulnerable to attack when used with get_resource_filename. Consider a more secure location (set with .set_extraction_path or the PYTHON_EGG_CACHE environment variable).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import vtk\n",
    "from vtk.util import numpy_support\n",
    "\n",
    "import numpy as np\n",
    "import bloscpack as bp\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.join(os.environ['REPO_DIR'], 'utilities'))\n",
    "from utilities2015 import *\n",
    "from registration_utilities import *\n",
    "\n",
    "from skimage.measure import marching_cubes, correct_mesh_orientation\n",
    "\n",
    "from vis3d_utilities import *\n",
    "from itertools import izip\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mesh_rootdir = create_if_not_exists('/home/yuncong/CSHL_meshes')\n",
    "volume_dir = '/home/yuncong/CSHL_volumes/'\n",
    "atlasAlignParams_dir = '/home/yuncong/CSHL_atlasAlignParams/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "volume_landmark_names_unsided = ['12N', '5N', '6N', '7N', '7n', 'AP', 'Amb', 'LC',\n",
    "                                 'LRt', 'Pn', 'R', 'RtTg', 'Tz', 'VLL', 'sp5']\n",
    "linear_landmark_names_unsided = ['outerContour']\n",
    "\n",
    "labels_unsided = volume_landmark_names_unsided + linear_landmark_names_unsided\n",
    "labels_unsided_indices = dict((j, i+1) for i, j in enumerate(labels_unsided))  # BackG always 0\n",
    "\n",
    "labelMap_unsidedToSided = {'12N': ['12N'],\n",
    "                            '5N': ['5N_L', '5N_R'],\n",
    "                            '6N': ['6N_L', '6N_R'],\n",
    "                            '7N': ['7N_L', '7N_R'],\n",
    "                            '7n': ['7n_L', '7n_R'],\n",
    "                            'AP': ['AP'],\n",
    "                            'Amb': ['Amb_L', 'Amb_R'],\n",
    "                            'LC': ['LC_L', 'LC_R'],\n",
    "                            'LRt': ['LRt_L', 'LRt_R'],\n",
    "                            'Pn': ['Pn_L', 'Pn_R'],\n",
    "                            'R': ['R_L', 'R_R'],\n",
    "                            'RtTg': ['RtTg'],\n",
    "                            'Tz': ['Tz_L', 'Tz_R'],\n",
    "                            'VLL': ['VLL_L', 'VLL_R'],\n",
    "                            'sp5': ['sp5'],\n",
    "                           'outerContour': ['outerContour']}\n",
    "\n",
    "labelMap_sidedToUnsided = {n: nu for nu, ns in labelMap_unsidedToSided.iteritems() for n in ns}\n",
    "\n",
    "from itertools import chain\n",
    "labels_sided = list(chain(*(labelMap_unsidedToSided[name_u] for name_u in labels_unsided)))\n",
    "labels_sided_indices = dict((j, i+1) for i, j in enumerate(labels_sided)) # BackG always 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack = 'MD594'\n",
    "with open(atlasAlignParams_dir + '/%(stack)s/%(stack)s_3dAlignParams.txt' % {'stack': stack}, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    global_params = np.array(map(float, lines[0].strip().split()))\n",
    "#     atlas_xdim, atlas_ydim, atlas_zdim  = np.array(map(float, lines[1].strip().split()))\n",
    "    atlas_centroid = np.array(map(float, lines[2].strip().split()))\n",
    "    test_xdim, test_ydim, test_zdim = np.array(map(int, lines[3].strip().split()))\n",
    "    test_centroid = np.array(map(float, lines[4].strip().split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ann_xmin, ann_xmax, ann_ymin, ann_ymax, ann_zmin, ann_zmax = \\\n",
    "np.loadtxt(volume_dir + '%(stack)s/volume_%(stack)s_annotation_withOuterContour_limits.txt' % {'stack': stack}, dtype=np.int)\n",
    "\n",
    "sco_xmin, sco_xmax, sco_ymin, sco_ymax, sco_zmin, sco_zmax = \\\n",
    "np.loadtxt(volume_dir + '%(stack)s/%(stack)s_scoreVolume_limits.txt' % {'stack': stack}, dtype=np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def align_principle_axes(vertices_normalized0, vertices_normalized):\n",
    "    \n",
    "    u1, _, _ = np.linalg.svd(np.dot(vertices_normalized0.T, vertices_normalized0)/vertices_normalized0.shape[0])\n",
    "    \n",
    "    u, s, v = np.linalg.svd(np.dot(vertices_normalized.T, vertices_normalized)/vertices_normalized.shape[0])\n",
    "\n",
    "    if np.dot(u[:,0], u1[:,0]) < 0:\n",
    "        u[:,0] = -u[:,0]\n",
    "    if np.dot(u[:,1], u1[:,1]) < 0:\n",
    "        u[:,1] = -u[:,1]\n",
    "    if np.dot(u[:,2], u1[:,2]) < 0:\n",
    "        u[:,2] = -u[:,2]\n",
    "\n",
    "    U, _, VT = np.linalg.svd(np.dot(u1, u.T))\n",
    "    R = np.dot(U, VT)\n",
    "    \n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.spatial import KDTree\n",
    "\n",
    "def icp(template2, moving, num_iter=10, rotation_only=True):\n",
    "    # https://www.wikiwand.com/en/Orthogonal_Procrustes_problem\n",
    "    # https://www.wikiwand.com/en/Kabsch_algorithm\n",
    "    \n",
    "    moving2 = moving.copy()\n",
    "    template = template2.copy()\n",
    "    \n",
    "    tree = KDTree(template)\n",
    "\n",
    "    for i in range(num_iter):\n",
    "        \n",
    "        t = time.time()\n",
    "        \n",
    "        _, nns = tree.query(moving2)\n",
    "        data = template[nns]\n",
    "        M = np.dot(moving2.T, data)\n",
    "        U, s, VT = np.linalg.svd(M)\n",
    "        if rotation_only:\n",
    "            s2 = np.ones_like(s)\n",
    "            s2[-1] = np.sign(np.linalg.det(np.dot(U, VT).T))\n",
    "            R = np.dot(np.dot(U, np.diag(s2)), VT).T\n",
    "        else:\n",
    "            R = np.dot(U, VT).T\n",
    "            \n",
    "        moving2 = np.dot(moving2, R.T)\n",
    "        d = np.sum(np.sqrt(np.sum((moving2 - data)**2, axis=1)))\n",
    "        if i > 1 and d_prev == d:\n",
    "            break\n",
    "        d_prev = d\n",
    "        \n",
    "        sys.stderr.write('icp @ %d err %.2f: %.2f\\n' % (i, d, time.time() - t))\n",
    "    \n",
    "    M = np.dot(moving.T, template[nns])\n",
    "    U, _, VT = np.linalg.svd(M)\n",
    "    R = np.dot(U, VT).T\n",
    "    \n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def average_shape(polydata_list, concensus_percentage=.5, num_simplify_iter=0, smooth=False):\n",
    "    \n",
    "    volume_list = []\n",
    "    origin_list = []\n",
    "\n",
    "    for p in polydata_list:\n",
    "        t = time.time()\n",
    "        v, orig, _ = polydata_to_volume(p)\n",
    "        sys.stderr.write('polydata_to_volume: %.2f\\n' % (time.time() - t))\n",
    "\n",
    "        volume_list.append(v)\n",
    "        origin_list.append(np.array(orig, np.int))\n",
    "\n",
    "    t = time.time()\n",
    "        \n",
    "    common_mins = np.min(origin_list, axis=0).astype(np.int)\n",
    "    relative_origins = origin_list - common_mins\n",
    "\n",
    "    common_xdim, common_ydim, common_zdim = np.max([(v.shape[1]+o[0], v.shape[0]+o[1], v.shape[2]+o[2])\n",
    "                                                    for v,o in zip(volume_list, relative_origins)], axis=0)\n",
    "\n",
    "    common_volume_list = []\n",
    "\n",
    "    for i, v in enumerate(volume_list):\n",
    "        common_volume = np.zeros( (common_ydim, common_xdim, common_zdim), np.uint8)\n",
    "        x0, y0, z0 = relative_origins[i]\n",
    "        ydim, xdim, zdim = v.shape\n",
    "        common_volume[y0:y0+ydim, x0:x0+xdim, z0:z0+zdim] = v\n",
    "\n",
    "        common_volume_list.append((common_volume > 0).astype(np.int))\n",
    "\n",
    "    average_volume = np.sum(common_volume_list, axis=0) >= min(2, len(common_volume_list)*concensus_percentage)\n",
    "        \n",
    "    sys.stderr.write('find common: %.2f\\n' % (time.time() - t))\n",
    "\n",
    "    print average_volume.shape\n",
    "    \n",
    "    t = time.time()\n",
    "    average_polydata = volume_to_polydata(average_volume, common_mins, num_simplify_iter=num_simplify_iter, \n",
    "                                          smooth=smooth)\n",
    "    sys.stderr.write('volume_to_polydata: %.2f\\n' % (time.time() - t))\n",
    "    \n",
    "    return average_volume, average_polydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outerContour\n",
      "[[ 1.  0.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  0.  1.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fill point array: 0.02 seconds\n",
      "fill cell array: 0.00 seconds\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "centroid_allLandmarks = defaultdict(list)\n",
    "average_polydata_allLandmarks = {}\n",
    "polydata_list_allLandmarks = {}\n",
    "\n",
    "# for name_unsided in labels_unsided:\n",
    "for name_unsided in ['outerContour']:\n",
    "    \n",
    "    print name_unsided    \n",
    "    \n",
    "    vertices_list = []\n",
    "    faces_list = []\n",
    "    \n",
    "#     for stack in ['MD589', 'MD594']:\n",
    "    for stack in ['MD594']:\n",
    "\n",
    "        names = labelMap_unsidedToSided[name_unsided]\n",
    "        \n",
    "        if len(names) == 2:\n",
    "        \n",
    "            for name_sided in names:\n",
    "\n",
    "                fn = \"/home/yuncong/CSHL_meshes/%(stack)s/%(stack)s_%(label)s_gaussianSmoothed.stl\" % {'stack':stack, 'label':name_sided}\n",
    "               \n",
    "                if os.path.exists(fn):\n",
    "                    vertices, faces = load_mesh_stl(fn)\n",
    "                else:\n",
    "                    continue\n",
    "            \n",
    "                if '_L' in name_sided:\n",
    "                    zmean = vertices[:,2].mean(axis=0)\n",
    "                    vertices[:, 2] = - (vertices[:, 2] - zmean) + zmean # mirror L to align with R, keep zmin        \n",
    "\n",
    "                vertices_list.append(vertices)\n",
    "\n",
    "                if stack == 'MD594':\n",
    "                    vertices_alignedToScoreVolume = vertices + (ann_xmin,ann_ymin,ann_zmin) - (sco_xmin,sco_ymin,sco_zmin)\n",
    "                    vertices_alignedToAtlas = transform_points_inverse(global_params, pts_prime=vertices_alignedToScoreVolume, \n",
    "                                                                       c_prime=test_centroid, c=atlas_centroid)\n",
    "\n",
    "                faces_list.append(faces)\n",
    "\n",
    "                centroid_prime = vertices.mean(axis=0)\n",
    "\n",
    "                if stack == 'MD594':\n",
    "\n",
    "                    centroid_prime_alignedToScoreVolume = centroid_prime + (ann_xmin,ann_ymin,ann_zmin) - (sco_xmin,sco_ymin,sco_zmin)\n",
    "                    centroid_prime_alignedToAtlas = transform_points_inverse(global_params, pts_prime=[centroid_prime_alignedToScoreVolume], \n",
    "                                                                       c_prime=test_centroid, c=atlas_centroid)[0]\n",
    "                    centroid_allLandmarks[name_sided].append(centroid_prime_alignedToAtlas)\n",
    "                else:\n",
    "                    centroid_allLandmarks[name_sided].append(centroid_prime)\n",
    "        \n",
    "        elif len(names) == 1:\n",
    "            \n",
    "            name_sided = names[0]\n",
    "            \n",
    "            fn = \"/home/yuncong/CSHL_meshes/%(stack)s/%(stack)s_%(label)s_gaussianSmoothed.stl\" % {'stack':stack, 'label':name_sided}\n",
    "            \n",
    "            if os.path.exists(fn):\n",
    "                vertices, faces = load_mesh_stl(fn)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "#             vertices_mirrored = vertices.copy()    \n",
    "#             zmean = vertices[:,2].mean(axis=0)\n",
    "#             vertices_mirrored[:, 2] = - (vertices[:, 2] - zmean) + zmean # mirror L to align with R, keep zmin        \n",
    "            \n",
    "#             t = time.time()\n",
    "            \n",
    "#             if name_unsided == 'sp5' or name_unsided == 'outerContour':\n",
    "#                 _, symmetric_poly = average_shape([mesh_to_polydata(vertices, faces), mesh_to_polydata(vertices_mirrored, faces)],\n",
    "#                                               num_simplify_iter=5, smooth=True)\n",
    "#             else:\n",
    "#                 _, symmetric_poly = average_shape([mesh_to_polydata(vertices, faces), mesh_to_polydata(vertices_mirrored, faces)],\n",
    "#                                               num_simplify_iter=3, smooth=True)\n",
    "                \n",
    "#             # must simplify so the ICP later can be fast\n",
    "#             # must also smooth, because otherwise the number of points gets stuck\n",
    "            \n",
    "#             sys.stderr.write('average shape: %.2f\\n' % (time.time() - t))\n",
    "#             # cost mostly comes from :\n",
    "#             # - marching cube\n",
    "#             # - first two rounds of decimation and smoothing\n",
    "\n",
    "#             symmetric_vertices, symmetric_faces = polydata_to_mesh(symmetric_poly)\n",
    "         \n",
    "#             vertices_list.append(symmetric_vertices)\n",
    "#             faces_list.append(symmetric_faces)\n",
    "            \n",
    "            symmetric_vertices, symmetric_faces = (vertices, faces)\n",
    "            vertices_list.append(symmetric_vertices)\n",
    "            faces_list.append(symmetric_faces)\n",
    "    \n",
    "            centroid_prime = symmetric_vertices.mean(axis=0)\n",
    "\n",
    "            if stack == 'MD594':\n",
    "\n",
    "                centroid_prime_alignedToScoreVolume = centroid_prime + (ann_xmin,ann_ymin,ann_zmin) - (sco_xmin,sco_ymin,sco_zmin)\n",
    "                centroid_prime_alignedToAtlas = transform_points_inverse(global_params, pts_prime=[centroid_prime_alignedToScoreVolume], \n",
    "                                                                   c_prime=test_centroid, c=atlas_centroid)[0]\n",
    "                centroid_allLandmarks[name_sided].append(centroid_prime_alignedToAtlas)\n",
    "            else:\n",
    "                centroid_allLandmarks[name_sided].append(centroid_prime)\n",
    "\n",
    "            \n",
    "#             for i in range(2):\n",
    "#                 if i == 1:\n",
    "#                     zmean = vertices[:,2].mean(axis=0)\n",
    "#                     vertices[:, 2] = - (vertices[:, 2] - zmean) + zmean # mirror L to align with R, keep zmin        \n",
    "\n",
    "#                 vertices_list.append(vertices.copy())\n",
    "\n",
    "#                 if stack == 'MD594':\n",
    "#                     vertices_alignedToScoreVolume = vertices + (ann_xmin,ann_ymin,ann_zmin) - (sco_xmin,sco_ymin,sco_zmin)\n",
    "#                     vertices_alignedToAtlas = transform_points_inverse(global_params, pts_prime=vertices_alignedToScoreVolume, \n",
    "#                                                                        c_prime=test_centroid, c=atlas_centroid)\n",
    "\n",
    "#                 faces_list.append(faces)\n",
    "\n",
    "#                 centroid_prime = vertices.mean(axis=0)\n",
    "\n",
    "#                 if stack == 'MD594':\n",
    "\n",
    "#                     centroid_prime_alignedToScoreVolume = centroid_prime + (ann_xmin,ann_ymin,ann_zmin) - (sco_xmin,sco_ymin,sco_zmin)\n",
    "#                     centroid_prime_alignedToAtlas = transform_points_inverse(global_params, pts_prime=[centroid_prime_alignedToScoreVolume], \n",
    "#                                                                        c_prime=test_centroid, c=atlas_centroid)[0]\n",
    "#                     centroid_allLandmarks[name_sided].append(centroid_prime_alignedToAtlas)\n",
    "#                 else:\n",
    "#                     centroid_allLandmarks[name_sided].append(centroid_prime)\n",
    "                            \n",
    "    \n",
    "    ###### Align meshes ######\n",
    "    \n",
    "    u1 = None\n",
    "    vertices_normalized_aligned_list = []\n",
    "    vertices_aligned_list = []\n",
    "    centroid_list = []\n",
    "\n",
    "    for i, vertices in enumerate(vertices_list):\n",
    "\n",
    "        centroid = vertices.mean(axis=0)\n",
    "        centroid_list.append(centroid)\n",
    "\n",
    "        scale = np.sqrt(((vertices - centroid)**2).mean())\n",
    "        vertices_normalized = (vertices - centroid) / scale\n",
    "\n",
    "        if i == 0:\n",
    "            vertices_normalized1 = vertices_normalized.copy()\n",
    "            R = np.eye(3)\n",
    "        else:            \n",
    "            t = time.time()\n",
    "            R = icp(vertices_normalized1, vertices_normalized, num_iter=100)\n",
    "            sys.stderr.write('icp: %.2f\\n' % (time.time() - t))\n",
    "\n",
    "        print R\n",
    "\n",
    "        vertices_normalized_alignedTo1 = np.dot(vertices_normalized, R.T)\n",
    "        vertices_normalized_aligned_list.append(vertices_normalized_alignedTo1)\n",
    "\n",
    "        vertices_alignedTo1 = vertices_normalized_alignedTo1 * scale\n",
    "        vertices_aligned_list.append(vertices_alignedTo1)\n",
    "    \n",
    "    polydata_list = [mesh_to_polydata(vs, fs) for vs, fs in zip(vertices_aligned_list, faces_list)]\n",
    "            \n",
    "    # if landmark has only one instance, add its mirrored version\n",
    "#     if len(labelMap_unsidedToSided[name_unsided]) == 1:\n",
    "#         for vs, fs in zip(vertices_aligned_list, faces_list):\n",
    "#             zmean = vs[:,2].mean(axis=0)\n",
    "#             vs_mirrored = vs.copy()\n",
    "#             vs_mirrored[:, 2] = - (vs[:, 2] - zmean) + zmean # mirror L to align with R, keep zmin        \n",
    "#             polydata_list.append(mesh_to_polydata(vs_mirrored, fs))\n",
    "\n",
    "    polydata_list_allLandmarks[name_unsided] = polydata_list\n",
    "    \n",
    "    ######### Compute Average #########\n",
    "#     t = time.time()\n",
    "\n",
    "#     if name_unsided == 'outerContour' or name_unsided == 'sp5':\n",
    "#         _, average_polydata = average_shape(polydata_list, num_simplify_iter=5, smooth=True)\n",
    "#     else:\n",
    "#         _, average_polydata = average_shape(polydata_list, num_simplify_iter=3, smooth=True)\n",
    "    \n",
    "#     sys.stderr.write('average shape: %.2f\\n' % (time.time() - t))\n",
    "\n",
    "#     average_polydata_allLandmarks[name_unsided] = average_polydata\n",
    "\n",
    "#     bp.pack_ndarray_file(average_volume, mesh_rootdir + \"/%(name)s_average.bp\" % {'stack': stack, 'name': name_unsided})\n",
    "    \n",
    "#     save_mesh_stl(average_polydata, mesh_rootdir + \"/%(name)s_average.stl\" % {'stack': stack, 'name': name_unsided})\n",
    "\n",
    "centroid_allLandmarks.default_factory = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_mesh_stl(polydata_list_allLandmarks['outerContour'][0], '/home/yuncong/contour.stl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name_to_show = 'outerContour'\n",
    "\n",
    "######## show overlay list of meshes ########\n",
    "ren1 = vtk.vtkRenderer()\n",
    "renWin1 = vtk.vtkRenderWindow()\n",
    "renWin1.AddRenderer(ren1)\n",
    "iren1 = vtk.vtkRenderWindowInteractor()\n",
    "iren1.SetRenderWindow(renWin1)\n",
    "\n",
    "colors = [(0,0,1), (0,1,0), (1,0,0), (1,1,0)]\n",
    "\n",
    "for i, polydata in enumerate(polydata_list_allLandmarks[name_to_show]):\n",
    "    \n",
    "    m = vtk.vtkPolyDataMapper()\n",
    "    m.SetInputData(polydata)\n",
    "\n",
    "    a = vtk.vtkActor()\n",
    "    a.SetMapper(m)\n",
    "    a.GetProperty().SetRepresentationToWireframe()\n",
    "    a.GetProperty().SetColor(colors[i % len(colors)])\n",
    "    \n",
    "    ren1.AddActor(a)\n",
    "\n",
    "axes_widget1 = add_axes(iren1)\n",
    "\n",
    "renWin1.Render()\n",
    "renWin1.SetWindowName('overlay')\n",
    "\n",
    "camera = vtk.vtkCamera()\n",
    "ren1.SetActiveCamera(camera)\n",
    "ren1.ResetCamera()\n",
    "\n",
    "iren1.Start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'sp5'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-d033fee7bd73>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mcolors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpolydata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpolydata_list_allLandmarks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname_to_show\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvtk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvtkPolyDataMapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'sp5'"
     ]
    }
   ],
   "source": [
    "name_to_show = 'sp5'\n",
    "\n",
    "######## show overlay list of meshes ########\n",
    "ren1 = vtk.vtkRenderer()\n",
    "renWin1 = vtk.vtkRenderWindow()\n",
    "renWin1.AddRenderer(ren1)\n",
    "iren1 = vtk.vtkRenderWindowInteractor()\n",
    "iren1.SetRenderWindow(renWin1)\n",
    "\n",
    "colors = [(1,0,0), (0,1,0), (0,0,1), (1,1,0)]\n",
    "\n",
    "for i, polydata in enumerate(polydata_list_allLandmarks[name_to_show]):\n",
    "    \n",
    "    m = vtk.vtkPolyDataMapper()\n",
    "    m.SetInputData(polydata)\n",
    "\n",
    "    a = vtk.vtkActor()\n",
    "    a.SetMapper(m)\n",
    "    a.GetProperty().SetRepresentationToWireframe()\n",
    "    a.GetProperty().SetColor(colors[i % len(colors)])\n",
    "    \n",
    "    ren1.AddActor(a)\n",
    "\n",
    "axes_widget1 = add_axes(iren1)\n",
    "\n",
    "renWin1.Render()\n",
    "renWin1.SetWindowName('overlay')\n",
    "\n",
    "######### show average mesh #########\n",
    "ren2 = vtk.vtkRenderer()\n",
    "\n",
    "renWin2 = vtk.vtkRenderWindow()\n",
    "renWin2.AddRenderer(ren2)\n",
    "\n",
    "iren2 = vtk.vtkRenderWindowInteractor()\n",
    "iren2.SetRenderWindow(renWin2)\n",
    "\n",
    "m2 = vtk.vtkPolyDataMapper()\n",
    "m2.SetInputData(average_polydata_allLandmarks[name_to_show])\n",
    "\n",
    "a2 = vtk.vtkActor()\n",
    "a2.SetMapper(m2)\n",
    "a2.GetProperty().SetRepresentationToWireframe()\n",
    "# a.GetProperty().SetColor(colors[2])\n",
    "\n",
    "ren2.AddActor(a2)\n",
    "axes_widget2 = add_axes(iren2)\n",
    "\n",
    "renWin2.Render()\n",
    "renWin2.SetWindowName('average')\n",
    "\n",
    "#####################################\n",
    "\n",
    "camera = vtk.vtkCamera()\n",
    "ren1.SetActiveCamera(camera)\n",
    "ren2.SetActiveCamera(camera)\n",
    "ren1.ResetCamera()\n",
    "ren2.ResetCamera()\n",
    "\n",
    "iren1.Start()\n",
    "iren2.Start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
