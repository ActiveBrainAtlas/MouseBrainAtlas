{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import vtk\n",
    "from vtk.util import numpy_support\n",
    "\n",
    "import numpy as np\n",
    "import bloscpack as bp\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.join(os.environ['REPO_DIR'], 'utilities'))\n",
    "from utilities2015 import *\n",
    "from registration_utilities import *\n",
    "\n",
    "from skimage.measure import marching_cubes, correct_mesh_orientation\n",
    "\n",
    "from vis3d_utilities import *\n",
    "from itertools import izip\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mesh_rootdir = create_if_not_exists('/home/yuncong/CSHL_meshes')\n",
    "volume_dir = '/home/yuncong/CSHL_volumes/'\n",
    "atlasAlignParams_dir = '/home/yuncong/CSHL_atlasAlignParams/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "volume_landmark_names_unsided = ['12N', '5N', '6N', '7N', '7n', 'AP', 'Amb', 'LC',\n",
    "                                 'LRt', 'Pn', 'R', 'RtTg', 'Tz', 'VLL', 'sp5']\n",
    "linear_landmark_names_unsided = ['outerContour']\n",
    "\n",
    "labels_unsided = volume_landmark_names_unsided + linear_landmark_names_unsided\n",
    "labels_unsided_indices = dict((j, i+1) for i, j in enumerate(labels_unsided))  # BackG always 0\n",
    "\n",
    "labelMap_unsidedToSided = {'12N': ['12N'],\n",
    "                            '5N': ['5N_L', '5N_R'],\n",
    "                            '6N': ['6N_L', '6N_R'],\n",
    "                            '7N': ['7N_L', '7N_R'],\n",
    "                            '7n': ['7n_L', '7n_R'],\n",
    "                            'AP': ['AP'],\n",
    "                            'Amb': ['Amb_L', 'Amb_R'],\n",
    "                            'LC': ['LC_L', 'LC_R'],\n",
    "                            'LRt': ['LRt_L', 'LRt_R'],\n",
    "                            'Pn': ['Pn_L', 'Pn_R'],\n",
    "                            'R': ['R_L', 'R_R'],\n",
    "                            'RtTg': ['RtTg'],\n",
    "                            'Tz': ['Tz_L', 'Tz_R'],\n",
    "                            'VLL': ['VLL_L', 'VLL_R'],\n",
    "                            'sp5': ['sp5'],\n",
    "                           'outerContour': ['outerContour']}\n",
    "\n",
    "labelMap_sidedToUnsided = {n: nu for nu, ns in labelMap_unsidedToSided.iteritems() for n in ns}\n",
    "\n",
    "from itertools import chain\n",
    "labels_sided = list(chain(*(labelMap_unsidedToSided[name_u] for name_u in labels_unsided)))\n",
    "labels_sided_indices = dict((j, i+1) for i, j in enumerate(labels_sided)) # BackG always 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack = 'MD594'\n",
    "with open(atlasAlignParams_dir + '/%(stack)s/%(stack)s_3dAlignParams.txt' % {'stack': stack}, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    global_params = np.array(map(float, lines[0].strip().split()))\n",
    "#     atlas_xdim, atlas_ydim, atlas_zdim  = np.array(map(float, lines[1].strip().split()))\n",
    "    atlas_centroid = np.array(map(float, lines[2].strip().split()))\n",
    "    test_xdim, test_ydim, test_zdim = np.array(map(int, lines[3].strip().split()))\n",
    "    test_centroid = np.array(map(float, lines[4].strip().split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ann_xmin, ann_xmax, ann_ymin, ann_ymax, ann_zmin, ann_zmax = \\\n",
    "np.loadtxt(volume_dir + '%(stack)s/volume_%(stack)s_annotation_withOuterContour_limits.txt' % {'stack': stack}, dtype=np.int)\n",
    "\n",
    "sco_xmin, sco_xmax, sco_ymin, sco_ymax, sco_zmin, sco_zmax = \\\n",
    "np.loadtxt(volume_dir + '%(stack)s/%(stack)s_scoreVolume_limits.txt' % {'stack': stack}, dtype=np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def align_principle_axes(vertices_normalized0, vertices_normalized):\n",
    "    \n",
    "    u1, _, _ = np.linalg.svd(np.dot(vertices_normalized0.T, vertices_normalized0)/vertices_normalized0.shape[0])\n",
    "    \n",
    "    u, s, v = np.linalg.svd(np.dot(vertices_normalized.T, vertices_normalized)/vertices_normalized.shape[0])\n",
    "\n",
    "    if np.dot(u[:,0], u1[:,0]) < 0:\n",
    "        u[:,0] = -u[:,0]\n",
    "    if np.dot(u[:,1], u1[:,1]) < 0:\n",
    "        u[:,1] = -u[:,1]\n",
    "    if np.dot(u[:,2], u1[:,2]) < 0:\n",
    "        u[:,2] = -u[:,2]\n",
    "\n",
    "    U, _, VT = np.linalg.svd(np.dot(u1, u.T))\n",
    "    R = np.dot(U, VT)\n",
    "    \n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.spatial import KDTree\n",
    "\n",
    "def icp(template2, moving, num_iter=10, rotation_only=True):\n",
    "    # https://www.wikiwand.com/en/Orthogonal_Procrustes_problem\n",
    "    # https://www.wikiwand.com/en/Kabsch_algorithm\n",
    "    \n",
    "    moving2 = moving.copy()\n",
    "    template = template2.copy()\n",
    "    \n",
    "    tree = KDTree(template)\n",
    "\n",
    "    for i in range(num_iter):\n",
    "        \n",
    "        t = time.time()\n",
    "        \n",
    "        _, nns = tree.query(moving2)\n",
    "        data = template[nns]\n",
    "        M = np.dot(moving2.T, data)\n",
    "        U, s, VT = np.linalg.svd(M)\n",
    "        if rotation_only:\n",
    "            s2 = np.ones_like(s)\n",
    "            s2[-1] = np.sign(np.linalg.det(np.dot(U, VT).T))\n",
    "            R = np.dot(np.dot(U, np.diag(s2)), VT).T\n",
    "        else:\n",
    "            R = np.dot(U, VT).T\n",
    "            \n",
    "        moving2 = np.dot(moving2, R.T)\n",
    "        d = np.sum(np.sqrt(np.sum((moving2 - data)**2, axis=1)))\n",
    "        if i > 1 and d_prev == d:\n",
    "            break\n",
    "        d_prev = d\n",
    "        \n",
    "        sys.stderr.write('icp @ %d err %.2f: %.2f\\n' % (i, d, time.time() - t))\n",
    "    \n",
    "    M = np.dot(moving.T, template[nns])\n",
    "    U, _, VT = np.linalg.svd(M)\n",
    "    R = np.dot(U, VT).T\n",
    "    \n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def average_shape(polydata_list, concensus_percentage=.5, num_simplify_iter=0, smooth=False):\n",
    "    \n",
    "    volume_list = []\n",
    "    origin_list = []\n",
    "\n",
    "    for p in polydata_list:\n",
    "        t = time.time()\n",
    "        v, orig, _ = polydata_to_volume(p)\n",
    "        sys.stderr.write('polydata_to_volume: %.2f\\n' % (time.time() - t))\n",
    "\n",
    "        volume_list.append(v)\n",
    "        origin_list.append(np.array(orig, np.int))\n",
    "\n",
    "    t = time.time()\n",
    "        \n",
    "    common_mins = np.min(origin_list, axis=0).astype(np.int)\n",
    "    relative_origins = origin_list - common_mins\n",
    "\n",
    "    common_xdim, common_ydim, common_zdim = np.max([(v.shape[1]+o[0], v.shape[0]+o[1], v.shape[2]+o[2])\n",
    "                                                    for v,o in zip(volume_list, relative_origins)], axis=0)\n",
    "\n",
    "    common_volume_list = []\n",
    "\n",
    "    for i, v in enumerate(volume_list):\n",
    "        common_volume = np.zeros( (common_ydim, common_xdim, common_zdim), np.uint8)\n",
    "        x0, y0, z0 = relative_origins[i]\n",
    "        ydim, xdim, zdim = v.shape\n",
    "        common_volume[y0:y0+ydim, x0:x0+xdim, z0:z0+zdim] = v\n",
    "\n",
    "        common_volume_list.append((common_volume > 0).astype(np.int))\n",
    "\n",
    "    average_volume = np.sum(common_volume_list, axis=0) >= min(2, len(common_volume_list)*concensus_percentage)\n",
    "        \n",
    "    sys.stderr.write('find common: %.2f\\n' % (time.time() - t))\n",
    "\n",
    "    print average_volume.shape\n",
    "    \n",
    "    t = time.time()\n",
    "    average_polydata = volume_to_polydata(average_volume, common_mins, num_simplify_iter=num_simplify_iter, \n",
    "                                          smooth=smooth)\n",
    "    sys.stderr.write('volume_to_polydata: %.2f\\n' % (time.time() - t))\n",
    "    \n",
    "    return average_volume, average_polydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outerContour\n",
      "[[ 1.  0.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  0.  1.]]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "icp @ 0 err 3254.18: 7.15\n",
      "icp @ 1 err 3132.45: 6.89\n",
      "icp @ 2 err 3056.80: 6.79\n",
      "icp @ 3 err 3011.54: 6.70\n",
      "icp @ 4 err 2982.09: 6.63\n",
      "icp @ 5 err 2953.09: 6.60\n",
      "icp @ 6 err 2928.58: 6.83\n",
      "icp @ 7 err 2909.55: 6.56\n",
      "icp @ 8 err 2896.79: 6.53\n",
      "icp @ 9 err 2887.98: 6.69\n",
      "icp @ 10 err 2881.01: 6.54\n",
      "icp @ 11 err 2876.38: 6.78\n",
      "icp @ 12 err 2873.00: 6.85\n",
      "icp @ 13 err 2870.95: 6.65\n",
      "icp @ 14 err 2869.71: 6.42\n",
      "icp @ 15 err 2868.80: 7.69\n",
      "icp @ 16 err 2868.42: 6.38\n",
      "icp @ 17 err 2867.84: 6.35\n",
      "icp @ 18 err 2867.38: 6.35\n",
      "icp @ 19 err 2866.72: 6.34\n",
      "icp @ 20 err 2866.45: 6.35\n",
      "icp @ 21 err 2866.22: 6.34\n",
      "icp @ 22 err 2865.90: 6.33\n",
      "icp @ 23 err 2865.66: 6.35\n",
      "icp @ 24 err 2865.53: 6.52\n",
      "icp @ 25 err 2865.42: 6.54\n",
      "icp @ 26 err 2865.31: 6.38\n",
      "icp @ 27 err 2865.21: 6.33\n",
      "icp @ 28 err 2865.12: 6.31\n",
      "icp @ 29 err 2865.05: 6.39\n",
      "icp @ 30 err 2865.02: 6.33\n",
      "icp @ 31 err 2864.99: 6.33\n",
      "icp @ 32 err 2864.95: 6.33\n",
      "icp @ 33 err 2864.90: 6.32\n",
      "icp @ 34 err 2864.79: 6.33\n",
      "icp @ 35 err 2864.67: 6.43\n",
      "icp @ 36 err 2864.52: 6.58\n",
      "icp @ 37 err 2864.40: 6.61\n",
      "icp @ 38 err 2864.24: 6.62\n",
      "icp @ 39 err 2864.10: 66.96\n",
      "icp @ 40 err 2863.97: 6.45\n",
      "icp @ 41 err 2863.87: 6.42\n",
      "icp @ 42 err 2863.82: 6.46\n",
      "icp @ 43 err 2863.76: 6.53\n",
      "icp @ 44 err 2863.69: 6.37\n",
      "icp @ 45 err 2863.59: 6.34\n",
      "icp @ 46 err 2863.54: 6.35\n",
      "icp @ 47 err 2863.50: 6.35\n",
      "icp @ 48 err 2863.48: 6.51\n",
      "icp @ 49 err 2863.48: 6.35\n",
      "icp @ 50 err 2863.45: 6.36\n",
      "icp @ 51 err 2863.38: 7.44\n",
      "icp @ 52 err 2863.32: 6.34\n",
      "icp @ 53 err 2863.22: 6.35\n",
      "icp @ 54 err 2863.12: 6.38\n",
      "icp @ 55 err 2863.07: 6.53\n",
      "icp @ 56 err 2863.05: 6.51\n",
      "icp @ 57 err 2863.04: 6.33\n",
      "icp @ 58 err 2863.04: 6.31\n",
      "icp @ 59 err 2863.02: 6.31\n",
      "icp @ 60 err 2863.00: 6.32\n",
      "icp @ 61 err 2862.99: 6.31\n",
      "icp @ 62 err 2862.99: 6.34\n",
      "icp @ 63 err 2862.96: 6.39\n",
      "icp @ 64 err 2862.92: 6.31\n",
      "icp @ 65 err 2862.89: 6.32\n",
      "icp @ 66 err 2862.86: 6.31\n",
      "icp @ 67 err 2862.85: 6.32\n",
      "icp @ 68 err 2862.83: 6.31\n",
      "icp @ 69 err 2862.84: 6.31\n",
      "icp @ 70 err 2862.84: 6.31\n",
      "icp @ 71 err 2862.85: 6.33\n",
      "icp @ 72 err 2862.85: 6.32\n",
      "icp @ 73 err 2862.88: 6.35\n",
      "icp @ 74 err 2862.89: 6.31\n",
      "icp @ 75 err 2862.89: 6.32\n",
      "icp @ 76 err 2862.90: 6.32\n",
      "icp @ 77 err 2862.89: 6.31\n",
      "icp @ 78 err 2862.90: 6.31\n",
      "icp @ 79 err 2862.91: 6.31\n",
      "icp @ 80 err 2862.92: 6.31\n",
      "icp @ 81 err 2862.96: 6.33\n",
      "icp @ 82 err 2862.98: 6.32\n",
      "icp @ 83 err 2862.99: 6.45\n",
      "icp @ 84 err 2863.00: 6.39\n",
      "icp @ 85 err 2863.01: 6.39\n",
      "icp @ 86 err 2863.02: 6.39\n",
      "icp @ 87 err 2863.03: 6.38\n",
      "icp @ 88 err 2863.03: 6.38\n",
      "icp @ 89 err 2863.04: 6.51\n",
      "icp @ 90 err 2863.04: 6.44\n",
      "icp @ 91 err 2863.04: 6.42\n",
      "icp @ 92 err 2863.03: 6.42\n",
      "icp @ 93 err 2863.02: 6.42\n",
      "icp @ 94 err 2863.02: 6.41\n",
      "icp @ 95 err 2863.02: 6.41\n",
      "icp @ 96 err 2863.02: 6.41\n",
      "icp @ 97 err 2863.01: 6.39\n",
      "icp @ 98 err 2863.01: 6.40\n",
      "icp: 705.90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[ 0.97954637 -0.18393658  0.08158516]\n",
      " [ 0.19129926  0.97700858 -0.09412119]\n",
      " [-0.06239707  0.10780326  0.99221218]]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fill point array: 0.02 seconds\n",
      "fill cell array: 0.00 seconds\n",
      "fill point array: 0.02 seconds\n",
      "fill cell array: 0.00 seconds\n",
      "polydata_to_volume: 0.78\n",
      "polydata_to_volume: 0.98\n",
      "find common: 11.24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(543, 951, 545)\n",
      "area: 2490494.54"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "marching cube: 29.27 seconds\n",
      "compute surface area: 0.89 seconds\n",
      "fill point array: 3.39 seconds\n",
      "fill cell array: 0.18 seconds\n",
      "mesh_to_polydata: 3.59 seconds\n",
      "simplify 0 @ 2610385: 26.89 seconds\n",
      "simplify 1 @ 522738: 36.61 seconds\n",
      "simplify 2 @ 105387: 8.38 seconds\n",
      "simplify 3 @ 21928: 1.45 seconds\n",
      "simplify 4 @ 5230: 0.21 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "volume_to_polydata: 108.16\n",
      "average shape: 121.25\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "centroid_allLandmarks = defaultdict(list)\n",
    "average_polydata_allLandmarks = {}\n",
    "polydata_list_allLandmarks = {}\n",
    "\n",
    "# for name_unsided in labels_unsided:\n",
    "for name_unsided in ['outerContour']:\n",
    "    \n",
    "    print name_unsided    \n",
    "    \n",
    "    vertices_list = []\n",
    "    faces_list = []\n",
    "    \n",
    "    for stack in ['MD589', 'MD594']:\n",
    "#     for stack in ['MD594']:\n",
    "\n",
    "        names = labelMap_unsidedToSided[name_unsided]\n",
    "        \n",
    "        if len(names) == 2:\n",
    "        \n",
    "            for name_sided in names:\n",
    "\n",
    "                fn = \"/home/yuncong/CSHL_meshes/%(stack)s/%(stack)s_%(label)s_gaussianSmoothed.stl\" % {'stack':stack, 'label':name_sided}\n",
    "               \n",
    "                if os.path.exists(fn):\n",
    "                    vertices, faces = load_mesh_stl(fn)\n",
    "                else:\n",
    "                    continue\n",
    "            \n",
    "                if '_L' in name_sided:\n",
    "                    zmean = vertices[:,2].mean(axis=0)\n",
    "                    vertices[:, 2] = - (vertices[:, 2] - zmean) + zmean # mirror L to align with R, keep zmin        \n",
    "\n",
    "                vertices_list.append(vertices)\n",
    "\n",
    "                if stack == 'MD594':\n",
    "                    vertices_alignedToScoreVolume = vertices + (ann_xmin,ann_ymin,ann_zmin) - (sco_xmin,sco_ymin,sco_zmin)\n",
    "                    vertices_alignedToAtlas = transform_points_inverse(global_params, pts_prime=vertices_alignedToScoreVolume, \n",
    "                                                                       c_prime=test_centroid, c=atlas_centroid)\n",
    "\n",
    "                faces_list.append(faces)\n",
    "\n",
    "                centroid_prime = vertices.mean(axis=0)\n",
    "\n",
    "                if stack == 'MD594':\n",
    "\n",
    "                    centroid_prime_alignedToScoreVolume = centroid_prime + (ann_xmin,ann_ymin,ann_zmin) - (sco_xmin,sco_ymin,sco_zmin)\n",
    "                    centroid_prime_alignedToAtlas = transform_points_inverse(global_params, pts_prime=[centroid_prime_alignedToScoreVolume], \n",
    "                                                                       c_prime=test_centroid, c=atlas_centroid)[0]\n",
    "                    centroid_allLandmarks[name_sided].append(centroid_prime_alignedToAtlas)\n",
    "                else:\n",
    "                    centroid_allLandmarks[name_sided].append(centroid_prime)\n",
    "        \n",
    "        elif len(names) == 1:\n",
    "            \n",
    "            name_sided = names[0]\n",
    "            \n",
    "            fn = \"/home/yuncong/CSHL_meshes/%(stack)s/%(stack)s_%(label)s_gaussianSmoothed.stl\" % {'stack':stack, 'label':name_sided}\n",
    "            \n",
    "            if os.path.exists(fn):\n",
    "                vertices, faces = load_mesh_stl(fn)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "#             vertices_mirrored = vertices.copy()    \n",
    "#             zmean = vertices[:,2].mean(axis=0)\n",
    "#             vertices_mirrored[:, 2] = - (vertices[:, 2] - zmean) + zmean # mirror L to align with R, keep zmin        \n",
    "            \n",
    "#             t = time.time()\n",
    "            \n",
    "#             if name_unsided == 'sp5' or name_unsided == 'outerContour':\n",
    "#                 _, symmetric_poly = average_shape([mesh_to_polydata(vertices, faces), mesh_to_polydata(vertices_mirrored, faces)],\n",
    "#                                               num_simplify_iter=5, smooth=True)\n",
    "#             else:\n",
    "#                 _, symmetric_poly = average_shape([mesh_to_polydata(vertices, faces), mesh_to_polydata(vertices_mirrored, faces)],\n",
    "#                                               num_simplify_iter=3, smooth=True)\n",
    "                \n",
    "#             # must simplify so the ICP later can be fast\n",
    "#             # must also smooth, because otherwise the number of points gets stuck\n",
    "            \n",
    "#             sys.stderr.write('average shape: %.2f\\n' % (time.time() - t))\n",
    "#             # cost mostly comes from :\n",
    "#             # - marching cube\n",
    "#             # - first two rounds of decimation and smoothing\n",
    "\n",
    "#             symmetric_vertices, symmetric_faces = polydata_to_mesh(symmetric_poly)\n",
    "         \n",
    "#             vertices_list.append(symmetric_vertices)\n",
    "#             faces_list.append(symmetric_faces)\n",
    "            \n",
    "            symmetric_vertices, symmetric_faces = (vertices, faces)\n",
    "            vertices_list.append(symmetric_vertices)\n",
    "            faces_list.append(symmetric_faces)\n",
    "    \n",
    "            centroid_prime = symmetric_vertices.mean(axis=0)\n",
    "\n",
    "            if stack == 'MD594':\n",
    "\n",
    "                centroid_prime_alignedToScoreVolume = centroid_prime + (ann_xmin,ann_ymin,ann_zmin) - (sco_xmin,sco_ymin,sco_zmin)\n",
    "                centroid_prime_alignedToAtlas = transform_points_inverse(global_params, pts_prime=[centroid_prime_alignedToScoreVolume], \n",
    "                                                                   c_prime=test_centroid, c=atlas_centroid)[0]\n",
    "                centroid_allLandmarks[name_sided].append(centroid_prime_alignedToAtlas)\n",
    "            else:\n",
    "                centroid_allLandmarks[name_sided].append(centroid_prime)\n",
    "\n",
    "            \n",
    "#             for i in range(2):\n",
    "#                 if i == 1:\n",
    "#                     zmean = vertices[:,2].mean(axis=0)\n",
    "#                     vertices[:, 2] = - (vertices[:, 2] - zmean) + zmean # mirror L to align with R, keep zmin        \n",
    "\n",
    "#                 vertices_list.append(vertices.copy())\n",
    "\n",
    "#                 if stack == 'MD594':\n",
    "#                     vertices_alignedToScoreVolume = vertices + (ann_xmin,ann_ymin,ann_zmin) - (sco_xmin,sco_ymin,sco_zmin)\n",
    "#                     vertices_alignedToAtlas = transform_points_inverse(global_params, pts_prime=vertices_alignedToScoreVolume, \n",
    "#                                                                        c_prime=test_centroid, c=atlas_centroid)\n",
    "\n",
    "#                 faces_list.append(faces)\n",
    "\n",
    "#                 centroid_prime = vertices.mean(axis=0)\n",
    "\n",
    "#                 if stack == 'MD594':\n",
    "\n",
    "#                     centroid_prime_alignedToScoreVolume = centroid_prime + (ann_xmin,ann_ymin,ann_zmin) - (sco_xmin,sco_ymin,sco_zmin)\n",
    "#                     centroid_prime_alignedToAtlas = transform_points_inverse(global_params, pts_prime=[centroid_prime_alignedToScoreVolume], \n",
    "#                                                                        c_prime=test_centroid, c=atlas_centroid)[0]\n",
    "#                     centroid_allLandmarks[name_sided].append(centroid_prime_alignedToAtlas)\n",
    "#                 else:\n",
    "#                     centroid_allLandmarks[name_sided].append(centroid_prime)\n",
    "                            \n",
    "    \n",
    "    ###### Align meshes ######\n",
    "    \n",
    "    u1 = None\n",
    "    vertices_normalized_aligned_list = []\n",
    "    vertices_aligned_list = []\n",
    "    centroid_list = []\n",
    "\n",
    "    for i, vertices in enumerate(vertices_list):\n",
    "\n",
    "        centroid = vertices.mean(axis=0)\n",
    "        centroid_list.append(centroid)\n",
    "\n",
    "        scale = np.sqrt(((vertices - centroid)**2).mean())\n",
    "        vertices_normalized = (vertices - centroid) / scale\n",
    "\n",
    "        if i == 0:\n",
    "            vertices_normalized1 = vertices_normalized.copy()\n",
    "            R = np.eye(3)\n",
    "        else:            \n",
    "            t = time.time()\n",
    "            R = icp(vertices_normalized1, vertices_normalized, num_iter=100)\n",
    "            sys.stderr.write('icp: %.2f\\n' % (time.time() - t))\n",
    "\n",
    "        print R\n",
    "\n",
    "        vertices_normalized_alignedTo1 = np.dot(vertices_normalized, R.T)\n",
    "        vertices_normalized_aligned_list.append(vertices_normalized_alignedTo1)\n",
    "\n",
    "        vertices_alignedTo1 = vertices_normalized_alignedTo1 * scale\n",
    "        vertices_aligned_list.append(vertices_alignedTo1)\n",
    "    \n",
    "    polydata_list = [mesh_to_polydata(vs, fs) for vs, fs in zip(vertices_aligned_list, faces_list)]\n",
    "            \n",
    "    # if landmark has only one instance, add its mirrored version\n",
    "#     if len(labelMap_unsidedToSided[name_unsided]) == 1:\n",
    "#         for vs, fs in zip(vertices_aligned_list, faces_list):\n",
    "#             zmean = vs[:,2].mean(axis=0)\n",
    "#             vs_mirrored = vs.copy()\n",
    "#             vs_mirrored[:, 2] = - (vs[:, 2] - zmean) + zmean # mirror L to align with R, keep zmin        \n",
    "#             polydata_list.append(mesh_to_polydata(vs_mirrored, fs))\n",
    "\n",
    "    polydata_list_allLandmarks[name_unsided] = polydata_list\n",
    "    \n",
    "    ######### Compute Average #########\n",
    "    t = time.time()\n",
    "\n",
    "    if name_unsided == 'outerContour' or name_unsided == 'sp5':\n",
    "        _, average_polydata = average_shape(polydata_list, num_simplify_iter=5, smooth=True)\n",
    "    else:\n",
    "        _, average_polydata = average_shape(polydata_list, num_simplify_iter=3, smooth=True)\n",
    "    \n",
    "    sys.stderr.write('average shape: %.2f\\n' % (time.time() - t))\n",
    "\n",
    "    average_polydata_allLandmarks[name_unsided] = average_polydata\n",
    "\n",
    "#     bp.pack_ndarray_file(average_volume, mesh_rootdir + \"/%(name)s_average.bp\" % {'stack': stack, 'name': name_unsided})\n",
    "    \n",
    "    save_mesh_stl(average_polydata, mesh_rootdir + \"/%(name)s_average.stl\" % {'stack': stack, 'name': name_unsided})\n",
    "\n",
    "centroid_allLandmarks.default_factory = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name_to_show = 'outerContour'\n",
    "\n",
    "######## show overlay list of meshes ########\n",
    "ren1 = vtk.vtkRenderer()\n",
    "renWin1 = vtk.vtkRenderWindow()\n",
    "renWin1.AddRenderer(ren1)\n",
    "iren1 = vtk.vtkRenderWindowInteractor()\n",
    "iren1.SetRenderWindow(renWin1)\n",
    "\n",
    "colors = [(0,0,1), (0,1,0), (1,0,0), (1,1,0)]\n",
    "\n",
    "for i, polydata in enumerate(polydata_list_allLandmarks[name_to_show]):\n",
    "    \n",
    "    m = vtk.vtkPolyDataMapper()\n",
    "    m.SetInputData(polydata)\n",
    "\n",
    "    a = vtk.vtkActor()\n",
    "    a.SetMapper(m)\n",
    "    a.GetProperty().SetRepresentationToWireframe()\n",
    "    a.GetProperty().SetColor(colors[i % len(colors)])\n",
    "    \n",
    "    ren1.AddActor(a)\n",
    "\n",
    "axes_widget1 = add_axes(iren1)\n",
    "\n",
    "renWin1.Render()\n",
    "renWin1.SetWindowName('overlay')\n",
    "\n",
    "camera = vtk.vtkCamera()\n",
    "ren1.SetActiveCamera(camera)\n",
    "ren1.ResetCamera()\n",
    "\n",
    "iren1.Start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name_to_show = 'sp5'\n",
    "\n",
    "######## show overlay list of meshes ########\n",
    "ren1 = vtk.vtkRenderer()\n",
    "renWin1 = vtk.vtkRenderWindow()\n",
    "renWin1.AddRenderer(ren1)\n",
    "iren1 = vtk.vtkRenderWindowInteractor()\n",
    "iren1.SetRenderWindow(renWin1)\n",
    "\n",
    "colors = [(1,0,0), (0,1,0), (0,0,1), (1,1,0)]\n",
    "\n",
    "for i, polydata in enumerate(polydata_list_allLandmarks[name_to_show]):\n",
    "    \n",
    "    m = vtk.vtkPolyDataMapper()\n",
    "    m.SetInputData(polydata)\n",
    "\n",
    "    a = vtk.vtkActor()\n",
    "    a.SetMapper(m)\n",
    "    a.GetProperty().SetRepresentationToWireframe()\n",
    "    a.GetProperty().SetColor(colors[i % len(colors)])\n",
    "    \n",
    "    ren1.AddActor(a)\n",
    "\n",
    "axes_widget1 = add_axes(iren1)\n",
    "\n",
    "renWin1.Render()\n",
    "renWin1.SetWindowName('overlay')\n",
    "\n",
    "######### show average mesh #########\n",
    "ren2 = vtk.vtkRenderer()\n",
    "\n",
    "renWin2 = vtk.vtkRenderWindow()\n",
    "renWin2.AddRenderer(ren2)\n",
    "\n",
    "iren2 = vtk.vtkRenderWindowInteractor()\n",
    "iren2.SetRenderWindow(renWin2)\n",
    "\n",
    "m2 = vtk.vtkPolyDataMapper()\n",
    "m2.SetInputData(average_polydata_allLandmarks[name_to_show])\n",
    "\n",
    "a2 = vtk.vtkActor()\n",
    "a2.SetMapper(m2)\n",
    "a2.GetProperty().SetRepresentationToWireframe()\n",
    "# a.GetProperty().SetColor(colors[2])\n",
    "\n",
    "ren2.AddActor(a2)\n",
    "axes_widget2 = add_axes(iren2)\n",
    "\n",
    "renWin2.Render()\n",
    "renWin2.SetWindowName('average')\n",
    "\n",
    "#####################################\n",
    "\n",
    "camera = vtk.vtkCamera()\n",
    "ren1.SetActiveCamera(camera)\n",
    "ren2.SetActiveCamera(camera)\n",
    "ren1.ResetCamera()\n",
    "ren2.ResetCamera()\n",
    "\n",
    "iren1.Start()\n",
    "iren2.Start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
