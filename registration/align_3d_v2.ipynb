{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.environ['REPO_DIR'] + '/utilities')\n",
    "from utilities2015 import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import time\n",
    "\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from quarternion import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# labels = ['BackG', '5N', '7n', '7N', '12N', 'Gr', 'LVe', 'Pn', 'SuVe', 'VLL']\n",
    "\n",
    "labels = ['BackG', '5N', '7n', '7N', '12N', 'Gr', 'LVe', 'Pn', 'SuVe', 'VLL', \n",
    "                     '6N', 'Amb', 'R', 'Tz', 'Sol', 'RtTg', 'LRt', 'LC', 'AP', 'sp5']\n",
    "\n",
    "n_labels = len(labels)\n",
    "\n",
    "label_dict = dict([(l,i) for i, l in enumerate(labels)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "volume_dir = '/oasis/projects/nsf/csd395/yuncong/CSHL_volumes/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "809 405 536\n"
     ]
    }
   ],
   "source": [
    "volume1 = bp.unpack_ndarray_file(os.path.join(volume_dir, 'volume_MD589_annotation.bp'))\n",
    "atlas_ydim, atlas_xdim, atlas_zdim = volume1.shape\n",
    "print atlas_xdim, atlas_ydim, atlas_zdim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.20171308517 seconds\n",
      "0 808 0 404 0 535\n",
      "[ 404.   202.   267.5]\n"
     ]
    }
   ],
   "source": [
    "def parallel_where(l):\n",
    "    w = np.where(volume1 == l)\n",
    "    return [w[1], w[0], w[2]]\n",
    "\n",
    "t = time.time()\n",
    "\n",
    "atlas_nzs = Parallel(n_jobs=16)(delayed(parallel_where)(l) for l in range(1, n_labels))\n",
    "\n",
    "print time.time() - t, 'seconds'\n",
    "\n",
    "atlas_xmin, atlas_ymin, atlas_zmin = np.min([np.min(atlas_nzs[l-1], axis=1) for l in range(1, n_labels)], axis=0)\n",
    "atlas_xmax, atlas_ymax, atlas_zmax = np.max([np.max(atlas_nzs[l-1], axis=1) for l in range(1, n_labels)], axis=0)\n",
    "print atlas_xmin, atlas_xmax, atlas_ymin, atlas_ymax, atlas_zmin, atlas_zmax\n",
    "\n",
    "atlas_centroid = np.array([.5*atlas_xmin+.5*atlas_xmax, .5*atlas_ymin+.5*atlas_ymax, .5*atlas_zmin+.5*atlas_zmax])\n",
    "print atlas_centroid\n",
    "\n",
    "atlas_cx, atlas_cy, atlas_cz = atlas_centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "downsample_factor = 16\n",
    "\n",
    "section_thickness = 20 # in um\n",
    "xy_pixel_distance_lossless = 0.46\n",
    "xy_pixel_distance_tb = xy_pixel_distance_lossless * 32 # in um, thumbnail\n",
    "# factor = section_thickness/xy_pixel_distance_lossless\n",
    "\n",
    "xy_pixel_distance_downsampled = xy_pixel_distance_lossless * downsample_factor\n",
    "z_xy_ratio_downsampled = section_thickness / xy_pixel_distance_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "atlasAlignOptLogs_dir = '/oasis/projects/nsf/csd395/yuncong/CSHL_atlasAlignOptLogs'\n",
    "if not os.path.exists(atlasAlignOptLogs_dir):\n",
    "    os.makedirs(atlasAlignOptLogs_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "atlasAlignParams_dir = '/oasis/projects/nsf/csd395/yuncong/CSHL_atlasAlignParams'\n",
    "if not os.path.exists(atlasAlignParams_dir):\n",
    "    os.makedirs(atlasAlignParams_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "annotationsViz_rootdir = '/oasis/projects/nsf/csd395/yuncong/CSHL_annotaionsPojectedViz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colors = np.loadtxt(os.environ['REPO_DIR'] + '/visualization/100colors.txt')\n",
    "colors[label_dict['BackG']] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "volume2_allLabels = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_transform(tx, ty, tz, qr, qx, qy, qz):\n",
    "    \n",
    "    R = quarternion_to_matrix(qr, qx, qy, qz)\n",
    "                \n",
    "    scores = np.empty((n_labels-1,))\n",
    "    for l in range(1, n_labels):\n",
    "                    \n",
    "        test_xs, test_ys, test_zs = (np.dot(R, np.array(atlas_nzs[l-1]) - atlas_centroid[:, np.newaxis]) + \\\n",
    "                                    np.asarray([tx + test_cx, \n",
    "                                                ty + test_cy, \n",
    "                                                tz + test_cz])[:,np.newaxis]).astype(np.int)\n",
    "\n",
    "        ydim, xdim, zdim = volume2_allLabels[l-1].shape\n",
    "\n",
    "        valid = (test_xs >= 0) & (test_ys >= 0) & (test_zs >= 0) & \\\n",
    "                (test_ys < ydim) & (test_xs < xdim) & (test_zs < zdim)\n",
    "\n",
    "        voxel_probs_valid = volume2_allLabels[l-1][test_ys[valid], test_xs[valid], test_zs[valid]] / 1e4\n",
    "        \n",
    "        scores[l-1] = voxel_probs_valid.sum()\n",
    "        \n",
    "    del voxel_probs_valid, valid, test_xs, test_ys, test_zs\n",
    "                \n",
    "    score = np.sum(scores)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for stack in ['MD593', 'MD592', 'MD590', 'MD591', 'MD595', 'MD598', 'MD602', 'MD585']:\n",
    "for stack in ['MD585']:\n",
    "    \n",
    "    section_bs_begin, section_bs_end = section_range_lookup[stack]\n",
    "    print section_bs_begin, section_bs_end\n",
    "\n",
    "    (volume_xmin, volume_xmax, volume_ymin, volume_ymax, volume_zmin, volume_zmax) = \\\n",
    "    np.loadtxt(os.path.join(volume_dir, 'volume_%(stack)s_scoreMap_limits.txt' % {'stack': stack}), dtype=np.int)\n",
    "\n",
    "    map_z_to_section = {}\n",
    "    for s in range(section_bs_begin, section_bs_end+1):\n",
    "        for z in range(int(z_xy_ratio_downsampled*s) - volume_zmin, int(z_xy_ratio_downsampled*(s+1)) - volume_zmin + 1):\n",
    "            map_z_to_section[z] = s\n",
    "\n",
    "            \n",
    "    global volume2_allLabels\n",
    "    volume2_allLabels = []\n",
    "\n",
    "    for l in labels[1:]:\n",
    "        \n",
    "        print l\n",
    "\n",
    "        volume2 = bp.unpack_ndarray_file(os.path.join(volume_dir, 'volume_%(stack)s_scoreMap_%(label)s.bp' % \\\n",
    "                                                      {'stack': stack, 'label': l}))\n",
    "\n",
    "        volume2_cropped = volume2[volume_ymin:volume_ymax+1, volume_xmin:volume_xmax+1]\n",
    "        # copy is important, because then you can delete the large array\n",
    "\n",
    "        volume2_allLabels.append(volume2_cropped.copy())\n",
    "\n",
    "        del volume2, volume2_cropped\n",
    "\n",
    "\n",
    "    test_ydim, test_xdim, test_zdim = volume2_allLabels[0].shape\n",
    "\n",
    "    print test_xdim, test_ydim, test_zdim\n",
    "\n",
    "    test_centroid = (.5*test_xdim, .5*test_ydim, .5*test_ydim)\n",
    "    print test_centroid\n",
    "\n",
    "    test_cx, test_cy, test_cz = test_centroid\n",
    "\n",
    "    \n",
    "    handler = logging.FileHandler(atlasAlignOptLogs_dir + '/%(stack)s_atlasAlignOpt.log' % {'stack': stack})\n",
    "    handler.setLevel(logging.INFO)\n",
    "    logger.addHandler(handler)\n",
    "\n",
    "\n",
    "    ########## Grid Search ##########\n",
    "\n",
    "    grid_search_iteration_number = 10\n",
    "\n",
    "    params2_best_upToNow = (0, 0, 0, 0,0, np.deg2rad(0))\n",
    "    score_best_upToNow = 0\n",
    "\n",
    "    for iteration in range(grid_search_iteration_number):\n",
    "\n",
    "        logger.info('grid search iteration %d', iteration)\n",
    "\n",
    "        init_tx, init_ty, init_tz, init_vx, init_vy, init_theta  = params2_best_upToNow\n",
    "\n",
    "        n = int(1000*np.exp(-iteration/3.))\n",
    "\n",
    "        sigma_tx = 300*np.exp(-iteration/3.)\n",
    "        sigma_ty = 300*np.exp(-iteration/3.)\n",
    "        sigma_tz = 200*np.exp(-iteration/3.)\n",
    "\n",
    "        sigma_v = .1 # axis of rotation\n",
    "        sigma_theta = np.deg2rad(30*np.exp(-iteration/3.))\n",
    "\n",
    "        tx_grid = init_tx + sigma_tx * (2 * np.random.random(n) - 1)\n",
    "        ty_grid = init_ty + sigma_ty * (2 * np.random.random(n) - 1)\n",
    "        tz_grid = init_tz + sigma_tz * (2 * np.random.random(n) - 1)\n",
    "        vx_grid = init_vx + sigma_v * (2 * np.random.random(n) - 1)\n",
    "        vy_grid = init_vy + sigma_v * (2 * np.random.random(n) - 1)\n",
    "        theta_grid = init_theta + sigma_theta * (2 * np.random.random(n) - 1)\n",
    "\n",
    "        qr_grid = np.cos(theta_grid/2)\n",
    "        qx_grid = np.sin(theta_grid/2)*vx_grid\n",
    "        qy_grid = np.sin(theta_grid/2)*vy_grid\n",
    "\n",
    "        vz_grid = np.sqrt(1-vx_grid**2-vy_grid**2)\n",
    "        qz_grid = np.sin(theta_grid/2)*vz_grid\n",
    "\n",
    "        samples = np.c_[tx_grid, ty_grid, tz_grid, qr_grid, qx_grid, qy_grid, qz_grid]\n",
    "\n",
    "        q_norm = np.sqrt(qr_grid**2 + qx_grid**2 + qy_grid**2 + qz_grid**2)\n",
    "        qr_grid = qr_grid / q_norm \n",
    "        qx_grid = qx_grid / q_norm \n",
    "        qy_grid = qy_grid / q_norm \n",
    "        qz_grid = qz_grid / q_norm \n",
    "\n",
    "        import time\n",
    "        t = time.time()\n",
    "\n",
    "        scores = Parallel(n_jobs=16)(delayed(score_transform)(tx, ty, tz, qr, qx, qy, qz ) \n",
    "                                     for tx, ty, tz, qr, qx, qy, qz in samples)\n",
    "\n",
    "        print time.time() - t, 'seconds'\n",
    "\n",
    "        score_best = np.max(scores)\n",
    "\n",
    "        tx_best, ty_best, tz_best, qr_best, qx_best, qy_best, qz_best = samples[np.argmax(scores)]\n",
    "\n",
    "        if score_best > score_best_upToNow:\n",
    "            logger.info('%f %f', score_best_upToNow, score_best)\n",
    "\n",
    "            score_best_upToNow = score_best\n",
    "            params_best_upToNow = tx_best, ty_best, tz_best, qr_best, qx_best, qy_best, qz_best\n",
    "\n",
    "            v_best = np.array([qx_best,qy_best,qz_best])/np.sqrt(qx_best**2+qy_best**2+qz_best**2)\n",
    "            theta_best = np.arccos(qr_best)\n",
    "\n",
    "            params2_best_upToNow = tx_best, ty_best, tz_best, v_best[0], v_best[1], theta_best\n",
    "\n",
    "            logger.info('%f %f %f (%f %f %f) %f', \n",
    "                         tx_best, ty_best, tz_best, v_best[0], v_best[1], v_best[2], np.rad2deg(theta_best))\n",
    "            logger.info(' '.join(['%f']*7) % params_best_upToNow)\n",
    "            logger.info('\\n')\n",
    "\n",
    "    ########## Compute score volume gradient ##########\n",
    "\n",
    "    dSdyxz = []\n",
    "    for l in range(1, n_labels):\n",
    "        print labels[l]\n",
    "\n",
    "        t = time.time()\n",
    "        dSdyxz.append(np.gradient(volume2_allLabels[l-1], 10, 10, 10))\n",
    "        print time.time() - t, 'seconds'\n",
    "\n",
    "\n",
    "    ########## Gradient descent ##########\n",
    "\n",
    "    def optimal_global_rigid_params(init_params, iter_num=100, return_scores=False, lr=(.01, 1e-6)):\n",
    "\n",
    "        fudge_factor = 1e-6 #for numerical stability\n",
    "\n",
    "        dMdu_historical = 0\n",
    "        dMdv_historical = 0\n",
    "        dMdw_historical = 0\n",
    "        dMdqr_historical = 0\n",
    "        dMdqx_historical = 0\n",
    "        dMdqy_historical = 0\n",
    "        dMdqz_historical = 0\n",
    "\n",
    "        lr1, lr2 = lr\n",
    "\n",
    "        score_best = 0\n",
    "\n",
    "        tx_best, ty_best, tz_best, qr_best, qx_best, qy_best, qz_best = init_params\n",
    "\n",
    "        scores = []\n",
    "\n",
    "        for iteration in range(iter_num):\n",
    "\n",
    "            logger.info('iteration %d\\n', iteration)\n",
    "\n",
    "            dMdu = 0\n",
    "            dMdv = 0\n",
    "            dMdw = 0\n",
    "            dMdqr = 0\n",
    "            dMdqx = 0\n",
    "            dMdqy = 0\n",
    "            dMdqz = 0\n",
    "\n",
    "            R_best = quarternion_to_matrix(qr_best, qx_best, qy_best, qz_best)\n",
    "\n",
    "            for l in range(1, n_labels):\n",
    "\n",
    "                ds = np.array(atlas_nzs[l-1]) - atlas_centroid[:, np.newaxis]\n",
    "\n",
    "                xs_prime, ys_prime, zs_prime = (np.dot(R_best, atlas_nzs[l-1] - atlas_centroid[:, np.newaxis]) + \\\n",
    "                                                np.asarray([tx_best + test_cx, \n",
    "                                                            ty_best + test_cy, \n",
    "                                                            tz_best + test_cz])[:,np.newaxis]).astype(np.int)\n",
    "\n",
    "                valid = (xs_prime >= 0) & (ys_prime >= 0) & (zs_prime >= 0) & \\\n",
    "                    (xs_prime < test_xdim) & (ys_prime < test_ydim) & (zs_prime < test_zdim)\n",
    "\n",
    "                if np.count_nonzero(valid) > 0:\n",
    "\n",
    "                    xs_prime_valid = xs_prime[valid]\n",
    "                    ys_prime_valid = ys_prime[valid]\n",
    "                    zs_prime_valid = zs_prime[valid]\n",
    "\n",
    "                    Sx = dSdyxz[l-1][1][ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "                    Sy = dSdyxz[l-1][0][ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "                    Sz = dSdyxz[l-1][2][ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "\n",
    "                    dMdu += Sx.sum()\n",
    "                    dMdv += Sy.sum()\n",
    "                    dMdw += Sz.sum()\n",
    "\n",
    "                    ds_valid = ds[:, valid]\n",
    "                    xs, ys, zs = ds_valid\n",
    "\n",
    "                    qn_jac = quarternion_normalization_jacobian(qr_best,qx_best,qy_best,qz_best)\n",
    "\n",
    "                    qr = qr_best\n",
    "                    qx = qx_best\n",
    "                    qy = qy_best\n",
    "                    qz = qz_best\n",
    "\n",
    "                    dxdqr = 2*(-qz*ys+qy*zs)\n",
    "                    dxdqx = 2*qy*ys+qz*zs\n",
    "                    dxdqy = 2*(-2*qy*xs+qx*ys+qr*zs)\n",
    "                    dxdqz = 2*(-2*qz*xs-qr*ys+qx*zs)\n",
    "\n",
    "                    dydqr = 2*(qz*xs-qx*zs)\n",
    "                    dydqx = 2*(qy*xs-2*qx*ys-qr*zs)\n",
    "                    dydqy = 2*(qx*xs+qz*zs)\n",
    "                    dydqz = 2*(qr*xs-2*qz*ys+qy*zs)\n",
    "\n",
    "                    dzdqr = 2*(-qy*xs+qx*ys)\n",
    "                    dzdqx = 2*(qz*xs+qr*ys-2*qx*zs)\n",
    "                    dzdqy = 2*(-qr*xs+qz*ys-2*qy*zs)\n",
    "                    dzdqz = 2*(qx*xs+qy*ys)\n",
    "\n",
    "                    dxdq = np.dot(np.c_[dxdqr, dxdqx, dxdqy, dxdqz], qn_jac)\n",
    "                    dydq = np.dot(np.c_[dydqr, dydqx, dydqy, dydqz], qn_jac)\n",
    "                    dzdq = np.dot(np.c_[dzdqr, dzdqx, dzdqy, dzdqz], qn_jac)\n",
    "\n",
    "                    dx2dqr = dxdq[:,0]\n",
    "                    dx2dqx = dxdq[:,1]\n",
    "                    dx2dqy = dxdq[:,2]\n",
    "                    dx2dqz = dxdq[:,3]\n",
    "\n",
    "                    dy2dqr = dydq[:,0]\n",
    "                    dy2dqx = dydq[:,1]\n",
    "                    dy2dqy = dydq[:,2]\n",
    "                    dy2dqz = dydq[:,3]\n",
    "\n",
    "                    dz2dqr = dzdq[:,0]\n",
    "                    dz2dqx = dzdq[:,1]\n",
    "                    dz2dqy = dzdq[:,2]\n",
    "                    dz2dqz = dzdq[:,3]\n",
    "\n",
    "                    dMdqr += np.dot(Sx, dx2dqr) + np.dot(Sy, dy2dqr) + np.dot(Sz, dz2dqr)\n",
    "                    dMdqx += np.dot(Sx, dx2dqx) + np.dot(Sy, dy2dqx) + np.dot(Sz, dz2dqx)\n",
    "                    dMdqy += np.dot(Sx, dx2dqy) + np.dot(Sy, dy2dqy) + np.dot(Sz, dz2dqy)\n",
    "                    dMdqz += np.dot(Sx, dx2dqz) + np.dot(Sy, dy2dqz) + np.dot(Sz, dz2dqz)\n",
    "\n",
    "\n",
    "            logger.info('(dMdu, dMdv, dMdw): %f %f %f', dMdu, dMdv, dMdw)\n",
    "            logger.info('(dMdqr, dMdqx, dMdqy, dMdqz): %f %f %f %f', dMdqr, dMdqx, dMdqy, dMdqz)\n",
    "\n",
    "            dMdu_historical += dMdu**2\n",
    "            dMdv_historical += dMdv**2\n",
    "            dMdw_historical += dMdw**2\n",
    "            dMdqr_historical += dMdqr**2\n",
    "            dMdqx_historical += dMdqx**2\n",
    "            dMdqy_historical += dMdqy**2\n",
    "            dMdqz_historical += dMdqz**2\n",
    "\n",
    "            dMdu_adjusted = dMdu / (fudge_factor + np.sqrt(dMdu_historical))\n",
    "            dMdv_adjusted = dMdv / (fudge_factor + np.sqrt(dMdv_historical))\n",
    "            dMdw_adjusted = dMdw / (fudge_factor + np.sqrt(dMdw_historical))\n",
    "            dMdqr_adjusted = dMdqr / (fudge_factor + np.sqrt(dMdqr_historical))\n",
    "            dMdqx_adjusted = dMdqx / (fudge_factor + np.sqrt(dMdqx_historical))\n",
    "            dMdqy_adjusted = dMdqy / (fudge_factor + np.sqrt(dMdqy_historical))\n",
    "            dMdqz_adjusted = dMdqz / (fudge_factor + np.sqrt(dMdqz_historical))\n",
    "\n",
    "            logger.info('lr1: %f, lr2: %f', lr1, lr2)\n",
    "            tx_best += lr1*dMdu_adjusted\n",
    "            ty_best += lr1*dMdv_adjusted\n",
    "            tz_best += lr1*dMdw_adjusted\n",
    "            qr_best += lr2*dMdqr_adjusted\n",
    "            qx_best += lr2*dMdqx_adjusted\n",
    "            qy_best += lr2*dMdqy_adjusted\n",
    "            qz_best += lr2*dMdqz_adjusted\n",
    "\n",
    "            logger.info('(dMdu, dMdv, dMdw) adjusted: %f %f %f', \n",
    "                        dMdu_adjusted, dMdv_adjusted, dMdw_adjusted)\n",
    "            logger.info('(dMdqr, dMdqx, dMdqy, dMdqz) adjusted: %f %f %f %f', \n",
    "                        dMdqr_adjusted, dMdqx_adjusted, dMdqy_adjusted, dMdqz_adjusted)\n",
    "\n",
    "            logger.info('(tx_best, ty_best, tz_best):  %f %f %f', tx_best, ty_best, tz_best)\n",
    "            logger.info('(qr_best, qx_best, qy_best, qz_best): %f %f %f %f', qr_best, qx_best, qy_best, qz_best)\n",
    "\n",
    "            qn = np.sqrt(qr_best**2 + qx_best**2 + qy_best**2 + qz_best**2)\n",
    "            qx_best = qx_best / qn\n",
    "            qy_best = qy_best / qn\n",
    "            qz_best = qz_best / qn\n",
    "            qr_best = qr_best / qn\n",
    "\n",
    "            v_best = np.array([qx_best, qy_best, qz_best])/np.sqrt(qx_best**2+qy_best**2+qz_best**2)\n",
    "            theta_best = np.arccos(qr_best)\n",
    "            logger.info('(v_best, theta_best): (%f %f %f) %f', v_best[0], v_best[1], v_best[2], np.rad2deg(theta_best))\n",
    "\n",
    "            s = score_transform(tx_best, ty_best, tz_best, qr_best, qx_best, qy_best, qz_best)\n",
    "            logger.info('score: %f', s)\n",
    "            scores.append(s)\n",
    "\n",
    "            logger.info('\\n')\n",
    "\n",
    "            history_len = 50\n",
    "            if iteration > 200:\n",
    "                if np.abs(np.mean(scores[iteration-history_len:iteration]) - \\\n",
    "                          np.mean(scores[iteration-2*history_len:iteration-history_len])) < 1e-3:\n",
    "                    break\n",
    "            \n",
    "            if s > score_best:\n",
    "                logger.info('Current best')\n",
    "                best_params = (tx_best, ty_best, tz_best, qr_best, qx_best, qy_best, qz_best)\n",
    "                score_best = s\n",
    "\n",
    "        if return_scores:\n",
    "            return best_params, scores\n",
    "        else:\n",
    "            return best_params\n",
    "\n",
    "\n",
    "\n",
    "    init_params = params_best_upToNow\n",
    "#     learning_rate = (10., 1e-3)\n",
    "    learning_rate = (1., 1e-3)\n",
    "    iteration_number = 4000\n",
    "\n",
    "    t = time.time()\n",
    "\n",
    "    best_global_params, scores = optimal_global_rigid_params(init_params=init_params, \n",
    "                                                             iter_num=iteration_number, \n",
    "                                                             return_scores=True,\n",
    "                                                            lr=learning_rate)\n",
    "    print best_global_params\n",
    "\n",
    "    print time.time() - t, 'seconds'\n",
    "\n",
    "    plt.plot(scores);\n",
    "    plt.title('improvement of overlap score');\n",
    "    plt.xlabel('iteration');\n",
    "    plt.ylabel('overlap score');\n",
    "    plt.show();\n",
    "\n",
    "    np.save(atlasAlignOptLogs_dir + '/%(stack)s_scoreEvolutions.npy' % {'stack':stack}, scores)\n",
    "    \n",
    "    ########## Project atlas to test images using found alignment matrix ########## \n",
    "\n",
    "    tx_best, ty_best, tz_best, qr_best, qx_best, qy_best, qz_best = best_global_params\n",
    "    R_best = quarternion_to_matrix(qr_best, qx_best, qy_best, qz_best)\n",
    "\n",
    "    atlas_nzs_projected_to_test = [(np.dot(R_best, vs - atlas_centroid[:, np.newaxis]) + \\\n",
    "                                                np.asarray([tx_best + test_cx, \n",
    "                                                            ty_best + test_cy, \n",
    "                                                            tz_best + test_cz])[:,np.newaxis]).astype(np.int)\n",
    "                                    for vs in atlas_nzs]\n",
    "\n",
    "    print np.min(atlas_nzs_projected_to_test[0], axis=1)\n",
    "    print np.max(atlas_nzs_projected_to_test[0], axis=1)\n",
    "\n",
    "    test_volume_atlas_projected = np.zeros_like(volume2_allLabels[0], np.int)\n",
    "\n",
    "    for l in range(1, n_labels):\n",
    "\n",
    "        test_xs, test_ys, test_zs = atlas_nzs_projected_to_test[l-1].astype(np.int)\n",
    "\n",
    "        valid = (test_xs >= 0) & (test_ys >= 0) & (test_zs >= 0) & \\\n",
    "            (test_xs < test_xdim) & (test_ys < test_ydim) & (test_zs < test_zdim)\n",
    "\n",
    "        atlas_xs, atlas_ys, atlas_zs = atlas_nzs[l-1]\n",
    "\n",
    "        test_volume_atlas_projected[test_ys[valid], test_xs[valid], test_zs[valid]] = \\\n",
    "        volume1[atlas_ys[valid], atlas_xs[valid], atlas_zs[valid]]\n",
    "\n",
    "        \n",
    "    del atlas_nzs_projected_to_test\n",
    "        \n",
    "    bp.pack_ndarray_file(test_volume_atlas_projected, \n",
    "                         volume_dir + '/%(stack)s_volume_atlasProjected.bp'%{'stack':stack})\n",
    "\n",
    "\n",
    "    with open(os.path.join(atlasAlignParams_dir, '%(stack)s_3dAlignParams.txt' % {'stack':stack}), 'w') as f:\n",
    "        f.writelines(' '.join(['%f']*len(params_best_upToNow)) % tuple(params_best_upToNow) + '\\n')\n",
    "        f.writelines(' '.join(['%f']*len(best_global_params)) % tuple(best_global_params) + '\\n')\n",
    "        f.writelines(' '.join(['%f']*len(learning_rate)) % tuple(learning_rate) + '\\n')\n",
    "        f.writelines('%d' % iteration_number + '\\n')\n",
    "\n",
    "    annotationsViz_dir = annotationsViz_rootdir + '/' + stack\n",
    "    if not os.path.exists(annotationsViz_dir):\n",
    "        os.makedirs(annotationsViz_dir)\n",
    "\n",
    "    for z in range(0, test_zdim, 10):\n",
    "        print z\n",
    "\n",
    "        dm = DataManager(stack=stack, section=map_z_to_section[z])\n",
    "        dm._load_image(versions=['rgb-jpg'])\n",
    "        viz1 = dm.image_rgb_jpg[::downsample_factor, ::downsample_factor][volume_ymin:volume_ymax+1, volume_xmin:volume_xmax+1]\n",
    "\n",
    "        viz2 = colors[test_volume_atlas_projected[...,z]]\n",
    "        viz = alpha_blending(viz2, viz1[...,:3], .2, 1.)\n",
    "\n",
    "        cv2.imwrite(annotationsViz_dir + '/%(stack)s_%(sec)04d_annotationsProjectedViz_z%(z)04d.jpg' % \\\n",
    "                    {'stack': stack, 'sec': map_z_to_section[z], 'z': z}, \n",
    "                    img_as_ubyte(viz[..., [2,1,0,3]]))\n",
    "        \n",
    "        del  viz1, viz2, viz\n",
    "        \n",
    "        \n",
    "    del test_volume_atlas_projected\n",
    "    \n",
    "    logger.removeHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage.measure import find_contours\n",
    "\n",
    "def find_contour_points(labelmap):\n",
    "    '''\n",
    "    return is (x,y)\n",
    "    '''\n",
    "\n",
    "    regions = regionprops(labelmap)\n",
    "\n",
    "    contour_points = {}\n",
    "\n",
    "    for r in regions:\n",
    "\n",
    "        (min_row, min_col, max_row, max_col) = r.bbox\n",
    "\n",
    "        padded = np.pad(r.filled_image, ((5,5),(5,5)), mode='constant', constant_values=0)\n",
    "\n",
    "        contours = find_contours(padded, .5, fully_connected='high')\n",
    "        contours = [cnt.astype(np.int) for cnt in contours if len(cnt) > 10]\n",
    "        if len(contours) > 1:\n",
    "            sys.stderr.write('region has more than one part\\n')\n",
    "        elif len(contours) == 0:\n",
    "            sys.stderr.write('no contour is found\\n')\n",
    "\n",
    "        pts = contours[0] - (5,5)\n",
    "\n",
    "        pts_sampled = pts[np.arange(0, pts.shape[0], 10)]\n",
    "\n",
    "    #         viz = np.zeros_like(r.filled_image)\n",
    "    #         viz[pts_sampled[:,0], pts_sampled[:,1]] = 1\n",
    "    #         plt.imshow(viz, cmap=plt.cm.gray);\n",
    "    #         plt.show();\n",
    "\n",
    "        contour_points[r.label] = pts_sampled[:, ::-1] + (min_col, min_row)\n",
    "        \n",
    "    return contour_points"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
