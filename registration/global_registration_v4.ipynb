{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(os.path.join(os.environ['REPO_DIR'], 'utilities'))\n",
    "from utilities2015 import *\n",
    "from registration_utilities import *\n",
    "from annotation_utilities import *\n",
    "from metadata import *\n",
    "from data_manager import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack_fixed = 'MD661'\n",
    "# stack_fixed = 'MD652'\n",
    "stack_moving = 'atlasV4'\n",
    "# stack_moving = 'atlasV3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "detector_id = 1\n",
    "warp_setting = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>upstream_warp_id</th>\n",
       "      <th>transform_type</th>\n",
       "      <th>terminate_thresh</th>\n",
       "      <th>grad_computation_sample_number</th>\n",
       "      <th>grid_search_sample_number</th>\n",
       "      <th>std_tx_um</th>\n",
       "      <th>std_ty_um</th>\n",
       "      <th>std_tz_um</th>\n",
       "      <th>std_theta_xy_degree</th>\n",
       "      <th>surround_weight</th>\n",
       "      <th>regularization_weight</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>warp_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>affine</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>rigid</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>rigid</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>rigid</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>inverse</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>affine</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>None</td>\n",
       "      <td>rigid</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>rigid</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>30</td>\n",
       "      <td>inverse</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13</td>\n",
       "      <td>rigid</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>30</td>\n",
       "      <td>inverse</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>None</td>\n",
       "      <td>rigid</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>affine</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>None</td>\n",
       "      <td>affine</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>30</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>None</td>\n",
       "      <td>affine</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>30</td>\n",
       "      <td>-1.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>None</td>\n",
       "      <td>bspline</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>30</td>\n",
       "      <td>-1.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>13</td>\n",
       "      <td>bspline</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>30</td>\n",
       "      <td>-1.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        upstream_warp_id transform_type  terminate_thresh  \\\n",
       "warp_id                                                     \n",
       "1                   None         affine          0.000010   \n",
       "2                      1          rigid          0.000010   \n",
       "4                      1          rigid          0.000001   \n",
       "5                      1          rigid          0.000001   \n",
       "6                      1         affine          0.000010   \n",
       "7                   None          rigid          0.000001   \n",
       "8                      1          rigid          0.000001   \n",
       "9                     13          rigid          0.000001   \n",
       "10                  None          rigid          0.000010   \n",
       "11                     1         affine          0.000010   \n",
       "12                  None         affine          0.000010   \n",
       "13                  None         affine          0.000010   \n",
       "14                  None        bspline          0.000010   \n",
       "15                    13        bspline          0.000010   \n",
       "\n",
       "         grad_computation_sample_number  grid_search_sample_number  std_tx_um  \\\n",
       "warp_id                                                                         \n",
       "1                              100000.0                     1000.0       2000   \n",
       "2                              100000.0                    10000.0        100   \n",
       "4                              100000.0                    10000.0        100   \n",
       "5                              100000.0                    10000.0        100   \n",
       "6                              100000.0                    10000.0        100   \n",
       "7                              100000.0                     1000.0         50   \n",
       "8                              100000.0                    10000.0        200   \n",
       "9                              100000.0                    10000.0        200   \n",
       "10                             100000.0                     1000.0        100   \n",
       "11                             100000.0                    10000.0        100   \n",
       "12                             100000.0                     1000.0       2000   \n",
       "13                             100000.0                     1000.0       2000   \n",
       "14                             100000.0                     1000.0       2000   \n",
       "15                             100000.0                     1000.0       2000   \n",
       "\n",
       "         std_ty_um  std_tz_um  std_theta_xy_degree surround_weight  \\\n",
       "warp_id                                                              \n",
       "1             2000       2000                   30               0   \n",
       "2              100        100                   30               0   \n",
       "4              100        100                   10               0   \n",
       "5              100        100                   30         inverse   \n",
       "6              100        100                   30            -0.5   \n",
       "7               50         50                   10               0   \n",
       "8              200        200                   30         inverse   \n",
       "9              200        200                   30         inverse   \n",
       "10             100        100                   30               0   \n",
       "11             100        100                   30            -0.1   \n",
       "12            2000       2000                   30            -0.5   \n",
       "13            2000       2000                   30             -1.   \n",
       "14            2000       2000                   30             -1.   \n",
       "15            2000       2000                   30             -1.   \n",
       "\n",
       "         regularization_weight  \n",
       "warp_id                         \n",
       "1                          NaN  \n",
       "2                          NaN  \n",
       "4                     0.000001  \n",
       "5                     0.000000  \n",
       "6                     0.000000  \n",
       "7                          NaN  \n",
       "8                     0.000000  \n",
       "9                     0.000000  \n",
       "10                         NaN  \n",
       "11                    0.000000  \n",
       "12                         NaN  \n",
       "13                         NaN  \n",
       "14                         NaN  \n",
       "15                         NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "registration_settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upstream_warp_id                    None\n",
      "transform_type                    affine\n",
      "terminate_thresh                   1e-05\n",
      "grad_computation_sample_number    100000\n",
      "grid_search_sample_number           1000\n",
      "std_tx_um                           2000\n",
      "std_ty_um                           2000\n",
      "std_tz_um                           2000\n",
      "std_theta_xy_degree                   30\n",
      "surround_weight                      -1.\n",
      "regularization_weight                NaN\n",
      "Name: 13, dtype: object\n",
      "135.869565217 135.869565217 135.869565217 0.523598775598\n"
     ]
    }
   ],
   "source": [
    "warp_properties = registration_settings.loc[warp_setting]\n",
    "print warp_properties\n",
    "\n",
    "upstream_warp_setting = warp_properties['upstream_warp_id']\n",
    "if upstream_warp_setting == 'None':\n",
    "    upstream_warp_setting = None\n",
    "transform_type = warp_properties['transform_type']\n",
    "terminate_thresh = warp_properties['terminate_thresh']\n",
    "grad_computation_sample_number = warp_properties['grad_computation_sample_number']\n",
    "grid_search_sample_number = warp_properties['grid_search_sample_number']\n",
    "std_tx_um = warp_properties['std_tx_um']\n",
    "std_ty_um = warp_properties['std_ty_um']\n",
    "std_tz_um = warp_properties['std_tz_um']\n",
    "std_tx = std_tx_um/(XY_PIXEL_DISTANCE_LOSSLESS*32)\n",
    "std_ty = std_ty_um/(XY_PIXEL_DISTANCE_LOSSLESS*32)\n",
    "std_tz = std_tz_um/(XY_PIXEL_DISTANCE_LOSSLESS*32)\n",
    "std_theta_xy = np.deg2rad(warp_properties['std_theta_xy_degree'])\n",
    "print std_tx, std_ty, std_tz, std_theta_xy\n",
    "\n",
    "try:\n",
    "    surround_weight = float(warp_properties['surround_weight'])\n",
    "    include_surround = surround_weight != 0 and not np.isnan(surround_weight)\n",
    "except:\n",
    "    surround_weight = str(warp_properties['surround_weight'])\n",
    "    include_surround = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_ITER_NUM = 1000\n",
    "HISTORY_LEN = 10\n",
    "MAX_GRID_SEARCH_ITER_NUM = 30\n",
    "\n",
    "lr1 = 10\n",
    "lr2 = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_10N_L.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_10N_L.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_10N_L.bp\"\n"
     ]
    }
   ],
   "source": [
    "_ = DataManager.load_original_volume(stack=stack_moving, structure='10N_L', downscale=32,\n",
    "                                     volume_type='score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf \"/shared/CSHL_data_processed/MD585/MD585_prep2_thumbnail/MD585-N16-2015.07.16-20.32.33_MD585_2_0047_prep2_thumbnail.tif\" && mkdir -p \"/shared/CSHL_data_processed/MD585/MD585_prep2_thumbnail\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_data_processed/MD585/MD585_prep2_thumbnail/MD585-N16-2015.07.16-20.32.33_MD585_2_0047_prep2_thumbnail.tif\" \"/shared/CSHL_data_processed/MD585/MD585_prep2_thumbnail/MD585-N16-2015.07.16-20.32.33_MD585_2_0047_prep2_thumbnail.tif\"\n",
      "rm -rf \"/shared/CSHL_data_processed/MD589/MD589_prep2_thumbnail/MD589-N16-2015.07.30-17.03.43_MD589_3_0048_prep2_thumbnail.tif\" && mkdir -p \"/shared/CSHL_data_processed/MD589/MD589_prep2_thumbnail\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_data_processed/MD589/MD589_prep2_thumbnail/MD589-N16-2015.07.30-17.03.43_MD589_3_0048_prep2_thumbnail.tif\" \"/shared/CSHL_data_processed/MD589/MD589_prep2_thumbnail/MD589-N16-2015.07.30-17.03.43_MD589_3_0048_prep2_thumbnail.tif\"\n",
      "rm -rf \"/shared/CSHL_data_processed/MD590/MD590_prep2_thumbnail/MD590-IHC17-2015.08.10-19.09.09_MD590_2_0050_prep2_thumbnail.tif\" && mkdir -p \"/shared/CSHL_data_processed/MD590/MD590_prep2_thumbnail\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_data_processed/MD590/MD590_prep2_thumbnail/MD590-IHC17-2015.08.10-19.09.09_MD590_2_0050_prep2_thumbnail.tif\" \"/shared/CSHL_data_processed/MD590/MD590_prep2_thumbnail/MD590-IHC17-2015.08.10-19.09.09_MD590_2_0050_prep2_thumbnail.tif\"\n",
      "rm -rf \"/shared/CSHL_data_processed/MD591/MD591_prep2_thumbnail/MD591-IHC17-2015.08.28-04.23.47_MD591_1_0049_prep2_thumbnail.tif\" && mkdir -p \"/shared/CSHL_data_processed/MD591/MD591_prep2_thumbnail\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_data_processed/MD591/MD591_prep2_thumbnail/MD591-IHC17-2015.08.28-04.23.47_MD591_1_0049_prep2_thumbnail.tif\" \"/shared/CSHL_data_processed/MD591/MD591_prep2_thumbnail/MD591-IHC17-2015.08.28-04.23.47_MD591_1_0049_prep2_thumbnail.tif\"\n",
      "rm -rf \"/shared/CSHL_data_processed/MD592/MD592_prep2_thumbnail/MD592-N16-2015.08.22-00.50.39_MD592_2_0047_prep2_thumbnail.tif\" && mkdir -p \"/shared/CSHL_data_processed/MD592/MD592_prep2_thumbnail\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_data_processed/MD592/MD592_prep2_thumbnail/MD592-N16-2015.08.22-00.50.39_MD592_2_0047_prep2_thumbnail.tif\" \"/shared/CSHL_data_processed/MD592/MD592_prep2_thumbnail/MD592-N16-2015.08.22-00.50.39_MD592_2_0047_prep2_thumbnail.tif\"\n",
      "rm -rf \"/shared/CSHL_data_processed/MD593/MD593_prep2_thumbnail/MD593-N15-2015.08.21-16.53.02_MD593_3_0045_prep2_thumbnail.tif\" && mkdir -p \"/shared/CSHL_data_processed/MD593/MD593_prep2_thumbnail\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_data_processed/MD593/MD593_prep2_thumbnail/MD593-N15-2015.08.21-16.53.02_MD593_3_0045_prep2_thumbnail.tif\" \"/shared/CSHL_data_processed/MD593/MD593_prep2_thumbnail/MD593-N15-2015.08.21-16.53.02_MD593_3_0045_prep2_thumbnail.tif\"\n",
      "rm -rf \"/shared/CSHL_data_processed/MD594/MD594_prep2_thumbnail/MD594-IHC16-2015.08.26-16.11.01_MD594_1_0046_prep2_thumbnail.tif\" && mkdir -p \"/shared/CSHL_data_processed/MD594/MD594_prep2_thumbnail\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_data_processed/MD594/MD594_prep2_thumbnail/MD594-IHC16-2015.08.26-16.11.01_MD594_1_0046_prep2_thumbnail.tif\" \"/shared/CSHL_data_processed/MD594/MD594_prep2_thumbnail/MD594-IHC16-2015.08.26-16.11.01_MD594_1_0046_prep2_thumbnail.tif\"\n",
      "rm -rf \"/shared/CSHL_data_processed/MD595/MD595_prep2_thumbnail/MD595-IHC12-2015.09.15-01.21.39_MD595_2_0035_prep2_thumbnail.tif\" && mkdir -p \"/shared/CSHL_data_processed/MD595/MD595_prep2_thumbnail\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_data_processed/MD595/MD595_prep2_thumbnail/MD595-IHC12-2015.09.15-01.21.39_MD595_2_0035_prep2_thumbnail.tif\" \"/shared/CSHL_data_processed/MD595/MD595_prep2_thumbnail/MD595-IHC12-2015.09.15-01.21.39_MD595_2_0035_prep2_thumbnail.tif\"\n",
      "rm -rf \"/shared/CSHL_data_processed/MD598/MD598_prep2_thumbnail/MD598-N18-2015.09.29-17.40.03_MD598_3_0054_prep2_thumbnail.tif\" && mkdir -p \"/shared/CSHL_data_processed/MD598/MD598_prep2_thumbnail\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_data_processed/MD598/MD598_prep2_thumbnail/MD598-N18-2015.09.29-17.40.03_MD598_3_0054_prep2_thumbnail.tif\" \"/shared/CSHL_data_processed/MD598/MD598_prep2_thumbnail/MD598-N18-2015.09.29-17.40.03_MD598_3_0054_prep2_thumbnail.tif\"\n",
      "rm -rf \"/shared/CSHL_data_processed/MD599/MD599_prep2_thumbnail/MD599-N19-2015.10.02-18.12.13_MD599_3_0057_prep2_thumbnail.tif\" && mkdir -p \"/shared/CSHL_data_processed/MD599/MD599_prep2_thumbnail\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_data_processed/MD599/MD599_prep2_thumbnail/MD599-N19-2015.10.02-18.12.13_MD599_3_0057_prep2_thumbnail.tif\" \"/shared/CSHL_data_processed/MD599/MD599_prep2_thumbnail/MD599-N19-2015.10.02-18.12.13_MD599_3_0057_prep2_thumbnail.tif\"\n",
      "rm -rf \"/shared/CSHL_data_processed/MD602/MD602_prep2_thumbnail/MD602-N19-2015.12.01-16.24.09_MD602_2_0056_prep2_thumbnail.tif\" && mkdir -p \"/shared/CSHL_data_processed/MD602/MD602_prep2_thumbnail\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_data_processed/MD602/MD602_prep2_thumbnail/MD602-N19-2015.12.01-16.24.09_MD602_2_0056_prep2_thumbnail.tif\" \"/shared/CSHL_data_processed/MD602/MD602_prep2_thumbnail/MD602-N19-2015.12.01-16.24.09_MD602_2_0056_prep2_thumbnail.tif\"\n",
      "rm -rf \"/shared/CSHL_data_processed/MD603/MD603_prep2_thumbnail/MD603-N11-2016.03.02-12.51.47_MD603_1_0031_prep2_thumbnail.tif\" && mkdir -p \"/shared/CSHL_data_processed/MD603/MD603_prep2_thumbnail\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_data_processed/MD603/MD603_prep2_thumbnail/MD603-N11-2016.03.02-12.51.47_MD603_1_0031_prep2_thumbnail.tif\" \"/shared/CSHL_data_processed/MD603/MD603_prep2_thumbnail/MD603-N11-2016.03.02-12.51.47_MD603_1_0031_prep2_thumbnail.tif\"\n",
      "rm -rf \"/shared/CSHL_data_processed/MD635/MD635_prep2_thumbnail/MD635-F25-2016.05.18-21.02.30_MD635_3_0075_prep2_thumbnail.tif\" && mkdir -p \"/shared/CSHL_data_processed/MD635/MD635_prep2_thumbnail\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_data_processed/MD635/MD635_prep2_thumbnail/MD635-F25-2016.05.18-21.02.30_MD635_3_0075_prep2_thumbnail.tif\" \"/shared/CSHL_data_processed/MD635/MD635_prep2_thumbnail/MD635-F25-2016.05.18-21.02.30_MD635_3_0075_prep2_thumbnail.tif\"\n",
      "rm -rf \"/shared/CSHL_data_processed/MD653/MD653_prep2_thumbnail/MD653-F15-2016.12.20-21.04.12_MD653_1_0043_prep2_thumbnail.tif\" && mkdir -p \"/shared/CSHL_data_processed/MD653/MD653_prep2_thumbnail\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_data_processed/MD653/MD653_prep2_thumbnail/MD653-F15-2016.12.20-21.04.12_MD653_1_0043_prep2_thumbnail.tif\" \"/shared/CSHL_data_processed/MD653/MD653_prep2_thumbnail/MD653-F15-2016.12.20-21.04.12_MD653_1_0043_prep2_thumbnail.tif\"\n",
      "rm -rf \"/shared/CSHL_data_processed/MD652/MD652_prep2_thumbnail/MD652-F15-2016.12.16-20.45.52_MD652_3_0045_prep2_thumbnail.tif\" && mkdir -p \"/shared/CSHL_data_processed/MD652/MD652_prep2_thumbnail\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_data_processed/MD652/MD652_prep2_thumbnail/MD652-F15-2016.12.16-20.45.52_MD652_3_0045_prep2_thumbnail.tif\" \"/shared/CSHL_data_processed/MD652/MD652_prep2_thumbnail/MD652-F15-2016.12.16-20.45.52_MD652_3_0045_prep2_thumbnail.tif\"\n",
      "rm -rf \"/shared/CSHL_data_processed/MD642/MD642_prep2_thumbnail/MD642-N14-2017.01.18-16.25.58_MD642_2_0041_prep2_thumbnail.tif\" && mkdir -p \"/shared/CSHL_data_processed/MD642/MD642_prep2_thumbnail\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_data_processed/MD642/MD642_prep2_thumbnail/MD642-N14-2017.01.18-16.25.58_MD642_2_0041_prep2_thumbnail.tif\" \"/shared/CSHL_data_processed/MD642/MD642_prep2_thumbnail/MD642-N14-2017.01.18-16.25.58_MD642_2_0041_prep2_thumbnail.tif\"\n",
      "rm -rf \"/shared/CSHL_data_processed/MD657/MD657_prep2_thumbnail/MD657-N13-2017.02.22-14.33.34_MD657_3_0039_prep2_thumbnail.tif\" && mkdir -p \"/shared/CSHL_data_processed/MD657/MD657_prep2_thumbnail\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_data_processed/MD657/MD657_prep2_thumbnail/MD657-N13-2017.02.22-14.33.34_MD657_3_0039_prep2_thumbnail.tif\" \"/shared/CSHL_data_processed/MD657/MD657_prep2_thumbnail/MD657-N13-2017.02.22-14.33.34_MD657_3_0039_prep2_thumbnail.tif\"\n",
      "rm -rf \"/shared/CSHL_data_processed/MD658/MD658_prep2_thumbnail/MD658-N18-2017.03.31-17.34.22_MD658_2_0053_prep2_thumbnail.tif\" && mkdir -p \"/shared/CSHL_data_processed/MD658/MD658_prep2_thumbnail\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_data_processed/MD658/MD658_prep2_thumbnail/MD658-N18-2017.03.31-17.34.22_MD658_2_0053_prep2_thumbnail.tif\" \"/shared/CSHL_data_processed/MD658/MD658_prep2_thumbnail/MD658-N18-2017.03.31-17.34.22_MD658_2_0053_prep2_thumbnail.tif\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File does not exist: /shared/CSHL_volumes/atlasV4/atlasV4_down32_annotationVolume/atlasV4_down32_annotationVolume_nameToLabel.txt\n",
      "Prior structure/index map not found. Generating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_10N_L_surround_200.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_10N_L_surround_200.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_10N_L_surround_200.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_10N_R.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_10N_R.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_10N_R.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_10N_R_surround_200.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_10N_R_surround_200.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_10N_R_surround_200.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_12N.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_12N.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_12N.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_12N_surround_200.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_12N_surround_200.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_12N_surround_200.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_3N_L.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_3N_L.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_3N_L.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_3N_L_surround_200.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_3N_L_surround_200.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_3N_L_surround_200.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_3N_R.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_3N_R.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_3N_R.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_3N_R_surround_200.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_3N_R_surround_200.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_3N_R_surround_200.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_4N_L.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_4N_L.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_4N_L.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_4N_L_surround_200.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_4N_L_surround_200.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_4N_L_surround_200.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_4N_R.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_4N_R.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_4N_R.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_4N_R_surround_200.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_4N_R_surround_200.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_4N_R_surround_200.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_5N_L.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_5N_L.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_5N_L.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_5N_L_surround_200.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_5N_L_surround_200.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_5N_L_surround_200.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_5N_R.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_5N_R.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_5N_R.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_5N_R_surround_200.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_5N_R_surround_200.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_5N_R_surround_200.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_6N_L.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_6N_L.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_6N_L.bp\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_6N_L_surround_200.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_6N_L_surround_200.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_6N_L_surround_200.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_6N_R.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_6N_R.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_6N_R.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_6N_R_surround_200.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_6N_R_surround_200.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_6N_R_surround_200.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_7N_L.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_7N_L.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_7N_L.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_7N_L_surround_200.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_7N_L_surround_200.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_7N_L_surround_200.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_7N_R.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_7N_R.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_7N_R.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_7N_R_surround_200.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_7N_R_surround_200.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_7N_R_surround_200.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_7n_L.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_7n_L.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_7n_L.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_7n_L_surround_200.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_7n_L_surround_200.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_7n_L_surround_200.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_7n_R.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_7n_R.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_7n_R.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_7n_R_surround_200.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_7n_R_surround_200.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_7n_R_surround_200.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_AP.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_AP.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_AP.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_AP_surround_200.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_AP_surround_200.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_AP_surround_200.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Amb_L.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Amb_L.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Amb_L.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Amb_L_surround_200.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Amb_L_surround_200.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Amb_L_surround_200.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Amb_R.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Amb_R.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Amb_R.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Amb_R_surround_200.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Amb_R_surround_200.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Amb_R_surround_200.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_DC_L.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_DC_L.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_DC_L.bp\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_DC_L_surround_200.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_DC_L_surround_200.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_DC_L_surround_200.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_DC_R.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_DC_R.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_DC_R.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_DC_R_surround_200.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_DC_R_surround_200.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_DC_R_surround_200.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_IC.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_IC.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_IC.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_IC_surround_200.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_IC_surround_200.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_IC_surround_200.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_LC_L.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_LC_L.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_LC_L.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_LC_L_surround_200.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_LC_L_surround_200.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_LC_L_surround_200.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_LC_R.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_LC_R.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_LC_R.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_LC_R_surround_200.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_LC_R_surround_200.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_LC_R_surround_200.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_LRt_L.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_LRt_L.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_LRt_L.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_LRt_L_surround_200.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_LRt_L_surround_200.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_LRt_L_surround_200.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_LRt_R.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_LRt_R.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_LRt_R.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_LRt_R_surround_200.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_LRt_R_surround_200.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_LRt_R_surround_200.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_PBG_L.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_PBG_L.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_PBG_L.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_PBG_L_surround_200.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_PBG_L_surround_200.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_PBG_L_surround_200.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_PBG_R.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_PBG_R.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_PBG_R.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_PBG_R_surround_200.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_PBG_R_surround_200.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_PBG_R_surround_200.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Pn_L.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Pn_L.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Pn_L.bp\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Pn_L_surround_200.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Pn_L_surround_200.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Pn_L_surround_200.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Pn_R.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Pn_R.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Pn_R.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Pn_R_surround_200.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Pn_R_surround_200.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Pn_R_surround_200.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_RMC_L.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_RMC_L.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_RMC_L.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_RMC_L_surround_200.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_RMC_L_surround_200.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_RMC_L_surround_200.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_RMC_R.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_RMC_R.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_RMC_R.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_RMC_R_surround_200.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_RMC_R_surround_200.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_RMC_R_surround_200.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_RtTg.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_RtTg.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_RtTg.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_RtTg_surround_200.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_RtTg_surround_200.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_RtTg_surround_200.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_SC.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_SC.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_SC.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_SC_surround_200.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_SC_surround_200.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_SC_surround_200.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_SNC_L.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_SNC_L.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_SNC_L.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_SNC_L_surround_200.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_SNC_L_surround_200.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_SNC_L_surround_200.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_SNC_R.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_SNC_R.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_SNC_R.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_SNC_R_surround_200.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_SNC_R_surround_200.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_SNC_R_surround_200.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_SNR_L.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_SNR_L.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_SNR_L.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_SNR_L_surround_200.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_SNR_L_surround_200.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_SNR_L_surround_200.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_SNR_R.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_SNR_R.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_SNR_R.bp\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_SNR_R_surround_200.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_SNR_R_surround_200.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_SNR_R_surround_200.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Sp5C_L.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Sp5C_L.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Sp5C_L.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Sp5C_L_surround_200.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Sp5C_L_surround_200.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Sp5C_L_surround_200.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Sp5C_R.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Sp5C_R.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Sp5C_R.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Sp5C_R_surround_200.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Sp5C_R_surround_200.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Sp5C_R_surround_200.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Sp5I_L.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Sp5I_L.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Sp5I_L.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Sp5I_L_surround_200.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Sp5I_L_surround_200.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Sp5I_L_surround_200.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Sp5I_R.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Sp5I_R.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Sp5I_R.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Sp5I_R_surround_200.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Sp5I_R_surround_200.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Sp5I_R_surround_200.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Sp5O_L.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Sp5O_L.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Sp5O_L.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Sp5O_L_surround_200.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Sp5O_L_surround_200.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Sp5O_L_surround_200.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Sp5O_R.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Sp5O_R.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Sp5O_R.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Sp5O_R_surround_200.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Sp5O_R_surround_200.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Sp5O_R_surround_200.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Tz_L.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Tz_L.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Tz_L.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Tz_L_surround_200.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Tz_L_surround_200.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Tz_L_surround_200.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Tz_R.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Tz_R.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Tz_R.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Tz_R_surround_200.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Tz_R_surround_200.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_Tz_R_surround_200.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_VCA_L.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_VCA_L.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_VCA_L.bp\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_VCA_L_surround_200.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_VCA_L_surround_200.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_VCA_L_surround_200.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_VCA_R.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_VCA_R.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_VCA_R.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_VCA_R_surround_200.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_VCA_R_surround_200.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_VCA_R_surround_200.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_VCP_L.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_VCP_L.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_VCP_L.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_VCP_L_surround_200.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_VCP_L_surround_200.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_VCP_L_surround_200.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_VCP_R.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_VCP_R.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_VCP_R.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_VCP_R_surround_200.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_VCP_R_surround_200.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_VCP_R_surround_200.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_VLL_L.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_VLL_L.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_VLL_L.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_VLL_L_surround_200.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_VLL_L_surround_200.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_VLL_L_surround_200.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_VLL_R.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_VLL_R.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_VLL_R.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_VLL_R_surround_200.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_VLL_R_surround_200.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_VLL_R_surround_200.bp\"\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_outerContour.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_outerContour.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_outerContour.bp\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File does not exist: /shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_outerContour.bp\n",
      "Score volume for outerContour does not exist: [Errno 2] No such file or directory: '/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_outerContour.bp'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_outerContour_surround_200.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_outerContour_surround_200.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_outerContour_surround_200.bp\""
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File does not exist: /shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_outerContour_surround_200.bp\n",
      "Score volume for outerContour_surround_200 does not exist: [Errno 2] No such file or directory: '/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_outerContour_surround_200.bp'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_sp5.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_sp5.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_sp5.bp\""
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File does not exist: /shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_sp5.bp\n",
      "Score volume for sp5 does not exist: [Errno 2] No such file or directory: '/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_sp5.bp'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "rm -rf \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_sp5_surround_200.bp\" && mkdir -p \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_sp5_surround_200.bp\" \"/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_sp5_surround_200.bp\"\n",
      "(373, 432, 369)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File does not exist: /shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_sp5_surround_200.bp\n",
      "Score volume for sp5_surround_200 does not exist: [Errno 2] No such file or directory: '/shared/CSHL_volumes/atlasV4/atlasV4_down32_scoreVolume/score_volumes/atlasV4_down32_scoreVolume_sp5_surround_200.bp'\n",
      "Volume shape: (373, 432, 369)\n"
     ]
    }
   ],
   "source": [
    "volume_moving, structure_to_label_moving, label_to_structure_moving = \\\n",
    "DataManager.load_original_volume_all_known_structures(stack=stack_moving, sided=True, volume_type='score', \n",
    "                                                      include_surround=include_surround)\n",
    "print volume_moving[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prior structure/index map not found. Generating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf \"/shared/CSHL_volumes/MD661/MD661_prep2_detector1_down32_scoreVolume/score_volumes/MD661_prep2_detector1_down32_scoreVolume_outerContour.bp\" && mkdir -p \"/shared/CSHL_volumes/MD661/MD661_prep2_detector1_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/MD661/MD661_prep2_detector1_down32_scoreVolume/score_volumes/MD661_prep2_detector1_down32_scoreVolume_outerContour.bp\" \"/shared/CSHL_volumes/MD661/MD661_prep2_detector1_down32_scoreVolume/score_volumes/MD661_prep2_detector1_down32_scoreVolume_outerContour.bp\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File does not exist: /shared/CSHL_volumes/MD661/MD661_prep2_detector1_down32_scoreVolume/score_volumes/MD661_prep2_detector1_down32_scoreVolume_outerContour.bp\n",
      "Score volume for outerContour does not exist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf \"/shared/CSHL_volumes/MD661/MD661_prep2_detector1_down32_scoreVolume/score_volumes/MD661_prep2_detector1_down32_scoreVolume_sp5.bp\" && mkdir -p \"/shared/CSHL_volumes/MD661/MD661_prep2_detector1_down32_scoreVolume/score_volumes\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_volumes/MD661/MD661_prep2_detector1_down32_scoreVolume/score_volumes/MD661_prep2_detector1_down32_scoreVolume_sp5.bp\" \"/shared/CSHL_volumes/MD661/MD661_prep2_detector1_down32_scoreVolume/score_volumes/MD661_prep2_detector1_down32_scoreVolume_sp5.bp\"\n",
      "(492, 777, 371)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File does not exist: /shared/CSHL_volumes/MD661/MD661_prep2_detector1_down32_scoreVolume/score_volumes/MD661_prep2_detector1_down32_scoreVolume_sp5.bp\n",
      "Score volume for sp5 does not exist.\n",
      "Volume shape: (492, 777, 371)\n"
     ]
    }
   ],
   "source": [
    "volume_fixed, structure_to_label_fixed, label_to_structure_fixed = \\\n",
    "DataManager.load_original_volume_all_known_structures(stack=stack_fixed, detector_id=detector_id, prep_id=2,\n",
    "                                                   sided=False, volume_type='score')\n",
    "\n",
    "print volume_fixed[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Experiment: find the smallest set of structures that still work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_loaded_structures_sided = set([convert_to_nonsurround_name(s) for s in structure_to_label_moving.keys()])\n",
    "all_loaded_structures = set([convert_to_original_name(s) for s in all_loaded_structures_sided])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from scipy.spatial.distance import squareform, pdist\n",
    "from itertools import permutations\n",
    "\n",
    "structure_center_locations = {s: np.mean(np.where(DataManager.load_original_volume(stack=stack_moving, structure=s, downscale=32)), axis=1)\n",
    "              for s in all_loaded_structures_sided}\n",
    "structure_names = structure_center_locations.keys()\n",
    "structure_distances = squareform(pdist(structure_center_locations.values()))\n",
    "structure_distances_um = structure_distances * XY_PIXEL_DISTANCE_LOSSLESS * 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_n_dispersed_structures(n, thresh):\n",
    "    g = nx.from_numpy_matrix(structure_distances_um > thresh)\n",
    "    k_cliques = [frozenset([structure_names[i] for i in c]) for c in nx.find_cliques(g) if len(c) == n]\n",
    "    return set(k_cliques)\n",
    "#     k_cliques = [[structure_names[i] for i in c] for c in nx.enumerate_all_cliques(g) if len(c) == n]\n",
    "#     return k_cliques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 sets of 9 structures satisfy the sparsity requirements of 2000 um.\n",
      "0 sets of 9 structures satisfy the sparsity requirements of 2100 um.\n",
      "0 sets of 9 structures satisfy the sparsity requirements of 2200 um.\n",
      "0 sets of 9 structures satisfy the sparsity requirements of 2300 um.\n",
      "0 sets of 9 structures satisfy the sparsity requirements of 2400 um.\n",
      "0 sets of 9 structures satisfy the sparsity requirements of 2500 um.\n",
      "0 sets of 9 structures satisfy the sparsity requirements of 2600 um.\n",
      "0 sets of 9 structures satisfy the sparsity requirements of 2700 um.\n",
      "0 sets of 9 structures satisfy the sparsity requirements of 2800 um.\n",
      "0 sets of 9 structures satisfy the sparsity requirements of 2900 um.\n",
      "0 sets of 9 structures satisfy the sparsity requirements of 3000 um.\n",
      "0 sets of 9 structures satisfy the sparsity requirements of 3100 um.\n",
      "0 sets of 9 structures satisfy the sparsity requirements of 3200 um.\n",
      "0 sets of 9 structures satisfy the sparsity requirements of 3300 um.\n",
      "0 sets of 9 structures satisfy the sparsity requirements of 3400 um.\n",
      "0 sets of 9 structures satisfy the sparsity requirements of 3500 um.\n",
      "0 sets of 9 structures satisfy the sparsity requirements of 3600 um.\n",
      "0 sets of 9 structures satisfy the sparsity requirements of 3700 um.\n",
      "0 sets of 9 structures satisfy the sparsity requirements of 3800 um.\n",
      "0 sets of 9 structures satisfy the sparsity requirements of 3900 um.\n"
     ]
    }
   ],
   "source": [
    "for min_distance_um in range(2000, 4000, 100):\n",
    "#     for n_structures in range(3, 10):\n",
    "    for n_structures in [9]:\n",
    "        structure_subsets = find_n_dispersed_structures(n_structures, min_distance_um)\n",
    "        print len(structure_subsets), 'sets of %d structures satisfy the sparsity requirements of %d um.' % (n_structures, min_distance_um)\n",
    "#         print list(structure_subsets)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset(['LRt_R', 'Sp5C_L', 'Pn_L', '6N_R', 'PBG_L', 'SC', 'SNR_R', 'VCA_R', 'DC_L'])\n"
     ]
    }
   ],
   "source": [
    "min_distance_um = 2000\n",
    "n_structures = 9\n",
    "structure_subsets = find_n_dispersed_structures(n_structures, min_distance_um)\n",
    "print list(structure_subsets)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "structure_subset = ['LRt_R', 'Sp5C_L', 'Pn_L', '6N_R', 'PBG_L', 'SC', 'SNR_R', 'VCA_R', 'DC_L']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# End experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# structure_subset = ['7N_L', '7N_R', '12N', '5N_L', 'Pn_R', 'SNR_L', 'VLL_R', '7n_L', 'Tz_R', 'VCA_L', 'VCP_R']\n",
    "# structure_subset = ['7N_L', '7N_R', '12N', '5N_L','5N_R','Pn_L', 'Pn_R', 'SNR_L', 'SNR_R', 'VLL_L', 'VLL_R', '7n_L',\n",
    "#           '7n_R', 'Tz_L', 'Tz_R', 'VCA_L', 'VCP_R']\n",
    "structure_subset = ['7N_L', '7N_R', '12N', '5N_L','5N_R','Pn_L', 'Pn_R', 'SNR_L', 'SNR_R', \n",
    "                    'VLL_L', 'VLL_R', '7n_L', '7n_R', 'Tz_L', 'Tz_R', \n",
    "                    'VCA_L', 'VCA_R', 'VCP_L', 'VCP_R']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if include_surround:\n",
    "    structure_subset = structure_subset + [convert_to_surround_name(s, margin=200) for s in structure_subset]\n",
    "\n",
    "# structure_subset = label_to_structure_moving.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_mapping_m2f = {label_m: structure_to_label_fixed[convert_to_original_name(name_m)] \n",
    "                     for label_m, name_m in label_to_structure_moving.iteritems()\n",
    "                     if name_m in structure_subset}\n",
    "\n",
    "# label_mapping_m2f = {label_m: structure_to_label_fixed[convert_to_original_name(name_m)] \n",
    "#                      for label_m, name_m in label_to_structure_moving.iteritems()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# volume_moving_structure_sizes = {l: np.count_nonzero(vol > 0) for l, vol in volume_moving.iteritems()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# structures_sorted_by_size = [x[1] for x in sorted((s, label_to_structure_moving[l]) for l, s in volume_moving_structure_sizes.iteritems())]\n",
    "# print structures_sorted_by_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if surround_weight == 'inverse':\n",
    "    volume_moving_structure_sizes = {l: np.count_nonzero(vol > 0) for l, vol in volume_moving.iteritems()}\n",
    "    label_weights_m = {label_m: -volume_moving_structure_sizes[structure_to_label_moving[convert_to_nonsurround_name(name_m)]]\n",
    "                       /float(volume_moving_structure_sizes[label_m])\n",
    "                       if is_surround_label(name_m) else 1. \\\n",
    "                       for label_m, name_m in label_to_structure_moving.iteritems()}\n",
    "elif isinstance(surround_weight, int) or isinstance(surround_weight, float):\n",
    "    label_weights_m = {label_m: surround_weight if is_surround_label(name_m) else 1. \\\n",
    "                   for label_m, name_m in label_to_structure_moving.iteritems()}\n",
    "else:\n",
    "    sys.stderr.write(\"surround_weight %s is not recognized. Using the default.\\n\" % surround_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Label weights not set, default to 1 for all structures.\n",
      "Regularization weights not set, default to 0.\n"
     ]
    }
   ],
   "source": [
    "aligner = Aligner4(volume_fixed, volume_moving, labelIndexMap_m2f=label_mapping_m2f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m: [ 216.   186.5  184.5] f: [ 216.   186.5  184.5]\n"
     ]
    }
   ],
   "source": [
    "# aligner.set_centroid(centroid_m='origin', centroid_f='origin')\n",
    "aligner.set_centroid(centroid_m='volume_centroid', centroid_f='centroid_m')\n",
    "# aligner.set_centroid(centroid_m='structure_centroid', centroid_f='centroid_m', indices_m=[structure_to_label_moving['7N_L']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gradient_filepath_map_f = \\\n",
    "{ind_f: DataManager.get_volume_gradient_filepath_template(\\\n",
    "                                                          stack=stack_fixed, \n",
    "                                                          structure=label_to_structure_fixed[ind_f],\n",
    "                                                          detector_id=detector_id, \n",
    "                                                         prep_id=2)\n",
    " for ind_m, ind_f in label_mapping_m2f.iteritems()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([2, 5, 7, 8, 16, 21, 25, 26, 27, 28])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load gradient 2: 12.165888 seconds\n",
      "load gradient 5: 10.636648 seconds\n",
      "load gradient 7: 7.386432 seconds\n",
      "load gradient 8: 9.417606 seconds\n",
      "load gradient 16: 9.287623 seconds\n",
      "load gradient 21: 5.890761 seconds\n",
      "load gradient 25: 7.149051 seconds\n",
      "load gradient 26: 8.574810 seconds\n",
      "load gradient 27: 7.333534 seconds\n",
      "load gradient 28: 8.523521 seconds\n",
      "overall: 86.366888 seconds\n"
     ]
    }
   ],
   "source": [
    "aligner.load_gradient(gradient_filepath_map_f=gradient_filepath_map_f) # 120s-170 = 2 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aligner.set_label_weights(label_weights=label_weights_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "grid search: 43.045564 seconds\n",
      "tx_best: 66.27 (voxel), ty_best: 61.06, tz_best: 2.74, theta_xy_best: -9.26 (deg)\n",
      "sigma_tx: 135.87 (voxel), sigma_ty: 135.87, sigma_tz: 135.87, sigma_theta_xy: 30.00 (deg)\n",
      "-inf 0.134249\n",
      "grid search: 35.025514 seconds\n",
      "tx_best: 74.13 (voxel), ty_best: 60.90, tz_best: -7.12, theta_xy_best: -6.19 (deg)\n",
      "sigma_tx: 97.35 (voxel), sigma_ty: 97.35, sigma_tz: 97.35, sigma_theta_xy: 21.50 (deg)\n",
      "0.134249 0.137093\n",
      "grid search: 26.002588 seconds\n",
      "tx_best: 74.13 (voxel), ty_best: 60.90, tz_best: -7.12, theta_xy_best: -6.19 (deg)\n",
      "sigma_tx: 69.76 (voxel), sigma_ty: 69.76, sigma_tz: 69.76, sigma_theta_xy: 15.40 (deg)\n",
      "grid search: 19.354551 seconds\n",
      "tx_best: 74.13 (voxel), ty_best: 60.90, tz_best: -7.12, theta_xy_best: -6.19 (deg)\n",
      "sigma_tx: 49.98 (voxel), sigma_ty: 49.98, sigma_tz: 49.98, sigma_theta_xy: 11.04 (deg)\n",
      "grid search: 15.242978 seconds\n",
      "tx_best: 74.13 (voxel), ty_best: 60.90, tz_best: -7.12, theta_xy_best: -6.19 (deg)\n",
      "sigma_tx: 35.81 (voxel), sigma_ty: 35.81, sigma_tz: 35.81, sigma_theta_xy: 7.91 (deg)\n",
      "grid search: 11.848698 seconds\n",
      "tx_best: 74.13 (voxel), ty_best: 60.90, tz_best: -7.12, theta_xy_best: -6.19 (deg)\n",
      "sigma_tx: 25.66 (voxel), sigma_ty: 25.66, sigma_tz: 25.66, sigma_theta_xy: 5.67 (deg)\n",
      "grid search: 10.027476 seconds\n",
      "tx_best: 66.68 (voxel), ty_best: 58.95, tz_best: -2.19, theta_xy_best: -6.91 (deg)\n",
      "sigma_tx: 18.39 (voxel), sigma_ty: 18.39, sigma_tz: 18.39, sigma_theta_xy: 4.06 (deg)\n",
      "0.137093 0.146828\n",
      "grid search: 7.819888 seconds\n",
      "tx_best: 71.43 (voxel), ty_best: 48.62, tz_best: -1.41, theta_xy_best: -9.78 (deg)\n",
      "sigma_tx: 13.18 (voxel), sigma_ty: 13.18, sigma_tz: 13.18, sigma_theta_xy: 2.91 (deg)\n",
      "0.146828 0.150916\n",
      "grid search: 6.537710 seconds\n",
      "tx_best: 67.35 (voxel), ty_best: 54.14, tz_best: -3.81, theta_xy_best: -9.51 (deg)\n",
      "sigma_tx: 9.44 (voxel), sigma_ty: 9.44, sigma_tz: 9.44, sigma_theta_xy: 2.08 (deg)\n",
      "0.150916 0.156059\n",
      "\n",
      "iteration 0\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params_best_upToNow [ 67.34999449  54.13542573  -3.8081059   -0.16593085]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 77.3324187   64.11532178   6.18182862]\n",
      "det: 1.03\n",
      "step: 2.30 seconds\n",
      "score: 0.156059\n",
      "\n",
      "iteration 1\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 72.8760883   56.18286168  12.35540157]\n",
      "det: 1.10\n",
      "step: 2.35 seconds\n",
      "score: 0.025324\n",
      "\n",
      "iteration 2\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "98070 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "84480 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 67.3587045   61.67967467   3.6866075 ]\n",
      "det: 1.24\n",
      "step: 2.33 seconds\n",
      "score: 0.042511\n",
      "\n",
      "iteration 3\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 63.78824999  54.82455738   8.77048273]\n",
      "det: 1.24\n",
      "step: 2.35 seconds\n",
      "score: 0.061269\n",
      "\n",
      "iteration 4\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "92961 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 68.76320903  59.13733356   6.15455203]\n",
      "det: 1.24\n",
      "step: 2.29 seconds\n",
      "score: 0.099370\n",
      "\n",
      "iteration 5\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 70.51855936  52.00892653   2.9713448 ]\n",
      "det: 1.18\n",
      "step: 2.36 seconds\n",
      "score: 0.056646\n",
      "\n",
      "iteration 6\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 77.26600309  54.22282235   2.80717848]\n",
      "det: 1.17\n",
      "step: 2.38 seconds\n",
      "score: 0.133354\n",
      "\n",
      "iteration 7\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 69.56071683  51.48089018  -1.33011918]\n",
      "det: 1.21\n",
      "step: 2.34 seconds\n",
      "score: 0.046478\n",
      "\n",
      "iteration 8\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 72.5045925   50.73042558   3.09939261]\n",
      "det: 1.28\n",
      "step: 2.31 seconds\n",
      "score: 0.105462\n",
      "\n",
      "iteration 9\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 72.92861285  52.82181523  -2.23450333]\n",
      "det: 1.29\n",
      "step: 2.32 seconds\n",
      "score: 0.102832\n",
      "\n",
      "iteration 10\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 75.65305996  47.77687564  -1.13554995]\n",
      "det: 1.25\n",
      "step: 2.34 seconds\n",
      "score: 0.094718\n",
      "\n",
      "iteration 11\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 75.70724238  46.58753075  -5.5077878 ]\n",
      "det: 1.29\n",
      "step: 2.31 seconds\n",
      "score: 0.138856\n",
      "\n",
      "iteration 12\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 81.3741299   45.07505837  -2.22342515]\n",
      "det: 1.26\n",
      "step: 2.32 seconds\n",
      "score: 0.114047\n",
      "\n",
      "iteration 13\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 75.52494349  40.17475555  -5.67083857]\n",
      "det: 1.30\n",
      "step: 2.30 seconds\n",
      "score: 0.109660\n",
      "\n",
      "iteration 14\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 81.40336304  41.90578863  -4.37576536]\n",
      "det: 1.29\n",
      "step: 2.28 seconds\n",
      "score: 0.128446\n",
      "\n",
      "iteration 15\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 77.20232664  37.14059038  -6.75797748]\n",
      "det: 1.30\n",
      "step: 2.30 seconds\n",
      "score: 0.134988\n",
      "\n",
      "iteration 16\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 80.61646868  40.04679152  -2.33276866]\n",
      "det: 1.32\n",
      "step: 2.29 seconds\n",
      "score: 0.136682\n",
      "\n",
      "iteration 17\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 76.55037764  35.40903607  -5.75538099]\n",
      "det: 1.32\n",
      "step: 2.34 seconds\n",
      "score: 0.154546\n",
      "\n",
      "iteration 18\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 78.27644025  37.88864114  -0.84938228]\n",
      "det: 1.34\n",
      "step: 2.29 seconds\n",
      "score: 0.144936\n",
      "\n",
      "iteration 19\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 75.78380459  34.77308666  -6.08844645]\n",
      "det: 1.34\n",
      "step: 2.35 seconds\n",
      "score: 0.162748\n",
      "\n",
      "iteration 20\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 76.35518766  35.15753569  -1.89260183]\n",
      "det: 1.34\n",
      "step: 2.30 seconds\n",
      "score: 0.143603\n",
      "\n",
      "iteration 21\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 74.77194678  32.98529667  -3.6338588 ]\n",
      "det: 1.34\n",
      "step: 2.35 seconds\n",
      "score: 0.184614\n",
      "\n",
      "iteration 22\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 75.3713813   34.22729036  -0.83680987]\n",
      "det: 1.35\n",
      "step: 2.31 seconds\n",
      "score: 0.185021\n",
      "\n",
      "iteration 23\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 71.77892225  29.93605515  -2.01418652]\n",
      "det: 1.32\n",
      "step: 2.36 seconds\n",
      "score: 0.168780\n",
      "\n",
      "iteration 24\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 75.2323747   34.60352913  -1.37059255]\n",
      "det: 1.35\n",
      "step: 2.31 seconds\n",
      "score: 0.173385\n",
      "\n",
      "iteration 25\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 71.32826714  29.4633981   -0.73956395]\n",
      "det: 1.31\n",
      "step: 2.33 seconds\n",
      "score: 0.144406\n",
      "\n",
      "iteration 26\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 73.86959947  32.62290292  -0.47558337]\n",
      "det: 1.33\n",
      "step: 2.29 seconds\n",
      "score: 0.187813\n",
      "\n",
      "iteration 27\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 70.4576654   29.05872384  -0.85169669]\n",
      "det: 1.31\n",
      "step: 2.33 seconds\n",
      "score: 0.173531\n",
      "\n",
      "iteration 28\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 73.10872375  31.97544946  -0.49304969]\n",
      "det: 1.32\n",
      "step: 2.33 seconds\n",
      "score: 0.193169\n",
      "\n",
      "iteration 29\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 70.05132116  28.82023311  -0.91302835]\n",
      "det: 1.30\n",
      "step: 2.36 seconds\n",
      "score: 0.175911\n",
      "\n",
      "iteration 30\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 71.89163517  31.18998985  -0.45325083]\n",
      "det: 1.31\n",
      "step: 2.32 seconds\n",
      "score: 0.201996\n",
      "\n",
      "iteration 31\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 69.52953213  29.0808703   -0.61264797]\n",
      "det: 1.30\n",
      "step: 2.35 seconds\n",
      "score: 0.187623\n",
      "\n",
      "iteration 32\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 70.95992297  30.50846434   0.2898528 ]\n",
      "det: 1.31\n",
      "step: 2.32 seconds\n",
      "score: 0.209071\n",
      "\n",
      "iteration 33\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 69.22979436  28.88644027  -1.55837966]\n",
      "det: 1.30\n",
      "step: 2.38 seconds\n",
      "score: 0.194972\n",
      "\n",
      "iteration 34\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 69.95276489  29.96579176   1.17040259]\n",
      "det: 1.31\n",
      "step: 2.36 seconds\n",
      "score: 0.201397\n",
      "\n",
      "iteration 35\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 68.69282988  28.73833179  -1.41239307]\n",
      "det: 1.30\n",
      "step: 2.39 seconds\n",
      "score: 0.191416\n",
      "\n",
      "iteration 36\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000 samples\n",
      "T: [ 69.73785316  29.65610177   1.24803047]\n",
      "det: 1.31\n",
      "step: 2.32 seconds\n",
      "score: 0.197904\n",
      "\n",
      "iteration 37\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 68.0723971   28.25079326  -0.65188769]\n",
      "det: 1.30\n",
      "step: 2.36 seconds\n",
      "score: 0.194895\n",
      "\n",
      "iteration 38\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 69.0107379   29.32097613   1.35114997]\n",
      "det: 1.31\n",
      "step: 2.32 seconds\n",
      "score: 0.203462\n",
      "\n",
      "iteration 39\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 67.82519406  28.08123457   0.75885223]\n",
      "det: 1.30\n",
      "step: 2.35 seconds\n",
      "score: 0.198778\n",
      "\n",
      "iteration 40\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 68.15260793  28.69961991   1.77715788]\n",
      "det: 1.31\n",
      "step: 2.32 seconds\n",
      "score: 0.212339\n",
      "\n",
      "iteration 41\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 67.4857847   27.97147215   0.30937756]\n",
      "det: 1.30\n",
      "step: 2.34 seconds\n",
      "score: 0.206164\n",
      "\n",
      "iteration 42\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 68.01699495  28.43722787   2.17937658]\n",
      "det: 1.31\n",
      "step: 2.33 seconds\n",
      "score: 0.209796\n",
      "\n",
      "iteration 43\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [  6.70806793e+01   2.80090657e+01   2.99200998e-02]\n",
      "det: 1.31\n",
      "step: 2.34 seconds\n",
      "score: 0.204759\n",
      "\n",
      "iteration 44\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 67.70404115  28.09741543   1.46206469]\n",
      "det: 1.30\n",
      "step: 2.32 seconds\n",
      "score: 0.204085\n",
      "\n",
      "iteration 45\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 66.92314924  27.6558033    0.84199794]\n",
      "det: 1.30\n",
      "step: 2.34 seconds\n",
      "score: 0.209037\n",
      "\n",
      "iteration 46\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 67.22806871  27.9367858    2.59705929]\n",
      "det: 1.31\n",
      "step: 2.32 seconds\n",
      "score: 0.210369\n",
      "\n",
      "iteration 47\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 66.54247313  27.59086094   0.24936447]\n",
      "det: 1.31\n",
      "step: 2.34 seconds\n",
      "score: 0.203902\n",
      "\n",
      "iteration 48\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 67.17836983  27.53302848   1.8560523 ]\n",
      "det: 1.30\n",
      "step: 2.32 seconds\n",
      "score: 0.205183\n",
      "\n",
      "iteration 49\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 66.42591367  27.20499149   0.85145773]\n",
      "det: 1.31\n",
      "step: 2.34 seconds\n",
      "score: 0.210195\n",
      "\n",
      "iteration 50\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 66.90518643  27.513363     2.36380842]\n",
      "det: 1.31\n",
      "step: 2.32 seconds\n",
      "score: 0.210824\n",
      "\n",
      "iteration 51\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 65.94205673  27.04880441   0.29408646]\n",
      "det: 1.31\n",
      "step: 2.34 seconds\n",
      "score: 0.205905\n",
      "\n",
      "iteration 52\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 66.62115648  27.25544876   1.57140589]\n",
      "det: 1.31\n",
      "step: 2.33 seconds\n",
      "score: 0.205439\n",
      "\n",
      "iteration 53\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 66.11455363  26.88126412   1.61334412]\n",
      "det: 1.30\n",
      "step: 2.34 seconds\n",
      "score: 0.210376\n",
      "\n",
      "iteration 54\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 66.32469549  27.05157061   1.9907935 ]\n",
      "det: 1.30\n",
      "step: 2.33 seconds\n",
      "score: 0.214675\n",
      "\n",
      "iteration 55\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 65.89989483  26.79369985   1.60483575]\n",
      "det: 1.30\n",
      "step: 2.33 seconds\n",
      "score: 0.212917\n",
      "\n",
      "iteration 56\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 66.13300072  27.02488406   1.84702554]\n",
      "det: 1.31\n",
      "step: 2.35 seconds\n",
      "score: 0.213944\n",
      "\n",
      "iteration 57\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 65.6382008   26.7484057    1.63908412]\n",
      "det: 1.30\n",
      "step: 2.33 seconds\n",
      "score: 0.212514\n",
      "\n",
      "iteration 58\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 65.69673311  26.89953982   2.20337402]\n",
      "det: 1.31\n",
      "step: 2.35 seconds\n",
      "score: 0.214190\n",
      "\n",
      "iteration 59\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 65.74132048  26.66897701   1.5304245 ]\n",
      "det: 1.30\n",
      "step: 2.34 seconds\n",
      "score: 0.213679\n",
      "\n",
      "iteration 60\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 65.40761679  26.89808896   2.68211622]\n",
      "det: 1.30\n",
      "step: 2.33 seconds\n",
      "score: 0.213703\n",
      "\n",
      "iteration 61\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 65.23253589  26.63364074   1.02988274]\n",
      "det: 1.30\n",
      "step: 2.34 seconds\n",
      "score: 0.210255\n",
      "\n",
      "iteration 62\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 65.21799913  26.83194914   2.76960362]\n",
      "det: 1.30\n",
      "step: 2.33 seconds\n",
      "score: 0.208702\n",
      "\n",
      "iteration 63\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 65.14467676  26.63273195   1.04597164]\n",
      "det: 1.30\n",
      "step: 2.35 seconds\n",
      "score: 0.209354\n",
      "\n",
      "iteration 64\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 65.10225502  26.77389567   2.42008799]\n",
      "det: 1.30\n",
      "step: 2.33 seconds\n",
      "score: 0.207904\n",
      "\n",
      "iteration 65\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 64.93820925  26.55117261   1.78223838]\n",
      "det: 1.30\n",
      "step: 2.35 seconds\n",
      "score: 0.211055\n",
      "\n",
      "iteration 66\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 64.80256123  26.82195026   2.95859807]\n",
      "det: 1.31\n",
      "step: 2.34 seconds\n",
      "score: 0.213635\n",
      "\n",
      "iteration 67\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 64.82588948  26.63364421   1.68184036]\n",
      "det: 1.30\n",
      "step: 2.34 seconds\n",
      "score: 0.212373\n",
      "\n",
      "iteration 68\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 64.76788086  26.86616842   3.18885699]\n",
      "det: 1.31\n",
      "step: 2.33 seconds\n",
      "score: 0.211313\n",
      "\n",
      "iteration 69\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 64.7362599   26.71022841   1.63347766]\n",
      "det: 1.30\n",
      "step: 2.34 seconds\n",
      "score: 0.209468\n",
      "\n",
      "iteration 70\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 64.57153087  26.64309624   3.15828786]\n",
      "det: 1.30\n",
      "step: 2.33 seconds\n",
      "score: 0.210381\n",
      "\n",
      "iteration 71\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 64.68606491  26.65455621   1.87464792]\n",
      "det: 1.30\n",
      "step: 2.34 seconds\n",
      "score: 0.211601\n",
      "\n",
      "iteration 72\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 64.75561453  26.85749683   3.40709105]\n",
      "det: 1.30\n",
      "step: 2.33 seconds\n",
      "score: 0.212183\n",
      "\n",
      "iteration 73\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 64.34223836  26.93338972   1.4348754 ]\n",
      "det: 1.30\n",
      "step: 2.34 seconds\n",
      "score: 0.208742\n",
      "\n",
      "iteration 74\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 64.59424369  26.609131     2.82395918]\n",
      "det: 1.29\n",
      "step: 2.32 seconds\n",
      "score: 0.208078\n",
      "\n",
      "iteration 75\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 64.43314692  26.97508593   2.02545003]\n",
      "det: 1.30\n",
      "step: 2.34 seconds\n",
      "score: 0.213692\n",
      "\n",
      "iteration 76\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 64.36229667  26.65195892   3.10241252]\n",
      "det: 1.30\n",
      "step: 2.33 seconds\n",
      "score: 0.212182\n",
      "\n",
      "iteration 77\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 64.30571482  26.88727108   2.12146472]\n",
      "det: 1.30\n",
      "step: 2.34 seconds\n",
      "score: 0.213185\n",
      "\n",
      "iteration 78\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 64.33915585  26.68872646   2.97367027]\n",
      "det: 1.30\n",
      "step: 2.33 seconds\n",
      "score: 0.213035\n",
      "\n",
      "iteration 79\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 64.2683008   26.87496639   2.30001697]\n",
      "det: 1.30\n",
      "step: 2.34 seconds\n",
      "score: 0.214034\n",
      "\n",
      "iteration 80\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 64.15398894  26.78119572   3.03621152]\n",
      "det: 1.30\n",
      "step: 2.33 seconds\n",
      "score: 0.214097\n",
      "\n",
      "iteration 81\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 64.1896608   26.95054016   2.02389383]\n",
      "det: 1.30\n",
      "step: 2.34 seconds\n",
      "score: 0.213440\n",
      "\n",
      "iteration 82\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 64.19770061  26.78486823   3.1882465 ]\n",
      "det: 1.29\n",
      "step: 2.35 seconds\n",
      "score: 0.212880\n",
      "\n",
      "iteration 83\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 63.97076284  27.00036594   1.69090203]\n",
      "det: 1.30\n",
      "step: 2.34 seconds\n",
      "score: 0.212092\n",
      "\n",
      "iteration 84\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 63.99086929  26.8916017    3.07348957]\n",
      "det: 1.30\n",
      "step: 2.34 seconds\n",
      "score: 0.210947\n",
      "\n",
      "iteration 85\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000 samples\n",
      "T: [ 63.99376394  26.9327828    2.26858938]\n",
      "det: 1.30\n",
      "step: 2.34 seconds\n",
      "score: 0.213737\n",
      "\n",
      "iteration 86\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 63.84144836  26.68475667   2.77793275]\n",
      "det: 1.29\n",
      "step: 2.33 seconds\n",
      "score: 0.213452\n",
      "\n",
      "iteration 87\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 63.87436879  27.01720226   2.38247403]\n",
      "det: 1.30\n",
      "step: 2.33 seconds\n",
      "score: 0.215414\n",
      "\n",
      "iteration 88\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 63.63103959  26.48850209   2.74739772]\n",
      "det: 1.29\n",
      "step: 2.33 seconds\n",
      "score: 0.213274\n",
      "\n",
      "iteration 89\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 63.8413244   27.1282139    2.26536244]\n",
      "det: 1.30\n",
      "step: 2.33 seconds\n",
      "score: 0.215125\n",
      "\n",
      "iteration 90\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 63.49619346  26.36779955   2.65691344]\n",
      "det: 1.29\n",
      "step: 2.32 seconds\n",
      "score: 0.211637\n",
      "\n",
      "iteration 91\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 63.94523172  27.4092963    2.31937891]\n",
      "det: 1.30\n",
      "step: 2.32 seconds\n",
      "score: 0.216150\n",
      "\n",
      "iteration 92\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 63.40724255  26.19615352   2.39934148]\n",
      "det: 1.29\n",
      "step: 2.33 seconds\n",
      "score: 0.210552\n",
      "\n",
      "iteration 93\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 64.22730308  27.65193003   2.51146958]\n",
      "det: 1.30\n",
      "step: 2.32 seconds\n",
      "score: 0.216240\n",
      "\n",
      "iteration 94\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 62.92352323  25.79824135   2.50582124]\n",
      "det: 1.28\n",
      "step: 2.34 seconds\n",
      "score: 0.203995\n",
      "\n",
      "iteration 95\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "63984 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "100000 samples\n",
      "T: [ 64.22260154  27.71590641   2.4420951 ]\n",
      "det: 1.30\n",
      "step: 2.33 seconds\n",
      "score: 0.212869\n"
     ]
    }
   ],
   "source": [
    "# For rigid, \n",
    "# grad_computation_sample_number = 1e5 is desired\n",
    "# grid_search_iteration_number and grid_search_sample_number seem to be unimportant as well, set to 100\n",
    "# lr1=10, lr2=.1 is best\n",
    "\n",
    "# For affine, \n",
    "# lr2 = .001 is too slow; 0.1 rises faster than 0.01\n",
    "# lr1 does not matter\n",
    "# plateus around iteration 100, but keep rising afterwards.\n",
    "# grad_computation_sample_number does not make a difference\n",
    "\n",
    "# while True:\n",
    "\n",
    "trial_num = 1\n",
    "\n",
    "T_all_trials = []\n",
    "scores_all_trials = []\n",
    "\n",
    "for _ in range(trial_num):\n",
    "\n",
    "    try:\n",
    "        T, scores = aligner.optimize(tf_type=transform_type, max_iter_num=MAX_ITER_NUM, history_len=HISTORY_LEN, \n",
    "                                     terminate_thresh=terminate_thresh,\n",
    "                                     grid_search_iteration_number=MAX_GRID_SEARCH_ITER_NUM,\n",
    "                                     grid_search_sample_number=grid_search_sample_number,\n",
    "                                     grid_search_eta=3.,\n",
    "                                     grad_computation_sample_number=grad_computation_sample_number,\n",
    "                                     lr1=lr1, lr2=lr2,\n",
    "                                     std_tx=std_tx, std_ty=std_ty, std_tz=std_tz, std_theta_xy=std_theta_xy)\n",
    "                \n",
    "        T_all_trials.append(T)\n",
    "        scores_all_trials.append(scores)\n",
    "        \n",
    "    except Exception as e:\n",
    "        sys.stderr.write('%s\\n' % e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plt.plot(np.arange(30), std_tx*np.exp(-np.arange(30)/3.));\n",
    "# plt.xlabel('Iteration');\n",
    "# plt.ylabel('Search radius (voxel)');\n",
    "# plt.title('Grid search radius shrinking schedule');\n",
    "# plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inliers [0 1 3]\n",
      "Widest standard deviation of converged translation parameters for different trials: 0.25 voxels, 3.74 um\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb57a9a9ad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "converged_scores = np.array([s[-1] for s in scores_all_trials])\n",
    "q3 = np.percentile(converged_scores, 55)\n",
    "q1 = np.percentile(converged_scores, 45)\n",
    "iqr = q3 - q1\n",
    "inlier_min = q1 - 1.5 * iqr\n",
    "inlier_max = q3 + 1.5 * iqr\n",
    "inliers = np.where((converged_scores > inlier_min) & (converged_scores < inlier_max))[0]\n",
    "print 'inliers', inliers\n",
    "\n",
    "plt.figure();\n",
    "for trial_idx, scores in enumerate(scores_all_trials):\n",
    "    plt.plot(scores, label='trial ' + str(trial_idx));\n",
    "plt.xlabel('Iteration');\n",
    "plt.ylabel('Score');\n",
    "plt.legend();\n",
    "plt.title('Score evolution for different optimization runs');\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=3)\n",
    "T_all_trials = np.array(T_all_trials)\n",
    "t_std = np.std(pca.fit_transform(T_all_trials[inliers[:,None] ,[3,7,11]])[0])\n",
    "t_std_um = t_std * XY_PIXEL_DISTANCE_TB\n",
    "print 'Widest standard deviation of converged translation parameters for different trials: %.2f voxels, %.2f um' % (t_std, t_std_um)\n",
    "\n",
    "# tx_std = np.std(T_all_trials[inliers, 3])\n",
    "# ty_std = np.std(T_all_trials[inliers, 7])\n",
    "# tz_std = np.std(T_all_trials[inliers, 11])\n",
    "# tx_std_um = tx_std * XY_PIXEL_DISTANCE_TB\n",
    "# ty_std_um = ty_std * XY_PIXEL_DISTANCE_TB\n",
    "# tz_std_um = tz_std * XY_PIXEL_DISTANCE_TB\n",
    "# print 'tx std:', tx_std, 'voxels', tx_std_um, 'um'\n",
    "# print 'ty std:', ty_std, 'voxels', ty_std_um, 'um'\n",
    "# print 'tz std:', tz_std, 'voxels', tz_std_um, 'um'\n",
    "\n",
    "# plt.scatter(np.ones((5,)), np.array(T_all_trials)[:, 3], marker='+');\n",
    "# plt.scatter(2*np.ones((5,)), np.array(T_all_trials)[:, 7], marker='+');\n",
    "# plt.scatter(3*np.ones((5,)), np.array(T_all_trials)[:, 11], marker='+');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: 0\n",
      "0.216239912435 0.212869237177\n",
      "[[  9.65987135e-01   3.16554500e-01  -6.03069118e-02   6.42273031e+01]\n",
      " [ -2.93737823e-01   1.24593970e+00   5.03416836e-02   2.76519300e+01]\n",
      " [  4.25866995e-02  -2.44821545e-02   9.89498733e-01   2.51146958e+00]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2830108950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_trial = np.argsort([np.max(scores) for scores in scores_all_trials])[-1]\n",
    "T = T_all_trials[best_trial]\n",
    "scores = scores_all_trials[best_trial]\n",
    "print 'Best trial:', best_trial\n",
    "print max(scores), scores[-1]\n",
    "\n",
    "print T.reshape((3,4))\n",
    "plt.figure();\n",
    "plt.plot(scores);\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print T.reshape((3,4))\n",
    "# plt.plot(scores);\n",
    "# print max(scores), scores[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Export parameters and score plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 cp /shared/CSHL_registration_parameters/atlasV3/atlasV3_down32_scoreVolume_clf_30_warp_1_MD657_down32_scoreVolume_clf_30_trial_0/atlasV3_down32_scoreVolume_clf_30_warp_1_MD657_down32_scoreVolume_clf_30_trial_0_parameters.txt s3://mousebrainatlas-data/CSHL_registration_parameters/atlasV3/atlasV3_down32_scoreVolume_clf_30_warp_1_MD657_down32_scoreVolume_clf_30_trial_0/atlasV3_down32_scoreVolume_clf_30_warp_1_MD657_down32_scoreVolume_clf_30_trial_0_parameters.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "0.81 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 cp /shared/CSHL_registration_parameters/atlasV3/atlasV3_down32_scoreVolume_clf_30_warp_1_MD657_down32_scoreVolume_clf_30_trial_0/atlasV3_down32_scoreVolume_clf_30_warp_1_MD657_down32_scoreVolume_clf_30_trial_0_scoreHistory.bp s3://mousebrainatlas-data/CSHL_registration_parameters/atlasV3/atlasV3_down32_scoreVolume_clf_30_warp_1_MD657_down32_scoreVolume_clf_30_trial_0/atlasV3_down32_scoreVolume_clf_30_warp_1_MD657_down32_scoreVolume_clf_30_trial_0_scoreHistory.bp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "0.70 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 cp /shared/CSHL_registration_parameters/atlasV3/atlasV3_down32_scoreVolume_clf_30_warp_1_MD657_down32_scoreVolume_clf_30_trial_0/atlasV3_down32_scoreVolume_clf_30_warp_1_MD657_down32_scoreVolume_clf_30_trial_0_scoreEvolution.png s3://mousebrainatlas-data/CSHL_registration_parameters/atlasV3/atlasV3_down32_scoreVolume_clf_30_warp_1_MD657_down32_scoreVolume_clf_30_trial_0/atlasV3_down32_scoreVolume_clf_30_warp_1_MD657_down32_scoreVolume_clf_30_trial_0_scoreEvolution.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "0.81 seconds.\n"
     ]
    }
   ],
   "source": [
    "for trial_idx in range(trial_num):\n",
    "    \n",
    "    T = T_all_trials[trial_idx]\n",
    "    scores = scores_all_trials[trial_idx]\n",
    "    \n",
    "    params_fp = \\\n",
    "    DataManager.get_alignment_parameters_filepath(stack_m=stack_moving, \n",
    "                                                  stack_f=stack_fixed,\n",
    "                                                  detector_id_f=detector_id,\n",
    "                                                  warp_setting=warp_setting,\n",
    "                                                  trial_idx=trial_idx)\n",
    "    DataManager.save_alignment_parameters(params_fp, T, \n",
    "                                          aligner.centroid_m, aligner.centroid_f,\n",
    "                                          aligner.xdim_m, aligner.ydim_m, aligner.zdim_m, \n",
    "                                          aligner.xdim_f, aligner.ydim_f, aligner.zdim_f)\n",
    "    upload_from_ec2_to_s3(params_fp)\n",
    "    \n",
    "    history_fp = DataManager.get_score_history_filepath(stack_m=stack_moving, stack_f=stack_fixed,\n",
    "                                                          classifier_setting_m=classifier_setting,\n",
    "                                                          classifier_setting_f=classifier_setting,\n",
    "                                                          warp_setting=warp_setting,\n",
    "                                                          trial_idx=trial_idx)\n",
    "    bp.pack_ndarray_file(np.array(scores), history_fp)\n",
    "    upload_from_ec2_to_s3(history_fp)\n",
    "\n",
    "    score_plot_fp = \\\n",
    "    DataManager.get_alignment_score_plot_filepath(stack_m=stack_moving, stack_f=stack_fixed,\n",
    "                                                         classifier_setting_m=classifier_setting,\n",
    "                                                         classifier_setting_f=classifier_setting,\n",
    "                                                         warp_setting=warp_setting,\n",
    "                                                         trial_idx=trial_idx)\n",
    "    fig = plt.figure();\n",
    "    plt.plot(scores);\n",
    "    plt.savefig(score_plot_fp, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "\n",
    "    upload_from_ec2_to_s3(score_plot_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draw Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# global_params, centroid_m, centroid_f, xdim_m, ydim_m, zdim_m, xdim_f, ydim_f, zdim_f = \\\n",
    "# (affine_components_to_vector(-9.77304587,  48.73149657,  -2.80149108,  -0.16628751), \n",
    "#   aligner.centroid_m, aligner.centroid_f,\n",
    "#   aligner.xdim_m, aligner.ydim_m, aligner.zdim_m, \n",
    "#   aligner.xdim_f, aligner.ydim_f, aligner.zdim_f)\n",
    "\n",
    "global_params, centroid_m, centroid_f, xdim_m, ydim_m, zdim_m, xdim_f, ydim_f, zdim_f = \\\n",
    "(T, \n",
    "  aligner.centroid_m, aligner.centroid_f,\n",
    "  aligner.xdim_m, aligner.ydim_m, aligner.zdim_m, \n",
    "  aligner.xdim_f, aligner.ydim_f, aligner.zdim_f)\n",
    "\n",
    "# global_params, centroid_m, centroid_f, xdim_m, ydim_m, zdim_m, xdim_f, ydim_f, zdim_f = \\\n",
    "# ([1,0,0,0,0,1,0,0,0,0,1,0], \n",
    "#   aligner.centroid_m, aligner.centroid_f,\n",
    "#   aligner.xdim_m, aligner.ydim_m, aligner.zdim_m, \n",
    "#   aligner.xdim_f, aligner.ydim_f, aligner.zdim_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Transform moving volume, sided, without surround\n",
    "\n",
    "structure = 'IC'\n",
    "\n",
    "vol_m = DataManager.load_original_volume(stack=stack_moving, structure=structure, downscale=32)\n",
    "\n",
    "volume_m_alignedTo_f = \\\n",
    "transform_volume(vol=vol_m, global_params=global_params, centroid_m=centroid_m, centroid_f=centroid_f,\n",
    "                  xdim_f=xdim_f, ydim_f=ydim_f, zdim_f=zdim_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set colors for different contour level\n",
    "levels = [0.1, 0.25, 0.5, 0.75, .99]\n",
    "level_colors = {level: (int(level*255),0,0) for level in levels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate overlay visualization\n",
    "\n",
    "# For getting correct contour location\n",
    "\n",
    "xmin_vol_f, xmax_vol_f, ymin_vol_f, ymax_vol_f, zmin_vol_f, zmax_vol_f = \\\n",
    "DataManager.load_original_volume_bbox(stack=stack_fixed, volume_type='score', structure='7N', \n",
    "                             downscale=32, detector_id=detector_id, prep_id=2)\n",
    "print xmin_vol_f, xmax_vol_f, ymin_vol_f, ymax_vol_f, zmin_vol_f, zmax_vol_f\n",
    "\n",
    "# Generate atlas overlay image for every section\n",
    "\n",
    "zf, zl = bbox_3d(volume_m_alignedTo_f)[4:]\n",
    "sec_first = DataManager.convert_z_to_section(stack=stack_fixed, z=zf, downsample=32)\n",
    "sec_last = DataManager.convert_z_to_section(stack=stack_fixed, z=zl, downsample=32)\n",
    "\n",
    "for sec in range(sec_first, sec_last+1, 5):\n",
    "# for sec in [155]:\n",
    "    \n",
    "    if is_invalid(metadata_cache['sections_to_filenames'][stack_fixed][sec]):\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "#         img = DataManager.load_image(stack=stack_fixed, section=sec, resol='thumbnail', version='cropped_tif')\n",
    "        sc_viz_fp = DataManager.get_scoremap_viz_filepath(stack=stack_fixed, section=sec, \n",
    "                                                           downscale=8,\n",
    "                                                           structure=convert_to_original_name(structure), \n",
    "                                                           detector_id=detector_id, prep_id=2)\n",
    "        download_from_s3(sc_viz_fp)\n",
    "        img = imread(sc_viz_fp)[::4, ::4]\n",
    "#         sc_viz_fp = DataManager.get_scoremap_viz_filepath(stack=stack_fixed, section=sec, \n",
    "#                                                            downscale=32,\n",
    "#                                                            structure=convert_to_original_name(structure), \n",
    "#                                                            detector_id=detector_id, prep_id=2)\n",
    "#         download_from_s3(sc_viz_fp)\n",
    "#         img = imread(sc_viz_fp)\n",
    "    except:\n",
    "        sys.stderr.write('Error loading scoremap for section %d\\n' % sec)\n",
    "        continue\n",
    "    \n",
    "    viz = img.copy()\n",
    "    \n",
    "    z1, z2 = DataManager.convert_section_to_z(stack=stack_fixed, sec=sec, downsample=32)\n",
    "    z = int(z1)\n",
    "    \n",
    "    # Find moving volume annotation contours\n",
    "    c = 0\n",
    "    vol = volume_m_alignedTo_f\n",
    "    for level in levels:\n",
    "        cnts = find_contours(vol[..., z], level=level) # rows, cols\n",
    "        c += len(cnts)\n",
    "        for cnt in cnts:\n",
    "            # r,c to x,y\n",
    "            cnt_on_cropped = cnt[:, ::-1] + (xmin_vol_f, ymin_vol_f)\n",
    "            cv2.polylines(viz, [cnt_on_cropped.astype(np.int)], True, level_colors[level], 1)\n",
    "    \n",
    "    if c > 0:    \n",
    "        plt.figure(figsize=(20,20));\n",
    "#         plt.figure();\n",
    "        plt.title(\"sec=%d, z=%d, c=%d\" % (sec, z, c));\n",
    "        plt.imshow(viz);\n",
    "        plt.show();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
