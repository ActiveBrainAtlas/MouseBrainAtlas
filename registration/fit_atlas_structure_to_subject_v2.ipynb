{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting environment for Gordon\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.environ['REPO_DIR'] + '/utilities')\n",
    "from utilities2015 import *\n",
    "from registration_utilities import *\n",
    "from metadata import *\n",
    "from data_manager import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack_fixed = 'MD591'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_sample_scheme = 1\n",
    "global_transform_scheme = 1\n",
    "\n",
    "local_transform_scheme = 2\n",
    "# 1: no regularization, structures weight the same\n",
    "# 2: with regularization, structures weight the same\n",
    "# 3: no regularization, with surround\n",
    "# 4: with regularization, with surround\n",
    "# 5: no regularization, structure weight inversely prop to size\n",
    "# 6: with regularization, structure weight inversely prop to size\n",
    "\n",
    "if local_transform_scheme == 1:\n",
    "    reg_weights = np.array([0.,0.,0.])\n",
    "elif local_transform_scheme == 2:\n",
    "    reg_weights = np.array([1e-6, 1e-6, 1e-6])\n",
    "elif local_transform_scheme == 3:\n",
    "    reg_weights = np.array([0.,0.,0.])\n",
    "elif local_transform_scheme == 4:\n",
    "    reg_weights = np.array([1e-4, 1e-4, 1e-4])\n",
    "    \n",
    "# stack_moving = 'atlas_on_MD589'\n",
    "stack_moving = 'atlasV2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "paired_structures = ['5N', '6N', '7N', '7n', 'Amb', 'LC', 'LRt', 'Pn', 'Tz', 'VLL', 'RMC', 'SNC', 'SNR', '3N', '4N',\n",
    "                    'Sp5I', 'Sp5O', 'Sp5C', 'PBG', '10N', 'VCA', 'VCP', 'DC']\n",
    "singular_structures = ['AP', '12N', 'RtTg', 'SC', 'IC']\n",
    "structures = paired_structures + singular_structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_to_name_fixed = {i+1: name for i, name in enumerate(sorted(structures))}\n",
    "name_to_label_fixed = {n:l for l, n in label_to_name_fixed.iteritems()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# name_to_label_moving = DataManager.load_annotation_volume_nameToLabel(stack='MD589', downscale=32)\n",
    "# label_to_name_moving = {l:n for n, l in name_to_label_moving.iteritems()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "structures_sided = sum([[n] if n in singular_structures \n",
    "                        else [convert_to_left_name(n), convert_to_right_name(n)] \n",
    "                        for n in structures], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if local_transform_scheme == 1 or local_transform_scheme == 2:\n",
    "    \n",
    "    label_to_name_moving = {i+1: name for i, name in enumerate(structures_sided)}\n",
    "    name_to_label_moving = {n:l for l, n in label_to_name_moving.iteritems()}\n",
    "\n",
    "elif local_transform_scheme == 3 or local_transform_scheme == 4:\n",
    "\n",
    "    structures_sided_plus_surround = sum([[s, s+'_surround'] for s in structures_sided], [])\n",
    "\n",
    "    label_to_name_moving = {i+1: name for i, name in enumerate(structures_sided_plus_surround)}\n",
    "    name_to_label_moving = {n:l for l, n in label_to_name_moving.iteritems()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(410, 500, 375)\n",
      "float16\n"
     ]
    }
   ],
   "source": [
    "# Load fixed volumes\n",
    "\n",
    "volume_fixed = {name_to_label_fixed[name]: DataManager.load_score_volume(stack=stack_fixed, label=name, downscale=32, train_sample_scheme=train_sample_scheme)\n",
    "               for name in structures}\n",
    "\n",
    "print volume_fixed.values()[0].shape\n",
    "print volume_fixed.values()[0].dtype\n",
    "\n",
    "vol_fixed_ydim, vol_fixed_xdim, vol_fixed_zdim = volume_fixed.values()[0].shape\n",
    "\n",
    "# vol_fixed_xmin, vol_fixed_ymin, vol_fixed_zmin = (0,0,0)\n",
    "# vol_fixed_ymax, vol_fixed_xmax, vol_fixed_zmax = np.array(volume_fixed.values()[0].shape) - 1\n",
    "# vol_fixed_xdim = vol_fixed_xmax + 1 - vol_fixed_xmin\n",
    "# vol_fixed_ydim = vol_fixed_ymax + 1 - vol_fixed_ymin\n",
    "# vol_fixed_zdim = vol_fixed_zmax + 1 - vol_fixed_zmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# volume_moving = bp.unpack_ndarray_file(DataManager.get_transformed_volume_filepath(stack_m='MD589', type_m='annotation',\n",
    "#                                                            stack_f=stack_fixed, type_f='score',\n",
    "#                                                            downscale=32,\n",
    "#                                                            train_sample_scheme_f=1))\n",
    "\n",
    "# print volume_moving.shape\n",
    "\n",
    "# vol_moving_xmin, vol_moving_ymin, vol_moving_zmin = (0,0,0)\n",
    "# vol_moving_ymax, vol_moving_xmax, vol_moving_zmax = np.array(volume_moving.shape) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# volume_moving = {name_to_label_moving[name_s]: DataManager.load_transformed_volume(stack_m='atlas_on_MD589',\n",
    "#                                                                                    type_m='score',\n",
    "#                                                                                    stack_f=stack_fixed,\n",
    "#                                                                                    type_f='score',\n",
    "#                                                                                    downscale=32,\n",
    "#                                                                                    train_sample_scheme_f=train_sample_scheme,\n",
    "#                                                                                    label=name_s)\n",
    "#                  for name_s in structures_sided}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# volume_moving = {name_to_label_moving[name_s]: DataManager.load_transformed_volume(stack_m='atlas_on_MD589',\n",
    "#                                                                                    type_m='score',\n",
    "#                                                                                    stack_f=stack_fixed,\n",
    "#                                                                                    type_f='score',\n",
    "#                                                                                    downscale=32,\n",
    "#                                                                                    train_sample_scheme_f=train_sample_scheme,\n",
    "#                                                                                    label=name_s)\n",
    "#                  for name_s in structures_sided_plus_surround}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(410, 500, 375)\n",
      "float16\n"
     ]
    }
   ],
   "source": [
    "# Load moving volumes\n",
    "\n",
    "if local_transform_scheme == 3 or local_transform_scheme == 4:\n",
    "\n",
    "    volume_moving = {name_to_label_moving[name_s]: DataManager.load_transformed_volume(stack_m=stack_moving,\n",
    "                                                                                       type_m='score',\n",
    "                                                                                       stack_f=stack_fixed,\n",
    "                                                                                       type_f='score',\n",
    "                                                                                       downscale=32,\n",
    "                                                                                       train_sample_scheme_f=train_sample_scheme,\n",
    "                                                                                       label=name_s)\n",
    "                     for name_s in structures_sided_plus_surround}\n",
    "\n",
    "else:\n",
    "\n",
    "    volume_moving = {name_to_label_moving[name_s]: DataManager.load_transformed_volume(stack_m=stack_moving,\n",
    "                                                                                       type_m='score',\n",
    "                                                                                       stack_f=stack_fixed,\n",
    "                                                                                       type_f='score',\n",
    "                                                                                       downscale=32,\n",
    "                                                                                       train_sample_scheme_f=train_sample_scheme,\n",
    "                                                                                       label=name_s)\n",
    "                     for name_s in structures_sided}    \n",
    "    \n",
    "print volume_moving.values()[0].shape\n",
    "print volume_moving.values()[0].dtype\n",
    "\n",
    "# vol_moving_xmin, vol_moving_ymin, vol_moving_zmin = (0,0,0)\n",
    "# vol_moving_ymax, vol_moving_xmax, vol_moving_zmax = np.array(volume_moving.values()[0].shape) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# volume_moving_structure_sizes = {l: np.count_nonzero(vol > 0) for l, vol in volume_moving.iteritems()}\n",
    "\n",
    "# for lm, s in volume_moving_structure_sizes.iteritems():\n",
    "#     print label_to_name_moving[lm], s, 'voxels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_to_original_name(name):\n",
    "    return name.split('_')[0]\n",
    "\n",
    "labelIndexMap_m2f = {}\n",
    "for label_m, name_m in label_to_name_moving.iteritems():\n",
    "    labelIndexMap_m2f[label_m] = name_to_label_fixed[convert_to_original_name(name_m)]\n",
    "    \n",
    "label_weights_m = {}\n",
    "for label_m, name_m in label_to_name_moving.iteritems():\n",
    "    if 'surround' in name_m:\n",
    "        if local_transform_scheme == 3 or local_transform_scheme == 4:\n",
    "            label_weights_m[label_m] = -1\n",
    "        else:\n",
    "            label_weights_m[label_m] = 0\n",
    "    else:\n",
    "        label_weights_m[label_m] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "local_transform_scheme = 1\n",
    "# reg_weights = np.array([1e-6, 1e-6, 1e-6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DC_L\n",
      "set([11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load gradient 11: 0.682504 seconds\n",
      "overall: 0.682660 seconds\n",
      "grid search: 6.482705 seconds\n",
      "-inf 0.042814\n",
      "grid search: 5.935343 seconds\n",
      "0.042814 0.043098\n",
      "grid search: 3.940483 seconds\n",
      "0.043098 0.043159\n",
      "grid search: 3.127475 seconds\n",
      "0.043159 0.043374\n",
      "grid search: 2.281717 seconds\n",
      "0.043374 0.043464\n",
      "grid search: 1.658838 seconds\n",
      "0.043464 0.043555\n",
      "grid search: 1.276463 seconds\n",
      "grid search: 0.957695 seconds\n",
      "0.043555 0.043555\n",
      "grid search: 0.753707 seconds\n",
      "0.043555 0.043594\n",
      "grid search: 0.555471 seconds\n",
      "grid search: 0.450978 seconds\n",
      "grid search: 0.455822 seconds\n",
      "0.043594 0.043613\n",
      "grid search: 0.351199 seconds\n",
      "0.043613 0.043622\n",
      "grid search: 0.357208 seconds\n",
      "grid search: 0.252363 seconds\n",
      "grid search: 0.252266 seconds\n",
      "grid search: 0.246915 seconds\n",
      "grid search: 0.246341 seconds\n",
      "grid search: 0.248362 seconds\n",
      "grid search: 0.245022 seconds\n",
      "iteration 0\n",
      "step: 0.04 seconds\n",
      "score: 0.043622\n",
      "iteration 1\n",
      "step: 0.04 seconds\n",
      "score: 0.038684\n",
      "iteration 2\n",
      "step: 0.04 seconds\n",
      "score: 0.039459\n",
      "iteration 3\n",
      "step: 0.04 seconds\n",
      "score: 0.038729\n",
      "iteration 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params_best_upToNow [ 35.04238896  39.04949171  63.05503159  -0.21207121]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step: 0.04 seconds\n",
      "score: 0.040689\n",
      "iteration 5\n",
      "step: 0.04 seconds\n",
      "score: 0.039238\n",
      "iteration 6\n",
      "step: 0.04 seconds\n",
      "score: 0.039207\n",
      "iteration 7\n",
      "step: 0.04 seconds\n",
      "score: 0.040672\n",
      "iteration 8\n",
      "step: 0.04 seconds\n",
      "score: 0.041546\n",
      "iteration 9\n",
      "step: 0.04 seconds\n",
      "score: 0.040443\n",
      "iteration 10\n",
      "step: 0.04 seconds\n",
      "score: 0.040831\n",
      "iteration 11\n",
      "step: 0.04 seconds\n",
      "score: 0.040432\n",
      "iteration 12\n",
      "step: 0.04 seconds\n",
      "score: 0.040749\n",
      "iteration 13\n",
      "step: 0.04 seconds\n",
      "score: 0.040425\n",
      "iteration 14\n",
      "step: 0.04 seconds\n",
      "score: 0.040647\n",
      "iteration 15\n",
      "step: 0.04 seconds\n",
      "score: 0.040633\n",
      "iteration 16\n",
      "step: 0.04 seconds\n",
      "score: 0.040953\n",
      "iteration 17\n",
      "step: 0.04 seconds\n",
      "score: 0.040892\n",
      "iteration 18\n",
      "step: 0.04 seconds\n",
      "score: 0.040574\n",
      "iteration 19\n",
      "step: 0.04 seconds\n",
      "score: 0.040349\n",
      "iteration 20\n",
      "step: 0.04 seconds\n",
      "score: 0.040341\n",
      "iteration 21\n",
      "step: 0.04 seconds\n",
      "score: 0.040277\n",
      "iteration 22\n",
      "step: 0.04 seconds\n",
      "score: 0.038923\n",
      "iteration 23\n",
      "step: 0.04 seconds\n",
      "score: 0.039938\n",
      "iteration 24\n",
      "step: 0.04 seconds\n",
      "score: 0.039971\n",
      "iteration 25\n",
      "step: 0.04 seconds\n",
      "score: 0.039332\n",
      "iteration 26\n",
      "step: 0.04 seconds\n",
      "score: 0.039312\n",
      "iteration 27\n",
      "step: 0.04 seconds\n",
      "score: 0.038562\n",
      "iteration 28\n",
      "step: 0.04 seconds\n",
      "score: 0.039173\n",
      "iteration 29\n",
      "step: 0.04 seconds\n",
      "score: 0.038432\n",
      "iteration 30\n",
      "step: 0.04 seconds\n",
      "score: 0.038899\n",
      "iteration 31\n",
      "step: 0.04 seconds\n",
      "score: 0.038310\n",
      "iteration 32\n",
      "step: 0.04 seconds\n",
      "score: 0.038559\n",
      "iteration 33\n",
      "step: 0.04 seconds\n",
      "score: 0.038196\n",
      "iteration 34\n",
      "step: 0.04 seconds\n",
      "score: 0.038291\n",
      "iteration 35\n",
      "step: 0.04 seconds\n",
      "score: 0.037924\n",
      "iteration 36\n",
      "step: 0.04 seconds\n",
      "score: 0.037810\n",
      "iteration 37\n",
      "step: 0.04 seconds\n",
      "score: 0.037540\n",
      "iteration 38\n",
      "step: 0.04 seconds\n",
      "score: 0.037495\n",
      "iteration 39\n",
      "step: 0.04 seconds\n",
      "score: 0.037447\n",
      "iteration 40\n",
      "step: 0.04 seconds\n",
      "score: 0.037365\n",
      "iteration 41\n",
      "step: 0.04 seconds\n",
      "score: 0.037233\n",
      "iteration 42\n",
      "step: 0.04 seconds\n",
      "score: 0.037267\n",
      "iteration 43\n",
      "step: 0.04 seconds\n",
      "score: 0.037045\n",
      "iteration 44\n",
      "step: 0.04 seconds\n",
      "score: 0.037006\n",
      "iteration 45\n",
      "step: 0.04 seconds\n",
      "score: 0.036934\n",
      "iteration 46\n",
      "step: 0.04 seconds\n",
      "score: 0.037097\n",
      "iteration 47\n",
      "step: 0.04 seconds\n",
      "score: 0.037011\n",
      "iteration 48\n",
      "step: 0.04 seconds\n",
      "score: 0.037193\n",
      "iteration 49\n",
      "step: 0.04 seconds\n",
      "score: 0.037028\n",
      "iteration 50\n",
      "step: 0.04 seconds\n",
      "score: 0.037278\n",
      "iteration 51\n",
      "step: 0.04 seconds\n",
      "score: 0.037186\n",
      "iteration 52\n",
      "step: 0.04 seconds\n",
      "score: 0.037347\n",
      "iteration 53\n",
      "step: 0.04 seconds\n",
      "score: 0.037467\n",
      "iteration 54\n",
      "step: 0.04 seconds\n",
      "score: 0.037605\n",
      "iteration 55\n",
      "step: 0.04 seconds\n",
      "score: 0.037710\n",
      "iteration 56\n",
      "step: 0.04 seconds\n",
      "score: 0.037639\n",
      "iteration 57\n",
      "step: 0.04 seconds\n",
      "score: 0.037704\n",
      "iteration 58\n",
      "step: 0.04 seconds\n",
      "score: 0.037622\n",
      "iteration 59\n",
      "step: 0.04 seconds\n",
      "score: 0.037537\n",
      "iteration 60\n",
      "step: 0.04 seconds\n",
      "score: 0.037552\n",
      "iteration 61\n",
      "step: 0.04 seconds\n",
      "score: 0.037529\n",
      "iteration 62\n",
      "step: 0.04 seconds\n",
      "score: 0.037404\n",
      "iteration 63\n",
      "step: 0.04 seconds\n",
      "score: 0.037322\n",
      "iteration 64\n",
      "step: 0.04 seconds\n",
      "score: 0.037338\n",
      "iteration 65\n",
      "step: 0.04 seconds\n",
      "score: 0.037434\n",
      "iteration 66\n",
      "step: 0.04 seconds\n",
      "score: 0.037488\n",
      "iteration 67\n",
      "step: 0.04 seconds\n",
      "score: 0.037445\n",
      "iteration 68\n",
      "step: 0.04 seconds\n",
      "score: 0.037469\n",
      "iteration 69\n",
      "step: 0.04 seconds\n",
      "score: 0.037336\n",
      "iteration 70\n",
      "step: 0.04 seconds\n",
      "score: 0.037112\n",
      "iteration 71\n",
      "step: 0.04 seconds\n",
      "score: 0.037470\n",
      "iteration 72\n",
      "step: 0.04 seconds\n",
      "score: 0.037562\n",
      "iteration 73\n",
      "step: 0.04 seconds\n",
      "score: 0.037443\n",
      "iteration 74\n",
      "step: 0.04 seconds\n",
      "score: 0.037379\n",
      "iteration 75\n",
      "step: 0.04 seconds\n",
      "score: 0.037282\n",
      "iteration 76\n",
      "step: 0.04 seconds\n",
      "score: 0.037468\n",
      "iteration 77\n",
      "step: 0.04 seconds\n",
      "score: 0.037371\n",
      "iteration 78\n",
      "step: 0.04 seconds\n",
      "score: 0.037498\n",
      "iteration 79\n",
      "step: 0.04 seconds\n",
      "score: 0.037533\n",
      "iteration 80\n",
      "step: 0.04 seconds\n",
      "score: 0.037372\n",
      "iteration 81\n",
      "step: 0.04 seconds\n",
      "score: 0.037271\n",
      "iteration 82\n",
      "step: 0.04 seconds\n",
      "score: 0.037271\n",
      "iteration 83\n",
      "step: 0.04 seconds\n",
      "score: 0.037224\n",
      "iteration 84\n",
      "step: 0.04 seconds\n",
      "score: 0.037191\n",
      "iteration 85\n",
      "step: 0.04 seconds\n",
      "score: 0.037159\n",
      "iteration 86\n",
      "step: 0.04 seconds\n",
      "score: 0.037222\n",
      "iteration 87\n",
      "step: 0.04 seconds\n",
      "score: 0.037214\n",
      "iteration 88\n",
      "step: 0.04 seconds\n",
      "score: 0.037172\n",
      "iteration 89\n",
      "step: 0.04 seconds\n",
      "score: 0.037190\n",
      "iteration 90\n",
      "step: 0.04 seconds\n",
      "score: 0.037058\n",
      "iteration 91\n",
      "step: 0.04 seconds\n",
      "score: 0.037176\n",
      "iteration 92\n",
      "step: 0.04 seconds\n",
      "score: 0.037159\n",
      "iteration 93\n",
      "step: 0.04 seconds\n",
      "score: 0.037146\n",
      "iteration 94\n",
      "step: 0.04 seconds\n",
      "score: 0.037078\n",
      "iteration 95\n",
      "step: 0.04 seconds\n",
      "score: 0.037087\n",
      "iteration 96\n",
      "step: 0.04 seconds\n",
      "score: 0.037011\n",
      "iteration 97\n",
      "step: 0.04 seconds\n",
      "score: 0.037057\n",
      "iteration 98\n",
      "step: 0.04 seconds\n",
      "score: 0.037099\n",
      "iteration 99\n",
      "step: 0.04 seconds\n",
      "score: 0.037071\n",
      "iteration 100\n",
      "step: 0.04 seconds\n",
      "score: 0.037006\n",
      "iteration 101\n",
      "step: 0.04 seconds\n",
      "score: 0.036962\n",
      "iteration 102\n",
      "step: 0.04 seconds\n",
      "score: 0.036892\n",
      "iteration 103\n",
      "step: 0.04 seconds\n",
      "score: 0.036814\n",
      "iteration 104\n",
      "step: 0.04 seconds\n",
      "score: 0.036680\n",
      "iteration 105\n",
      "step: 0.04 seconds\n",
      "score: 0.036619\n",
      "iteration 106\n",
      "step: 0.04 seconds\n",
      "score: 0.036510\n",
      "iteration 107\n",
      "step: 0.04 seconds\n",
      "score: 0.036355\n",
      "iteration 108\n",
      "step: 0.04 seconds\n",
      "score: 0.036353\n",
      "iteration 109\n",
      "step: 0.04 seconds\n",
      "score: 0.036289\n",
      "iteration 110\n",
      "step: 0.04 seconds\n",
      "score: 0.036078\n",
      "iteration 111\n",
      "step: 0.04 seconds\n",
      "score: 0.036186\n",
      "iteration 112\n",
      "step: 0.04 seconds\n",
      "score: 0.036108\n",
      "iteration 113\n",
      "step: 0.04 seconds\n",
      "score: 0.036230\n",
      "iteration 114\n",
      "step: 0.04 seconds\n",
      "score: 0.036145\n",
      "iteration 115\n",
      "step: 0.04 seconds\n",
      "score: 0.036186\n",
      "iteration 116\n",
      "step: 0.04 seconds\n",
      "score: 0.036156\n",
      "iteration 117\n",
      "step: 0.04 seconds\n",
      "score: 0.036117\n",
      "iteration 118\n",
      "step: 0.04 seconds\n",
      "score: 0.036187\n",
      "iteration 119\n",
      "step: 0.04 seconds\n",
      "score: 0.036079\n",
      "iteration 120\n",
      "step: 0.04 seconds\n",
      "score: 0.036120\n",
      "iteration 121\n",
      "step: 0.04 seconds\n",
      "score: 0.036065\n",
      "iteration 122\n",
      "step: 0.04 seconds\n",
      "score: 0.036118\n",
      "iteration 123\n",
      "step: 0.04 seconds\n",
      "score: 0.035952\n",
      "iteration 124\n",
      "step: 0.04 seconds\n",
      "score: 0.036003\n",
      "iteration 125\n",
      "step: 0.04 seconds\n",
      "score: 0.035874\n",
      "iteration 126\n",
      "step: 0.04 seconds\n",
      "score: 0.035761\n",
      "iteration 127\n",
      "step: 0.04 seconds\n",
      "score: 0.035739\n",
      "iteration 128\n",
      "step: 0.04 seconds\n",
      "score: 0.035635\n",
      "iteration 129\n",
      "step: 0.04 seconds\n",
      "score: 0.035627\n",
      "iteration 130\n",
      "step: 0.04 seconds\n",
      "score: 0.035414\n",
      "iteration 131\n",
      "step: 0.04 seconds\n",
      "score: 0.035304\n",
      "iteration 132\n",
      "step: 0.04 seconds\n",
      "score: 0.035139\n",
      "iteration 133\n",
      "step: 0.04 seconds\n",
      "score: 0.035007\n",
      "iteration 134\n",
      "step: 0.04 seconds\n",
      "score: 0.034821\n",
      "iteration 135\n",
      "step: 0.04 seconds\n",
      "score: 0.034705\n",
      "iteration 136\n",
      "step: 0.04 seconds\n",
      "score: 0.034570\n",
      "iteration 137\n",
      "step: 0.04 seconds\n",
      "score: 0.034435\n",
      "iteration 138\n",
      "step: 0.04 seconds\n",
      "score: 0.034326\n",
      "iteration 139\n",
      "step: 0.04 seconds\n",
      "score: 0.034155\n",
      "iteration 140\n",
      "step: 0.04 seconds\n",
      "score: 0.033948\n",
      "iteration 141\n",
      "step: 0.04 seconds\n",
      "score: 0.033869\n",
      "iteration 142\n",
      "step: 0.04 seconds\n",
      "score: 0.033847\n",
      "iteration 143\n",
      "step: 0.04 seconds\n",
      "score: 0.033778\n",
      "iteration 144\n",
      "step: 0.04 seconds\n",
      "score: 0.033608\n",
      "iteration 145\n",
      "step: 0.04 seconds\n",
      "score: 0.033509\n",
      "iteration 146\n",
      "step: 0.04 seconds\n",
      "score: 0.033464\n",
      "iteration 147\n",
      "step: 0.04 seconds\n",
      "score: 0.033279\n",
      "iteration 148\n",
      "step: 0.04 seconds\n",
      "score: 0.033183\n",
      "iteration 149\n",
      "step: 0.04 seconds\n",
      "score: 0.033021\n",
      "iteration 150\n",
      "step: 0.04 seconds\n",
      "score: 0.032955\n",
      "iteration 151\n",
      "step: 0.04 seconds\n",
      "score: 0.032884\n",
      "iteration 152\n",
      "step: 0.04 seconds\n",
      "score: 0.032792\n",
      "iteration 153\n",
      "step: 0.04 seconds\n",
      "score: 0.032624\n",
      "iteration 154\n",
      "step: 0.04 seconds\n",
      "score: 0.032556\n",
      "iteration 155\n",
      "step: 0.04 seconds\n",
      "score: 0.032526\n",
      "iteration 156\n",
      "step: 0.04 seconds\n",
      "score: 0.032470\n",
      "iteration 157\n",
      "step: 0.04 seconds\n",
      "score: 0.032391\n",
      "iteration 158\n",
      "step: 0.04 seconds\n",
      "score: 0.032350\n",
      "iteration 159\n",
      "step: 0.04 seconds\n",
      "score: 0.032284\n",
      "iteration 160\n",
      "step: 0.04 seconds\n",
      "score: 0.032125\n",
      "iteration 161\n",
      "step: 0.04 seconds\n",
      "score: 0.032167\n",
      "iteration 162\n",
      "step: 0.04 seconds\n",
      "score: 0.032046\n",
      "iteration 163\n",
      "step: 0.04 seconds\n",
      "score: 0.031996\n",
      "iteration 164\n",
      "step: 0.04 seconds\n",
      "score: 0.031994\n",
      "iteration 165\n",
      "step: 0.04 seconds\n",
      "score: 0.031923\n",
      "iteration 166\n",
      "step: 0.04 seconds\n",
      "score: 0.031772\n",
      "iteration 167\n",
      "step: 0.04 seconds\n",
      "score: 0.031833\n",
      "iteration 168\n",
      "step: 0.04 seconds\n",
      "score: 0.031925\n",
      "iteration 169\n",
      "step: 0.04 seconds\n",
      "score: 0.031958\n",
      "iteration 170\n",
      "step: 0.04 seconds\n",
      "score: 0.032083\n",
      "iteration 171\n",
      "step: 0.04 seconds\n",
      "score: 0.032356\n",
      "iteration 172\n",
      "step: 0.04 seconds\n",
      "score: 0.032444\n",
      "iteration 173\n",
      "step: 0.04 seconds\n",
      "score: 0.032627\n",
      "iteration 174\n",
      "step: 0.04 seconds\n",
      "score: 0.032689\n",
      "iteration 175\n",
      "step: 0.04 seconds\n",
      "score: 0.032770\n",
      "iteration 176\n",
      "step: 0.04 seconds\n",
      "score: 0.032975\n",
      "iteration 177\n",
      "step: 0.04 seconds\n",
      "score: 0.033038\n",
      "iteration 178\n",
      "step: 0.04 seconds\n",
      "score: 0.033088\n",
      "iteration 179\n",
      "step: 0.04 seconds\n",
      "score: 0.033326\n",
      "iteration 180\n",
      "step: 0.04 seconds\n",
      "score: 0.033426\n",
      "iteration 181\n",
      "step: 0.04 seconds\n",
      "score: 0.033719\n",
      "iteration 182\n",
      "step: 0.04 seconds\n",
      "score: 0.034212\n",
      "iteration 183\n",
      "step: 0.04 seconds\n",
      "score: 0.034463\n",
      "iteration 184\n",
      "step: 0.04 seconds\n",
      "score: 0.034550\n",
      "iteration 185\n",
      "step: 0.04 seconds\n",
      "score: 0.034557\n",
      "iteration 186\n",
      "step: 0.04 seconds\n",
      "score: 0.034687\n",
      "iteration 187\n",
      "step: 0.04 seconds\n",
      "score: 0.034695\n",
      "iteration 188\n",
      "step: 0.04 seconds\n",
      "score: 0.034719\n",
      "iteration 189\n",
      "step: 0.04 seconds\n",
      "score: 0.034857\n",
      "iteration 190\n",
      "step: 0.04 seconds\n",
      "score: 0.034820\n",
      "iteration 191\n",
      "step: 0.04 seconds\n",
      "score: 0.035069\n",
      "iteration 192\n",
      "step: 0.04 seconds\n",
      "score: 0.035196\n",
      "iteration 193\n",
      "step: 0.04 seconds\n",
      "score: 0.035312\n",
      "iteration 194\n",
      "step: 0.04 seconds\n",
      "score: 0.035551\n",
      "iteration 195\n",
      "step: 0.04 seconds\n",
      "score: 0.035687\n",
      "iteration 196\n",
      "step: 0.04 seconds\n",
      "score: 0.035979\n",
      "iteration 197\n",
      "step: 0.04 seconds\n",
      "score: 0.036080\n",
      "iteration 198\n",
      "step: 0.04 seconds\n",
      "score: 0.036195\n",
      "iteration 199\n",
      "step: 0.04 seconds\n",
      "score: 0.036277\n",
      "iteration 200\n",
      "step: 0.04 seconds\n",
      "score: 0.036383\n",
      "iteration 201\n",
      "step: 0.04 seconds\n",
      "score: 0.036440\n",
      "iteration 202\n",
      "step: 0.04 seconds\n",
      "score: 0.036593\n",
      "iteration 203\n",
      "step: 0.04 seconds\n",
      "score: 0.036854\n",
      "iteration 204\n",
      "step: 0.04 seconds\n",
      "score: 0.037031\n",
      "iteration 205\n",
      "step: 0.04 seconds\n",
      "score: 0.037385\n",
      "iteration 206\n",
      "step: 0.04 seconds\n",
      "score: 0.037776\n",
      "iteration 207\n",
      "step: 0.04 seconds\n",
      "score: 0.037964\n",
      "iteration 208\n",
      "step: 0.04 seconds\n",
      "score: 0.038465\n",
      "iteration 209\n",
      "step: 0.04 seconds\n",
      "score: 0.038933\n",
      "iteration 210\n",
      "step: 0.04 seconds\n",
      "score: 0.038857\n",
      "iteration 211\n",
      "step: 0.04 seconds\n",
      "score: 0.038798\n",
      "iteration 212\n",
      "step: 0.04 seconds\n",
      "score: 0.038554\n",
      "iteration 213\n",
      "step: 0.04 seconds\n",
      "score: 0.038384\n",
      "iteration 214\n",
      "step: 0.04 seconds\n",
      "score: 0.038186\n",
      "iteration 215\n",
      "step: 0.04 seconds\n",
      "score: 0.038125\n",
      "iteration 216\n",
      "step: 0.04 seconds\n",
      "score: 0.038133\n",
      "iteration 217\n",
      "step: 0.04 seconds\n",
      "score: 0.038088\n",
      "iteration 218\n",
      "step: 0.04 seconds\n",
      "score: 0.038207\n",
      "iteration 219\n",
      "step: 0.04 seconds\n",
      "score: 0.038137\n",
      "iteration 220\n",
      "step: 0.04 seconds\n",
      "score: 0.038096\n",
      "iteration 221\n",
      "step: 0.04 seconds\n",
      "score: 0.037964\n",
      "iteration 222\n",
      "step: 0.04 seconds\n",
      "score: 0.038028\n",
      "iteration 223\n",
      "step: 0.04 seconds\n",
      "score: 0.038304\n",
      "iteration 224\n",
      "step: 0.04 seconds\n",
      "score: 0.038644\n",
      "iteration 225\n",
      "step: 0.04 seconds\n",
      "score: 0.038737\n",
      "iteration 226\n",
      "step: 0.04 seconds\n",
      "score: 0.038865\n",
      "iteration 227\n",
      "step: 0.04 seconds\n",
      "score: 0.039058\n",
      "iteration 228\n",
      "step: 0.04 seconds\n",
      "score: 0.039201\n",
      "iteration 229\n",
      "step: 0.04 seconds\n",
      "score: 0.039258\n",
      "iteration 230\n",
      "step: 0.04 seconds\n",
      "score: 0.039479\n",
      "iteration 231\n",
      "step: 0.04 seconds\n",
      "score: 0.039575\n",
      "iteration 232\n",
      "step: 0.04 seconds\n",
      "score: 0.039925\n",
      "iteration 233\n",
      "step: 0.04 seconds\n",
      "score: 0.040275\n",
      "iteration 234\n",
      "step: 0.04 seconds\n",
      "score: 0.040766\n",
      "iteration 235\n",
      "step: 0.04 seconds\n",
      "score: 0.041219\n",
      "iteration 236\n",
      "step: 0.04 seconds\n",
      "score: 0.041693\n",
      "iteration 237\n",
      "step: 0.04 seconds\n",
      "score: 0.041992\n",
      "iteration 238\n",
      "step: 0.04 seconds\n",
      "score: 0.042141\n",
      "iteration 239\n",
      "step: 0.04 seconds\n",
      "score: 0.042343\n",
      "iteration 240\n",
      "step: 0.04 seconds\n",
      "score: 0.042680\n",
      "iteration 241\n",
      "step: 0.04 seconds\n",
      "score: 0.043072\n",
      "iteration 242\n",
      "step: 0.04 seconds\n",
      "score: 0.043477\n",
      "iteration 243\n",
      "step: 0.04 seconds\n",
      "score: 0.043807\n",
      "iteration 244\n",
      "step: 0.04 seconds\n",
      "score: 0.043895\n",
      "iteration 245\n",
      "step: 0.04 seconds\n",
      "score: 0.043973\n",
      "iteration 246\n",
      "step: 0.04 seconds\n",
      "score: 0.043866\n",
      "iteration 247\n",
      "step: 0.04 seconds\n",
      "score: 0.043812\n",
      "iteration 248\n",
      "step: 0.04 seconds\n",
      "score: 0.043548\n",
      "iteration 249\n",
      "step: 0.04 seconds\n",
      "score: 0.043888\n",
      "iteration 250\n",
      "step: 0.04 seconds\n",
      "score: 0.043681\n",
      "iteration 251\n",
      "step: 0.04 seconds\n",
      "score: 0.043846\n",
      "iteration 252\n",
      "step: 0.04 seconds\n",
      "score: 0.043508\n",
      "iteration 253\n",
      "step: 0.04 seconds\n",
      "score: 0.043644\n",
      "iteration 254\n",
      "step: 0.04 seconds\n",
      "score: 0.043464\n",
      "iteration 255\n",
      "step: 0.04 seconds\n",
      "score: 0.043492\n",
      "iteration 256\n",
      "step: 0.04 seconds\n",
      "score: 0.043242\n",
      "iteration 257\n",
      "step: 0.04 seconds\n",
      "score: 0.043312\n",
      "iteration 258\n",
      "step: 0.04 seconds\n",
      "score: 0.043162\n",
      "iteration 259\n",
      "step: 0.04 seconds\n",
      "score: 0.043263\n",
      "iteration 260\n",
      "step: 0.04 seconds\n",
      "score: 0.043226\n",
      "iteration 261\n",
      "step: 0.04 seconds\n",
      "score: 0.043230\n",
      "iteration 262\n",
      "step: 0.04 seconds\n",
      "score: 0.043123\n",
      "iteration 263\n",
      "step: 0.04 seconds\n",
      "score: 0.043128\n",
      "iteration 264\n",
      "step: 0.04 seconds\n",
      "score: 0.043145\n",
      "iteration 265\n",
      "step: 0.04 seconds\n",
      "score: 0.043077\n",
      "iteration 266\n",
      "step: 0.04 seconds\n",
      "score: 0.043027\n",
      "iteration 267\n",
      "step: 0.04 seconds\n",
      "score: 0.042892\n",
      "iteration 268\n",
      "step: 0.04 seconds\n",
      "score: 0.042893\n",
      "iteration 269\n",
      "step: 0.04 seconds\n",
      "score: 0.042795\n",
      "iteration 270\n",
      "step: 0.04 seconds\n",
      "score: 0.042730\n",
      "iteration 271\n",
      "step: 0.04 seconds\n",
      "score: 0.042632\n",
      "iteration 272\n",
      "step: 0.04 seconds\n",
      "score: 0.042597\n",
      "iteration 273\n",
      "step: 0.04 seconds\n",
      "score: 0.042516\n",
      "iteration 274\n",
      "step: 0.04 seconds\n",
      "score: 0.042358\n",
      "iteration 275\n",
      "step: 0.04 seconds\n",
      "score: 0.042266\n",
      "iteration 276\n",
      "step: 0.04 seconds\n",
      "score: 0.042217\n",
      "iteration 277\n",
      "step: 0.04 seconds\n",
      "score: 0.042088\n",
      "iteration 278\n",
      "step: 0.04 seconds\n",
      "score: 0.042001\n",
      "iteration 279\n",
      "step: 0.04 seconds\n",
      "score: 0.041910\n",
      "iteration 280\n",
      "step: 0.04 seconds\n",
      "score: 0.041779\n",
      "iteration 281\n",
      "step: 0.04 seconds\n",
      "score: 0.041653\n",
      "iteration 282\n",
      "step: 0.04 seconds\n",
      "score: 0.041584\n",
      "iteration 283\n",
      "step: 0.04 seconds\n",
      "score: 0.041454\n",
      "iteration 284\n",
      "step: 0.04 seconds\n",
      "score: 0.041270\n",
      "iteration 285\n",
      "step: 0.04 seconds\n",
      "score: 0.041047\n",
      "iteration 286\n",
      "step: 0.04 seconds\n",
      "score: 0.041049\n",
      "iteration 287\n",
      "step: 0.04 seconds\n",
      "score: 0.040920\n",
      "iteration 288\n",
      "step: 0.04 seconds\n",
      "score: 0.040734\n",
      "iteration 289\n",
      "step: 0.04 seconds\n",
      "score: 0.040680\n",
      "iteration 290\n",
      "step: 0.04 seconds\n",
      "score: 0.040708\n",
      "iteration 291\n",
      "step: 0.04 seconds\n",
      "score: 0.040669\n",
      "iteration 292\n",
      "step: 0.04 seconds\n",
      "score: 0.040569\n",
      "iteration 293\n",
      "step: 0.04 seconds\n",
      "score: 0.040406\n",
      "iteration 294\n",
      "step: 0.04 seconds\n",
      "score: 0.040299\n",
      "iteration 295\n",
      "step: 0.04 seconds\n",
      "score: 0.040226\n",
      "iteration 296\n",
      "step: 0.04 seconds\n",
      "score: 0.040103\n",
      "iteration 297\n",
      "step: 0.04 seconds\n",
      "score: 0.040115\n",
      "iteration 298\n",
      "step: 0.04 seconds\n",
      "score: 0.040032\n",
      "iteration 299\n",
      "step: 0.04 seconds\n",
      "score: 0.039945\n",
      "iteration 300\n",
      "step: 0.04 seconds\n",
      "score: 0.039899\n",
      "iteration 301\n",
      "step: 0.04 seconds\n",
      "score: 0.039799\n",
      "iteration 302\n",
      "step: 0.04 seconds\n",
      "score: 0.039751\n",
      "iteration 303\n",
      "step: 0.04 seconds\n",
      "score: 0.039706\n",
      "iteration 304\n",
      "step: 0.04 seconds\n",
      "score: 0.039597\n",
      "iteration 305\n",
      "step: 0.04 seconds\n",
      "score: 0.039626\n",
      "iteration 306\n",
      "step: 0.04 seconds\n",
      "score: 0.039362\n",
      "iteration 307\n",
      "step: 0.04 seconds\n",
      "score: 0.039440\n",
      "iteration 308\n",
      "step: 0.04 seconds\n",
      "score: 0.039366\n",
      "iteration 309\n",
      "step: 0.04 seconds\n",
      "score: 0.039454\n",
      "iteration 310\n",
      "step: 0.04 seconds\n",
      "score: 0.039245\n",
      "iteration 311\n",
      "step: 0.04 seconds\n",
      "score: 0.039226\n",
      "iteration 312\n",
      "step: 0.04 seconds\n",
      "score: 0.039210\n",
      "iteration 313\n",
      "step: 0.04 seconds\n",
      "score: 0.039151\n",
      "iteration 314\n",
      "step: 0.04 seconds\n",
      "score: 0.039252\n",
      "iteration 315\n",
      "step: 0.04 seconds\n",
      "score: 0.039163\n",
      "iteration 316\n",
      "step: 0.04 seconds\n",
      "score: 0.039205\n",
      "iteration 317\n",
      "step: 0.04 seconds\n",
      "score: 0.039165\n",
      "iteration 318\n",
      "step: 0.04 seconds\n",
      "score: 0.039090\n",
      "iteration 319\n",
      "step: 0.04 seconds\n",
      "score: 0.039095\n",
      "iteration 320\n",
      "step: 0.04 seconds\n",
      "score: 0.039074\n",
      "iteration 321\n",
      "step: 0.04 seconds\n",
      "score: 0.039030\n",
      "iteration 322\n",
      "step: 0.04 seconds\n",
      "score: 0.039066\n",
      "iteration 323\n",
      "step: 0.04 seconds\n",
      "score: 0.039057\n",
      "iteration 324\n",
      "step: 0.04 seconds\n",
      "score: 0.039032\n",
      "iteration 325\n",
      "step: 0.04 seconds\n",
      "score: 0.038944\n",
      "iteration 326\n",
      "step: 0.04 seconds\n",
      "score: 0.038927\n",
      "iteration 327\n",
      "step: 0.04 seconds\n",
      "score: 0.038788\n",
      "iteration 328\n",
      "step: 0.04 seconds\n",
      "score: 0.038782\n",
      "iteration 329\n",
      "step: 0.04 seconds\n",
      "score: 0.038724\n",
      "iteration 330\n",
      "step: 0.04 seconds\n",
      "score: 0.038728\n",
      "iteration 331\n",
      "step: 0.04 seconds\n",
      "score: 0.038645\n",
      "iteration 332\n",
      "step: 0.04 seconds\n",
      "score: 0.038612\n",
      "iteration 333\n",
      "step: 0.04 seconds\n",
      "score: 0.038504\n",
      "iteration 334\n",
      "step: 0.04 seconds\n",
      "score: 0.038476\n",
      "iteration 335\n",
      "step: 0.04 seconds\n",
      "score: 0.038459\n",
      "iteration 336\n",
      "step: 0.04 seconds\n",
      "score: 0.038461\n",
      "iteration 337\n",
      "step: 0.04 seconds\n",
      "score: 0.038426\n",
      "iteration 338\n",
      "step: 0.04 seconds\n",
      "score: 0.038356\n",
      "iteration 339\n",
      "step: 0.04 seconds\n",
      "score: 0.038285\n",
      "iteration 340\n",
      "step: 0.04 seconds\n",
      "score: 0.038298\n",
      "iteration 341\n",
      "step: 0.04 seconds\n",
      "score: 0.038230\n",
      "iteration 342\n",
      "step: 0.04 seconds\n",
      "score: 0.038119\n",
      "iteration 343\n",
      "step: 0.04 seconds\n",
      "score: 0.038137\n",
      "iteration 344\n",
      "step: 0.04 seconds\n",
      "score: 0.038278\n",
      "iteration 345\n",
      "step: 0.04 seconds\n",
      "score: 0.038185\n",
      "iteration 346\n",
      "step: 0.04 seconds\n",
      "score: 0.038210\n",
      "iteration 347\n",
      "step: 0.04 seconds\n",
      "score: 0.038121\n",
      "iteration 348\n",
      "step: 0.04 seconds\n",
      "score: 0.038004\n",
      "iteration 349\n",
      "step: 0.04 seconds\n",
      "score: 0.037914\n",
      "iteration 350\n",
      "step: 0.04 seconds\n",
      "score: 0.037922\n",
      "iteration 351\n",
      "step: 0.04 seconds\n",
      "score: 0.037836\n",
      "iteration 352\n",
      "step: 0.04 seconds\n",
      "score: 0.037785\n",
      "iteration 353\n",
      "step: 0.04 seconds\n",
      "score: 0.037773\n",
      "iteration 354\n",
      "step: 0.04 seconds\n",
      "score: 0.037765\n",
      "iteration 355\n",
      "step: 0.04 seconds\n",
      "score: 0.037786\n",
      "iteration 356\n",
      "step: 0.04 seconds\n",
      "score: 0.037798\n",
      "iteration 357\n",
      "step: 0.04 seconds\n",
      "score: 0.037825\n",
      "iteration 358\n",
      "step: 0.04 seconds\n",
      "score: 0.037826\n",
      "iteration 359\n",
      "step: 0.04 seconds\n",
      "score: 0.037870\n",
      "iteration 360\n",
      "step: 0.04 seconds\n",
      "score: 0.037927\n",
      "iteration 361\n",
      "step: 0.04 seconds\n",
      "score: 0.037925\n",
      "iteration 362\n",
      "step: 0.04 seconds\n",
      "score: 0.038005\n",
      "iteration 363\n",
      "step: 0.04 seconds\n",
      "score: 0.037934\n",
      "iteration 364\n",
      "step: 0.04 seconds\n",
      "score: 0.037971\n",
      "iteration 365\n",
      "step: 0.04 seconds\n",
      "score: 0.037961\n",
      "iteration 366\n",
      "step: 0.04 seconds\n",
      "score: 0.038046\n",
      "iteration 367\n",
      "step: 0.04 seconds\n",
      "score: 0.037984\n",
      "iteration 368\n",
      "step: 0.04 seconds\n",
      "score: 0.037962\n",
      "iteration 369\n",
      "step: 0.04 seconds\n",
      "score: 0.037960\n",
      "iteration 370\n",
      "step: 0.04 seconds\n",
      "score: 0.037878\n",
      "iteration 371\n",
      "step: 0.04 seconds\n",
      "score: 0.037807\n",
      "iteration 372\n",
      "step: 0.04 seconds\n",
      "score: 0.037883\n",
      "iteration 373\n",
      "step: 0.04 seconds\n",
      "score: 0.037819\n",
      "iteration 374\n",
      "step: 0.04 seconds\n",
      "score: 0.037859\n",
      "iteration 375\n",
      "step: 0.04 seconds\n",
      "score: 0.037898\n",
      "iteration 376\n",
      "step: 0.04 seconds\n",
      "score: 0.037950\n",
      "iteration 377\n",
      "step: 0.04 seconds\n",
      "score: 0.037917\n",
      "iteration 378\n",
      "step: 0.04 seconds\n",
      "score: 0.037861\n",
      "iteration 379\n",
      "step: 0.04 seconds\n",
      "score: 0.037908\n",
      "iteration 380\n",
      "step: 0.04 seconds\n",
      "score: 0.037879\n",
      "iteration 381\n",
      "step: 0.04 seconds\n",
      "score: 0.037825\n",
      "iteration 382\n",
      "step: 0.04 seconds\n",
      "score: 0.037676\n",
      "iteration 383\n",
      "step: 0.04 seconds\n",
      "score: 0.037692\n",
      "iteration 384\n",
      "step: 0.04 seconds\n",
      "score: 0.037653\n",
      "iteration 385\n",
      "step: 0.04 seconds\n",
      "score: 0.037562\n",
      "iteration 386\n",
      "step: 0.04 seconds\n",
      "score: 0.037529\n",
      "iteration 387\n",
      "step: 0.04 seconds\n",
      "score: 0.037491\n",
      "iteration 388\n",
      "step: 0.04 seconds\n",
      "score: 0.037446\n",
      "iteration 389\n",
      "step: 0.04 seconds\n",
      "score: 0.037356\n",
      "iteration 390\n",
      "step: 0.04 seconds\n",
      "score: 0.037328\n",
      "iteration 391\n",
      "step: 0.04 seconds\n",
      "score: 0.037194\n",
      "iteration 392\n",
      "step: 0.04 seconds\n",
      "score: 0.037150\n",
      "iteration 393\n",
      "step: 0.04 seconds\n",
      "score: 0.037106\n",
      "iteration 394\n",
      "step: 0.04 seconds\n",
      "score: 0.037081\n",
      "iteration 395\n",
      "step: 0.04 seconds\n",
      "score: 0.037043\n",
      "iteration 396\n",
      "step: 0.04 seconds\n",
      "score: 0.036976\n",
      "iteration 397\n",
      "step: 0.04 seconds\n",
      "score: 0.036927\n",
      "iteration 398\n",
      "step: 0.04 seconds\n",
      "score: 0.036858\n",
      "iteration 399\n",
      "step: 0.04 seconds\n",
      "score: 0.036802\n",
      "iteration 400\n",
      "step: 0.04 seconds\n",
      "score: 0.036762\n",
      "iteration 401\n",
      "step: 0.04 seconds\n",
      "score: 0.036725\n",
      "iteration 402\n",
      "step: 0.04 seconds\n",
      "score: 0.036541\n",
      "iteration 403\n",
      "step: 0.04 seconds\n",
      "score: 0.036449\n",
      "iteration 404\n",
      "step: 0.04 seconds\n",
      "score: 0.036380\n",
      "iteration 405\n",
      "step: 0.04 seconds\n",
      "score: 0.036369\n",
      "iteration 406\n",
      "step: 0.04 seconds\n",
      "score: 0.036349\n",
      "iteration 407\n",
      "step: 0.04 seconds\n",
      "score: 0.036367\n",
      "iteration 408\n",
      "step: 0.04 seconds\n",
      "score: 0.036317\n",
      "iteration 409\n",
      "step: 0.04 seconds\n",
      "score: 0.036339\n",
      "iteration 410\n",
      "step: 0.04 seconds\n",
      "score: 0.036273\n",
      "iteration 411\n",
      "step: 0.04 seconds\n",
      "score: 0.036206\n",
      "iteration 412\n",
      "step: 0.04 seconds\n",
      "score: 0.036122\n",
      "iteration 413\n",
      "step: 0.04 seconds\n",
      "score: 0.036214\n",
      "iteration 414\n",
      "step: 0.04 seconds\n",
      "score: 0.035997\n",
      "iteration 415\n",
      "step: 0.04 seconds\n",
      "score: 0.036129\n",
      "iteration 416\n",
      "step: 0.04 seconds\n",
      "score: 0.036082\n",
      "iteration 417\n",
      "step: 0.04 seconds\n",
      "score: 0.036072\n",
      "iteration 418\n",
      "step: 0.04 seconds\n",
      "score: 0.036071\n",
      "iteration 419\n",
      "step: 0.04 seconds\n",
      "score: 0.035985\n",
      "iteration 420\n",
      "step: 0.04 seconds\n",
      "score: 0.035986\n",
      "iteration 421\n",
      "step: 0.04 seconds\n",
      "score: 0.035942\n",
      "iteration 422\n",
      "step: 0.04 seconds\n",
      "score: 0.035918\n",
      "iteration 423\n",
      "step: 0.04 seconds\n",
      "score: 0.035911\n",
      "iteration 424\n",
      "step: 0.04 seconds\n",
      "score: 0.035947\n",
      "iteration 425\n",
      "step: 0.04 seconds\n",
      "score: 0.035958\n",
      "iteration 426\n",
      "step: 0.04 seconds\n",
      "score: 0.036026\n",
      "iteration 427\n",
      "step: 0.04 seconds\n",
      "score: 0.036149\n",
      "iteration 428\n",
      "step: 0.04 seconds\n",
      "score: 0.036073\n",
      "iteration 429\n",
      "step: 0.04 seconds\n",
      "score: 0.036202\n",
      "iteration 430\n",
      "step: 0.04 seconds\n",
      "score: 0.036287\n",
      "iteration 431\n",
      "step: 0.04 seconds\n",
      "score: 0.036229\n",
      "iteration 432\n",
      "step: 0.04 seconds\n",
      "score: 0.036204\n",
      "iteration 433\n",
      "step: 0.04 seconds\n",
      "score: 0.036272\n",
      "iteration 434\n",
      "step: 0.04 seconds\n",
      "score: 0.036285\n",
      "iteration 435\n",
      "step: 0.04 seconds\n",
      "score: 0.036337\n",
      "iteration 436\n",
      "step: 0.04 seconds\n",
      "score: 0.036356\n",
      "iteration 437\n",
      "step: 0.04 seconds\n",
      "score: 0.036434\n",
      "iteration 438\n",
      "step: 0.04 seconds\n",
      "score: 0.036292\n",
      "iteration 439\n",
      "step: 0.04 seconds\n",
      "score: 0.036625\n",
      "iteration 440\n",
      "step: 0.04 seconds\n",
      "score: 0.036824\n",
      "iteration 441\n",
      "step: 0.04 seconds\n",
      "score: 0.036987\n",
      "iteration 442\n",
      "step: 0.04 seconds\n",
      "score: 0.036997\n",
      "iteration 443\n",
      "step: 0.04 seconds\n",
      "score: 0.037149\n",
      "iteration 444\n",
      "step: 0.04 seconds\n",
      "score: 0.037426\n",
      "iteration 445\n",
      "step: 0.04 seconds\n",
      "score: 0.037585\n",
      "iteration 446\n",
      "step: 0.04 seconds\n",
      "score: 0.037792\n",
      "iteration 447\n",
      "step: 0.04 seconds\n",
      "score: 0.037904\n",
      "iteration 448\n",
      "step: 0.04 seconds\n",
      "score: 0.038201\n",
      "iteration 449\n",
      "step: 0.04 seconds\n",
      "score: 0.038455\n",
      "iteration 450\n",
      "step: 0.04 seconds\n",
      "score: 0.038658\n",
      "iteration 451\n",
      "step: 0.04 seconds\n",
      "score: 0.038929\n",
      "iteration 452\n",
      "step: 0.04 seconds\n",
      "score: 0.039023\n",
      "iteration 453\n",
      "step: 0.04 seconds\n",
      "score: 0.039221\n",
      "iteration 454\n",
      "step: 0.04 seconds\n",
      "score: 0.039432\n",
      "iteration 455\n",
      "step: 0.04 seconds\n",
      "score: 0.039636\n",
      "iteration 456\n",
      "step: 0.04 seconds\n",
      "score: 0.039894\n",
      "iteration 457\n",
      "step: 0.04 seconds\n",
      "score: 0.040098\n",
      "iteration 458\n",
      "step: 0.04 seconds\n",
      "score: 0.040279\n",
      "iteration 459\n",
      "step: 0.04 seconds\n",
      "score: 0.040548\n",
      "iteration 460\n",
      "step: 0.04 seconds\n",
      "score: 0.040784\n",
      "iteration 461\n",
      "step: 0.04 seconds\n",
      "score: 0.040981\n",
      "iteration 462\n",
      "step: 0.04 seconds\n",
      "score: 0.041263\n",
      "iteration 463\n",
      "step: 0.04 seconds\n",
      "score: 0.041369\n",
      "iteration 464\n",
      "step: 0.04 seconds\n",
      "score: 0.041630\n",
      "iteration 465\n",
      "step: 0.04 seconds\n",
      "score: 0.041759\n",
      "iteration 466\n",
      "step: 0.04 seconds\n",
      "score: 0.041928\n",
      "iteration 467\n",
      "step: 0.04 seconds\n",
      "score: 0.042055\n",
      "iteration 468\n",
      "step: 0.04 seconds\n",
      "score: 0.042221\n",
      "iteration 469\n",
      "step: 0.04 seconds\n",
      "score: 0.042481\n",
      "iteration 470\n",
      "step: 0.04 seconds\n",
      "score: 0.042552\n",
      "iteration 471\n",
      "step: 0.04 seconds\n",
      "score: 0.042642\n",
      "iteration 472\n",
      "step: 0.04 seconds\n",
      "score: 0.042754\n",
      "iteration 473\n",
      "step: 0.04 seconds\n",
      "score: 0.042879\n",
      "iteration 474\n",
      "step: 0.04 seconds\n",
      "score: 0.042925\n",
      "iteration 475\n",
      "step: 0.04 seconds\n",
      "score: 0.043026\n",
      "iteration 476\n",
      "step: 0.04 seconds\n",
      "score: 0.043103\n",
      "iteration 477\n",
      "step: 0.04 seconds\n",
      "score: 0.043180\n",
      "iteration 478\n",
      "step: 0.04 seconds\n",
      "score: 0.043307\n",
      "iteration 479\n",
      "step: 0.04 seconds\n",
      "score: 0.043408\n",
      "iteration 480\n",
      "step: 0.04 seconds\n",
      "score: 0.043545\n",
      "iteration 481\n",
      "step: 0.04 seconds\n",
      "score: 0.043715\n",
      "iteration 482\n",
      "step: 0.04 seconds\n",
      "score: 0.043729\n",
      "iteration 483\n",
      "step: 0.04 seconds\n",
      "score: 0.043830\n",
      "iteration 484\n",
      "step: 0.04 seconds\n",
      "score: 0.043870\n",
      "iteration 485\n",
      "step: 0.04 seconds\n",
      "score: 0.043943\n",
      "iteration 486\n",
      "step: 0.04 seconds\n",
      "score: 0.043950\n",
      "iteration 487\n",
      "step: 0.04 seconds\n",
      "score: 0.044042\n",
      "iteration 488\n",
      "step: 0.04 seconds\n",
      "score: 0.044037\n",
      "iteration 489\n",
      "step: 0.04 seconds\n",
      "score: 0.044108\n",
      "iteration 490\n",
      "step: 0.04 seconds\n",
      "score: 0.044082\n",
      "iteration 491\n",
      "step: 0.04 seconds\n",
      "score: 0.044156\n",
      "iteration 492\n",
      "step: 0.04 seconds\n",
      "score: 0.044182\n",
      "iteration 493\n",
      "step: 0.04 seconds\n",
      "score: 0.044274\n",
      "iteration 494\n",
      "step: 0.04 seconds\n",
      "score: 0.044348\n",
      "iteration 495\n",
      "step: 0.04 seconds\n",
      "score: 0.044451\n",
      "iteration 496\n",
      "step: 0.04 seconds\n",
      "score: 0.044608\n",
      "iteration 497\n",
      "step: 0.04 seconds\n",
      "score: 0.044610\n",
      "iteration 498\n",
      "step: 0.04 seconds\n",
      "score: 0.044678\n",
      "iteration 499\n",
      "step: 0.04 seconds\n",
      "score: 0.044658\n",
      "iteration 500\n",
      "step: 0.04 seconds\n",
      "score: 0.044701\n",
      "iteration 501\n",
      "step: 0.04 seconds\n",
      "score: 0.044828\n",
      "iteration 502\n",
      "step: 0.04 seconds\n",
      "score: 0.044842\n",
      "iteration 503\n",
      "step: 0.04 seconds\n",
      "score: 0.044864\n",
      "iteration 504\n",
      "step: 0.04 seconds\n",
      "score: 0.045010\n",
      "iteration 505\n",
      "step: 0.04 seconds\n",
      "score: 0.045034\n",
      "iteration 506\n",
      "step: 0.04 seconds\n",
      "score: 0.045079\n",
      "iteration 507\n",
      "step: 0.04 seconds\n",
      "score: 0.045062\n",
      "iteration 508\n",
      "step: 0.04 seconds\n",
      "score: 0.045072\n",
      "iteration 509\n",
      "step: 0.04 seconds\n",
      "score: 0.045108\n",
      "iteration 510\n",
      "step: 0.04 seconds\n",
      "score: 0.045143\n",
      "iteration 511\n",
      "step: 0.04 seconds\n",
      "score: 0.045212\n",
      "iteration 512\n",
      "step: 0.04 seconds\n",
      "score: 0.045321\n",
      "iteration 513\n",
      "step: 0.04 seconds\n",
      "score: 0.045351\n",
      "iteration 514\n",
      "step: 0.04 seconds\n",
      "score: 0.045372\n",
      "iteration 515\n",
      "step: 0.04 seconds\n",
      "score: 0.045406\n",
      "iteration 516\n",
      "step: 0.04 seconds\n",
      "score: 0.045442\n",
      "iteration 517\n",
      "step: 0.04 seconds\n",
      "score: 0.045442\n",
      "iteration 518\n",
      "step: 0.04 seconds\n",
      "score: 0.045476\n",
      "iteration 519\n",
      "step: 0.04 seconds\n",
      "score: 0.045408\n",
      "iteration 520\n",
      "step: 0.04 seconds\n",
      "score: 0.045435\n",
      "iteration 521\n",
      "step: 0.04 seconds\n",
      "score: 0.045425\n",
      "iteration 522\n",
      "step: 0.04 seconds\n",
      "score: 0.045446\n",
      "iteration 523\n",
      "step: 0.04 seconds\n",
      "score: 0.045504\n",
      "iteration 524\n",
      "step: 0.04 seconds\n",
      "score: 0.045463\n",
      "iteration 525\n",
      "step: 0.04 seconds\n",
      "score: 0.045468\n",
      "iteration 526\n",
      "step: 0.04 seconds\n",
      "score: 0.045457\n",
      "iteration 527\n",
      "step: 0.04 seconds\n",
      "score: 0.045523\n",
      "iteration 528\n",
      "step: 0.04 seconds\n",
      "score: 0.045512\n",
      "iteration 529\n",
      "step: 0.04 seconds\n",
      "score: 0.045479\n",
      "iteration 530\n",
      "step: 0.04 seconds\n",
      "score: 0.045475\n",
      "iteration 531\n",
      "step: 0.04 seconds\n",
      "score: 0.045471\n",
      "iteration 532\n",
      "step: 0.04 seconds\n",
      "score: 0.045470\n",
      "iteration 533\n",
      "step: 0.04 seconds\n",
      "score: 0.045478\n",
      "iteration 534\n",
      "step: 0.04 seconds\n",
      "score: 0.045498\n",
      "iteration 535\n",
      "step: 0.04 seconds\n",
      "score: 0.045520\n",
      "iteration 536\n",
      "step: 0.04 seconds\n",
      "score: 0.045580\n",
      "iteration 537\n",
      "step: 0.04 seconds\n",
      "score: 0.045612\n",
      "iteration 538\n",
      "step: 0.04 seconds\n",
      "score: 0.045578\n",
      "iteration 539\n",
      "step: 0.04 seconds\n",
      "score: 0.045591\n",
      "iteration 540\n",
      "step: 0.04 seconds\n",
      "score: 0.045642\n",
      "iteration 541\n",
      "step: 0.04 seconds\n",
      "score: 0.045651\n",
      "iteration 542\n",
      "step: 0.04 seconds\n",
      "score: 0.045712\n",
      "iteration 543\n",
      "step: 0.04 seconds\n",
      "score: 0.045694\n",
      "iteration 544\n",
      "step: 0.04 seconds\n",
      "score: 0.045704\n",
      "iteration 545\n",
      "step: 0.04 seconds\n",
      "score: 0.045661\n",
      "iteration 546\n",
      "step: 0.04 seconds\n",
      "score: 0.045665\n",
      "iteration 547\n",
      "step: 0.04 seconds\n",
      "score: 0.045774\n",
      "iteration 548\n",
      "step: 0.04 seconds\n",
      "score: 0.045722\n",
      "iteration 549\n",
      "step: 0.04 seconds\n",
      "score: 0.045739\n",
      "iteration 550\n",
      "step: 0.04 seconds\n",
      "score: 0.045666\n",
      "iteration 551\n",
      "step: 0.04 seconds\n",
      "score: 0.045675\n",
      "iteration 552\n",
      "step: 0.04 seconds\n",
      "score: 0.045655\n",
      "iteration 553\n",
      "step: 0.04 seconds\n",
      "score: 0.045683\n",
      "iteration 554\n",
      "step: 0.04 seconds\n",
      "score: 0.045670\n",
      "iteration 555\n",
      "step: 0.04 seconds\n",
      "score: 0.045649\n",
      "iteration 556\n",
      "step: 0.04 seconds\n",
      "score: 0.045632\n",
      "iteration 557\n",
      "step: 0.04 seconds\n",
      "score: 0.045651\n",
      "iteration 558\n",
      "step: 0.04 seconds\n",
      "score: 0.045582\n",
      "iteration 559\n",
      "step: 0.04 seconds\n",
      "score: 0.045646\n",
      "iteration 560\n",
      "step: 0.04 seconds\n",
      "score: 0.045637\n",
      "iteration 561\n",
      "step: 0.04 seconds\n",
      "score: 0.045623\n",
      "iteration 562\n",
      "step: 0.04 seconds\n",
      "score: 0.045660\n",
      "iteration 563\n",
      "step: 0.04 seconds\n",
      "score: 0.045651\n",
      "iteration 564\n",
      "step: 0.04 seconds\n",
      "score: 0.045651\n",
      "iteration 565\n",
      "step: 0.04 seconds\n",
      "score: 0.045671\n",
      "iteration 566\n",
      "step: 0.04 seconds\n",
      "score: 0.045667\n",
      "iteration 567\n",
      "step: 0.04 seconds\n",
      "score: 0.045758\n",
      "iteration 568\n",
      "step: 0.04 seconds\n",
      "score: 0.045829\n",
      "iteration 569\n",
      "step: 0.04 seconds\n",
      "score: 0.045745\n",
      "iteration 570\n",
      "step: 0.04 seconds\n",
      "score: 0.045793\n",
      "iteration 571\n",
      "step: 0.04 seconds\n",
      "score: 0.045790\n",
      "iteration 572\n",
      "step: 0.04 seconds\n",
      "score: 0.045766\n",
      "iteration 573\n",
      "step: 0.04 seconds\n",
      "score: 0.045777\n",
      "iteration 574\n",
      "step: 0.04 seconds\n",
      "score: 0.045791\n",
      "iteration 575\n",
      "step: 0.04 seconds\n",
      "score: 0.045827\n",
      "iteration 576\n",
      "step: 0.04 seconds\n",
      "score: 0.045800\n",
      "iteration 577\n",
      "step: 0.04 seconds\n",
      "score: 0.045863\n",
      "iteration 578\n",
      "step: 0.04 seconds\n",
      "score: 0.045848\n",
      "iteration 579\n",
      "step: 0.04 seconds\n",
      "score: 0.045886\n",
      "iteration 580\n",
      "step: 0.04 seconds\n",
      "score: 0.045834\n",
      "iteration 581\n",
      "step: 0.04 seconds\n",
      "score: 0.045839\n",
      "iteration 582\n",
      "step: 0.04 seconds\n",
      "score: 0.045899\n",
      "iteration 583\n",
      "step: 0.04 seconds\n",
      "score: 0.045851\n",
      "iteration 584\n",
      "step: 0.04 seconds\n",
      "score: 0.045832\n",
      "iteration 585\n",
      "step: 0.04 seconds\n",
      "score: 0.045841\n",
      "iteration 586\n",
      "step: 0.04 seconds\n",
      "score: 0.045816\n",
      "iteration 587\n",
      "step: 0.04 seconds\n",
      "score: 0.045844\n",
      "iteration 588\n",
      "step: 0.04 seconds\n",
      "score: 0.045866\n",
      "iteration 589\n",
      "step: 0.04 seconds\n",
      "score: 0.045934\n",
      "iteration 590\n",
      "step: 0.04 seconds\n",
      "score: 0.045891\n",
      "iteration 591\n",
      "step: 0.04 seconds\n",
      "score: 0.045812\n",
      "iteration 592\n",
      "step: 0.04 seconds\n",
      "score: 0.045874\n",
      "iteration 593\n",
      "step: 0.04 seconds\n",
      "score: 0.045901\n",
      "iteration 594\n",
      "step: 0.04 seconds\n",
      "score: 0.045864\n",
      "iteration 595\n",
      "step: 0.04 seconds\n",
      "score: 0.045824\n",
      "iteration 596\n",
      "step: 0.04 seconds\n",
      "score: 0.045738\n",
      "iteration 597\n",
      "step: 0.04 seconds\n",
      "score: 0.045838\n",
      "iteration 598\n",
      "step: 0.04 seconds\n",
      "score: 0.045858\n",
      "iteration 599\n",
      "step: 0.04 seconds\n",
      "score: 0.045829\n",
      "iteration 600\n",
      "step: 0.04 seconds\n",
      "score: 0.045699\n",
      "iteration 601\n",
      "step: 0.04 seconds\n",
      "score: 0.045728\n",
      "iteration 602\n",
      "step: 0.04 seconds\n",
      "score: 0.045747\n",
      "iteration 603\n",
      "step: 0.04 seconds\n",
      "score: 0.045704\n",
      "iteration 604\n",
      "step: 0.04 seconds\n",
      "score: 0.045717\n",
      "iteration 605\n",
      "step: 0.04 seconds\n",
      "score: 0.045623\n",
      "iteration 606\n",
      "step: 0.04 seconds\n",
      "score: 0.045566\n",
      "iteration 607\n",
      "step: 0.04 seconds\n",
      "score: 0.045606\n",
      "iteration 608\n",
      "step: 0.04 seconds\n",
      "score: 0.045584\n",
      "iteration 609\n",
      "step: 0.04 seconds\n",
      "score: 0.045497\n",
      "iteration 610\n",
      "step: 0.04 seconds\n",
      "score: 0.045574\n",
      "iteration 611\n",
      "step: 0.04 seconds\n",
      "score: 0.045633\n",
      "iteration 612\n",
      "step: 0.04 seconds\n",
      "score: 0.045521\n",
      "iteration 613\n",
      "step: 0.04 seconds\n",
      "score: 0.045432\n",
      "iteration 614\n",
      "step: 0.04 seconds\n",
      "score: 0.045491\n",
      "iteration 615\n",
      "step: 0.04 seconds\n",
      "score: 0.045462\n",
      "iteration 616\n",
      "step: 0.04 seconds\n",
      "score: 0.045487\n",
      "iteration 617\n",
      "step: 0.04 seconds\n",
      "score: 0.045491\n",
      "iteration 618\n",
      "step: 0.04 seconds\n",
      "score: 0.045548\n",
      "iteration 619\n",
      "step: 0.04 seconds\n",
      "score: 0.045529\n",
      "iteration 620\n",
      "step: 0.04 seconds\n",
      "score: 0.045470\n",
      "iteration 621\n",
      "step: 0.04 seconds\n",
      "score: 0.045498\n",
      "iteration 622\n",
      "step: 0.04 seconds\n",
      "score: 0.045524\n",
      "iteration 623\n",
      "step: 0.04 seconds\n",
      "score: 0.045554\n",
      "iteration 624\n",
      "step: 0.04 seconds\n",
      "score: 0.045529\n",
      "iteration 625\n",
      "step: 0.04 seconds\n",
      "score: 0.045465\n",
      "iteration 626\n",
      "step: 0.04 seconds\n",
      "score: 0.045560\n",
      "iteration 627\n",
      "step: 0.04 seconds\n",
      "score: 0.045645\n",
      "iteration 628\n",
      "step: 0.04 seconds\n",
      "score: 0.045635\n",
      "iteration 629\n",
      "step: 0.04 seconds\n",
      "score: 0.045698\n",
      "iteration 630\n",
      "step: 0.04 seconds\n",
      "score: 0.045752\n",
      "54.55 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  8.15610273e-01   2.34106884e-01  -5.29125551e-01   3.79011798e+01]\n",
      " [ -1.82392364e-01   9.71891868e-01   1.48859737e-01   2.21175994e+01]\n",
      " [  5.49101910e-01  -2.49030707e-02   8.35384301e-01   7.11236279e+01]]\n",
      "0.0459344127545 0.0457523840521\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAFkCAYAAACAUFlOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b336c05a190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for name_s in structures_sided:\n",
    "for name_s in ['DC_L']:\n",
    "# for name_s in ['IC']:\n",
    "    \n",
    "    print name_s\n",
    "\n",
    "#     try:\n",
    "        \n",
    "    if local_transform_scheme == 1 or local_transform_scheme == 2:\n",
    "    \n",
    "        aligner = Aligner4(volume_fixed, {name_to_label_moving[name_s]: \n",
    "                                          volume_moving[name_to_label_moving[name_s]]}, \\\n",
    "                           labelIndexMap_m2f={name_to_label_moving[name_s]:\n",
    "                                              name_to_label_fixed[convert_name_to_unsided(name_s)]})\n",
    "\n",
    "    elif local_transform_scheme == 3 or local_transform_scheme == 4:\n",
    "                \n",
    "        aligner = Aligner4(volume_fixed, {name_to_label_moving[name_s]: volume_moving[name_to_label_moving[name_s]],\n",
    "                                         name_to_label_moving[name_s+'_surround']: volume_moving[name_to_label_moving[name_s+'_surround']]}, \\\n",
    "                        labelIndexMap_m2f={name_to_label_moving[name_s]: name_to_label_fixed[convert_name_to_unsided(name_s)],\n",
    "                                          name_to_label_moving[name_s+'_surround']: name_to_label_fixed[convert_to_original_name(name_s+'_surround')]})\n",
    "\n",
    "    # aligner.set_centroid(centroid_m='volume_centroid', centroid_f='volume_centroid')\n",
    "    aligner.set_centroid(centroid_m='structure_centroid', centroid_f='centroid_m', \n",
    "                         indices_m=[name_to_label_moving[name_s]])\n",
    "\n",
    "    gradient_filepath_map_f = {ind_f: VOLUME_ROOTDIR + '/%(stack)s/score_volume_gradients/%(stack)s_down32_scoreVolume_%(label)s_trainSampleScheme_%(scheme)d_%%(suffix)s.bp' % \\\n",
    "                           {'stack': stack_fixed, 'label': label_to_name_fixed[ind_f], 'scheme':train_sample_scheme}\n",
    "                           for ind_m, ind_f in labelIndexMap_m2f.iteritems()}\n",
    "\n",
    "    aligner.load_gradient(gradient_filepath_map_f=gradient_filepath_map_f, indices_f=None)\n",
    "\n",
    "    t = time.time()\n",
    "    \n",
    "    # SC + SC_surround\n",
    "    # grid_search_sample_number = 100, 6.2s (first iter) x 10 iters (exp. diminishing) ~ 20s\n",
    "    # grid_search_sample_number = 1000, 40s (first iter) x 10 iters ~ 143s\n",
    "    # grid_search_sample_number = 10000, 380s (first iter) x 10 iters ~ 1315s\n",
    "    \n",
    "    # IC + IC_surround\n",
    "    # grid_search_sample_number = 100, 4s (first iter)\n",
    "    # grid_search_sample_number = 1000, 27s (first iter)\n",
    "    # grid_search_sample_number = 10000, 215s (first iter)\n",
    "    T, scores = aligner.optimize(type='rigid', max_iter_num=1000, history_len=50, terminate_thresh=1e-5,\n",
    "                                 indices_m=None,\n",
    "                                grid_search_iteration_number=20,\n",
    "                                 grid_search_sample_number=10000,\n",
    "                                 grad_computation_sample_number=1e5,\n",
    "                                 lr1=10, lr2=0.1,\n",
    "                                label_weights=label_weights_m,\n",
    "                                std_tx=50, std_ty=50, std_tz=100, std_theta_xy=np.deg2rad(10),\n",
    "                                reg_weights=reg_weights,\n",
    "                                epsilon=1e-8)\n",
    "\n",
    "    sys.stderr.write('%.2f seconds\\n' % (time.time() - t))\n",
    "\n",
    "    print T.reshape((3,4))\n",
    "    plt.plot(scores);\n",
    "    print max(scores), scores[-1]\n",
    "\n",
    "    ########################################################\n",
    "\n",
    "#     params_fp = DataManager.get_local_alignment_parameters_filepath(stack_moving=stack_moving,\n",
    "#                                                                 moving_volume_type='score',\n",
    "#                                                                 stack_fixed=stack_fixed,\n",
    "#                                                                 fixed_volume_type='score',\n",
    "#                                                                 train_sample_scheme=train_sample_scheme,\n",
    "#                                                                 global_transform_scheme=global_transform_scheme,\n",
    "#                                                                 local_transform_scheme=local_transform_scheme,\n",
    "#                                                                label=name_s)\n",
    "\n",
    "#     DataManager.save_alignment_parameters(params_fp, \n",
    "#                                           T, aligner.centroid_m, aligner.centroid_f, \n",
    "#                                           aligner.xdim_m, aligner.ydim_m, aligner.zdim_m, \n",
    "#                                           aligner.xdim_f, aligner.ydim_f, aligner.zdim_f)\n",
    "\n",
    "\n",
    "#     score_plot_fp = DataManager.get_local_alignment_score_plot_filepath(stack_moving=stack_moving,\n",
    "#                                                                     moving_volume_type='score',\n",
    "#                                                                     stack_fixed=stack_fixed,\n",
    "#                                                                     fixed_volume_type='score',\n",
    "#                                                                     train_sample_scheme=train_sample_scheme,\n",
    "#                                                                     global_transform_scheme=global_transform_scheme,\n",
    "#                                                                     local_transform_scheme=local_transform_scheme,\n",
    "#                                                                    label=name_s)\n",
    "#     fig = plt.figure();\n",
    "#     plt.plot(scores);\n",
    "#     plt.savefig(score_plot_fp, bbox_inches='tight')\n",
    "#     plt.close(fig)\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         sys.stderr.write(e.message + '\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.018310122280167596"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aligner.compute_score(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from registration_utilities import transform_volume, transform_points, find_contour_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "volumes_annotation = {'MD594': bp.unpack_ndarray_file(DataManager.get_transformed_volume_filepath(stack_m='MD594', type_m='annotation',\n",
    "                                                stack_f=stack_fixed, type_f='score',\n",
    "                                                downscale=32, train_sample_scheme_f=1)),\n",
    "                      \n",
    "                      'MD589': bp.unpack_ndarray_file(DataManager.get_transformed_volume_filepath(stack_m='MD589', type_m='annotation',\n",
    "                                                stack_f=stack_fixed, type_f='score',\n",
    "                                                downscale=32, train_sample_scheme_f=1))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "name_to_label_annotation = DataManager.load_annotation_volume_nameToLabel('MD589', downscale=32)\n",
    "label_to_name_annotation = {l: n for n, l in name_to_label_annotation.iteritems()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack_colors = {'MD589': (255,0,0), 'MD594': (0,255,0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "structure_colors = {s: np.random.randint(0,255,3) for s in structures}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "first_sec, last_sec = metadata_cache['section_limits'][stack_fixed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 547 0 407 110 467\n"
     ]
    }
   ],
   "source": [
    "xmin_vol_f, xmax_vol_f, ymin_vol_f, ymax_vol_f, zmin_vol_f, zmax_vol_f = np.loadtxt('/home/yuncong/csd395/CSHL_volumes2/%(stack_fixed)s/score_volumes/%(stack_fixed)s_down32_scoreVolume_7N_bbox.txt' %\\\n",
    "          dict(stack_fixed=stack_fixed)).astype(np.int)\n",
    "print xmin_vol_f, xmax_vol_f, ymin_vol_f, ymax_vol_f, zmin_vol_f, zmax_vol_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "downsample_factor = 32\n",
    "xy_pixel_distance_downsampled = xy_pixel_distance_lossless * downsample_factor\n",
    "voxel_z_size = section_thickness / xy_pixel_distance_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "viz_dir = create_if_not_exists(DataManager.get_local_alignment_viz_dir(stack_moving=stack_moving,\n",
    "                                                        stack_fixed=stack_fixed,\n",
    "                                                        moving_volume_type='score',\n",
    "                                                        fixed_volume_type='score',\n",
    "                                                        train_sample_scheme=train_sample_scheme,\n",
    "                                                        global_transform_scheme=global_transform_scheme,\n",
    "                                                        local_transform_scheme=local_transform_scheme))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tx_params, centroid_m, centroid_f, xdim_m, ydim_m, zdim_m, xdim_f, ydim_f, zdim_f = \\\n",
    "#     DataManager.load_local_alignment_parameters(stack_moving=stack_moving,\n",
    "#                                                 moving_volume_type='score',\n",
    "#                                                 stack_fixed=stack_fixed,\n",
    "#                                                 fixed_volume_type='score',\n",
    "#                                                 train_sample_scheme=train_sample_scheme,\n",
    "#                                                 global_transform_scheme=global_transform_scheme,\n",
    "#                                                 local_transform_scheme=local_transform_scheme,\n",
    "#                                                label='5N_R')\n",
    "\n",
    "# annotation_volumes_volume_m_aligned_to_f = {}\n",
    "# for stack, volume_annotation in volumes_annotation.iteritems():\n",
    "#     annotation_volumes_volume_m_aligned_to_f[stack] = transform_volume(\\\n",
    "#                                            vol=volume_annotation==name_to_label_annotation['5N_R'], \n",
    "#                                                                        global_params=tx_params, \n",
    "#                                                                        centroid_m=centroid_m, \n",
    "#                                                                        centroid_f=centroid_f,\n",
    "#                                                                       xdim_f=xdim_f,\n",
    "#                                                                       ydim_f=ydim_f,\n",
    "#                                                                       zdim_f=zdim_f).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# bar = show_progress_bar(first_sec, last_sec)\n",
    "\n",
    "# for sec in range(first_sec, last_sec+1):\n",
    "\n",
    "#     if metadata_cache['sections_to_filenames'][stack_fixed][sec] in ['Placeholder', 'Rescan', 'Nonexisting']:\n",
    "#         continue\n",
    "\n",
    "#     bar.value = sec\n",
    "\n",
    "#     img_fn = DataManager.get_image_filepath(stack=stack_fixed, section=sec, resol='thumbnail', version='cropped_tif')\n",
    "#     img = imread(img_fn)\n",
    "\n",
    "# #         img_fn = DataManager.get_scoremap_viz_filepath(stack=stack_fixed, section=sec, label='7N', train_sample_scheme=train_sample_scheme)\n",
    "# #         img = imread(img_fn)[::4, ::4]\n",
    "\n",
    "#     viz = img.copy()\n",
    "\n",
    "#     z = voxel_z_size * (sec - 1) - zmin_vol_f\n",
    "\n",
    "#     # Find fixed volume annotation contours\n",
    "# #     contours_f_on_volume = find_contour_points(volume_fixed[..., int(z)])\n",
    "# #     contours_f_on_cropped = {i: [cnt + (xmin_vol_f, ymin_vol_f) for cnt in cnts] for i, cnts in contours_f_on_volume.iteritems()}\n",
    "\n",
    "#     # Find moving volume annotation contours\n",
    "\n",
    "#     for stack, volume_m_aligned_to_f in annotation_volumes_volume_m_aligned_to_f.iteritems():\n",
    "\n",
    "#         contours_m_alignedTo_f_on_volume = find_contour_points(volume_m_aligned_to_f[..., int(z)])\n",
    "#         contours_m_alignedTo_f_on_cropped = {i: [cnt + (xmin_vol_f, ymin_vol_f) for cnt in cnts] \n",
    "#                                              for i, cnts in contours_m_alignedTo_f_on_volume.iteritems()}\n",
    "\n",
    "#     #     # Draw fixed volume annotation contours\n",
    "#     #     for ind_f, cnts_f in contours_f_on_cropped.iteritems():\n",
    "#     #         for cnt_f in cnts_f:\n",
    "#     #             cv2.polylines(viz, [cnt_f.astype(np.int)], True, (0,255,0), 2)\n",
    "\n",
    "#         # Draw moving volume annotation contours\n",
    "#         for ind_m, cnts_m in contours_m_alignedTo_f_on_cropped.iteritems():\n",
    "#             for cnt_m in cnts_m:\n",
    "#                 cv2.polylines(viz, [cnt_m.astype(np.int)], True, stack_colors[stack], 2)\n",
    "\n",
    "#     viz_fn = os.path.join(viz_dir, '%(stack_moving)s_over_%(stack_fixed)s_%(sec)04d.jpg' % \\\n",
    "#           {'stack_moving': stack_moving, 'stack_fixed': stack_fixed, 'sec': sec})\n",
    "#     imsave(viz_fn, viz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# POLYRIGID TRANSFORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "annotation_structure_sizes = {s: len(parallel_where_binary(volume_annotation == name_to_label_annotation[s])) \n",
    "                              for s in structures_sided}\n",
    "annotation_structure_sizes_precent = {s: float(size)/sum(annotation_structure_sizes.values()) \n",
    "                                      for s, size in annotation_structure_sizes.iteritems()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "annotation_structure_radius = {}\n",
    "# annotation_structure_axes = {}\n",
    "annotation_structure_covars = {}\n",
    "for s in structures_sided:\n",
    "    nzs = parallel_where_binary(volume_annotation == name_to_label_annotation[s])\n",
    "    nzsc = nzs - nzs.mean(axis=0)\n",
    "    C = np.dot(nzsc.T, nzsc)/float(len(nzsc))\n",
    "    S, V = np.linalg.eigh(C)\n",
    "#     annotation_structure_axes[s] = V\n",
    "    annotation_structure_radius[s] = np.sqrt(S)\n",
    "    annotation_structure_covars[s] = C\n",
    "#     alpha = 1.\n",
    "#     scaled_C = np.dot(np.dot(V.T, alpha*S), V)\n",
    "#     annotation_structure_covars[s] = scaled_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read Transform of each structure, do polyrigid transform\n",
    "\n",
    "volume_m_aligned_to_f_allAnnotatedBrains = {}\n",
    "\n",
    "stack = 'MD589'\n",
    "volume_annotation = volumes_annotation[stack]\n",
    "\n",
    "# for stack, volume_annotation in volumes_annotation.iteritems():\n",
    "\n",
    "rigid_parameters_list = []\n",
    "anchor_points = []\n",
    "# sigmas = [1. for _ in structures_sided]\n",
    "\n",
    "alpha = 1.\n",
    "sigmas = [alpha * annotation_structure_covars[s] for s in structures_sided]\n",
    "\n",
    "# weights = [1. for s in structures_sided]\n",
    "weights = [annotation_structure_sizes_precent[s] for s in structures_sided]\n",
    "\n",
    "for name_s in structures_sided:\n",
    "# for name_s in ['VLL_L']:\n",
    "\n",
    "    try:\n",
    "        tx_params, centroid_m, centroid_f, xdim_m, ydim_m, zdim_m, xdim_f, ydim_f, zdim_f = \\\n",
    "        DataManager.load_local_alignment_parameters(stack_moving=stack_moving,\n",
    "                                                    moving_volume_type='score',\n",
    "                                                    stack_fixed=stack_fixed,\n",
    "                                                    fixed_volume_type='score',\n",
    "                                                    train_sample_scheme=train_sample_scheme,\n",
    "                                                    global_transform_scheme=global_transform_scheme,\n",
    "                                                    local_transform_scheme=local_transform_scheme,\n",
    "                                                   label=name_s,\n",
    "                                                   trial_idx=1)\n",
    "\n",
    "        rigid_parameters_list.append((tx_params, centroid_m, centroid_f, xdim_m, ydim_m, zdim_m, xdim_f, ydim_f, zdim_f))\n",
    "        anchor_points.append(centroid_m)\n",
    "    except:\n",
    "        sys.stderr.write('Cannot load parameters for %s.\\n' % name_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "volume_m_aligned_to_f_allAnnotatedBrains[stack] = transform_volume_polyrigid(volume_annotation, \n",
    "                                                                             rigid_parameters_list, \n",
    "                                                                             anchor_points, sigmas, \n",
    "                                                                             weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "viz_dir = create_if_not_exists(DataManager.get_local_alignment_viz_dir(stack_moving=stack_moving,\n",
    "                                                        stack_fixed=stack_fixed,\n",
    "                                                        moving_volume_type='score',\n",
    "                                                        fixed_volume_type='score',\n",
    "                                                        train_sample_scheme=train_sample_scheme,\n",
    "                                                        global_transform_scheme=global_transform_scheme,\n",
    "                                                        local_transform_scheme=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/oasis/projects/nsf/csd395/yuncong/brain_virtualenv/lib/python2.7/site-packages/skimage/external/tifffile/tifffile.py:1794: RuntimeWarning: py_decodelzw encountered unexpected end of stream\n",
      "  strip = decompress(strip)\n"
     ]
    }
   ],
   "source": [
    "bar = show_progress_bar(first_sec, last_sec)\n",
    "\n",
    "for sec in range(first_sec, last_sec+1):\n",
    "# for sec in range(140, 160):\n",
    "    \n",
    "    if metadata_cache['sections_to_filenames'][stack_fixed][sec] in ['Placeholder', 'Rescan', 'Nonexisting']:\n",
    "            continue\n",
    "\n",
    "    bar.value = sec\n",
    "\n",
    "    img_fn = DataManager.get_image_filepath(stack=stack_fixed, section=sec, resol='thumbnail', version='cropped_tif')\n",
    "    img = imread(img_fn)\n",
    "\n",
    "#         img_fn = DataManager.get_scoremap_viz_filepath(stack=stack_fixed, section=sec, label='7N', train_sample_scheme=train_sample_scheme)\n",
    "#         img = imread(img_fn)[::4, ::4]\n",
    "\n",
    "    viz = img.copy()\n",
    "\n",
    "    z = voxel_z_size * (sec - 1) - zmin_vol_f\n",
    "    \n",
    "    ##############################################\n",
    "    \n",
    "#     for stack, volume_m_aligned_to_f in volume_m_aligned_to_f_allAnnotatedBrains.iteritems():\n",
    "\n",
    "    stack = 'MD589'\n",
    "    volume_m_aligned_to_f = volume_m_aligned_to_f_allAnnotatedBrains[stack]\n",
    "            \n",
    "    contours_m_alignedTo_f_on_volume = find_contour_points(volume_m_aligned_to_f[..., int(z)])\n",
    "    contours_m_alignedTo_f_on_cropped = {i: [cnt + (xmin_vol_f, ymin_vol_f) for cnt in cnts] \n",
    "                                         for i, cnts in contours_m_alignedTo_f_on_volume.iteritems()}\n",
    "\n",
    "#     # Draw fixed volume annotation contours\n",
    "#     for ind_f, cnts_f in contours_f_on_cropped.iteritems():\n",
    "#         for cnt_f in cnts_f:\n",
    "#             cv2.polylines(viz, [cnt_f.astype(np.int)], True, (0,255,0), 2)\n",
    "\n",
    "    # Draw moving volume annotation contours\n",
    "    for ind_m, cnts_m in contours_m_alignedTo_f_on_cropped.iteritems():\n",
    "        for cnt_m in cnts_m:\n",
    "#             cv2.polylines(viz, [cnt_m.astype(np.int)], True, stack_colors[stack], 2)\n",
    "            cv2.polylines(viz, [cnt_m.astype(np.int)], True, structure_colors[convert_name_to_unsided(label_to_name_moving[ind_m])], 1)\n",
    "\n",
    "            # put label texts\n",
    "#             label_pos = cnt_m.mean(axis=0).astype(np.int)\n",
    "#             cv2.putText(viz, convert_name_to_unsided(name_s), tuple(label_pos), \n",
    "#                         cv2.FONT_HERSHEY_DUPLEX, .5, ((0,0,0)), 1)\n",
    "\n",
    "    viz_fn = os.path.join(viz_dir, '%(stack_moving)s_over_%(stack_fixed)s_%(sec)04d.jpg' % \\\n",
    "          {'stack_moving': stack_moving, 'stack_fixed': stack_fixed, 'sec': sec})\n",
    "    imsave(viz_fn, viz)\n",
    "\n",
    "#     plt.figure(figsize=(10, 10));\n",
    "#     plt.imshow(viz);\n",
    "#     plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TRANSFORM VOLUMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5N_L\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/oasis/projects/nsf/csd395/yuncong/brain_virtualenv/lib/python2.7/site-packages/ipykernel/__main__.py:22: DeprecationWarning: BaseException.message has been deprecated as of Python 2.6\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5N_R\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6N_L\n",
      "6N_R\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7N_L\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7N_R\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7n_L\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7n_R\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amb_L\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amb_R\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LC_L\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LC_R\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LRt_L\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LRt_R\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-0d23438d4cde>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m                           \u001b[0mxdim_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxdim_f\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                           \u001b[0mydim_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mydim_f\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                           zdim_f=zdim_f)\n\u001b[0m",
      "\u001b[0;32m/oasis/projects/nsf/csd395/yuncong/Brain/utilities/registration_utilities.py\u001b[0m in \u001b[0;36mtransform_volume\u001b[0;34m(vol, global_params, centroid_m, centroid_f, xdim_f, ydim_f, zdim_f)\u001b[0m\n\u001b[1;32m   2728\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtransform_volume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcentroid_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcentroid_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxdim_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mydim_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzdim_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2730\u001b[0;31m     \u001b[0mnzvoxels_m_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparallel_where_binary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvol\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2731\u001b[0m     \u001b[0;31m# \"_temp\" is appended to avoid name conflict with module level variable defined in registration.py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2732\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/oasis/projects/nsf/csd395/yuncong/Brain/utilities/registration_utilities.py\u001b[0m in \u001b[0;36mparallel_where_binary\u001b[0;34m(binary_volume, num_samples)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mparallel_where_binary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbinary_volume\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbinary_volume\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnum_samples\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Transforming each volume (only relevant structure is activated) according to computed local transforms\n",
    "\n",
    "volume_m_aligned_to_f_allNames = {'MD589': {}, 'MD594': {}}\n",
    "\n",
    "for name_s in structures_sided:\n",
    "# for name_s in ['VLL_L']:\n",
    "        \n",
    "    print name_s\n",
    "\n",
    "    try:\n",
    "        tx_params, centroid_m, centroid_f, xdim_m, ydim_m, zdim_m, xdim_f, ydim_f, zdim_f = \\\n",
    "        DataManager.load_local_alignment_parameters(stack_moving=stack_moving,\n",
    "                                                    moving_volume_type='score',\n",
    "                                                    stack_fixed=stack_fixed,\n",
    "                                                    fixed_volume_type='score',\n",
    "                                                    train_sample_scheme=train_sample_scheme,\n",
    "                                                    global_transform_scheme=global_transform_scheme,\n",
    "                                                    local_transform_scheme=local_transform_scheme,\n",
    "                                                   label=name_s)\n",
    "\n",
    "    except Exception as e:\n",
    "        \n",
    "        sys.stderr.write(e.message + '\\n')\n",
    "        \n",
    "        tx_params = (1,0,0,0,0,1,0,0,0,0,1,0)\n",
    "        centroid_m = (0,0,0)\n",
    "        centroid_f = (0,0,0)\n",
    "        xdim_f, ydim_f, zdim_f = (vol_fixed_xdim, vol_fixed_ydim, vol_fixed_zdim)\n",
    "\n",
    "\n",
    "    for stack, volume_annotation in volumes_annotation.iteritems():\n",
    "        volume_m_aligned_to_f_allNames[stack][name_s] = \\\n",
    "        transform_volume(vol=volume_annotation==name_to_label_annotation[name_s], \n",
    "                           global_params=tx_params, \n",
    "                           centroid_m=centroid_m, \n",
    "                           centroid_f=centroid_f,\n",
    "                          xdim_f=xdim_f,\n",
    "                          ydim_f=ydim_f,\n",
    "                          zdim_f=zdim_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bar = show_progress_bar(first_sec, last_sec)\n",
    "\n",
    "# for sec in range(first_sec, last_sec+1):\n",
    "for sec in range(140, 160):\n",
    "    \n",
    "    if metadata_cache['sections_to_filenames'][stack_fixed][sec] in ['Placeholder', 'Rescan', 'Nonexisting']:\n",
    "            continue\n",
    "\n",
    "    bar.value = sec\n",
    "\n",
    "    img_fn = DataManager.get_image_filepath(stack=stack_fixed, section=sec, resol='thumbnail', version='cropped_tif')\n",
    "    img = imread(img_fn)\n",
    "\n",
    "#         img_fn = DataManager.get_scoremap_viz_filepath(stack=stack_fixed, section=sec, label='7N', train_sample_scheme=train_sample_scheme)\n",
    "#         img = imread(img_fn)[::4, ::4]\n",
    "\n",
    "    viz = img.copy()\n",
    "\n",
    "    z = voxel_z_size * (sec - 1) - zmin_vol_f\n",
    "    \n",
    "    ##############################################\n",
    "    \n",
    "    for stack, x in volume_m_aligned_to_f_allNames.iteritems():\n",
    "        for name_s, volume_m_aligned_to_f in x.iteritems():\n",
    "        \n",
    "            contours_m_alignedTo_f_on_volume = find_contour_points(volume_m_aligned_to_f[..., int(z)])\n",
    "            contours_m_alignedTo_f_on_cropped = {i: [cnt + (xmin_vol_f, ymin_vol_f) for cnt in cnts] \n",
    "                                                 for i, cnts in contours_m_alignedTo_f_on_volume.iteritems()}\n",
    "\n",
    "        #     # Draw fixed volume annotation contours\n",
    "        #     for ind_f, cnts_f in contours_f_on_cropped.iteritems():\n",
    "        #         for cnt_f in cnts_f:\n",
    "        #             cv2.polylines(viz, [cnt_f.astype(np.int)], True, (0,255,0), 2)\n",
    "\n",
    "            # Draw moving volume annotation contours\n",
    "            for ind_m, cnts_m in contours_m_alignedTo_f_on_cropped.iteritems():\n",
    "                for cnt_m in cnts_m:\n",
    "                    cv2.polylines(viz, [cnt_m.astype(np.int)], True, stack_colors[stack], 2)\n",
    "                    \n",
    "                    # put label texts\n",
    "                    label_pos = cnt_m.mean(axis=0).astype(np.int)\n",
    "                    cv2.putText(viz, convert_name_to_unsided(name_s), tuple(label_pos), \n",
    "                                cv2.FONT_HERSHEY_DUPLEX, .5, ((0,0,0)), 1)\n",
    "\n",
    "    viz_fn = os.path.join(viz_dir, '%(stack_moving)s_over_%(stack_fixed)s_%(sec)04d.jpg' % \\\n",
    "          {'stack_moving': stack_moving, 'stack_fixed': stack_fixed, 'sec': sec})\n",
    "#     imsave(viz_fn, viz)\n",
    "\n",
    "#     plt.figure(figsize=(10, 10));\n",
    "#     plt.imshow(viz);\n",
    "#     plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
