Code
=======

[Github repository](https://github.com/mistycheney/MouseBrainAtlas)

Image data
==========

Raw and processed data are stored in two places:
- Lab server `birdstore.dk.ucsd.edu` under `/brainbucket/data/Active_Atlas_Data/`. 
       - Raw data are stored in folders that correspond to the scanner used, e.g. `UCSD_AxioScanner/CSHL2_2018-04-04`.
       - Processed data are stored in `CSHL_data_processed`.
- AWS S3 bucket `mousebrainatlas-rawdata` and `mousebrainatlas-data`.
       - Raw data are stored in bucket `mousebrainatlas-rawdata`.
       - Processed data are stored in bucket `mousebrainatlas-data`.
       
## Naming rule ##

Every image used and generated by our system can be uniquely identified by the following information:
- image name: See below.
- version: a word that specifies a channel or the processed result of a particular channel. For example, it can be "Ntb" for neurotrace channel, "CHAT" for the ChAT channel, "NtbNormalized" for the intensity-normalized neurotrace channel.
- resolution: a word that specifies the pixel resolution. It can be "raw", "down32" (downsample raw data in both dimensions by a factor of 32), "thumbnail" (same as "down32"). It can also be an absolute physical size such as "10.0um".
- prep id: a number or word that identifies the preprocessing procedure applied, such as rotation and cropping.

### Image Name ###

Each physical section is associated with an `imageName`.
There is no fixed composition rule for image names.
The principle is that one can trace back from an image name to the physical section. Therefore in each image name, these two elements are mandatory:
- slide number
- section or scene index in the slide

Other than that, the brain id is optional but desired. Other information such as the scan date or stain name are optional.
For example, both `CHATM3_slide31_2018_02_17-S2` and `Slide31-Nissl-S2` are valid image names.
It is important to use only one composition rule for each brain. **Do not use space or special characters such as ampersand as they will not be parsed correctly in Linux commandline.**


## Transfer files to/from birdstore

- Download folders: `scp -r <username>@birdstore.dk.ucsd.edu:<server_data_dir> <local_data_dir>`
- Download files: `scp <username>@birdstore.dk.ucsd.edu:<server_file_path> <local_data_dir>/`
- Upload folders: `scp -r <local_data_dir>/ <username>@birdstore.dk.ucsd.edu:<server_data_dir>`
- Upload files: `scp <local_file_dir>/ <username>@birdstore.dk.ucsd.edu:<server_data_dir>/`

## Transfer files to/from AWS S3

Here are the instructions for downloading one stack MD585 (~300 sections) from AWS. 

Method 1 (recommended): Use [CrossFTP](http://www.crossftp.com/).

Method 2: Using command-line tool
1. Install the aws command-line tool https://aws.amazon.com/cli/
2. Run "aws configure", enter the Access Key ID and Secret Access Key in the csv file (`datauser_credentials.csv`). Set region to "us-west-1".
3. To download images of a stack, run "aws s3 cp --recursive s3://mousebrainatlas-data/CSHL_data_processed/MD585/MD585_prep2_lossless_jpeg <local_folder>". 

To upload, run `aws s3 cp <local_filepath> s3://mousebrainatlas-data/<s3_filepath>`

Method 3: Using web console (This method cannot download the whole folder)
1. Go to https://mousebrainatlas.signin.aws.amazon.com/console
2. Login as 
username: datauser
password: <no passwords in github>
3. Choose "S3"
4. The data are in the bucket called "mousebrainatlas-data". 
5. Click on a file and click "Download".

**Yoav:** This data needs to be reorganized in an image storage to allow fast retrieval of individual sections and parts of sections.

## Reconstructed volumes or virtual sections
Collection of images representing virtual sections in all three directions (sagittal, coronal and horizontal).



Meta data
===

Annotations
-----------

There are three types of annotations (points, 2D polygons, 3D volumes). Each stack usually has one of each type.
They are stored as HDF tables. Each row represents one point/polygon/volume.

For point and 2D contour annotation files, the column names are:
```
Index([u'class', u'creator', u'downsample', u'edits', u'id', u'label_position',
       u'name', u'orientation', u'parent_structure', u'section', u'side',
       u'side_manually_assigned', u'time_created', u'type', u'vertices',
       u'filename'],
```

- `class`: "contour" or "neuron"
- `creator`: username of the creator
- `downsample`: the downsample factor the vertices are defined on
- `edits`: the list of edits made on this contour
- `id`: a random uuid for this contour
- `label_position`: the position of the structure name text item relative to the whole image
- `name`: unsided name of this structure
- `orientation`: sagittal, coronal or horizontal
- `parent_structure`: currently not used
- `section`: the section number
- `side`: L or R
- `side_manually_assigned`: True if the side is confirmed by human; False if the side is automatically inferred.
- `time_created`: the time that the contour is created
- `type`: "intersected" if this contour is the result of interpolation or "confirmed" if confirmed by human
- `vertices`: vertices of a polygon. (n,2)-ndarray.
- `filename`: the file name of the section.
