{
 "metadata": {
  "name": "",
  "signature": "sha256:b07565f0c9ee47671e806989ce30f5b0d5babda69d88e68de26362e54d4604ce"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cluster import MiniBatchKMeans \n",
      "\n",
      "from skimage.segmentation import slic, mark_boundaries\n",
      "from skimage.measure import regionprops\n",
      "from skimage.util import img_as_ubyte\n",
      "from skimage.color import hsv2rgb, label2rgb, gray2rgb\n",
      "from skimage.morphology import disk\n",
      "from skimage.filter.rank import gradient\n",
      "\n",
      "from scipy.sparse import coo_matrix\n",
      "from scipy.spatial.distance import pdist, squareform\n",
      "\n",
      "import numpy as np\n",
      "import cv2\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "from utilities import *\n",
      "\n",
      "class SaliencyDetector(object):\n",
      "    \n",
      "    def __init__(self, img, mask, features_input):\n",
      "        self.img = img\n",
      "        self.features = np.load(features_input)\n",
      "        self.n_feat = self.features.shape[-1]\n",
      "                \n",
      "        self.features = self.features[100:-100, 100:-100, :]\n",
      "        self.img = self.img[100:-100, 100:-100]\n",
      "        self.mask = mask[100:-100, 100:-100]\n",
      "        \n",
      "#         self.features = self.features.view(np.ma.MaskedArray)\n",
      "#         self.features[~self.mask,:] = np.ma.masked        \n",
      "#         self.img = self.img.view(np.ma.MaskedArray)\n",
      "#         self.img[~self.mask,:] = np.ma.masked\n",
      "    \n",
      "    def visualize_features(self, output=None):\n",
      "        fig, axes = plt.subplots(ncols=4, nrows=self.features.shape[-1]/4, figsize=(20,10))\n",
      "        for i, ax in zip(range(self.features.shape[-1]), axes.flat):\n",
      "            ax.matshow(self.features[...,i])\n",
      "            ax.set_title('feature %d'%i, fontsize=0.5)\n",
      "            ax.axis('off')\n",
      "        plt.close();\n",
      "        \n",
      "        if output is not None:\n",
      "            fig.savefig(output, bbox_inches='tight')\n",
      "    \n",
      "    @timeit\n",
      "    def compute_texton(self, num_textons = 10):\n",
      "        self.num_textons = num_textons\n",
      "        kmeans_model = MiniBatchKMeans(num_textons)\n",
      "        kmeans_model.fit(self.features[self.mask,:].reshape(-1, self.n_feat))\n",
      "        self.textonmap = kmeans_model.predict(self.features.reshape(-1, self.n_feat)).reshape(self.features.shape[:2])\n",
      "    \n",
      "    @timeit\n",
      "    def segment_superpixels(self, compactness=5, sigma=10):\n",
      "        self.segmentation = slic(gray2rgb(self.img), compactness=compactness, sigma=sigma, enforce_connectivity=True)\n",
      "        self.n_superpixels = len(np.unique(self.segmentation))\n",
      "\n",
      "        sp_props = regionprops(self.segmentation+1, intensity_image=self.img, cache=True)\n",
      "        self.sp_centroids = np.array([s.centroid for s in sp_props])\n",
      "        sp_centroid_dist = pdist(self.sp_centroids)\n",
      "        self.sp_centroid_dist_matrix = squareform(sp_centroid_dist)\n",
      "\n",
      "        self.sp_mean_intensity = np.array([s.mean_intensity for s in sp_props])\n",
      "        sp_areas = np.array([s.area for s in sp_props])\n",
      "        \n",
      "        superpixels_bg_count = np.array([(~self.mask[self.segmentation==i]).sum() for i in range(self.n_superpixels)])\n",
      "        self.bg_superpixels = np.nonzero((superpixels_bg_count/sp_areas) > .8)[0]\n",
      "        \n",
      "#         superpixels_fg_count = np.array([self.mask[self.segmentation==i].sum() for i in range(self.n_superpixels)])\n",
      "#         self.bg_superpixels = np.nonzero((superpixels_fg_count/sp_areas) < 0.3)[0]\n",
      "    \n",
      "    def visualize_superpixels(self, output=None):\n",
      "        img_superpixelized = mark_boundaries(gray2rgb(self.img), self.segmentation)\n",
      "        img_superpixelized_text = img_as_ubyte(img_superpixelized)\n",
      "        for s in range(self.n_superpixels):\n",
      "            img_superpixelized_text = cv2.putText(img_superpixelized_text, str(s), \n",
      "                                                  tuple(np.floor(self.sp_centroids[s][::-1]).astype(np.int)), \n",
      "                                                  cv2.FONT_HERSHEY_COMPLEX_SMALL,\n",
      "                                                  0.8, ((255,0,255)), 1)\n",
      "        img_superpixelized_text = img_superpixelized_text/255.\n",
      "        \n",
      "        if output is not None:\n",
      "            cv2.imwrite(output, img_as_ubyte(img_superpixelized_text))\n",
      "\n",
      "    def visualize_textonmap_superpixels(self, output=None):\n",
      "        textonmap_rgb = label2rgb(self.textonmap, image=None, colors=None, alpha=0.3, image_alpha=1)\n",
      "        \n",
      "        img_superpixelized = mark_boundaries(gray2rgb(self.img), self.segmentation)\n",
      "        img_superpixelized_text = img_as_ubyte(img_superpixelized)\n",
      "        for s in range(self.n_superpixels):\n",
      "            img_superpixelized_text = cv2.putText(img_superpixelized_text, str(s), \n",
      "                                                  tuple(np.floor(self.sp_centroids[s][::-1]).astype(np.int)), \n",
      "                                                  cv2.FONT_HERSHEY_COMPLEX_SMALL,\n",
      "                                                  0.8, ((255,0,255)), 1)\n",
      "        img_superpixelized_text = img_superpixelized_text/255.\n",
      "        \n",
      "        if output is not None:\n",
      "            cv2.imwrite(output, img_as_ubyte(.5*textonmap_rgb + .5*img_superpixelized_text))\n",
      "\n",
      "        \n",
      "    def _kl(self, u,v):\n",
      "        eps = 0.001\n",
      "        return np.sum((u+eps)*np.log((u+eps)/(v+eps)))\n",
      "\n",
      "    def _kl_no_eps(self, u,v):\n",
      "        return np.sum(u*np.log(u/v))\n",
      "    \n",
      "    def _chi2(self, u,v):\n",
      "        return np.sum(np.where(u+v!=0, (u-v)**2/(u+v), 0))\n",
      "\n",
      "    @timeit\n",
      "    def compute_distance_matrix(self):\n",
      "        sample_interval = 1\n",
      "        gridy, gridx = np.mgrid[:self.img.shape[0]:sample_interval, :self.img.shape[1]:sample_interval]\n",
      "\n",
      "        all_seg = self.segmentation[gridy.ravel(), gridx.ravel()]\n",
      "        all_texton = self.textonmap[gridy.ravel(), gridx.ravel()]\n",
      "        sp_texton_hist = np.array([np.bincount(all_texton[all_seg == s], minlength=self.num_textons) \n",
      "                         for s in range(self.n_superpixels)])\n",
      "\n",
      "        row_sums = sp_texton_hist.sum(axis=1)\n",
      "        self.sp_texton_hist_normalized = sp_texton_hist.astype(np.float) / row_sums[:, np.newaxis]\n",
      "        D = pdist(self.sp_texton_hist_normalized, self._kl)\n",
      "        self.hist_distance_matrix = squareform(D)\n",
      "\n",
      "    @timeit\n",
      "    def compute_connectivity(self):\n",
      "        edge_map = gradient(self.segmentation.astype(np.uint8), disk(3))\n",
      "        self.neighbors = [set() for i in range(self.n_superpixels)]\n",
      "        for y,x in zip(*np.nonzero(edge_map)):\n",
      "            self.neighbors[self.segmentation[y,x]] |= set(self.segmentation[y-2:y+2,x-2:x+2].ravel())\n",
      "\n",
      "        rows = np.hstack([s*np.ones((len(self.neighbors[s]),), dtype=np.int) for s in range(self.n_superpixels)])\n",
      "        cols = np.hstack([list(self.neighbors[s]) for s in range(self.n_superpixels)])\n",
      "        data = np.ones((cols.size, ), dtype=np.bool)\n",
      "        self.connectivity_matrix = coo_matrix((data, (rows, cols)), shape=(self.n_superpixels, self.n_superpixels))\n",
      "    \n",
      "    @timeit\n",
      "    def compute_saliency_map(self, neighbor_term_weight=1.):\n",
      "        overall_texton_hist = np.bincount(self.textonmap[self.mask].flat)\n",
      "        overall_texton_hist_normalized = overall_texton_hist.astype(np.float) / overall_texton_hist.sum()\n",
      "\n",
      "        individual_saliency_score = np.array([self._kl(sp_hist, overall_texton_hist_normalized) for sp_hist in self.sp_texton_hist_normalized])\n",
      "\n",
      "        self.saliency_score = np.zeros((self.n_superpixels,))\n",
      "        for i, sp_hist in enumerate(self.sp_texton_hist_normalized):\n",
      "            if i in self.bg_superpixels: continue\n",
      "            self.saliency_score[i] = individual_saliency_score[i]\n",
      "            neighbor_term = 0\n",
      "            for j in self.neighbors[i]:\n",
      "                if j!=i and j not in self.bg_superpixels:\n",
      "                    neighbor_term += np.exp(-self.hist_distance_matrix[i,j]) * individual_saliency_score[j]\n",
      "            self.saliency_score[i] += neighbor_term_weight*neighbor_term/(len(self.neighbors[i])-1)\n",
      "\n",
      "        self.saliency_map = self.saliency_score[self.segmentation]\n",
      "    \n",
      "    def visualize_saliency_map(self, output=None):\n",
      "        from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
      "        fig, ax = plt.subplots()\n",
      "        im = ax.matshow(self.saliency_map, cmap=plt.cm.Greys_r)\n",
      "        ax.axis('off')\n",
      "        divider = make_axes_locatable(ax)\n",
      "        cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
      "        plt.colorbar(im, cax=cax)\n",
      "        plt.close();\n",
      "        if output is not None:\n",
      "            fig.savefig(output, bbox_inches='tight')\n",
      "    \n",
      "    @timeit    \n",
      "    def find_salient_clusters(self, dist_thresh = 0.5, n_top_clusters=10):\n",
      "    \n",
      "        chosen_superpixels = set([])\n",
      "        self.clusters = []\n",
      "\n",
      "        for t in range(n_top_clusters):\n",
      "            for i in self.saliency_score.argsort()[::-1]:\n",
      "                if i not in chosen_superpixels and i not in self.bg_superpixels:\n",
      "                    break\n",
      "\n",
      "            curr_cluster = np.array([i], dtype=np.int)\n",
      "            frontier = [i]\n",
      "            while len(frontier) > 0:\n",
      "                i = frontier.pop(-1)\n",
      "                for j in self.neighbors[i]:\n",
      "                    if j != i and j not in curr_cluster and j not in chosen_superpixels\\\n",
      "                    and self.hist_distance_matrix[curr_cluster,j].mean() < dist_thresh\\\n",
      "                    and i not in self.bg_superpixels and j not in self.bg_superpixels:\n",
      "                        curr_cluster = np.append(curr_cluster, j)\n",
      "                        frontier.append(j)\n",
      "\n",
      "            self.clusters.append(curr_cluster)\n",
      "            chosen_superpixels |= set(curr_cluster)\n",
      "    \n",
      "    def visualize_salient_clusters(self, output=None):\n",
      "        segmentation_copy = np.zeros_like(self.segmentation)\n",
      "\n",
      "        for i, c in enumerate(self.clusters):\n",
      "            propagate_selection = np.equal.outer(self.segmentation, c).any(axis=2)\n",
      "            segmentation_copy[propagate_selection] = i + 1\n",
      "\n",
      "        selection_rgb = label2rgb(segmentation_copy, self.img, \n",
      "                                  bg_label=0, bg_color=(1,1,1), \n",
      "                                  colors=None)\n",
      "        if output is not None:\n",
      "            cv2.imwrite(output, img_as_ubyte(selection_rgb))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    }
   ],
   "metadata": {}
  }
 ]
}