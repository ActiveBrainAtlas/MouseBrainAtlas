{
 "metadata": {
  "name": "",
  "signature": "sha256:5de51e9f7f2f7302115f2032cfe465a2145002addbc0b7d7cafc75adfdb4db19"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext autoreload\n",
      "%autoreload 2\n",
      "\n",
      "import numpy as np\n",
      "import cv2\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "import random, itertools, sys, os\n",
      "from multiprocessing import Pool\n",
      "import json\n",
      "\n",
      "from skimage.segmentation import slic, mark_boundaries\n",
      "# from skimage.measure import regionprops\n",
      "# from skimage.util import img_as_ubyte\n",
      "from skimage.color import hsv2rgb, label2rgb, gray2rgb\n",
      "# from skimage.morphology import disk\n",
      "# from skimage.filter.rank import gradient\n",
      "# from skimage.filter import gabor_kernel\n",
      "# from skimage.transform import rescale, resize\n",
      "\n",
      "# from scipy.ndimage import gaussian_filter, measurements\n",
      "# from scipy.sparse import coo_matrix\n",
      "from scipy.spatial.distance import pdist, squareform, euclidean, cdist\n",
      "# from scipy.signal import fftconvolve\n",
      "\n",
      "# from IPython.display import FileLink, Image, FileLinks\n",
      "\n",
      "import utilities\n",
      "from utilities import chi2\n",
      "\n",
      "from joblib import Parallel, delayed\n",
      "\n",
      "import glob\n",
      "import re\n",
      "import os\n",
      "import sys\n",
      "import subprocess\n",
      "import argparse\n",
      "import pprint\n",
      "\n",
      "import cPickle as pickle\n",
      "\n",
      "\n",
      "data_dir = '/home/yuncong/BrainLocal/DavidData'\n",
      "repo_dir = '/home/yuncong/BrainSaliencyDetection'\n",
      "params_dir = os.path.join(repo_dir, 'params')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The autoreload extension is already loaded. To reload it, use:\n",
        "  %reload_ext autoreload\n"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# # parse arguments\n",
      "# parser = argparse.ArgumentParser(\n",
      "# formatter_class=argparse.RawDescriptionHelpFormatter,\n",
      "# description='Supervised learning',\n",
      "# # epilog=\"\"\"\n",
      "# # \"\"\"%(os.path.basename(sys.argv[0]))\n",
      "# )\n",
      "\n",
      "# parser.add_argument(\"labeling_fn\", type=str, help=\"path to labeling file\")\n",
      "# parser.add_argument(\"-o\", \"--output_dir\", type=str, help=\"output directory (default: %(default)s)\", default='/oasis/scratch/csd181/yuncong/output')\n",
      "# args = parser.parse_args()\n",
      "\n",
      "class args(object):\n",
      "    models_fn = '/home/yuncong/BrainLocal/DavidData/RS141/x5/0001/redNissl/labelings/RS141_x5_0001_redNissl_models.pkl'\n",
      "#     labeling_fn = '/home/yuncong/BrainLocal/DavidData/RS141/x5/0001/redNissl/labelings/RS141_x5_0001_redNissl_anon_10132014165928.pkl'\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def save_array(arr, suffix):\n",
      "    utilities.save_array(arr, suffix, instance_name=instance_name, results_dir=results_dir)\n",
      "        \n",
      "def save_image(img, suffix):\n",
      "    utilities.save_image(img, suffix, instance_name=instance_name, results_dir=results_dir, overwrite=True)\n",
      "\n",
      "def load_image(suffix):\n",
      "    return utilities.load_image(suffix, instance_name=instance_name, results_dir=results_dir)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# stack_name, resolution, slice_id, params_name, username, logout_time = os.path.basename(args.labeling_fn)[:-4].split('_')\n",
      "\n",
      "stack_name = 'RS141'\n",
      "resolution = 'x5'\n",
      "slice_id = '0002'\n",
      "params_name = 'redNissl'\n",
      "\n",
      "results_dir = os.path.join(data_dir, stack_name, resolution, slice_id, params_name, 'pipelineResults')\n",
      "labelings_dir = os.path.join(data_dir, stack_name, resolution, slice_id, params_name, 'labelings')\n",
      "\n",
      "instance_name = '_'.join([stack_name, resolution, slice_id, params_name])\n",
      "# parent_labeling_name = username + '_' + logout_time\n",
      "parent_labeling_name = None\n",
      "\n",
      "def full_object_name(obj_name, ext):\n",
      "    return os.path.join(data_dir, stack_name, resolution, slice_id, params_name, 'pipelineResults', instance_name + '_' + obj_name + '.' + ext)\n",
      "\n",
      "segmentation = np.load(full_object_name('segmentation', 'npy'))\n",
      "n_superpixels = np.max(segmentation) + 1\n",
      "\n",
      "# load parameter settings\n",
      "params_dir = os.path.realpath(params_dir)\n",
      "param_file = os.path.join(params_dir, 'param_%s.json'%params_name)\n",
      "param_default_file = os.path.join(params_dir, 'param_default.json')\n",
      "param = json.load(open(param_file, 'r'))\n",
      "param_default = json.load(open(param_default_file, 'r'))\n",
      "\n",
      "for k, v in param_default.iteritems():\n",
      "    if not isinstance(param[k], basestring):\n",
      "        if np.isnan(param[k]):\n",
      "            param[k] = v\n",
      "\n",
      "pprint.pprint(param)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{u'bandwidth': 2,\n",
        " u'beta': 1.0,\n",
        " u'freq_step': 1.5,\n",
        " u'frontier_contrast_diff_thresh': 0.2,\n",
        " u'lr_decision_thresh': 0.3,\n",
        " u'lr_grow_thresh': 0.1,\n",
        " u'max_wavelen': 40.0,\n",
        " u'min_wavelen': 5.0,\n",
        " u'n_iter': 10,\n",
        " u'n_models': 10,\n",
        " u'n_sample': 10000,\n",
        " u'n_superpixels': 2000.0,\n",
        " u'n_texton': 100,\n",
        " u'param_id': u'redNissl',\n",
        " u'slic_compactness': 20.0,\n",
        " u'slic_sigma': 5.0,\n",
        " u'theta_interval': 16}\n"
       ]
      }
     ],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sp_texton_hist_normalized = np.load(full_object_name('texHist', 'npy'))\n",
      "sp_dir_hist_normalized = np.load(full_object_name('dirHist', 'npy'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# labellist = labeling['final_labellist']\n",
      "\n",
      "models = pickle.load(open(args.models_fn, 'r'))\n",
      "n_models = len(models)\n",
      "\n",
      "texton_models = [model['texton_hist'] for model in models]\n",
      "dir_models = [model['dir_hist'] for model in models]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# plt.bar(range(100), texton_models[0])\n",
      "# plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mask = np.load(full_object_name('cropMask','npy'))\n",
      "fg_superpixels = np.load(full_object_name('fg','npy'))\n",
      "bg_superpixels = np.load(full_object_name('bg','npy'))\n",
      "neighbors = np.load(full_object_name('neighbors','npy'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "D_texton_model = -1*np.ones((n_models, n_superpixels))\n",
      "D_dir_model = -1*np.ones((n_models, n_superpixels))\n",
      "D_texton_model[:, fg_superpixels] = cdist(sp_texton_hist_normalized[fg_superpixels], texton_models, chi2).T\n",
      "D_dir_model[:, fg_superpixels] = cdist(sp_dir_hist_normalized[fg_superpixels], dir_models, chi2).T\n",
      "\n",
      "textonmap = np.load(full_object_name('texMap', 'npy'))\n",
      "overall_texton_hist = np.bincount(textonmap[mask].flat)\n",
      "\n",
      "overall_texton_hist_normalized = overall_texton_hist.astype(np.float) / overall_texton_hist.sum()\n",
      "\n",
      "overall_dir_hist = sp_dir_hist_normalized[fg_superpixels].mean(axis=0)\n",
      "\n",
      "overall_dir_hist_normalized = overall_dir_hist.astype(np.float) / overall_dir_hist.sum()\n",
      "\n",
      "D_texton_null = np.squeeze(cdist(sp_texton_hist_normalized, [overall_texton_hist_normalized], chi2))\n",
      "D_dir_null = np.squeeze(cdist(sp_dir_hist_normalized, [overall_dir_hist_normalized], chi2))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def grow_cluster_likelihood_ratio_precomputed(seed, D_texton_model, D_dir_model, debug=False, lr_grow_thresh = 0.1):\n",
      "    '''\n",
      "    find the connected cluster of superpixels that are more likely to be explained by given model than by null, \n",
      "    starting from a superpixel as seed\n",
      "    using pre-computed distances between model and superpixels\n",
      "    '''\n",
      "\n",
      "    if seed in bg_superpixels:\n",
      "        return [], -1\n",
      "\n",
      "    curr_cluster = set([seed])\n",
      "    frontier = [seed]\n",
      "        \n",
      "    while len(frontier) > 0:\n",
      "        u = frontier.pop(-1)\n",
      "        for v in neighbors[u]:\n",
      "            if v in bg_superpixels or v in curr_cluster: \n",
      "                continue\n",
      "            \n",
      "            ratio_v = D_texton_null[v] - D_texton_model[v] +\\\n",
      "                        D_dir_null[v] - D_dir_model[v]\n",
      "            if debug:  \n",
      "                print 'u=', u, 'v=',v, 'ratio_v = ', ratio_v\n",
      "                print D_texton_null[v],  D_texton_model[v], \\\n",
      "                        D_dir_null[v], D_dir_model[v]\n",
      "            \n",
      "            if ratio_v > lr_grow_thresh:\n",
      "                curr_cluster.add(v)\n",
      "                frontier.append(v)\n",
      "                                \n",
      "    return curr_cluster, lr_grow_thresh"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "img = load_image('cropImg')\n",
      "\n",
      "# lr_decision_thresh = param['lr_decision_thresh']\n",
      "lr_decision_thresh = .2\n",
      "lr_grow_thresh = param['lr_grow_thresh']\n",
      "\n",
      "print lr_decision_thresh, lr_grow_thresh\n",
      "\n",
      "def f(i):\n",
      "    model_score = np.empty((n_models, ))\n",
      "\n",
      "    if i in bg_superpixels:\n",
      "        return -1\n",
      "    else:\n",
      "        for m in range(n_models):\n",
      "            matched, _ = grow_cluster_likelihood_ratio_precomputed(i, D_texton_model[m], D_dir_model[m], \n",
      "                                                                   lr_grow_thresh=lr_grow_thresh)         \n",
      "            matched = list(matched)\n",
      "            model_score[m] = np.mean(D_texton_null[matched] - D_texton_model[m, matched] +\\\n",
      "                                     D_dir_null[matched] - D_dir_model[m, matched])\n",
      "\n",
      "        best_sig = model_score.max()\n",
      "        if best_sig > lr_decision_thresh: # sp whose sig is smaller than this is assigned null\n",
      "          return model_score.argmax()    \n",
      "    return -1\n",
      "\n",
      "r = Parallel(n_jobs=16)(delayed(f)(i) for i in range(n_superpixels))\n",
      "labels = np.array(r, dtype=np.int)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.2 0.1\n"
       ]
      }
     ],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "img = load_image('cropImg')\n",
      "\n",
      "# lr_decision_thresh = param['lr_decision_thresh']\n",
      "lr_decision_thresh = .2\n",
      "lr_grow_thresh = param['lr_grow_thresh']\n",
      "\n",
      "print lr_decision_thresh, lr_grow_thresh\n",
      "\n",
      "def f(i):\n",
      "    model_score = np.empty((n_models, ))\n",
      "\n",
      "    if i in bg_superpixels:\n",
      "        return -1\n",
      "    else:\n",
      "        for m in range(n_models):\n",
      "            print 'model', m\n",
      "            matched, _ = grow_cluster_likelihood_ratio_precomputed(i, D_texton_model[m], D_dir_model[m], \n",
      "                                                                   lr_grow_thresh=lr_grow_thresh)\n",
      "            \n",
      "            a = utilities.paint_superpixels_on_image(matched, segmentation, img=img)\n",
      "            plt.imshow(a)\n",
      "            plt.show()\n",
      "            \n",
      "            matched = list(matched)\n",
      "            model_score[m] = np.mean(D_texton_null[matched] - D_texton_model[m, matched] +\\\n",
      "                                     D_dir_null[matched] - D_dir_model[m, matched])\n",
      "            print model_score[m]\n",
      "\n",
      "        best_sig = model_score.max()\n",
      "        if best_sig > lr_decision_thresh: # sp whose sig is smaller than this is assigned null\n",
      "          return model_score.argmax()    \n",
      "    return -1\n",
      "\n",
      "\n",
      "# f(1382) #0001\n",
      "f(811) # axon bundles on 0002"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.2 0.1\n",
        "model 0\n",
        "0.784256225913"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "model 1\n",
        "-0.209563929761"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "model 2\n",
        "-0.291975924136"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "model 3\n",
        "-0.248960422527"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 64,
       "text": [
        "0"
       ]
      }
     ],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "labelmap = labels[segmentation]\n",
      "\n",
      "hc_colors = np.loadtxt('../visualization/high_contrast_colors.txt', skiprows=1)\n",
      "\n",
      "img = load_image('cropImg')\n",
      "\n",
      "labelmap_rgb = label2rgb(labelmap.astype(np.int), image=img, colors=hc_colors[1:]/255., alpha=0.1, \n",
      "                         image_alpha=1, bg_color=hc_colors[0]/255.)\n",
      "\n",
      "import datetime\n",
      "dt = datetime.datetime.now().strftime(\"%m%d%Y%H%M%S\")\n",
      "\n",
      "new_labeling = {\n",
      "'username': 'sigboost',\n",
      "'parent_labeling_name': None,\n",
      "'login_time': dt,\n",
      "'logout_time': dt,\n",
      "'init_labellist': None,\n",
      "'final_labellist': labels,\n",
      "'labelnames': None,\n",
      "'history': None\n",
      "}\n",
      "\n",
      "labelmap_rgb = utilities.regulate_img(labelmap_rgb)\n",
      "new_preview_fn = os.path.join(labelings_dir, instance_name + '_sigboost_' + dt + '_preview.tif')\n",
      "cv2.imwrite(new_preview_fn, labelmap_rgb)\n",
      "\n",
      "new_labeling_fn = os.path.join(labelings_dir, instance_name + '_sigboost_' + dt + '.pkl')\n",
      "pickle.dump(new_labeling, open(new_labeling_fn, 'w'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 65
    }
   ],
   "metadata": {}
  }
 ]
}