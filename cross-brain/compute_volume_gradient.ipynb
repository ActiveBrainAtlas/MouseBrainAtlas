{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.environ['REPO_DIR'] + '/utilities')\n",
    "from utilities2015 import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import time\n",
    "\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = ['BackG', '5N', '7n', '7N', '12N', 'Pn', 'VLL', \n",
    "          '6N', 'Amb', 'R', 'Tz', 'RtTg', 'LRt', 'LC', 'AP', 'sp5']\n",
    "\n",
    "n_labels = len(labels)\n",
    "\n",
    "labels_index = dict((j, i) for i, j in enumerate(labels))\n",
    "\n",
    "labels_from_surround = dict( (l+'_surround', l) for l in labels[1:])\n",
    "\n",
    "labels_surroundIncluded_list = labels[1:] + [l+'_surround' for l in labels[1:]]\n",
    "labels_surroundIncluded = set(labels_surroundIncluded_list)\n",
    "\n",
    "labels_surroundIncluded_index = dict((j, i) for i, j in enumerate(labels_surroundIncluded_list))\n",
    "\n",
    "# colors = np.random.randint(0, 255, (len(labels_index), 3))\n",
    "\n",
    "colors = np.loadtxt(os.environ['REPO_DIR'] + '/visualization/100colors.txt')\n",
    "colors[labels_index['BackG']] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "volume_dir = '/oasis/projects/nsf/csd395/yuncong/CSHL_volumes/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "downsample_factor = 16\n",
    "\n",
    "section_thickness = 20 # in um\n",
    "xy_pixel_distance_lossless = 0.46\n",
    "xy_pixel_distance_tb = xy_pixel_distance_lossless * 32 # in um, thumbnail\n",
    "# factor = section_thickness/xy_pixel_distance_lossless\n",
    "\n",
    "xy_pixel_distance_downsampled = xy_pixel_distance_lossless * downsample_factor\n",
    "z_xy_ratio_downsampled = section_thickness / xy_pixel_distance_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for stack in ['MD585', 'MD593', 'MD592', 'MD590', 'MD591', 'MD595', 'MD598', 'MD602']:\n",
    "\n",
    "    section_bs_begin, section_bs_end = section_range_lookup[stack]\n",
    "    print section_bs_begin, section_bs_end\n",
    "\n",
    "    (volume_xmin, volume_xmax, volume_ymin, volume_ymax, volume_zmin, volume_zmax) = \\\n",
    "    np.loadtxt(os.path.join(volume_dir, 'volume_%(stack)s_scoreMap_limits.txt' % {'stack': stack}), dtype=np.int)\n",
    "\n",
    "    volume2_allLabels = []\n",
    "\n",
    "    for l in labels[1:]:\n",
    "\n",
    "        print l\n",
    "\n",
    "        volume2 = bp.unpack_ndarray_file(os.path.join(volume_dir, 'volume_%(stack)s_scoreMap_%(label)s.bp' % \\\n",
    "                                                      {'stack': stack, 'label': l}))\n",
    "\n",
    "        volume2_cropped = volume2[volume_ymin:volume_ymax+1, volume_xmin:volume_xmax+1]\n",
    "        # copy is important, because then you can delete the large array\n",
    "\n",
    "        volume2_allLabels.append(volume2_cropped.copy())\n",
    "\n",
    "        del volume2, volume2_cropped\n",
    "\n",
    "    for l in range(1, n_labels):\n",
    "\n",
    "        print labels[l]\n",
    "        t = time.time()\n",
    "\n",
    "        # compute gradient\n",
    "        gy, gx, gz = np.gradient(volume2_allLabels[l-1], 10, 10, 10)\n",
    "        save_hdf(gx, volume_dir + '/volume_%(stack)s_scoreMap_%(lab)s_gx.hdf' % {'stack': stack, 'lab': labels[l]})\n",
    "        save_hdf(gy, volume_dir + '/volume_%(stack)s_scoreMap_%(lab)s_gy.hdf' % {'stack': stack, 'lab': labels[l]})\n",
    "        save_hdf(gz, volume_dir + '/volume_%(stack)s_scoreMap_%(lab)s_gz.hdf' % {'stack': stack, 'lab': labels[l]})\n",
    "\n",
    "        sys.stderr.write('compute gradient: %f seconds\\n' % (time.time() - t))\n",
    "\n",
    "        t = time.time()\n",
    "\n",
    "        # compute hessian\n",
    "        gxy, gxx, gxz = np.gradient(gx, 10, 10, 10)    \n",
    "        save_hdf(gxx, volume_dir + '/volume_%(stack)s_scoreMap_%(lab)s_gxx.hdf' % {'stack': stack, 'lab': labels[l]})\n",
    "        save_hdf(gxy, volume_dir + '/volume_%(stack)s_scoreMap_%(lab)s_gxy.hdf' % {'stack': stack, 'lab': labels[l]})\n",
    "        save_hdf(gxz, volume_dir + '/volume_%(stack)s_scoreMap_%(lab)s_gxz.hdf' % {'stack': stack, 'lab': labels[l]})\n",
    "        del gx, gxx, gxy, gxz\n",
    "\n",
    "        gyy, gyx, gyz = np.gradient(gy, 10, 10, 10)\n",
    "        save_hdf(gyx, volume_dir + '/volume_%(stack)s_scoreMap_%(lab)s_gyx.hdf' % {'stack': stack, 'lab': labels[l]})\n",
    "        save_hdf(gyy, volume_dir + '/volume_%(stack)s_scoreMap_%(lab)s_gyy.hdf' % {'stack': stack, 'lab': labels[l]})\n",
    "        save_hdf(gyz, volume_dir + '/volume_%(stack)s_scoreMap_%(lab)s_gyz.hdf' % {'stack': stack, 'lab': labels[l]})\n",
    "        del gy, gyx, gyy, gyz\n",
    "\n",
    "        gzy, gzx, gzz = np.gradient(gz, 10, 10, 10)\n",
    "        save_hdf(gzx, volume_dir + '/volume_%(stack)s_scoreMap_%(lab)s_gzx.hdf' % {'stack': stack, 'lab': labels[l]})\n",
    "        save_hdf(gzy, volume_dir + '/volume_%(stack)s_scoreMap_%(lab)s_gzy.hdf' % {'stack': stack, 'lab': labels[l]})\n",
    "        save_hdf(gzz, volume_dir + '/volume_%(stack)s_scoreMap_%(lab)s_gzz.hdf' % {'stack': stack, 'lab': labels[l]})\n",
    "        del gz, gzx, gzy, gzz\n",
    "\n",
    "        sys.stderr.write('compute hessian: %f seconds\\n' % (time.time() - t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
