{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from matplotlib.path import Path\n",
    "\n",
    "from collections import deque\n",
    "from itertools import izip, chain\n",
    "\n",
    "sys.path.append(os.environ['REPO_DIR'] + '/utilities')\n",
    "from utilities2015 import *\n",
    "\n",
    "from skimage.measure import find_contours\n",
    "\n",
    "sys.path.append('/home/yuncong/Brain/preprocess/morphsnakes')\n",
    "import morphsnakes\n",
    "\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "from enum import Enum\n",
    "\n",
    "class PolygonType(Enum):\n",
    "    CLOSED = 'closed'\n",
    "    OPEN = 'open'\n",
    "    TEXTURE = 'textured'\n",
    "    TEXTURE_WITH_CONTOUR = 'texture with contour'\n",
    "    DIRECTION = 'directionality'\n",
    "    \n",
    "from skimage.morphology import binary_closing, disk, binary_dilation, binary_erosion, remove_small_holes\n",
    "from skimage.measure import grid_points_in_poly, subdivide_polygon, approximate_polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "volume_dir = '/oasis/projects/nsf/csd395/yuncong/CSHL_volumes/'\n",
    "scoremaps_rootdir = '/home/yuncong/csd395/CSHL_scoremaps_lossless/'\n",
    "# autoAnnotations_rootdir = '/oasis/projects/nsf/csd395/yuncong/CSHL_autoAnnotations_snake'\n",
    "autoAnnotations_rootdir = '/oasis/projects/nsf/csd395/yuncong/CSHL_data_labelings_losslessAlignCropped/'\n",
    "# autoAnnotationViz_rootdir = '/oasis/projects/nsf/csd395/yuncong/CSHL_autoAnnotationsViz_snake'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_contour_points(labelmap):\n",
    "    '''\n",
    "    return is (x,y)\n",
    "    '''\n",
    "\n",
    "    regions = regionprops(labelmap)\n",
    "    contour_points = {}\n",
    "\n",
    "    for r in regions:\n",
    "\n",
    "        (min_row, min_col, max_row, max_col) = r.bbox\n",
    "\n",
    "        padded = np.pad(r.filled_image, ((5,5),(5,5)), mode='constant', constant_values=0)\n",
    "\n",
    "        contours = find_contours(padded, .5, fully_connected='high')\n",
    "        contours = [cnt.astype(np.int) for cnt in contours if len(cnt) > 10]\n",
    "        if len(contours) > 0:                \n",
    "            contours = sorted(contours, key=lambda c: len(c), reverse=True)\n",
    "            contours_list = [c-(5,5) for c in contours]\n",
    "            contour_points[r.label] = sorted([c[np.arange(0, c.shape[0], 10)][:, ::-1] + (min_col, min_row) \n",
    "                                for c in contours_list], key=lambda c: len(c), reverse=True)\n",
    "            \n",
    "        elif len(contours) == 0:\n",
    "            continue\n",
    "        \n",
    "    return contour_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_contours(cnts, bg, title):\n",
    "    viz = bg.copy()\n",
    "    for cnt in cnts:\n",
    "        for c in cnt:\n",
    "            cv2.circle(viz, tuple(c.astype(np.int)), 1, (0,255,0), -1)\n",
    "        cv2.polylines(viz, [cnt.astype(np.int)], True, (0,255,0), 2)\n",
    "        \n",
    "    plt.figure(figsize=(10,10));\n",
    "    plt.imshow(viz);\n",
    "    plt.title(title);\n",
    "    plt.show();\n",
    "    \n",
    "def show_levelset(levelset, bg, title):\n",
    "    viz = bg.copy()\n",
    "    cnts = find_contours(levelset, .5)\n",
    "    for cnt in cnts:\n",
    "        for c in cnt[:,::-1]:\n",
    "            cv2.circle(viz, tuple(c.astype(np.int)), 1, (0,255,0), -1)\n",
    "    plt.figure(figsize=(10,10));\n",
    "    plt.imshow(viz);\n",
    "    plt.title(title);\n",
    "    plt.show();\n",
    "    \n",
    "# http://deparkes.co.uk/2015/02/01/find-concave-hull-python/\n",
    "# http://blog.thehumangeo.com/2014/05/12/drawing-boundaries-in-python/\n",
    "\n",
    "from shapely.ops import cascaded_union, polygonize\n",
    "from shapely.geometry import MultiLineString\n",
    "from scipy.spatial import Delaunay\n",
    "import numpy as np\n",
    "\n",
    "def alpha_shape(coords, alpha):\n",
    "    \"\"\"\n",
    "    Compute the alpha shape (concave hull) of a set\n",
    "    of points.\n",
    "    @param points: Iterable container of points.\n",
    "    @param alpha: alpha value to influence the\n",
    "        gooeyness of the border. Smaller numbers\n",
    "        don't fall inward as much as larger numbers.\n",
    "        Too large, and you lose everything!\n",
    "    \"\"\"\n",
    "    \n",
    "    tri = Delaunay(coords)\n",
    "    \n",
    "    pa = coords[tri.vertices[:,0]]\n",
    "    pb = coords[tri.vertices[:,1]]\n",
    "    pc = coords[tri.vertices[:,2]]\n",
    "    \n",
    "    a = np.sqrt(np.sum((pa - pb)**2, axis=1))\n",
    "    b = np.sqrt(np.sum((pb - pc)**2, axis=1))\n",
    "    c = np.sqrt(np.sum((pc - pa)**2, axis=1))\n",
    "    s = (a + b + c)/2.\n",
    "    area = np.sqrt(s*(s-a)*(s-b)*(s-c))\n",
    "    circum_r = a*b*c/(4.0*area)\n",
    "    \n",
    "    edges = tri.vertices[circum_r < 1.0/alpha]\n",
    "\n",
    "# slightly slower than below\n",
    "#     edge_points = list(chain(*[[coords[ [ia, ib] ], coords[ [ib, ic] ], coords[ [ic, ia] ]]\n",
    "#                    for ia, ib, ic in edges]))\n",
    "    \n",
    "    edge_points = []\n",
    "    for ia, ib, ic in edges:\n",
    "        edge_points.append(coords[ [ia, ib] ])\n",
    "        edge_points.append(coords[ [ib, ic] ])\n",
    "        edge_points.append(coords[ [ic, ia] ])\n",
    "\n",
    "    m = MultiLineString(edge_points)\n",
    "    triangles = list(polygonize(m))\n",
    "    r = cascaded_union(triangles)\n",
    "    \n",
    "    return r\n",
    "\n",
    "def less(center):\n",
    "    def less_helper(a, b):\n",
    "        if (a[0] - center[0] >= 0 and b[0] - center[0] < 0):\n",
    "            return 1;\n",
    "        if (a[0] - center[0] < 0 and b[0] - center[0] >= 0):\n",
    "            return -1;\n",
    "        if (a[0] - center[0] == 0 and b[0] - center[0] == 0):\n",
    "            if (a[1] - center[1] >= 0 or b[1] - center[1] >= 0):\n",
    "                return 2*int(a[1] > b[1]) - 1;\n",
    "            return 2*int(b[1] > a[1]) - 1\n",
    "\n",
    "        # compute the cross product of vectors (center -> a) x (center -> b)\n",
    "        det = (a[0] - center[0]) * (b[1] - center[1]) - (b[0] - center[0]) * (a[1] - center[1])\n",
    "        if (det < 0):\n",
    "            return 1;\n",
    "        if (det > 0):\n",
    "            return -1;\n",
    "\n",
    "        # points a and b are on the same line from the center\n",
    "        # check which point is closer to the center\n",
    "        d1 = (a[0] - center[0]) * (a[0] - center[0]) + (a[1] - center[1]) * (a[1] - center[1])\n",
    "        d2 = (b[0] - center[0]) * (b[0] - center[0]) + (b[1] - center[1]) * (b[1] - center[1])\n",
    "        return 2*int(d1 > d2) - 1\n",
    "    \n",
    "    return less_helper\n",
    "\n",
    "def sort_vertices_counterclockwise(cnt):\n",
    "    # http://stackoverflow.com/a/6989383\n",
    "    center = cnt.mean(axis=0)\n",
    "    return sorted(cnt, cmp=less(center))\n",
    "\n",
    "\n",
    "def contour_to_concave_hull(cnt, alpha=.1):\n",
    "    \n",
    "    xmin, ymin = cnt.min(axis=0)\n",
    "    xmax, ymax = cnt.max(axis=0)\n",
    "    h, w = (ymax-ymin+1, xmax-xmin+1)\n",
    "    inside_ys, inside_xs =np.where(grid_points_in_poly((h, w), cnt[:, ::-1]-(ymin,xmin))) \n",
    "    n = inside_ys.size\n",
    "    random_indices = np.random.choice(range(n), min(1000, n), replace=False)\n",
    "    inside_points = np.c_[inside_xs[random_indices], inside_ys[random_indices]]\n",
    "    \n",
    "    while True:\n",
    "        concave_hull = alpha_shape(inside_points, alpha=alpha)\n",
    "    \n",
    "        if concave_hull.geometryType() == 'MultiPolygon':\n",
    "            alpha -= .01\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    if not hasattr(concave_hull, 'exterior'):\n",
    "        sys.stderr.write('No concave hull produced.\\n')\n",
    "        return None\n",
    "\n",
    "    if concave_hull.exterior.length < 20 * 3:\n",
    "        point_interval = concave_hull.exterior.length / 4\n",
    "    else:\n",
    "        point_interval = 20\n",
    "    new_cnt_subsampled = np.array([concave_hull.exterior.interpolate(r, normalized=True).coords[:][0] \n",
    "                         for r in np.arange(0, 1, point_interval/concave_hull.exterior.length)], \n",
    "               dtype=np.int)\n",
    "    \n",
    "    return new_cnt_subsampled + (xmin, ymin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(479, 833, 470)\n",
      "\n",
      "\n",
      "147\n",
      "set(['VLL', 'sp5'])\n",
      "VLL\n",
      "initial shift [ -50 -120] 0.859483\n",
      "mean inside score: 0.956886\n",
      "area: 1747\n",
      "snake iteration: 24\n",
      "sp5\n",
      "initial shift [ 30 -10] 0.38066\n",
      "mean inside score: 0.832691\n",
      "area: 51259\n",
      "snake iteration: 241\n",
      "\n",
      "\n",
      "148\n",
      "set(['VLL', 'sp5'])\n",
      "VLL\n",
      "initial shift [-50 -60] 1.00024\n",
      "mean inside score: 0.993061\n",
      "area: 6132\n",
      "snake iteration: 105\n",
      "sp5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/oasis/projects/nsf/csd181/yuncong/virtualenv-1.9.1/yuncongve/lib/python2.7/site-packages/PIL/Image.py:2224: DecompressionBombWarning: Image size (260896768 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning)\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-37c58252d830>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    119\u001b[0m                 \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m             \u001b[0minit_cnt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontour_to_concave_hull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_cnt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m             \u001b[0minit_cnt_xmin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_cnt_ymin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_cnt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-ea306d1cc6aa>\u001b[0m in \u001b[0;36mcontour_to_concave_hull\u001b[1;34m(cnt, alpha)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m         \u001b[0mconcave_hull\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malpha_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minside_points\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mconcave_hull\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeometryType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'MultiPolygon'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-ea306d1cc6aa>\u001b[0m in \u001b[0;36malpha_shape\u001b[1;34m(coords, alpha)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[0mcircum_r\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4.0\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marea\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m     \u001b[0medges\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtri\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvertices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcircum_r\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;31m# slightly slower than below\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "# for stack in ['MD585', 'MD593', 'MD592', 'MD590', 'MD591', 'MD594', 'MD595', 'MD598', 'MD602']:\n",
    "# for stack in ['MD592', 'MD590', 'MD591', 'MD594', 'MD595', 'MD598', 'MD602']:\n",
    "for stack in ['MD592']:\n",
    "\n",
    "    autoAnnotationViz_dir = autoAnnotationViz_rootdir + '/' + stack\n",
    "    if not os.path.exists(autoAnnotationViz_dir):\n",
    "        os.makedirs(autoAnnotationViz_dir)\n",
    "\n",
    "    first_bs_sec, last_bs_sec = section_range_lookup[stack]\n",
    "    first_detect_sec, last_detect_sec = detect_bbox_range_lookup[stack]\n",
    "\n",
    "    dm = DataManager(stack=stack)\n",
    "\n",
    "    labels_to_detect = set(['5N', '7n', '7N', '12N', 'Gr', 'LVe', 'Pn', 'SuVe', 'VLL', \n",
    "                         '6N', 'Amb', 'R', 'Tz', 'Sol', 'RtTg', 'LRt', 'LC', 'AP', 'sp5'])\n",
    "\n",
    "    # section_contains_label = {}\n",
    "    # for sec in range(first_bs_sec, last_bs_sec+1):\n",
    "    #     dm = DataManager(stack=stack, section=sec)\n",
    "    #     try:\n",
    "    #         user, ts, _, res = dm.load_proposal_review_result('yuncong', 'latest', 'consolidated')\n",
    "    #         section_contains_label[sec] = set([lm['label'] for lm in res])\n",
    "    #     except:\n",
    "    #         pass\n",
    "\n",
    "    test_volume_atlas_projected = bp.unpack_ndarray_file(volume_dir + '/%(stack)s_volume_atlasProjected.bp'%{'stack':stack})\n",
    "    print test_volume_atlas_projected.shape\n",
    "\n",
    "    (volume_xmin, volume_xmax, volume_ymin, volume_ymax, volume_zmin, volume_zmax) = \\\n",
    "        np.loadtxt(os.path.join(volume_dir, 'volume_%(stack)s_scoreMap_limits.txt' % {'stack': stack}), dtype=np.int)\n",
    "\n",
    "    labels = ['BackG', '5N', '7n', '7N', '12N', 'Gr', 'LVe', 'Pn', 'SuVe', 'VLL', \n",
    "                         '6N', 'Amb', 'R', 'Tz', 'Sol', 'RtTg', 'LRt', 'LC', 'AP', 'sp5']\n",
    "\n",
    "    label_dict = dict([(l,i) for i, l in enumerate(labels)])\n",
    "\n",
    "\n",
    "    downsample_factor = 16\n",
    "\n",
    "    section_thickness = 20 # in um\n",
    "    xy_pixel_distance_lossless = 0.46\n",
    "    xy_pixel_distance_tb = xy_pixel_distance_lossless * 32 # in um, thumbnail\n",
    "\n",
    "    xy_pixel_distance_downsampled = xy_pixel_distance_lossless * downsample_factor\n",
    "    z_xy_ratio_downsampled = section_thickness / xy_pixel_distance_downsampled\n",
    "    \n",
    "    \n",
    "    ##########################################\n",
    "    \n",
    "    for sec in range(first_detect_sec, last_detect_sec+1):\n",
    "#     for sec in range(167, last_detect_sec+1):\n",
    "#     for sec in [167]:\n",
    "    \n",
    "        autoAnnotations_dir = autoAnnotations_rootdir + '/' + stack + '/' + '%04d'%sec\n",
    "        if not os.path.exists(autoAnnotations_dir):\n",
    "            os.makedirs(autoAnnotations_dir)\n",
    "\n",
    "        dm = DataManager(stack=stack, section=sec)\n",
    "        dm._load_image(versions=['rgb-jpg'])\n",
    "        cropped_img = dm.image_rgb_jpg[::8, ::8]\n",
    "\n",
    "        scoremaps_dir = os.path.join(scoremaps_rootdir, stack, '%04d'%sec)\n",
    "\n",
    "        print '\\n'\n",
    "        print sec\n",
    "\n",
    "        #########################\n",
    "\n",
    "        z_lowerlim = int(z_xy_ratio_downsampled*sec) - volume_zmin\n",
    "        z_nextsec = int(z_xy_ratio_downsampled*(sec+1)) - volume_zmin\n",
    "        z_previous = int(z_xy_ratio_downsampled*(sec-1)) - volume_zmin\n",
    "\n",
    "        projected_annotation_labelmap = test_volume_atlas_projected[..., z_lowerlim]\n",
    "\n",
    "        init_cnts = find_contour_points(projected_annotation_labelmap) # downsampled 16\n",
    "        init_cnts = dict([(labels[label_ind], (cnts[0]+(volume_xmin, volume_ymin))*2) \n",
    "                          for label_ind, cnts in init_cnts.iteritems()])\n",
    "\n",
    "        labels_exist = set(init_cnts.keys())\n",
    "\n",
    "        valid_labels = labels_to_detect & labels_exist\n",
    "        print valid_labels\n",
    "\n",
    "        if len(valid_labels) == 0:\n",
    "            sys.stderr.write('No valid labels exist.\\n')\n",
    "            continue\n",
    "\n",
    "        new_res = []\n",
    "\n",
    "        for l in valid_labels:\n",
    "\n",
    "            print l\n",
    "\n",
    "            try:\n",
    "                scoremap_whole = bp.unpack_ndarray_file(os.path.join(scoremaps_dir, \n",
    "                                                           '%(stack)s_%(sec)04d_roi1_denseScoreMapLossless_%(label)s.bp' % \\\n",
    "                                                           {'stack': stack, 'sec': sec, 'label': l}))\n",
    "            except:\n",
    "                sys.stderr.write('No scoremap of %s exists\\n' % (l))\n",
    "                continue\n",
    "\n",
    "\n",
    "            dataset = stack + '_' + '%04d'%sec + '_roi1'\n",
    "\n",
    "            interpolation_xmin, interpolation_xmax, \\\n",
    "            interpolation_ymin, interpolation_ymax = np.loadtxt(os.path.join(scoremaps_dir, \n",
    "                                                                             '%(dataset)s_denseScoreMapLossless_%(label)s_interpBox.txt' % \\\n",
    "                                            {'dataset': dataset, 'label': l})).astype(np.int)\n",
    "\n",
    "            dense_scoremap_lossless = np.zeros((dm.image_height, dm.image_width), np.float32)\n",
    "            dense_scoremap_lossless[interpolation_ymin:interpolation_ymax+1,\n",
    "                                    interpolation_xmin:interpolation_xmax+1] = scoremap_whole\n",
    "\n",
    "            scoremap = dense_scoremap_lossless[::8, ::8]\n",
    "            scoremap_height, scoremap_width = scoremap.shape[:2]\n",
    "\n",
    "            init_cnt = init_cnts[l]\n",
    "\n",
    "            if len(init_cnt) < 3:\n",
    "                sys.stderr.write('initial contour has less than 3 vertices. \\n')\n",
    "                continue\n",
    "\n",
    "            init_cnt = contour_to_concave_hull(init_cnt, alpha=.01)\n",
    "\n",
    "            init_cnt_xmin, init_cnt_ymin = init_cnt.min(axis=0)\n",
    "            init_cnt_xmax, init_cnt_ymax = init_cnt.max(axis=0)\n",
    "            init_cnt_height, init_cnt_width = (init_cnt_ymax - init_cnt_ymin + 1, init_cnt_xmax - init_cnt_xmin + 1)\n",
    "            init_cnt_cx, init_cnt_cy = np.mean(init_cnt, axis=0)\n",
    "\n",
    "            init_cnt_poly = Path(init_cnt)\n",
    "            init_cnt_bbox_xs, init_cnt_bbox_ys = np.meshgrid(range(init_cnt_xmin, init_cnt_xmax+1), \n",
    "                                                             range(init_cnt_ymin, init_cnt_ymax+1))\n",
    "            grid_points = np.c_[init_cnt_bbox_xs.flat, init_cnt_bbox_ys.flat]\n",
    "            is_inside = init_cnt_poly.contains_points(grid_points)\n",
    "            inside_points = grid_points[is_inside]\n",
    "\n",
    "            score_max = 0\n",
    "            for xshift in range(-200, 200, 10):\n",
    "                for yshift in range(-200, 200, 10):\n",
    "                    shifted_ys = inside_points[:,1] + int(yshift)\n",
    "                    shifted_xs = inside_points[:,0] + int(xshift)\n",
    "                    valid = (shifted_ys >= 0) & (shifted_ys < scoremap_height-1) & (shifted_xs >= 0) & (shifted_xs < scoremap_width-1)\n",
    "                    shifted_ys = shifted_ys[valid]\n",
    "                    shifted_xs = shifted_xs[valid]\n",
    "                    score = scoremap[shifted_ys, shifted_xs].mean()\n",
    "                    if score_max < score:\n",
    "                        score_max = score\n",
    "                        shift_best = np.array([int(xshift), int(yshift)])\n",
    "\n",
    "            print 'initial shift', shift_best, score_max\n",
    "\n",
    "            if l == 'RtTg':\n",
    "                shift_best = (0, 0)\n",
    "\n",
    "            init_cnt_xmin = max(init_cnt_xmin + shift_best[0], 0)\n",
    "            init_cnt_ymin = max(init_cnt_ymin + shift_best[1], 0)\n",
    "            init_cnt_xmax = min(init_cnt_xmax + shift_best[0], scoremap_width-1)\n",
    "            init_cnt_ymax = min(init_cnt_ymax + shift_best[1], scoremap_height-1)\n",
    "            inside_points += shift_best\n",
    "            inside_points = inside_points[(inside_points[:,0] > init_cnt_xmin) & \\\n",
    "                                          (inside_points[:,0] < init_cnt_xmax) & \\\n",
    "                                          (inside_points[:,1] > init_cnt_ymin) & \\\n",
    "                                          (inside_points[:,1] < init_cnt_ymax)]\n",
    "            \n",
    "            roi_margin = max(200, (400-min(init_cnt_height, init_cnt_width))/2)\n",
    "            # should be set to the largest landmark diameter (so that it is ok even if contour is placed at the end of it)\n",
    "\n",
    "            roi_xmin, roi_ymin = (max(0, init_cnt_xmin - roi_margin), max(0, init_cnt_ymin - roi_margin))\n",
    "            roi_xmax, roi_ymax = (min(scoremap_width-1, init_cnt_xmax + roi_margin), min(scoremap_height-1, init_cnt_ymax + roi_margin))\n",
    "            roi_height, roi_width = (roi_ymax + 1 - roi_ymin, roi_xmax + 1 - roi_xmin)\n",
    "\n",
    "            inside_points_inroi = inside_points - (roi_xmin, roi_ymin)\n",
    "\n",
    "            scoremap_roi = scoremap[roi_ymin:roi_ymax+1, roi_xmin:roi_xmax+1] \n",
    "\n",
    "\n",
    "            ######## landmark specific settings ########\n",
    "\n",
    "            if l == '12N':\n",
    "                score_thresh = 0.3\n",
    "            elif l == 'sp5':\n",
    "                score_thresh = 0.3\n",
    "            elif l == 'LRt':\n",
    "                score_thresh = 0.95\n",
    "            elif l == '7N':\n",
    "                score_thresh = 0.95\n",
    "            else:\n",
    "                score_thresh = 0.8\n",
    "\n",
    "            if l == 'sp5':\n",
    "                smoothing = 1\n",
    "            else:\n",
    "                smoothing = 3\n",
    "\n",
    "            if l == 'sp5':\n",
    "                alpha = .1\n",
    "            else:\n",
    "                alpha = .04\n",
    "\n",
    "            #############################################\n",
    "\n",
    "            scoremap_thresholded = scoremap_roi > score_thresh\n",
    "\n",
    "            scoremap_thresholded_padded = np.zeros((roi_height + 100, roi_width + 100), np.bool)\n",
    "            scoremap_thresholded_padded[50:-50, 50:-50] = scoremap_thresholded[:]\n",
    "    #         scoremap_thresholded_padded = binary_closing(scoremap_thresholded_padded, disk(10))\n",
    "            scoremap_thresholded_padded = remove_small_holes(scoremap_thresholded_padded, 1000)\n",
    "            scoremap_thresholded = scoremap_thresholded_padded[50:-50, 50:-50][:]\n",
    "\n",
    "            init_levelset = np.zeros((roi_height, roi_width))\n",
    "            init_levelset[inside_points_inroi[:,1], inside_points_inroi[:,0]] = 1.\n",
    "\n",
    "            msnake = morphsnakes.MorphACWE(scoremap_thresholded.astype(np.float), smoothing=smoothing, lambda1=1., lambda2=1.)\n",
    "\n",
    "            msnake.levelset = init_levelset.copy()\n",
    "            # levelset values are either 1.0 or 0.0\n",
    "\n",
    "            scoremap_roi2 = scoremap_roi.copy()\n",
    "            scoremap_roi2[scoremap_roi > 1.] = 1.\n",
    "            scoremap_layer_viz = img_as_ubyte(plt.cm.hot(scoremap_roi2)[..., :3])\n",
    "            scoremap_viz = img_as_ubyte(alpha_blending(scoremap_layer_viz,\n",
    "                                                       cropped_img[roi_ymin:roi_ymax+1, roi_xmin:roi_xmax+1],\n",
    "                                                       .3, 1))[..., :3]\n",
    "\n",
    "            dq = deque([None, None])\n",
    "            for i in range(1000): \n",
    "\n",
    "                # at stable stage, the levelset (thus contour) will oscilate, \n",
    "                # so instead of comparing to previous levelset, must compare to the one before the previous\n",
    "                oneBefore_levelset = dq.popleft()\n",
    "\n",
    "                if i > 10:\n",
    "                    if np.count_nonzero(msnake.levelset - oneBefore_levelset) < 3:\n",
    "                        break\n",
    "\n",
    "                dq.append(msnake.levelset)\n",
    "\n",
    "                msnake.step()\n",
    "\n",
    "            # in the final levelset, inside could be 0. or 1., hard to say        \n",
    "            edge_arr = np.r_[msnake.levelset[:,0], msnake.levelset[:,-1], msnake.levelset[0], msnake.levelset[-1]]        \n",
    "            pos_edge_num = np.count_nonzero(edge_arr)\n",
    "            bool_arr = msnake.levelset.astype(np.bool)\n",
    "\n",
    "            if pos_edge_num < len(edge_arr) - pos_edge_num:\n",
    "                mean_inside_score = scoremap_roi[bool_arr].mean()\n",
    "            else:\n",
    "                mean_inside_score = scoremap_roi[~bool_arr].mean()\n",
    "            print 'mean inside score:', mean_inside_score\n",
    "            print 'area:', np.count_nonzero(bool_arr)\n",
    "            print 'snake iteration:', i\n",
    "\n",
    "            if mean_inside_score < .3:\n",
    "                continue\n",
    "\n",
    "            new_cnts = find_contours(msnake.levelset, 0.5)\n",
    "            new_cnts = [c[:, ::-1] for c in new_cnts]\n",
    "\n",
    "            if len(new_cnts) == 0:\n",
    "                sys.stderr.write('No contour detected from snake levelset.\\n')\n",
    "                continue\n",
    "\n",
    "            all_cnt_points = np.concatenate(new_cnts)\n",
    "\n",
    "            new_cnt_subsampled = contour_to_concave_hull(all_cnt_points.astype(np.int), alpha=alpha)\n",
    "\n",
    "            if new_cnt_subsampled is None:\n",
    "                continue\n",
    "\n",
    "            area_lowerlim = 1000\n",
    "            area = Polygon(new_cnt_subsampled).area\n",
    "            if area < area_lowerlim:\n",
    "                sys.stderr.write('Concave hull area %d is too small.\\n' % area)\n",
    "                continue\n",
    "\n",
    "            new_cnt_subsampled = new_cnt_subsampled + (roi_xmin, roi_ymin)\n",
    "\n",
    "            new_lm = {}\n",
    "            new_lm['label'] = l\n",
    "            new_lm['vertices'] = new_cnt_subsampled.astype(np.int) * 8\n",
    "            new_lm['labelPos'] = new_lm['vertices'].mean(axis=0)\n",
    "            new_lm['refVertices'] = np.array(init_cnts[l]).copy() * 8\n",
    "            new_lm['subtype'] = PolygonType.CLOSED\n",
    "\n",
    "            new_res.append(new_lm)\n",
    "\n",
    "        ######################################\n",
    "\n",
    "        timestamp = datetime.datetime.now().strftime(\"%m%d%Y%H%M%S\")\n",
    "\n",
    "        autoAnnotation_filepath = autoAnnotations_dir + '/%(stack)s_%(sec)04d_autoAnnotate_%(timestamp)s_consolidated.pkl' % \\\n",
    "                            {'stack': stack, 'sec': sec, 'timestamp': timestamp}\n",
    "\n",
    "        pickle.dump(new_res, open(autoAnnotation_filepath, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15));\n",
    "plt.imshow(viz);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cnt = all_cnt_points.astype(np.int)\n",
    "\n",
    "xmin, ymin = cnt.min(axis=0)\n",
    "xmax, ymax = cnt.max(axis=0)\n",
    "h, w = (ymax-ymin+1, xmax-xmin+1)\n",
    "inside_ys, inside_xs =np.where(grid_points_in_poly((h, w), cnt[:, ::-1]-(ymin,xmin))) \n",
    "n = inside_ys.size\n",
    "random_indices = np.random.choice(range(n), min(1000, n), replace=False)\n",
    "inside_points = np.c_[inside_xs[random_indices], inside_ys[random_indices]]\n",
    "concave_hull = alpha_shape(inside_points, alpha=.01)\n",
    "concave_hull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_cnt_subsampled = contour_to_concave_hull(all_cnt_points.astype(np.int), alpha=.04)\n",
    "plt.scatter(new_cnt_subsampled[:,0], new_cnt_subsampled[:,1])\n",
    "plt.axis('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display(viz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
