{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Aligns a score volume with an annotation volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.environ['REPO_DIR'] + '/utilities')\n",
    "from utilities2015 import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import time\n",
    "\n",
    "import logging\n",
    "\n",
    "from registration_utilities import *\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = ['BackG', '5N', '7n', '7N', '12N', 'Pn', 'VLL', \n",
    "          '6N', 'Amb', 'R', 'Tz', 'RtTg', 'LRt', 'LC', 'AP', 'sp5']\n",
    "\n",
    "n_labels = len(labels)\n",
    "\n",
    "labels_index = dict((j, i) for i, j in enumerate(labels))\n",
    "\n",
    "labels_from_surround = dict( (l+'_surround', l) for l in labels[1:])\n",
    "\n",
    "labels_surroundIncluded_list = labels[1:] + [l+'_surround' for l in labels[1:]]\n",
    "labels_surroundIncluded = set(labels_surroundIncluded_list)\n",
    "\n",
    "labels_surroundIncluded_index = dict((j, i) for i, j in enumerate(labels_surroundIncluded_list))\n",
    "\n",
    "# colors = np.random.randint(0, 255, (len(labels_index), 3))\n",
    "colors = np.loadtxt(os.environ['REPO_DIR'] + '/visualization/100colors.txt')\n",
    "colors[labels_index['BackG']] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "volume_dir = '/oasis/projects/nsf/csd395/yuncong/CSHL_volumes/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(405.0, 202.5, 267.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load atlas: 1.196872 seconds\n"
     ]
    }
   ],
   "source": [
    "volume1 = bp.unpack_ndarray_file(os.path.join(volume_dir, 'volume_MD589_annotation.bp'))\n",
    "\n",
    "def parallel_where(l):\n",
    "    w = np.where(volume1 == l)\n",
    "    return np.array([w[1].astype(np.int16), w[0].astype(np.int16), w[2].astype(np.int16)]).T\n",
    "\n",
    "t = time.time()\n",
    "\n",
    "atlas_nzs = Parallel(n_jobs=16)(delayed(parallel_where)(l) for l in range(1, n_labels))\n",
    "\n",
    "sys.stderr.write('load atlas: %f seconds\\n' % (time.time() - t))\n",
    "\n",
    "# atlas_xmin, atlas_ymin, atlas_zmin = np.min([np.min(atlas_nzs[l-1], axis=0) for l in range(1, n_labels)], axis=0)\n",
    "# atlas_xmax, atlas_ymax, atlas_zmax = np.max([np.max(atlas_nzs[l-1], axis=0) for l in range(1, n_labels)], axis=0)\n",
    "\n",
    "# atlas_centroid = np.array([.5*atlas_xmin+.5*atlas_xmax, .5*atlas_ymin+.5*atlas_ymax, .5*atlas_zmin+.5*atlas_zmax])\n",
    "# print atlas_centroid\n",
    "\n",
    "atlas_ydim, atlas_xdim, atlas_zdim = volume1.shape\n",
    "atlas_centroid = (.5*atlas_xdim, .5*atlas_ydim, .5*atlas_zdim)\n",
    "print atlas_centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "atlas_vol_xmin, atlas_vol_xmax, atlas_vol_ymin, atlas_vol_ymax, atlas_vol_zmin, atlas_vol_zmax = \\\n",
    "np.loadtxt(os.path.join(volume_dir, 'volume_MD589_annotation_limits.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "downsample_factor = 16\n",
    "\n",
    "section_thickness = 20 # in um\n",
    "xy_pixel_distance_lossless = 0.46\n",
    "xy_pixel_distance_tb = xy_pixel_distance_lossless * 32 # in um, thumbnail\n",
    "# factor = section_thickness/xy_pixel_distance_lossless\n",
    "\n",
    "xy_pixel_distance_downsampled = xy_pixel_distance_lossless * downsample_factor\n",
    "z_xy_ratio_downsampled = section_thickness / xy_pixel_distance_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from annotation_utilities import *\n",
    "label_polygons = load_label_polygons_if_exists(stack='MD589', username='yuncong', force=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "annotation_on_sections = get_annotation_on_sections(label_polygons=label_polygons, \n",
    "                                                    filtered_labels=labels_surroundIncluded)\n",
    "\n",
    "landmark_range_limits = get_landmark_range_limits(stack='MD589', label_polygons=label_polygons, \n",
    "                                                  filtered_labels=labels_surroundIncluded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "landmark_zlimits = {l: [(int(z_xy_ratio_downsampled*e1) - atlas_vol_zmin, \n",
    "                         int(z_xy_ratio_downsampled*e2) -1 - atlas_vol_zmin) for e1, e2 in ranges] \n",
    "                    for l, ranges in landmark_range_limits.iteritems()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "landmark_zlimits_twoSides = {}\n",
    "for l in range(1, n_labels):\n",
    "    zlimits = landmark_zlimits[labels[l]]\n",
    "    if len(zlimits) == 2:\n",
    "        landmark_zlimits_twoSides[labels[l] + '_L'] = zlimits[0]\n",
    "        landmark_zlimits_twoSides[labels[l] + '_R'] = zlimits[1]\n",
    "    elif len(zlimits) == 1:\n",
    "        landmark_zlimits_twoSides[labels[l]] = zlimits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'12N': (204.0, 315.0),\n",
       " '5N_L': (52.0, 108.0),\n",
       " '5N_R': (424.0, 491.0),\n",
       " '6N': (202.0, 222.0),\n",
       " '7N_L': (58.0, 173.0),\n",
       " '7N_R': (392.0, 502.0),\n",
       " '7n_L': (49.0, 198.0),\n",
       " '7n_R': (343.0, 502.0),\n",
       " 'AP': (229.0, 277.0),\n",
       " 'Amb_L': (90.0, 105.0),\n",
       " 'Amb_R': (446.0, 456.0),\n",
       " 'LC_L': (120.0, 144.0),\n",
       " 'LC_R': (370.0, 385.0),\n",
       " 'LRt_L': (82.0, 154.0),\n",
       " 'LRt_R': (416.0, 475.0),\n",
       " 'Pn_L': (120.0, 266.0),\n",
       " 'Pn_R': (308.0, 442.0),\n",
       " 'R_L': (153.0, 228.0),\n",
       " 'R_R': (291.0, 309.0),\n",
       " 'RtTg': (161.0, 399.0),\n",
       " 'Tz_L': (180.0, 239.0),\n",
       " 'Tz_R': (324.0, 394.0),\n",
       " 'VLL_L': (33.0, 114.0),\n",
       " 'VLL_R': (443.0, 494.0),\n",
       " 'sp5': (0.0, 532.0)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmark_zlimits_twoSides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "atlas_nzs_twoSides = {}\n",
    "for name, (z_begin, z_end) in landmark_zlimits_twoSides.iteritems():\n",
    "    \n",
    "    if '_' in name:\n",
    "        l = labels_index[name[:-2]]\n",
    "    else:\n",
    "        l = labels_index[name]\n",
    "    \n",
    "    nzs = atlas_nzs[l-1]\n",
    "    atlas_nzs_twoSides[name] = nzs[(nzs[:,2] >= z_begin) & (nzs[:,2] <= z_end)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LRt_R', 'Pn_L', '7N_R', 'VLL_L', 'VLL_R', '7N_L', 'RtTg', 'Pn_R', 'LRt_L', '12N', '5N_L', 'sp5', 'AP', '5N_R', 'Amb_R', 'LC_R', 'R_R', '7n_R', '6N', 'Tz_L', 'Tz_R', '7n_L', 'R_L', 'LC_L', 'Amb_L']\n"
     ]
    }
   ],
   "source": [
    "print atlas_nzs_twoSides.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load test volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stack = 'MD590'\n",
    "\n",
    "atlasAlignParams_dir = '/oasis/projects/nsf/csd395/yuncong/CSHL_atlasAlignParams'\n",
    "\n",
    "with open(atlasAlignParams_dir + '/%(stack)s/%(stack)s_3dAlignParams.txt' % {'stack': stack}, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "T_final = np.array(map(float, lines[1].strip().split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(volume_xmin, volume_xmax, volume_ymin, volume_ymax, volume_zmin, volume_zmax) = \\\n",
    "np.loadtxt(os.path.join(volume_dir, 'volume_%(stack)s_scoreMap_limits.txt' % {'stack': stack}), dtype=np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load scoremap 5N: 2.488530 seconds\n",
      "load scoremap 7n: 2.328740 seconds\n",
      "load scoremap 7N: 2.407773 seconds\n",
      "load scoremap 12N: 2.367779 seconds\n",
      "load scoremap Pn: 2.564324 seconds\n",
      "load scoremap VLL: 2.863343 seconds\n",
      "load scoremap 6N: 2.365795 seconds\n",
      "load scoremap Amb: 2.406504 seconds\n",
      "load scoremap R: 3.186677 seconds\n",
      "load scoremap Tz: 2.332328 seconds\n",
      "load scoremap RtTg: 2.588118 seconds\n",
      "load scoremap LRt: 2.442694 seconds\n",
      "load scoremap LC: 2.405664 seconds\n",
      "load scoremap AP: 2.331292 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "820 469 397\n",
      "(410.0, 234.5, 234.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load scoremap sp5: 2.600098 seconds\n"
     ]
    }
   ],
   "source": [
    "global volume2_allLabels\n",
    "# volume2_allLabels = []\n",
    "volume2_allLabels = np.empty((n_labels-1, volume_ymax-volume_ymin+1, volume_xmax-volume_xmin+1, volume_zmax-volume_zmin+1), \n",
    "         dtype=np.float16) # use float32 is faster than float16 (2.5s/landmark), maybe because bp files are stored using float32\n",
    "\n",
    "for l in range(1, n_labels):\n",
    "\n",
    "    t = time.time()\n",
    "\n",
    "    volume2 = bp.unpack_ndarray_file(os.path.join(volume_dir, 'volume_%(stack)s_scoreMap_%(label)s.bp' % \\\n",
    "                                                  {'stack': stack, 'label': labels[l]}))\n",
    "\n",
    "    volume2_cropped = volume2[volume_ymin:volume_ymax+1, volume_xmin:volume_xmax+1]\n",
    "    # copy is important, because then you can delete the large array\n",
    "\n",
    "    volume2_allLabels[l-1] = volume2_cropped.copy()\n",
    "    \n",
    "#     volume2_allLabels.append(volume2_cropped.copy())\n",
    "\n",
    "    del volume2, volume2_cropped\n",
    "    \n",
    "    sys.stderr.write('load scoremap %s: %f seconds\\n' % (labels[l], time.time() - t)) # ~2.5s\n",
    "\n",
    "test_ydim, test_xdim, test_zdim = volume2_allLabels[0].shape\n",
    "test_centroid = (.5*test_xdim, .5*test_ydim, .5*test_ydim)\n",
    "test_cx, test_cy, test_cz = test_centroid\n",
    "\n",
    "print test_xdim, test_ydim, test_zdim\n",
    "print test_centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del dSdxyz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gradient 5N: 25.260826 seconds\n",
      "store 5N: 3.898045 seconds\n",
      "gradient 7n: 24.966540 seconds\n",
      "store 7n: 3.791497 seconds\n",
      "gradient 7N: 25.144790 seconds\n",
      "store 7N: 3.863565 seconds\n",
      "gradient 12N: 25.924368 seconds\n",
      "store 12N: 3.800498 seconds\n",
      "gradient Pn: 25.307048 seconds\n",
      "store Pn: 3.860661 seconds\n",
      "gradient VLL: 25.371451 seconds\n",
      "store VLL: 4.008324 seconds\n",
      "gradient 6N: 24.927751 seconds\n",
      "store 6N: 3.787949 seconds\n",
      "gradient Amb: 25.044733 seconds\n",
      "store Amb: 3.803134 seconds\n",
      "gradient R: 25.218576 seconds\n",
      "store R: 3.928529 seconds\n",
      "gradient Tz: 25.175845 seconds\n",
      "store Tz: 3.825253 seconds\n",
      "gradient RtTg: 25.678547 seconds\n",
      "store RtTg: 4.027368 seconds\n",
      "gradient LRt: 25.482600 seconds\n",
      "store LRt: 3.897548 seconds\n",
      "gradient LC: 25.438553 seconds\n",
      "store LC: 3.965837 seconds\n",
      "gradient AP: 25.373958 seconds\n",
      "store AP: 3.841350 seconds\n",
      "gradient sp5: 26.116564 seconds\n",
      "store sp5: 3.995572 seconds\n",
      "overall: 438.740719 seconds\n"
     ]
    }
   ],
   "source": [
    "dSdxyz = np.empty((n_labels-1, 3) + volume2_allLabels[0].shape, dtype=np.float16) \n",
    "\n",
    "# if memory is not limited, using float32 is faster, because the output of np.gradient is of type float32\n",
    "# time for storing output: float16 4s (due to dtype conversion overhead), float32 1s\n",
    "\n",
    "# using float16 avoids memory issues that make gradient computation utterly slow, 30s vs. 4s\n",
    "\n",
    "################# COMPUTE GRADIENTS ######################\n",
    "\n",
    "# dSdxyz = {}\n",
    "# DO NOT use python list because python will use contiguous memory for it\n",
    "# http://stackoverflow.com/questions/12274060/does-python-use-linked-lists-for-lists-why-is-inserting-slow  \n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "for l in range(1, n_labels):\n",
    "\n",
    "    t = time.time()\n",
    "    \n",
    "    gy, gx, gz = np.gradient(volume2_allLabels[l-1], 3, 3, 3) # 3.3 second, much faster than loading\n",
    "    # if memory is limited, this will be very slow\n",
    "    \n",
    "    sys.stderr.write('gradient %s: %f seconds\\n' % (labels[l], time.time() - t))\n",
    "    \n",
    "    t = time.time()\n",
    "    \n",
    "    dSdxyz[l-1, 0] = gx\n",
    "    dSdxyz[l-1, 1] = gy\n",
    "    dSdxyz[l-1, 2] = gz\n",
    "    \n",
    "#     dSdxyz[labels[l]] = np.array([gx, gy, gz]) # use np.array is better; using python list also causes contiguous memory overhead\n",
    "    \n",
    "#     del gx, gy, gz # does not make a difference\n",
    "    \n",
    "    sys.stderr.write('store %s: %f seconds\\n' % (labels[l], time.time() - t))\n",
    "    \n",
    "sys.stderr.write('overall: %f seconds\\n' % (time.time() - t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# memory size for storing the gradients\n",
    "print dSdxyz.size * dSdxyz.dtype.itemsize / 1024**3, 'GB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_points(T, pts=None, c=None, pts_centered=None, c_prime=0):\n",
    "    '''\n",
    "    T: 1x12 vector\n",
    "    c: center of volume 1\n",
    "    c_prime: center of volume 2\n",
    "    pts: nx3\n",
    "    '''\n",
    "    \n",
    "    if pts_centered is None:\n",
    "        pts_centered = pts - c\n",
    "    \n",
    "    Tm = np.reshape(T, (3,4))\n",
    "    t = Tm[:, 3]\n",
    "    A = Tm[:, :3]\n",
    "        \n",
    "    pts_prime = np.dot(A, pts_centered.T) + (t + c_prime)[:,None]\n",
    "        \n",
    "    return pts_prime.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "atlas_nzs2_twoSides = {name: transform_points(T_final, pts=nzs, c=atlas_centroid, \n",
    "                                              c_prime=test_centroid).astype(np.int16) \n",
    "                       for name, nzs in atlas_nzs_twoSides.iteritems()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def matrix_exp(w):\n",
    "    \n",
    "    wx, wy, wz = w\n",
    "    w_skew = np.array([[0, -wz, wy], [wz, 0, -wx], [-wy, wx, 0]])\n",
    "    \n",
    "    theta = np.sqrt(np.sum(w**2))\n",
    "    \n",
    "    exp_w = np.eye(3) + np.sin(theta)/theta*w_skew + (1-np.cos(theta))/theta**2*np.dot(w_skew, w_skew)\n",
    "    return exp_w\n",
    "\n",
    "def matrix_exp_v(v):\n",
    "    t = v[:3]\n",
    "    w = v[3:]\n",
    "    \n",
    "    theta = np.sqrt(np.sum(w**2))\n",
    "    \n",
    "    wx, wy, wz = w\n",
    "    w_skew = np.array([[0, -wz, wy], [wz, 0, -wx], [-wy, wx, 0]])\n",
    "    exp_w = np.eye(3) + np.sin(theta)/theta*w_skew + (1-np.cos(theta))/(theta**2)*np.dot(w_skew, w_skew)\n",
    "    \n",
    "    V = np.eye(3) + (1-np.cos(theta))/(theta**2)*w_skew + (theta-np.sin(theta))/(theta**3)*np.dot(w_skew, w_skew)\n",
    "    \n",
    "    return exp_w, np.dot(V, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Some Hessian codes\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "from scipy.optimize import approx_fprime\n",
    "\n",
    "def hessian ( x0, f, epsilon=1.e-5, linear_approx=False, *args ):\n",
    "    \"\"\"\n",
    "    A numerical approximation to the Hessian matrix of cost function at\n",
    "    location x0 (hopefully, the minimum)\n",
    "    \"\"\"\n",
    "    # ``calculate_cost_function`` is the cost function implementation\n",
    "    # The next line calculates an approximation to the first\n",
    "    # derivative\n",
    "    f1 = approx_fprime( x0, f, epsilon, *args) \n",
    "\n",
    "    # This is a linear approximation. Obviously much more efficient\n",
    "    # if cost function is linear\n",
    "    if linear_approx:\n",
    "        f1 = np.matrix(f1)\n",
    "        return f1.transpose() * f1    \n",
    "    # Allocate space for the hessian\n",
    "    n = x0.shape[0]\n",
    "    hessian = np.zeros ( ( n, n ) )\n",
    "    # The next loop fill in the matrix\n",
    "    xx = x0\n",
    "    for j in xrange( n ):\n",
    "        xx0 = xx[j] # Store old value\n",
    "        xx[j] = xx0 + epsilon[j] # Perturb with finite difference\n",
    "        # Recalculate the partial derivatives for this new point\n",
    "        f2 = approx_fprime( x0, f, epsilon, *args) \n",
    "        hessian[:, j] = (f2 - f1)/epsilon[j] # scale...\n",
    "        xx[j] = xx0 # Restore initial value of x0        \n",
    "    return hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_transform(T, name):\n",
    "    \n",
    "    pts_prime = transform_points(T, pts_centered=pts2_centered[name], c_prime=test_centroid2)\n",
    "    \n",
    "    if '_' in name:\n",
    "        l = labels_index[name[:-2]]\n",
    "    else:\n",
    "        l = labels_index[name]\n",
    "        \n",
    "    xs_prime = pts_prime[:,0]\n",
    "    ys_prime = pts_prime[:,1]\n",
    "    zs_prime = pts_prime[:,2]\n",
    "    \n",
    "    valid = (xs_prime >= 0) & (ys_prime >= 0) & (zs_prime >= 0) & \\\n",
    "            (xs_prime < test_xdim) & (ys_prime < test_ydim) & (zs_prime < test_zdim)\n",
    "            \n",
    "    assert np.count_nonzero(valid) > 0, 'No valid pixel after transform: %s' % name\n",
    "    \n",
    "    xs_prime_valid = xs_prime[valid].astype(np.int16)\n",
    "    ys_prime_valid = ys_prime[valid].astype(np.int16)\n",
    "    zs_prime_valid = zs_prime[valid].astype(np.int16)\n",
    "    \n",
    "    voxel_probs_valid = volume2_allLabels[l-1, ys_prime_valid, xs_prime_valid, zs_prime_valid] / 1e6\n",
    "    score = voxel_probs_valid.sum()\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def step(T, name, lr, verbose=False, num_samples=1000):\n",
    "    '''\n",
    "    T: 1x12 vector\n",
    "    l: landmark class label\n",
    "    '''\n",
    "    \n",
    "    pts_prime = transform_points(T, pts_centered=pts2_centered[name], c_prime=test_centroid2)\n",
    "    \n",
    "    if '_' in name:\n",
    "        l = labels_index[name[:-2]]\n",
    "    else:\n",
    "        l = labels_index[name]\n",
    "        \n",
    "    xs_prime = pts_prime[:,0]\n",
    "    ys_prime = pts_prime[:,1]\n",
    "    zs_prime = pts_prime[:,2]\n",
    "    \n",
    "    valid = (xs_prime >= 0) & (ys_prime >= 0) & (zs_prime >= 0) & \\\n",
    "            (xs_prime < test_xdim) & (ys_prime < test_ydim) & (zs_prime < test_zdim)\n",
    "    \n",
    "    if verbose:\n",
    "        print 'nz', np.count_nonzero(valid) \n",
    "        \n",
    "    assert np.count_nonzero(valid) > 0, 'No valid pixel after transform: %s' % name\n",
    "    \n",
    "    xs_prime_valid = xs_prime[valid].astype(np.int16)\n",
    "    ys_prime_valid = ys_prime[valid].astype(np.int16)\n",
    "    zs_prime_valid = zs_prime[valid].astype(np.int16)\n",
    "    \n",
    "    voxel_probs_valid = volume2_allLabels[l-1, ys_prime_valid, xs_prime_valid, zs_prime_valid] / 1e6\n",
    "    score = voxel_probs_valid.sum()\n",
    "    \n",
    "    if num_samples is not None:\n",
    "        # sample some voxels # this seems to make optimization more stable than using all voxels\n",
    "    \n",
    "        ii = np.random.choice(range(np.count_nonzero(valid)), min(num_samples, np.count_nonzero(valid)), \n",
    "                              replace=False)\n",
    "\n",
    "        dSdx = dSdxyz[l-1, 0, ys_prime_valid, xs_prime_valid, zs_prime_valid][ii]\n",
    "        dSdy = dSdxyz[l-1, 1, ys_prime_valid, xs_prime_valid, zs_prime_valid][ii]\n",
    "        dSdz = dSdxyz[l-1, 2, ys_prime_valid, xs_prime_valid, zs_prime_valid][ii]\n",
    "\n",
    "        xss = xs_prime[valid].astype(np.float)[ii]\n",
    "        yss = ys_prime[valid].astype(np.float)[ii]\n",
    "        zss = zs_prime[valid].astype(np.float)[ii]\n",
    "        \n",
    "    else:\n",
    "        # use all voxels    \n",
    "        dSdx = dSdxyz[l-1, 0, ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "        dSdy = dSdxyz[l-1, 1, ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "        dSdz = dSdxyz[l-1, 2, ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "\n",
    "        xss = xs_prime[valid].astype(np.float)\n",
    "        yss = ys_prime[valid].astype(np.float)\n",
    "        zss = zs_prime[valid].astype(np.float)\n",
    "\n",
    "    #############################################\n",
    "    \n",
    "    dMdv = np.c_[dSdx, dSdy, dSdz, \n",
    "                 -dSdy*zss + dSdz*yss, \n",
    "                 dSdx*zss - dSdz*xss,\n",
    "                 -dSdx*yss + dSdy*xss].sum(axis=0)\n",
    "\n",
    "    if verbose:\n",
    "        print 'dMdv:', dMdv\n",
    "        print 'score:', score\n",
    "\n",
    "#     lr = np.array([0, 0, 0, 0, 0, 1e-2])\n",
    "    global dMdv_historical\n",
    "    dMdv_historical += dMdv**2\n",
    "    dMdv_adjusted = dMdv / (1e-10 + np.sqrt(dMdv_historical))\n",
    "    v_opt = lr * dMdv_adjusted # no minus sign because maximizing\n",
    "\n",
    "#     global iteration\n",
    "#     lr = np.array([0, 0, 0, 0, 0, 1e-7])\n",
    "#     v_opt = lr * np.exp(-iteration/1000.) * dMdv # no minus sign because maximizing\n",
    "#     v_opt = lr * dMdv # no minus sign because maximizing\n",
    "\n",
    "    if verbose:\n",
    "        print 'v_opt:', v_opt\n",
    "\n",
    "    theta = np.sqrt(np.sum(v_opt[3:]**2))\n",
    "    if verbose:\n",
    "        print 'theta:', theta\n",
    "    assert theta < np.pi\n",
    "        \n",
    "    exp_w, Vt = matrix_exp_v(v_opt)\n",
    "    \n",
    "    if verbose:\n",
    "        print 'Vt:' , Vt\n",
    "    \n",
    "    Tm = np.reshape(T, (3,4))\n",
    "    t = Tm[:, 3]\n",
    "    R = Tm[:, :3]\n",
    "                        \n",
    "    R_new = np.dot(exp_w, R)\n",
    "    t_new = np.dot(exp_w, t) + Vt\n",
    "    \n",
    "    if verbose:\n",
    "        print '\\n'\n",
    "\n",
    "    return np.column_stack([R_new, t_new]).flatten(), score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### all landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params_dir = create_if_not_exists(atlasAlignParams_dir + '/' + stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hessian_allLandmarks = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LRt_R\n",
      "Pn_L\n",
      "7N_R\n",
      "VLL_L\n",
      "VLL_R\n",
      "7N_L\n",
      "RtTg\n",
      "Pn_R\n",
      "LRt_L\n",
      "12N\n",
      "5N_L\n",
      "sp5\n",
      "AP\n",
      "5N_R\n",
      "Amb_R\n",
      "LC_R\n",
      "R_R\n",
      "7n_R\n",
      "6N\n",
      "Tz_L\n",
      "Tz_R\n",
      "7n_L\n",
      "R_L\n",
      "LC_L\n",
      "Amb_L\n"
     ]
    }
   ],
   "source": [
    "history_len = 100\n",
    "T0 = np.array([1,0,0,0,0,1,0,0,0,0,1,0])\n",
    "max_iter = 100\n",
    "# max_iter = 5000\n",
    "\n",
    "# for name_of_interest in ['12N']:\n",
    "for name_of_interest in atlas_nzs_twoSides.keys():\n",
    "    \n",
    "    print name_of_interest\n",
    "    \n",
    "    # set the rotation center of both atlas and test volume to the landmark centroid after affine projection\n",
    "    \n",
    "    atlas_centroid2 = atlas_nzs2_twoSides[name_of_interest].mean(axis=0)\n",
    "    test_centroid2 = atlas_centroid2.copy()\n",
    "    pts2_centered = {name: nzs - atlas_centroid2 for name, nzs in atlas_nzs2_twoSides.iteritems()}\n",
    "    \n",
    "    ############ gradient descent ############\n",
    "\n",
    "    dMdv_historical = np.zeros((6,))\n",
    "\n",
    "    score_best = 0\n",
    "    scores = []\n",
    "    \n",
    "    T = T0.copy()\n",
    "\n",
    "    for iteration in range(max_iter):\n",
    "        \n",
    "        success = False\n",
    "        c = 0\n",
    "        while not success and c < 10:\n",
    "            try:\n",
    "                c += 1\n",
    "                T, s = step(T, name=name_of_interest, lr=np.array([1,1,1,1e-2,1e-2,1e-2]), verbose=False,\n",
    "                            num_samples=10000)\n",
    "                success = True\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "#         H = hessian(T, lambda x: score_transform(x, name_of_interest), epsilon=np.array([1e-1, 1e-1, 1e-1, 5,\n",
    "#                                                                                 1e-1, 1e-1, 1e-1, 5,\n",
    "#                                                                                 1e-1, 1e-1, 1e-1, 5]))\n",
    "#         print H.diagonal()[[3,7,11]]\n",
    "#         print H.diagonal()\n",
    "#         print np.sum(H.diagonal()[[3, 7, 11]])\n",
    "            \n",
    "        scores.append(s)\n",
    "\n",
    "        if iteration > 2*history_len:\n",
    "            if np.abs(np.mean(scores[iteration-history_len:iteration]) - \\\n",
    "                      np.mean(scores[iteration-2*history_len:iteration-history_len])) < 1e-4:\n",
    "                break\n",
    "\n",
    "        if s > score_best:\n",
    "            best_gradient_descent_params = T\n",
    "            score_best = s\n",
    "    \n",
    "    H = hessian(T, lambda x: score_transform(x, name_of_interest), epsilon=np.array([1e-1, 1e-1, 1e-1, 5,\n",
    "                                                                                1e-1, 1e-1, 1e-1, 5,\n",
    "                                                                                1e-1, 1e-1, 1e-1, 5]))\n",
    "    hessian_allLandmarks[name_of_interest] = H.diagonal()\n",
    "    \n",
    "#     print np.sum(H.diagonal())\n",
    "    \n",
    "#     print score_best\n",
    "#     print best_gradient_descent_params.reshape((3,4))\n",
    "\n",
    "#     print scores[0]\n",
    "#     print scores[-1]\n",
    "\n",
    "#     plt.plot(scores);\n",
    "#     plt.show();\n",
    "    \n",
    "#     with open(params_dir + '%(stack)s/%(stack)s_%(name)s_transformUponAffineProjection.txt' % {'stack': stack, 'name': name_of_interest}, \n",
    "#               'w') as f:\n",
    "#         f.write((' '.join(['%f']*12)+'\\n') % tuple(best_gradient_descent_params))\n",
    "#         f.write((' '.join(['%f']*3)+'\\n') % tuple(atlas_centroid2))\n",
    "#         f.write((' '.join(['%f']*3)+'\\n') % tuple(test_centroid2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del dSdxyz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parameters_allLandmarks = {}\n",
    "atlas_centroid_allLandmarks = {}\n",
    "test_centroid_allLandmarks = {}\n",
    "\n",
    "for name in atlas_nzs_twoSides.keys():\n",
    "    \n",
    "    with open(atlasAlignParams_dir + '/%(stack)s/%(stack)s_%(name)s_transformUponAffineProjection.txt' % \\\n",
    "                        {'stack': stack, 'name': name}, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        params = np.array(map(float, lines[0].strip().split()))\n",
    "        atlas_c = np.array(map(float, lines[1].strip().split()))\n",
    "        test_c = np.array(map(float, lines[2].strip().split()))\n",
    "    \n",
    "    parameters_allLandmarks[name] = params\n",
    "    atlas_centroid_allLandmarks[name] = atlas_c\n",
    "    test_centroid_allLandmarks[name] = test_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "################# PROJECT ATLAS TO IMAGE ######################\n",
    "\n",
    "atlas_nzs_projected_to_test = {name: transform_points(parameters_allLandmarks[name], pts=nzs, \n",
    "                                                      c=atlas_centroid_allLandmarks[name], \n",
    "                                                      c_prime=test_centroid_allLandmarks[name]).astype(np.int16)\n",
    "                               for name, nzs in atlas_nzs2_twoSides.iteritems()}\n",
    "\n",
    "test_volume_atlas_projected = np.zeros(volume2_allLabels.shape[1:], np.int16)\n",
    "\n",
    "for name in atlas_nzs_twoSides.keys():\n",
    "\n",
    "    test_xs = atlas_nzs_projected_to_test[name][:,0]\n",
    "    test_ys = atlas_nzs_projected_to_test[name][:,1]\n",
    "    test_zs = atlas_nzs_projected_to_test[name][:,2]\n",
    "\n",
    "    valid = (test_xs >= 0) & (test_ys >= 0) & (test_zs >= 0) & \\\n",
    "            (test_xs < test_xdim) & (test_ys < test_ydim) & (test_zs < test_zdim)\n",
    "\n",
    "    atlas_xs = atlas_nzs_twoSides[name][:,0]\n",
    "    atlas_ys = atlas_nzs_twoSides[name][:,1]\n",
    "    atlas_zs = atlas_nzs_twoSides[name][:,2]\n",
    "        \n",
    "    test_volume_atlas_projected[test_ys[valid], test_xs[valid], test_zs[valid]] = \\\n",
    "    volume1[atlas_ys[valid], atlas_xs[valid], atlas_zs[valid]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dm = DataManager(stack=stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "section_bs_begin, section_bs_end = section_range_lookup[stack]\n",
    "print section_bs_begin, section_bs_end\n",
    "\n",
    "map_z_to_section = {}\n",
    "for s in range(section_bs_begin, section_bs_end+1):\n",
    "    for z in range(int(z_xy_ratio_downsampled*s) - volume_zmin, int(z_xy_ratio_downsampled*(s+1)) - volume_zmin + 1):\n",
    "        map_z_to_section[z] = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "annotationsViz_rootdir = '/home/yuncong/csd395/CSHL_annotaionsIndividual3DShiftedViz/'\n",
    "annotationsViz_dir = create_if_not_exists(annotationsViz_rootdir + '/' + stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# z_begin = atlas_nzs_projected_to_test[name_of_interest][:,2].min()\n",
    "# z_end = atlas_nzs_projected_to_test[name_of_interest][:,2].max()\n",
    "\n",
    "# for z in range(int(z_begin), int(z_end), 10):\n",
    "\n",
    "# for z in range(0, test_zdim, 10):\n",
    "for z in [180]:\n",
    "    \n",
    "\n",
    "    dm.set_slice(map_z_to_section[z])\n",
    "    dm._load_image(versions=['rgb-jpg'])\n",
    "    viz = dm.image_rgb_jpg[::downsample_factor, ::downsample_factor][volume_ymin:volume_ymax+1, \n",
    "                                                                     volume_xmin:volume_xmax+1].copy()\n",
    "\n",
    "    projected_cnts = find_contour_points(test_volume_atlas_projected[...,z])\n",
    "\n",
    "    for label_ind, cnts in projected_cnts.iteritems():\n",
    "        for cnt in cnts:\n",
    "            cv2.polylines(viz, [cnt.astype(np.int)], True, tuple((colors[label_ind]*255).astype(np.int)), 2)\n",
    "\n",
    "#     plt.figure(figsize=(10, 10));\n",
    "#     plt.title('z = %d' % z)\n",
    "#     plt.imshow(viz)\n",
    "#     plt.show()\n",
    "    \n",
    "    cv2.imwrite(annotationsViz_dir + '/%(stack)s_%(sec)04d_annotaionsIndividual3DShiftedViz_z%(z)04d.jpg' % \\\n",
    "                {'stack': stack, 'sec': map_z_to_section[z], 'z': z}, \n",
    "                img_as_ubyte(viz[..., [2,1,0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
