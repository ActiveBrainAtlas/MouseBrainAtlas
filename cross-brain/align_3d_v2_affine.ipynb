{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Aligns a score volume with an annotation volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.environ['REPO_DIR'] + '/utilities')\n",
    "from utilities2015 import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import time\n",
    "\n",
    "import logging\n",
    "\n",
    "from registration_utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = ['BackG', '5N', '7n', '7N', '12N', 'Pn', 'VLL', \n",
    "          '6N', 'Amb', 'R', 'Tz', 'RtTg', 'LRt', 'LC', 'AP', 'sp5']\n",
    "\n",
    "n_labels = len(labels)\n",
    "\n",
    "labels_index = dict((j, i) for i, j in enumerate(labels))\n",
    "\n",
    "labels_from_surround = dict( (l+'_surround', l) for l in labels[1:])\n",
    "\n",
    "labels_surroundIncluded_list = labels[1:] + [l+'_surround' for l in labels[1:]]\n",
    "labels_surroundIncluded = set(labels_surroundIncluded_list)\n",
    "\n",
    "labels_surroundIncluded_index = dict((j, i) for i, j in enumerate(labels_surroundIncluded_list))\n",
    "\n",
    "# colors = np.random.randint(0, 255, (len(labels_index), 3))\n",
    "colors = np.loadtxt(os.environ['REPO_DIR'] + '/visualization/100colors.txt')\n",
    "colors[labels_index['BackG']] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "volume_dir = '/oasis/projects/nsf/csd395/yuncong/CSHL_volumes/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "volume1 = bp.unpack_ndarray_file(os.path.join(volume_dir, 'volume_MD589_annotation.bp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.20207500458 seconds\n",
      "(405.0, 202.5, 267.0)\n"
     ]
    }
   ],
   "source": [
    "def parallel_where(l):\n",
    "    w = np.where(volume1 == l)\n",
    "    return np.array([w[1].astype(np.int16), w[0].astype(np.int16), w[2].astype(np.int16)]).T\n",
    "\n",
    "t = time.time()\n",
    "\n",
    "atlas_nzs = Parallel(n_jobs=16)(delayed(parallel_where)(l) for l in range(1, n_labels))\n",
    "\n",
    "print time.time() - t, 'seconds'\n",
    "\n",
    "# atlas_xmin, atlas_ymin, atlas_zmin = np.min([np.min(atlas_nzs[l-1], axis=1) for l in range(1, n_labels)], axis=0)\n",
    "# atlas_xmax, atlas_ymax, atlas_zmax = np.max([np.max(atlas_nzs[l-1], axis=1) for l in range(1, n_labels)], axis=0)\n",
    "# print atlas_xmin, atlas_xmax, atlas_ymin, atlas_ymax, atlas_zmin, atlas_zmax\n",
    "\n",
    "# atlas_centroid = np.array([.5*atlas_xmin+.5*atlas_xmax, .5*atlas_ymin+.5*atlas_ymax, .5*atlas_zmin+.5*atlas_zmax])\n",
    "# print atlas_centroid\n",
    "\n",
    "# atlas_cx, atlas_cy, atlas_cz = atlas_centroid\n",
    "\n",
    "atlas_ydim, atlas_xdim, atlas_zdim = volume1.shape\n",
    "atlas_centroid = (.5*atlas_xdim, .5*atlas_ydim, .5*atlas_zdim)\n",
    "print atlas_centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "downsample_factor = 16\n",
    "\n",
    "section_thickness = 20 # in um\n",
    "xy_pixel_distance_lossless = 0.46\n",
    "xy_pixel_distance_tb = xy_pixel_distance_lossless * 32 # in um, thumbnail\n",
    "# factor = section_thickness/xy_pixel_distance_lossless\n",
    "\n",
    "xy_pixel_distance_downsampled = xy_pixel_distance_lossless * downsample_factor\n",
    "z_xy_ratio_downsampled = section_thickness / xy_pixel_distance_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "atlasAlignOptLogs_dir = '/oasis/projects/nsf/csd395/yuncong/CSHL_atlasAlignOptLogs'\n",
    "if not os.path.exists(atlasAlignOptLogs_dir):\n",
    "    os.makedirs(atlasAlignOptLogs_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "atlasAlignParams_dir = '/oasis/projects/nsf/csd395/yuncong/CSHL_atlasAlignParams'\n",
    "if not os.path.exists(atlasAlignParams_dir):\n",
    "    os.makedirs(atlasAlignParams_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "annotationsViz_rootdir = '/oasis/projects/nsf/csd395/yuncong/CSHL_annotaionsPojectedViz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "volume2_allLabels = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ds = []\n",
    "for l in range(1, n_labels):\n",
    "    ds.append(np.array(atlas_nzs[l-1]) - atlas_centroid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_points(T, pts=None, c=None, pts_centered=None, c_prime=0):\n",
    "    '''\n",
    "    T: 1x12 vector\n",
    "    c: center of volume 1\n",
    "    c_prime: center of volume 2\n",
    "    pts: nx3\n",
    "    '''\n",
    "    \n",
    "    if pts_centered is None:\n",
    "        pts_centered = pts - c\n",
    "    \n",
    "    Tm = np.reshape(T, (3,4))\n",
    "    t = Tm[:, 3]\n",
    "    A = Tm[:, :3]\n",
    "        \n",
    "    pts_prime = np.dot(A, pts_centered.T) + (t + c_prime)[:,None]\n",
    "        \n",
    "    return pts_prime.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_score_and_gradient(T):\n",
    "    global ds\n",
    "    \n",
    "    score = 0\n",
    "    dMdA = np.zeros((12,))\n",
    "    \n",
    "    for l in range(1, n_labels):\n",
    "#         t1 = time.time()\n",
    "    \n",
    "        pts_prime = transform_points(T, pts_centered=ds[l-1], c_prime=test_centroid)\n",
    "    \n",
    "        xs_prime = pts_prime[:,0]\n",
    "        ys_prime = pts_prime[:,1]\n",
    "        zs_prime = pts_prime[:,2]\n",
    "\n",
    "        valid = (xs_prime >= 0) & (ys_prime >= 0) & (zs_prime >= 0) & \\\n",
    "                (xs_prime < test_xdim) & (ys_prime < test_ydim) & (zs_prime < test_zdim)\n",
    "                   \n",
    "        if np.count_nonzero(valid) > 0:\n",
    "\n",
    "            xs_prime_valid = xs_prime[valid].astype(np.int16)\n",
    "            ys_prime_valid = ys_prime[valid].astype(np.int16)\n",
    "            zs_prime_valid = zs_prime[valid].astype(np.int16)\n",
    "            \n",
    "            voxel_probs_valid = volume2_allLabels[l-1][ys_prime_valid, xs_prime_valid, zs_prime_valid] / 1e4\n",
    "\n",
    "            score += voxel_probs_valid.sum()\n",
    "            \n",
    "            Sx = dSdxyz[l-1][0][ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "            Sy = dSdxyz[l-1][1][ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "            Sz = dSdxyz[l-1][2][ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "            \n",
    "            dxs, dys, dzs = ds[l-1][:, valid]\n",
    "\n",
    "#             dMdA += np.c_[Sx*dxs, Sx*dys, Sx*dzs, Sx, \n",
    "#                           Sy*dxs, Sy*dys, Sy*dzs, Sy,\n",
    "#                           Sz*dxs, Sz*dys, Sz*dzs, Sz].sum(axis=0)\n",
    "            \n",
    "            q = np.c_[Sx*dxs, Sx*dys, Sx*dzs, Sx, \n",
    "                          Sy*dxs, Sy*dys, Sy*dzs, Sy,\n",
    "                          Sz*dxs, Sz*dys, Sz*dzs, Sz]        \n",
    "            \n",
    "            dMdA += q.sum(axis=0)\n",
    "            \n",
    "            del voxel_probs_valid, q, Sx, Sy, Sz, dxs, dys, dzs, xs_prime_valid, ys_prime_valid, zs_prime_valid\n",
    "        \n",
    "#         sys.stderr.write('########### %s: %f seconds\\n' % (labels[l], time.time() - t1))\n",
    "        \n",
    "        del valid, xs_prime, ys_prime, zs_prime, pts_prime\n",
    "        \n",
    "    return score, dMdA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_score(T):\n",
    "    \n",
    "    score = 0\n",
    "    for l in range(1, n_labels):\n",
    "\n",
    "        pts_prime = transform_points(T, pts_centered=ds[l-1], c_prime=test_centroid)\n",
    "    \n",
    "        xs_prime = pts_prime[:,0].astype(np.int16)\n",
    "        ys_prime = pts_prime[:,1].astype(np.int16)\n",
    "        zs_prime = pts_prime[:,2].astype(np.int16)\n",
    "        \n",
    "        valid = (xs_prime >= 0) & (ys_prime >= 0) & (zs_prime >= 0) & \\\n",
    "            (xs_prime < test_xdim) & (ys_prime < test_ydim) & (zs_prime < test_zdim)\n",
    "        voxel_probs_valid = volume2_allLabels[l-1][ys_prime[valid], xs_prime[valid], zs_prime[valid]] / 1e4\n",
    "\n",
    "        score += voxel_probs_valid.sum()\n",
    "                \n",
    "    del voxel_probs_valid, valid, xs_prime, ys_prime, zs_prime, pts_prime\n",
    "                \n",
    "    return score\n",
    "\n",
    "def compute_score_gradient(T):\n",
    "\n",
    "\n",
    "    dMdA = np.zeros((12,))\n",
    "\n",
    "    for l in range(1, n_labels):\n",
    "        \n",
    "        pts_prime = transform_points(T, pts_centered=ds[l-1], c_prime=test_centroid)\n",
    "\n",
    "        xs_prime = pts_prime[:,0].astype(np.int16)\n",
    "        ys_prime = pts_prime[:,1].astype(np.int16)\n",
    "        zs_prime = pts_prime[:,2].astype(np.int16)\n",
    "\n",
    "        valid = (xs_prime >= 0) & (ys_prime >= 0) & (zs_prime >= 0) & \\\n",
    "            (xs_prime < test_xdim) & (ys_prime < test_ydim) & (zs_prime < test_zdim)\n",
    "            \n",
    "        if np.count_nonzero(valid) > 0:\n",
    "            \n",
    "            xs_prime_valid = xs_prime[valid]\n",
    "            ys_prime_valid = ys_prime[valid]\n",
    "            zs_prime_valid = zs_prime[valid]\n",
    "            \n",
    "            Sx = dSdxyz[l-1][0][ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "            Sy = dSdxyz[l-1][1][ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "            Sz = dSdxyz[l-1][2][ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "               \n",
    "            dxs, dys, dzs = ds[l-1][:, valid]\n",
    "            dMdA += np.c_[Sx*dxs, Sx*dys, Sx*dzs, Sx, \n",
    "                          Sy*dxs, Sy*dys, Sy*dzs, Sy,\n",
    "                          Sz*dxs, Sz*dys, Sz*dzs, Sz].sum(axis=0)\n",
    "            \n",
    "    return dMdA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack = 'MD598'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95 354\n",
      "5N\n",
      "7n\n",
      "7N\n",
      "12N\n",
      "Pn\n",
      "VLL\n",
      "6N\n",
      "Amb\n",
      "R\n",
      "Tz\n",
      "RtTg\n",
      "LRt\n",
      "LC\n",
      "AP\n",
      "sp5\n",
      "897 459 410\n",
      "(448.5, 229.5, 229.5)\n"
     ]
    }
   ],
   "source": [
    "# for stack in ['MD594', 'MD585', 'MD593', 'MD592', 'MD590', 'MD591', 'MD595', 'MD598', 'MD602']:\n",
    "# for stack in ['MD598']:\n",
    "\n",
    "################# LOAD TEST VOLUME ######################\n",
    "\n",
    "section_bs_begin, section_bs_end = section_range_lookup[stack]\n",
    "print section_bs_begin, section_bs_end\n",
    "\n",
    "(volume_xmin, volume_xmax, volume_ymin, volume_ymax, volume_zmin, volume_zmax) = \\\n",
    "np.loadtxt(os.path.join(volume_dir, 'volume_%(stack)s_scoreMap_limits.txt' % {'stack': stack}), dtype=np.int)\n",
    "\n",
    "map_z_to_section = {}\n",
    "for s in range(section_bs_begin, section_bs_end+1):\n",
    "    for z in range(int(z_xy_ratio_downsampled*s) - volume_zmin, int(z_xy_ratio_downsampled*(s+1)) - volume_zmin + 1):\n",
    "        map_z_to_section[z] = s\n",
    "\n",
    "global volume2_allLabels\n",
    "volume2_allLabels = []\n",
    "\n",
    "for l in labels[1:]:\n",
    "\n",
    "    print l\n",
    "\n",
    "    volume2 = bp.unpack_ndarray_file(os.path.join(volume_dir, 'volume_%(stack)s_scoreMap_%(label)s.bp' % \\\n",
    "                                                  {'stack': stack, 'label': l}))\n",
    "\n",
    "    volume2_cropped = volume2[volume_ymin:volume_ymax+1, volume_xmin:volume_xmax+1]\n",
    "    # copy is important, because then you can delete the large array\n",
    "\n",
    "    volume2_allLabels.append(volume2_cropped.copy())\n",
    "\n",
    "    del volume2, volume2_cropped\n",
    "\n",
    "test_ydim, test_xdim, test_zdim = volume2_allLabels[0].shape\n",
    "test_centroid = (.5*test_xdim, .5*test_ydim, .5*test_ydim)\n",
    "test_cx, test_cy, test_cz = test_centroid\n",
    "\n",
    "print test_xdim, test_ydim, test_zdim\n",
    "print test_centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:grid search iteration 0\n",
      "INFO:__main__:0.000000 75.142848\n",
      "INFO:__main__:-61.942285 55.148047 -65.577031\n",
      "INFO:__main__:\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.6715641022 seconds\n"
     ]
    }
   ],
   "source": [
    "handler = logging.FileHandler(atlasAlignOptLogs_dir + '/%(stack)s_atlasAlignOpt.log' % {'stack': stack})\n",
    "handler.setLevel(logging.INFO)\n",
    "logger.addHandler(handler)\n",
    "\n",
    "################# GRID SEARCH ######################\n",
    "\n",
    "#     grid_search_iteration_number = 10\n",
    "grid_search_iteration_number = 1\n",
    "\n",
    "params_best_upToNow = (0, 0, 0)\n",
    "score_best_upToNow = 0\n",
    "\n",
    "for iteration in range(grid_search_iteration_number):\n",
    "\n",
    "    logger.info('grid search iteration %d', iteration)\n",
    "\n",
    "    init_tx, init_ty, init_tz  = params_best_upToNow\n",
    "\n",
    "    n = int(1000*np.exp(-iteration/3.))\n",
    "\n",
    "    sigma_tx = 300*np.exp(-iteration/3.)\n",
    "    sigma_ty = 300*np.exp(-iteration/3.)\n",
    "    sigma_tz = 100*np.exp(-iteration/3.)\n",
    "\n",
    "    tx_grid = init_tx + sigma_tx * (2 * np.random.random(n) - 1)\n",
    "    ty_grid = init_ty + sigma_ty * (2 * np.random.random(n) - 1)\n",
    "    tz_grid = init_tz + sigma_tz * (2 * np.random.random(n) - 1)\n",
    "\n",
    "    samples = np.c_[tx_grid, ty_grid, tz_grid]\n",
    "\n",
    "    import time\n",
    "    t = time.time()\n",
    "\n",
    "    scores = Parallel(n_jobs=16)(delayed(compute_score)(np.array([1, 0, 0, tx, 0, 1, 0, ty, 0, 0, 1, tz]))\n",
    "                                 for tx, ty, tz in samples)\n",
    "\n",
    "#     scores = [compute_score([1, 0, 0, tx, 0, 1, 0, ty, 0, 0, 1, tz]) for tx, ty, tz in samples]\n",
    "\n",
    "    print time.time() - t, 'seconds'\n",
    "\n",
    "    score_best = np.max(scores)\n",
    "\n",
    "    tx_best, ty_best, tz_best = samples[np.argmax(scores)]\n",
    "\n",
    "    if score_best > score_best_upToNow:\n",
    "        logger.info('%f %f', score_best_upToNow, score_best)\n",
    "\n",
    "        score_best_upToNow = score_best\n",
    "        params_best_upToNow = tx_best, ty_best, tz_best\n",
    "\n",
    "        logger.info('%f %f %f', tx_best, ty_best, tz_best)\n",
    "        logger.info('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gradient 5N: 3.194637 seconds\n",
      "store 5N: 3.999422 seconds\n",
      "gradient 7n: 3.143157 seconds\n",
      "store 7n: 3.780772 seconds\n",
      "gradient 7N: 3.164200 seconds\n",
      "store 7N: 3.866401 seconds\n",
      "gradient 12N: 3.147282 seconds\n",
      "store 12N: 3.800223 seconds\n",
      "gradient Pn: 3.370479 seconds\n",
      "store Pn: 3.852262 seconds\n",
      "gradient VLL: 3.527252 seconds\n",
      "store VLL: 4.146684 seconds\n",
      "gradient 6N: 3.594103 seconds\n",
      "store 6N: 3.810074 seconds\n",
      "gradient Amb: 3.693601 seconds\n",
      "store Amb: 3.828036 seconds\n",
      "gradient R: 6.101754 seconds\n",
      "store R: 4.068227 seconds\n",
      "gradient Tz: 20.304137 seconds\n",
      "store Tz: 3.865987 seconds\n",
      "gradient RtTg: 24.929295 seconds\n",
      "store RtTg: 4.155099 seconds\n",
      "gradient LRt: 31.895824 seconds\n",
      "store LRt: 3.938405 seconds\n",
      "gradient LC: 28.409347 seconds\n",
      "store LC: 8.762701 seconds\n",
      "gradient AP: 23.406426 seconds\n",
      "store AP: 5.801922 seconds\n",
      "gradient sp5: 22.389653 seconds\n",
      "store sp5: 6.839631 seconds\n",
      "overall: 252.800252 seconds\n"
     ]
    }
   ],
   "source": [
    "dSdxyz = np.empty((n_labels-1, 3) + volume2_allLabels[0].shape, dtype=np.float16) \n",
    "\n",
    "# if memory is not limited, using float32 is faster, because the output of np.gradient is of type float32\n",
    "# time for storing output: float16 4s (due to dtype conversion overhead), float32 1s\n",
    "\n",
    "# using float16 avoids memory issues that make gradient computation utterly slow, 30s vs. 4s\n",
    "\n",
    "################# COMPUTE GRADIENTS ######################\n",
    "\n",
    "# dSdxyz = {}\n",
    "# DO NOT use python list because python will use contiguous memory for it\n",
    "# http://stackoverflow.com/questions/12274060/does-python-use-linked-lists-for-lists-why-is-inserting-slow  \n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "for l in range(1, n_labels):\n",
    "\n",
    "    t = time.time()\n",
    "    \n",
    "    gy, gx, gz = np.gradient(volume2_allLabels[l-1], 3, 3, 3) # 3.3 second, much faster than loading\n",
    "    # if memory is limited, this will be very slow\n",
    "    \n",
    "    sys.stderr.write('gradient %s: %f seconds\\n' % (labels[l], time.time() - t))\n",
    "    \n",
    "    t = time.time()\n",
    "    \n",
    "    dSdxyz[l-1, 0] = gx\n",
    "    dSdxyz[l-1, 1] = gy\n",
    "    dSdxyz[l-1, 2] = gz\n",
    "    \n",
    "#     dSdxyz[labels[l]] = np.array([gx, gy, gz]) # use np.array is better; using python list also causes contiguous memory overhead\n",
    "    \n",
    "#     del gx, gy, gz # does not make a difference\n",
    "    \n",
    "    sys.stderr.write('store %s: %f seconds\\n' % (labels[l], time.time() - t))\n",
    "    \n",
    "sys.stderr.write('overall: %f seconds\\n' % (time.time() - t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:iteration 0\n",
      "\n",
      "/oasis/projects/nsf/csd181/yuncong/virtualenv-1.9.1/yuncongve/lib/python2.7/site-packages/ipykernel/__main__.py:32: VisibleDeprecationWarning: boolean index did not match indexed array along dimension 1; dimension is 3 but corresponding boolean dimension is 447348\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-aa3e0aa50bab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdMdA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_score_and_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mT_best\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'compute_score_and_gradient: %f seconds\\n'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#~ 2s/iteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-34-7494914bf399>\u001b[0m in \u001b[0;36mcompute_score_and_gradient\u001b[1;34m(T)\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[0mSz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdSdxyz\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mys_prime_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxs_prime_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzs_prime_valid\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m             \u001b[0mdxs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdzs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;31m#             dMdA += np.c_[Sx*dxs, Sx*dys, Sx*dzs, Sx,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "################# GRADIENT DESCENT ######################\n",
    "\n",
    "lr1, lr2 = (10., 1e-1)\n",
    "# lr1, lr2 = (1., 1e-3)\n",
    "\n",
    "# auto_corr = .95\n",
    "\n",
    "max_iter_num = 100\n",
    "fudge_factor = 1e-6 #for numerical stability\n",
    "dMdA_historical = np.zeros((12,))\n",
    "\n",
    "tx_best, ty_best, tz_best = params_best_upToNow\n",
    "T_best = np.r_[1,0,0, tx_best, 0,1,0, ty_best, 0,0,1, tz_best]\n",
    "\n",
    "lr = np.array([lr2, lr2, lr2, lr1, lr2, lr2, lr2, lr1, lr2, lr2, lr2, lr1])\n",
    "\n",
    "score_best = 0\n",
    "\n",
    "scores = []\n",
    "\n",
    "for iteration in range(max_iter_num):\n",
    "\n",
    "    logger.info('iteration %d\\n', iteration)\n",
    "\n",
    "    t = time.time()\n",
    "    s, dMdA = compute_score_and_gradient(T_best)\n",
    "    sys.stderr.write('compute_score_and_gradient: %f seconds\\n' % (time.time() - t)) #~ 2s/iteration\n",
    "\n",
    "    dMdA_historical += dMdA**2\n",
    "#     dMdA_historical = auto_corr * dMdA_historical + (1-auto_corr) * dMdA**2\n",
    "\n",
    "    dMdA_adjusted = dMdA / (fudge_factor + np.sqrt(dMdA_historical))\n",
    "\n",
    "    T_best += lr*dMdA_adjusted\n",
    "\n",
    "#         logger.info('A: ' + ' '.join(['%f']*12) % tuple(A_best))\n",
    "#         logger.info('dMdA adjusted: ' + ' '.join(['%f']*12) % tuple(dMdA_adjusted))\n",
    "\n",
    "    logger.info('score: %f', s)\n",
    "    scores.append(s)\n",
    "\n",
    "#     logger.info('\\n')\n",
    "\n",
    "    history_len = 50\n",
    "    if iteration > 200:\n",
    "        if np.abs(np.mean(scores[iteration-history_len:iteration]) - \\\n",
    "                  np.mean(scores[iteration-2*history_len:iteration-history_len])) < 1e-1:\n",
    "            break\n",
    "\n",
    "    if s > score_best:\n",
    "#             logger.info('Current best')\n",
    "        best_gradient_descent_params = T_best\n",
    "        score_best = s\n",
    "\n",
    "#     np.save(atlasAlignOptLogs_dir + '/%(stack)s_scoreEvolutions.npy' % {'stack':stack}, scores)\n",
    "\n",
    "#     del dSdxyz\n",
    "\n",
    "################# PROJECT ATLAS TO IMAGE ######################\n",
    "\n",
    "\n",
    "#     Tm = np.reshape(best_gradient_descent_params, (3,4))\n",
    "#     tx_best, ty_best, tz_best  = Tm[:, 3]\n",
    "#     Amat_best = Tm[:, :3]\n",
    "\n",
    "#     atlas_nzs_projected_to_test = [(np.dot(Amat_best, vs - atlas_centroid[:, np.newaxis]) + \\\n",
    "#                                                 np.asarray([tx_best + test_cx, \n",
    "#                                                             ty_best + test_cy, \n",
    "#                                                             tz_best + test_cz])[:,np.newaxis]).astype(np.int)\n",
    "#                                     for vs in atlas_nzs]\n",
    "\n",
    "#     print np.min(atlas_nzs_projected_to_test[0], axis=1)\n",
    "#     print np.max(atlas_nzs_projected_to_test[0], axis=1)\n",
    "\n",
    "#     test_volume_atlas_projected = np.zeros_like(volume2_allLabels[0], np.int)\n",
    "\n",
    "#     for l in range(1, n_labels):\n",
    "\n",
    "#         test_xs, test_ys, test_zs = atlas_nzs_projected_to_test[l-1].astype(np.int)\n",
    "\n",
    "#         valid = (test_xs >= 0) & (test_ys >= 0) & (test_zs >= 0) & \\\n",
    "#             (test_xs < test_xdim) & (test_ys < test_ydim) & (test_zs < test_zdim)\n",
    "\n",
    "#         atlas_xs, atlas_ys, atlas_zs = atlas_nzs[l-1]\n",
    "\n",
    "#         test_volume_atlas_projected[test_ys[valid], test_xs[valid], test_zs[valid]] = \\\n",
    "#         volume1[atlas_ys[valid], atlas_xs[valid], atlas_zs[valid]]\n",
    "\n",
    "\n",
    "#     del atlas_nzs_projected_to_test\n",
    "\n",
    "#     bp.pack_ndarray_file(test_volume_atlas_projected, \n",
    "#                          volume_dir + '/%(stack)s_volume_atlasProjected.bp'%{'stack':stack})\n",
    "\n",
    "#     with open(os.path.join(atlasAlignParams_dir, '%(stack)s_3dAlignParams.txt' % {'stack':stack}), 'w') as f:\n",
    "#         f.writelines(' '.join(['%f']*len(params_best_upToNow)) % tuple(params_best_upToNow) + '\\n')\n",
    "#         f.writelines(' '.join(['%f']*len(best_gradient_descent_params)) % tuple(best_gradient_descent_params) + '\\n')\n",
    "#         f.writelines(' '.join(['%f']*len(lr)) % tuple(lr) + '\\n')\n",
    "#         f.writelines('%d' % iteration + '\\n')\n",
    "\n",
    "#     annotationsViz_dir = create_if_not_exists(annotationsViz_rootdir + '/' + stack)\n",
    "\n",
    "#     dm = DataManager(stack=stack)\n",
    "\n",
    "#     for z in range(0, test_zdim, 10):\n",
    "\n",
    "#         t = time.time()\n",
    "\n",
    "#         print z\n",
    "\n",
    "#         dm.set_slice(map_z_to_section[z])\n",
    "#         dm._load_image(versions=['rgb-jpg'])\n",
    "#         viz = dm.image_rgb_jpg[::downsample_factor, ::downsample_factor][volume_ymin:volume_ymax+1, \n",
    "#                                                                          volume_xmin:volume_xmax+1].copy()\n",
    "\n",
    "#         projected_cnts = find_contour_points(test_volume_atlas_projected[...,z])\n",
    "\n",
    "#         for label_ind, cnts in projected_cnts.iteritems():\n",
    "#             for cnt in cnts:\n",
    "#                 cv2.polylines(viz, [cnt.astype(np.int)], True, tuple((colors[label_ind]*255).astype(np.int)), 2)\n",
    "\n",
    "#         cv2.imwrite(annotationsViz_dir + '/%(stack)s_%(sec)04d_annotationsProjectedViz_z%(z)04d.jpg' % \\\n",
    "#                     {'stack': stack, 'sec': map_z_to_section[z], 'z': z}, \n",
    "#                     img_as_ubyte(viz[..., [2,1,0]]))\n",
    "\n",
    "#         del viz\n",
    "\n",
    "#         sys.stderr.write('visualize: %f seconds\\n' % (time.time() - t)) #~ 2s/iteration\n",
    "\n",
    "\n",
    "#     del test_volume_atlas_projected\n",
    "\n",
    "#     logger.removeHandler(handler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
