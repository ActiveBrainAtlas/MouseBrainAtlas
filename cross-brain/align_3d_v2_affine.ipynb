{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.environ['REPO_DIR'] + '/utilities')\n",
    "from utilities2015 import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import time\n",
    "\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# labels = ['BackG', '5N', '7n', '7N', '12N', 'Gr', 'LVe', 'Pn', 'SuVe', 'VLL']\n",
    "\n",
    "labels = ['BackG', '5N', '7n', '7N', '12N', 'Gr', 'LVe', 'Pn', 'SuVe', 'VLL', \n",
    "                     '6N', 'Amb', 'R', 'Tz', 'Sol', 'RtTg', 'LRt', 'LC', 'AP', 'sp5']\n",
    "\n",
    "n_labels = len(labels)\n",
    "\n",
    "label_dict = dict([(l,i) for i, l in enumerate(labels)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "volume_dir = '/oasis/projects/nsf/csd395/yuncong/CSHL_volumes/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "volume1 = bp.unpack_ndarray_file(os.path.join(volume_dir, 'volume_MD589_annotation.bp'))\n",
    "atlas_ydim, atlas_xdim, atlas_zdim = volume1.shape\n",
    "print atlas_xdim, atlas_ydim, atlas_zdim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parallel_where(l):\n",
    "    w = np.where(volume1 == l)\n",
    "    return [w[1], w[0], w[2]]\n",
    "\n",
    "t = time.time()\n",
    "\n",
    "atlas_nzs = Parallel(n_jobs=16)(delayed(parallel_where)(l) for l in range(1, n_labels))\n",
    "\n",
    "print time.time() - t, 'seconds'\n",
    "\n",
    "atlas_xmin, atlas_ymin, atlas_zmin = np.min([np.min(atlas_nzs[l-1], axis=1) for l in range(1, n_labels)], axis=0)\n",
    "atlas_xmax, atlas_ymax, atlas_zmax = np.max([np.max(atlas_nzs[l-1], axis=1) for l in range(1, n_labels)], axis=0)\n",
    "print atlas_xmin, atlas_xmax, atlas_ymin, atlas_ymax, atlas_zmin, atlas_zmax\n",
    "\n",
    "atlas_centroid = np.array([.5*atlas_xmin+.5*atlas_xmax, .5*atlas_ymin+.5*atlas_ymax, .5*atlas_zmin+.5*atlas_zmax])\n",
    "print atlas_centroid\n",
    "\n",
    "atlas_cx, atlas_cy, atlas_cz = atlas_centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "downsample_factor = 16\n",
    "\n",
    "section_thickness = 20 # in um\n",
    "xy_pixel_distance_lossless = 0.46\n",
    "xy_pixel_distance_tb = xy_pixel_distance_lossless * 32 # in um, thumbnail\n",
    "# factor = section_thickness/xy_pixel_distance_lossless\n",
    "\n",
    "xy_pixel_distance_downsampled = xy_pixel_distance_lossless * downsample_factor\n",
    "z_xy_ratio_downsampled = section_thickness / xy_pixel_distance_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "atlasAlignOptLogs_dir = '/oasis/projects/nsf/csd395/yuncong/CSHL_atlasAlignOptLogs'\n",
    "if not os.path.exists(atlasAlignOptLogs_dir):\n",
    "    os.makedirs(atlasAlignOptLogs_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "atlasAlignParams_dir = '/oasis/projects/nsf/csd395/yuncong/CSHL_atlasAlignParams'\n",
    "if not os.path.exists(atlasAlignParams_dir):\n",
    "    os.makedirs(atlasAlignParams_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "annotationsViz_rootdir = '/oasis/projects/nsf/csd395/yuncong/CSHL_annotaionsPojectedViz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colors = np.loadtxt(os.environ['REPO_DIR'] + '/visualization/100colors.txt')\n",
    "colors[label_dict['BackG']] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "volume2_allLabels = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_transform(tx, ty, tz, A=None):\n",
    "    \n",
    "    if A is None:\n",
    "        A = np.array([[1,0,0], [0,1,0], [0,0,1]])\n",
    "    \n",
    "    scores = np.empty((n_labels-1,))\n",
    "    for l in range(1, n_labels):\n",
    "                \n",
    "        test_xs, test_ys, test_zs = (np.dot(A, np.array(atlas_nzs[l-1]) - atlas_centroid[:, np.newaxis]) + \\\n",
    "                                    np.asarray([tx + test_cx, \n",
    "                                                ty + test_cy, \n",
    "                                                tz + test_cz])[:,np.newaxis]).astype(np.int)\n",
    "\n",
    "        ydim, xdim, zdim = volume2_allLabels[l-1].shape\n",
    "\n",
    "        valid = (test_xs >= 0) & (test_ys >= 0) & (test_zs >= 0) & \\\n",
    "                (test_ys < ydim) & (test_xs < xdim) & (test_zs < zdim)\n",
    "\n",
    "        voxel_probs_valid = volume2_allLabels[l-1][test_ys[valid], test_xs[valid], test_zs[valid]] / 1e4\n",
    "        \n",
    "        scores[l-1] = voxel_probs_valid.sum()\n",
    "        \n",
    "    del voxel_probs_valid, valid, test_xs, test_ys, test_zs\n",
    "                \n",
    "    score = np.sum(scores)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def ypr_to_matrix(y,p,r):\n",
    "#     cz = np.cos(y)\n",
    "#     sz = np.sin(y)\n",
    "#     cy = np.cos(p)\n",
    "#     sy = np.sin(p)\n",
    "#     cx = np.cos(r)\n",
    "#     sx = np.sin(r)\n",
    "    \n",
    "#     R = np.array([[cz*cy, cz*sy*sx-sz*cx, cz*sy*cx+sz*sx], \n",
    "#              [sz*cy, sz*sy*sx+cz*cx, sz*sy*cx-cz*sx],\n",
    "#              [-sy, cy*sx, cy*cx]])\n",
    "    \n",
    "#     return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tx0, ty0, tz0 = (0,0,0)\n",
    "# yaw0, pitch0, roll0 = (0,0,0)\n",
    "# sx0, sy0, sz0 = (1,1,1)\n",
    "# sh_xy0, sh_xz0, sh_yx0, sh_yz0, sh_zx0, sh_zy0 = (0,0,0,0,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def params12_to_matrix(params):\n",
    "#     tx,ty,tz,y,p,r,sx,sy,sz,sh_xy,sh_xz,sh_yx,sh_yz,sh_zx,sh_zy = params\n",
    "    \n",
    "#     cz = np.cos(y)\n",
    "#     sz = np.sin(y)\n",
    "#     cy = np.cos(p)\n",
    "#     sy = np.sin(p)\n",
    "#     cx = np.cos(r)\n",
    "#     sx = np.sin(r)\n",
    "    \n",
    "#     S = np.array([[sx,0,0],[0,sy,0],[0,0,sz]])\n",
    "#     Sh = np.array([[1,sh_xy,sh_xz],[sh_yx,1,sh_yz],[sh_zx,sh_zy,1]])\n",
    "#     Rx = np.array([[1,0,0],[0,cx,-sx],[0,sx,cx]])\n",
    "#     Ry = np.array([[cy,0,sy],[0,1,0],[-sy,0,cy]])\n",
    "#     Rz = np.array([[cz,-sz,0],[sz,cx,0],[0,0,1]])\n",
    "    \n",
    "#     A = np.dot(Sh, np.dot(np.dot(np.dot(Rz,Ry),Rx), S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage.measure import find_contours\n",
    "\n",
    "def find_contour_points(labelmap):\n",
    "    '''\n",
    "    return is (x,y)\n",
    "    '''\n",
    "\n",
    "    regions = regionprops(labelmap)\n",
    "\n",
    "    contour_points = {}\n",
    "\n",
    "    for r in regions:\n",
    "\n",
    "        (min_row, min_col, max_row, max_col) = r.bbox\n",
    "\n",
    "        padded = np.pad(r.filled_image, ((5,5),(5,5)), mode='constant', constant_values=0)\n",
    "\n",
    "        contours = find_contours(padded, .5, fully_connected='high')\n",
    "        contours = [cnt.astype(np.int) for cnt in contours if len(cnt) > 10]\n",
    "        if len(contours) > 0:\n",
    "            if len(contours) > 1:\n",
    "                sys.stderr.write('%d: region has more than one part\\n' % r.label)\n",
    "                \n",
    "            contours = sorted(contours, key=lambda c: len(c), reverse=True)\n",
    "            contours_list = [c-(5,5) for c in contours]\n",
    "            contour_points[r.label] = [c[np.arange(0, c.shape[0], 10)][:, ::-1] + (min_col, min_row) \n",
    "                                for c in contours_list]\n",
    "            \n",
    "        elif len(contours) == 0:\n",
    "            sys.stderr.write('no contour is found\\n')\n",
    "            continue\n",
    "\n",
    "    #         viz = np.zeros_like(r.filled_image)\n",
    "    #         viz[pts_sampled[:,0], pts_sampled[:,1]] = 1\n",
    "    #         plt.imshow(viz, cmap=plt.cm.gray);\n",
    "    #         plt.show();\n",
    "        \n",
    "    return contour_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for stack in ['MD592', 'MD590', 'MD591', 'MD595', 'MD598', 'MD602', 'MD594']:\n",
    "# for stack in ['MD593']:\n",
    "\n",
    "    ################# LOAD TEST VOLUME ######################\n",
    "    \n",
    "    section_bs_begin, section_bs_end = section_range_lookup[stack]\n",
    "    print section_bs_begin, section_bs_end\n",
    "\n",
    "    (volume_xmin, volume_xmax, volume_ymin, volume_ymax, volume_zmin, volume_zmax) = \\\n",
    "    np.loadtxt(os.path.join(volume_dir, 'volume_%(stack)s_scoreMap_limits.txt' % {'stack': stack}), dtype=np.int)\n",
    "\n",
    "    map_z_to_section = {}\n",
    "    for s in range(section_bs_begin, section_bs_end+1):\n",
    "        for z in range(int(z_xy_ratio_downsampled*s) - volume_zmin, int(z_xy_ratio_downsampled*(s+1)) - volume_zmin + 1):\n",
    "            map_z_to_section[z] = s\n",
    "\n",
    "\n",
    "    global volume2_allLabels\n",
    "    volume2_allLabels = []\n",
    "\n",
    "    for l in labels[1:]:\n",
    "\n",
    "        print l\n",
    "\n",
    "        volume2 = bp.unpack_ndarray_file(os.path.join(volume_dir, 'volume_%(stack)s_scoreMap_%(label)s.bp' % \\\n",
    "                                                      {'stack': stack, 'label': l}))\n",
    "\n",
    "        volume2_cropped = volume2[volume_ymin:volume_ymax+1, volume_xmin:volume_xmax+1]\n",
    "        # copy is important, because then you can delete the large array\n",
    "\n",
    "        volume2_allLabels.append(volume2_cropped.copy())\n",
    "\n",
    "        del volume2, volume2_cropped\n",
    "\n",
    "\n",
    "    test_ydim, test_xdim, test_zdim = volume2_allLabels[0].shape\n",
    "\n",
    "    print test_xdim, test_ydim, test_zdim\n",
    "\n",
    "    test_centroid = (.5*test_xdim, .5*test_ydim, .5*test_ydim)\n",
    "    print test_centroid\n",
    "\n",
    "    test_cx, test_cy, test_cz = test_centroid\n",
    "\n",
    "\n",
    "    handler = logging.FileHandler(atlasAlignOptLogs_dir + '/%(stack)s_atlasAlignOpt.log' % {'stack': stack})\n",
    "    handler.setLevel(logging.INFO)\n",
    "    logger.addHandler(handler)\n",
    "\n",
    "    ################# GRID SEARCH ######################\n",
    "    \n",
    "    grid_search_iteration_number = 10\n",
    "\n",
    "    params_best_upToNow = (0, 0, 0)\n",
    "    score_best_upToNow = 0\n",
    "\n",
    "    for iteration in range(grid_search_iteration_number):\n",
    "\n",
    "        logger.info('grid search iteration %d', iteration)\n",
    "\n",
    "        init_tx, init_ty, init_tz  = params_best_upToNow\n",
    "\n",
    "        n = int(1000*np.exp(-iteration/3.))\n",
    "\n",
    "        sigma_tx = 300*np.exp(-iteration/3.)\n",
    "        sigma_ty = 300*np.exp(-iteration/3.)\n",
    "        sigma_tz = 100*np.exp(-iteration/3.)\n",
    "\n",
    "        tx_grid = init_tx + sigma_tx * (2 * np.random.random(n) - 1)\n",
    "        ty_grid = init_ty + sigma_ty * (2 * np.random.random(n) - 1)\n",
    "        tz_grid = init_tz + sigma_tz * (2 * np.random.random(n) - 1)\n",
    "\n",
    "        samples = np.c_[tx_grid, ty_grid, tz_grid]\n",
    "\n",
    "        import time\n",
    "        t = time.time()\n",
    "\n",
    "        scores = Parallel(n_jobs=16)(delayed(score_transform)(tx, ty, tz) for tx, ty, tz in samples)\n",
    "\n",
    "    #     scores = [score_transform(tx, ty, tz) for tx, ty, tz in samples]\n",
    "\n",
    "        print time.time() - t, 'seconds'\n",
    "\n",
    "        score_best = np.max(scores)\n",
    "\n",
    "        tx_best, ty_best, tz_best = samples[np.argmax(scores)]\n",
    "\n",
    "        if score_best > score_best_upToNow:\n",
    "            logger.info('%f %f', score_best_upToNow, score_best)\n",
    "\n",
    "            score_best_upToNow = score_best\n",
    "            params_best_upToNow = tx_best, ty_best, tz_best\n",
    "\n",
    "            logger.info('%f %f %f', tx_best, ty_best, tz_best)\n",
    "            logger.info('\\n')\n",
    "            \n",
    "            \n",
    "    ################# COMPUTE GRADIENTS ######################\n",
    "\n",
    "    dSdyxz = []\n",
    "    for l in range(1, n_labels):\n",
    "        print labels[l]\n",
    "\n",
    "        t = time.time()\n",
    "\n",
    "        g = np.gradient(volume2_allLabels[l-1], 10, 10, 10)\n",
    "\n",
    "        dSdyxz.append(g)\n",
    "\n",
    "        print time.time() - t, 'seconds'\n",
    "    \n",
    "            \n",
    "    ################# GRADIENT DESCENT ######################\n",
    "            \n",
    "    lr1, lr2 = (100., 1e-1)\n",
    "#     lr1, lr2 = (10., 1e-3)\n",
    "    # lr1, lr2 = (10., 0)\n",
    "    max_iter_num = 5000\n",
    "\n",
    "    fudge_factor = 1e-6 #for numerical stability\n",
    "\n",
    "    dMdA_historical = np.zeros((12,))\n",
    "\n",
    "    tx_best, ty_best, tz_best = params_best_upToNow\n",
    "    A_best = np.r_[tx_best, ty_best, tz_best, 1,0,0,0,1,0,0,0,1]\n",
    "\n",
    "    lr = np.r_[lr1*np.ones((3,)), lr2*np.ones((9,))]\n",
    "\n",
    "    score_best = 0\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    for iteration in range(max_iter_num):\n",
    "\n",
    "        logger.info('iteration %d\\n', iteration)\n",
    "\n",
    "        dMdA = np.zeros((12,))\n",
    "\n",
    "        Amat_best = np.reshape(A_best[3:], (3,3))\n",
    "        tx_best, ty_best, tz_best = A_best[:3]\n",
    "\n",
    "        for l in range(1, n_labels):\n",
    "\n",
    "            ds = np.array(atlas_nzs[l-1]) - atlas_centroid[:, np.newaxis]\n",
    "\n",
    "            xs_prime, ys_prime, zs_prime = (np.dot(Amat_best, ds) + \\\n",
    "                                            np.asarray([tx_best + test_cx, \n",
    "                                                        ty_best + test_cy, \n",
    "                                                        tz_best + test_cz])[:,np.newaxis]).astype(np.int)\n",
    "\n",
    "            valid = (xs_prime >= 0) & (ys_prime >= 0) & (zs_prime >= 0) & \\\n",
    "                (xs_prime < test_xdim) & (ys_prime < test_ydim) & (zs_prime < test_zdim)\n",
    "\n",
    "            if np.count_nonzero(valid) > 0:\n",
    "\n",
    "                xs_prime_valid = xs_prime[valid]\n",
    "                ys_prime_valid = ys_prime[valid]\n",
    "                zs_prime_valid = zs_prime[valid]\n",
    "\n",
    "                Sx = dSdyxz[l-1][1][ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "                Sy = dSdyxz[l-1][0][ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "                Sz = dSdyxz[l-1][2][ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "\n",
    "                ds_valid = ds[:, valid]\n",
    "                dxs, dys, dzs = ds_valid\n",
    "\n",
    "                dMdA += np.c_[ Sx, Sy, Sz, Sx*dxs, Sx*dys, Sx*dzs, Sy*dxs, Sy*dys, Sy*dzs, Sz*dxs, Sz*dys, Sz*dzs].sum(axis=0)\n",
    "\n",
    "\n",
    "        dMdA_historical += dMdA**2\n",
    "        dMdA_adjusted = dMdA / (fudge_factor + np.sqrt(dMdA_historical))\n",
    "\n",
    "        A_best += lr*dMdA_adjusted\n",
    "\n",
    "        logger.info('A: ' + ' '.join(['%f']*12) % tuple(A_best))\n",
    "\n",
    "        logger.info('dMdA adjusted: ' + ' '.join(['%f']*12) % tuple(dMdA_adjusted))\n",
    "\n",
    "        tx_best, ty_best, tz_best = A_best[:3]\n",
    "        Amat_best = np.reshape(A_best[3:], (3,3))\n",
    "\n",
    "        s = score_transform(tx_best, ty_best, tz_best, Amat_best)\n",
    "        logger.info('score: %f', s)\n",
    "        scores.append(s)\n",
    "\n",
    "        logger.info('\\n')\n",
    "\n",
    "        history_len = 50\n",
    "        if iteration > 200:\n",
    "            if np.abs(np.mean(scores[iteration-history_len:iteration]) - \\\n",
    "                      np.mean(scores[iteration-2*history_len:iteration-history_len])) < 1e-2:\n",
    "                break\n",
    "\n",
    "        if s > score_best:\n",
    "            logger.info('Current best')\n",
    "            best_gradient_descent_params = A_best\n",
    "            score_best = s\n",
    "            \n",
    "            \n",
    "    np.save(atlasAlignOptLogs_dir + '/%(stack)s_scoreEvolutions.npy' % {'stack':stack}, scores)\n",
    "    \n",
    "    del dSdyxz\n",
    "    \n",
    "    ################# PROJECT ATLAS TO IMAGE ######################\n",
    "    \n",
    "    tx_best, ty_best, tz_best = best_gradient_descent_params[:3]\n",
    "    Amat_best = np.reshape(best_gradient_descent_params[3:], (3,3))\n",
    "\n",
    "    atlas_nzs_projected_to_test = [(np.dot(Amat_best, vs - atlas_centroid[:, np.newaxis]) + \\\n",
    "                                                np.asarray([tx_best + test_cx, \n",
    "                                                            ty_best + test_cy, \n",
    "                                                            tz_best + test_cz])[:,np.newaxis]).astype(np.int)\n",
    "                                    for vs in atlas_nzs]\n",
    "\n",
    "    print np.min(atlas_nzs_projected_to_test[0], axis=1)\n",
    "    print np.max(atlas_nzs_projected_to_test[0], axis=1)\n",
    "\n",
    "    test_volume_atlas_projected = np.zeros_like(volume2_allLabels[0], np.int)\n",
    "\n",
    "    for l in range(1, n_labels):\n",
    "\n",
    "        test_xs, test_ys, test_zs = atlas_nzs_projected_to_test[l-1].astype(np.int)\n",
    "\n",
    "        valid = (test_xs >= 0) & (test_ys >= 0) & (test_zs >= 0) & \\\n",
    "            (test_xs < test_xdim) & (test_ys < test_ydim) & (test_zs < test_zdim)\n",
    "\n",
    "        atlas_xs, atlas_ys, atlas_zs = atlas_nzs[l-1]\n",
    "\n",
    "        test_volume_atlas_projected[test_ys[valid], test_xs[valid], test_zs[valid]] = \\\n",
    "        volume1[atlas_ys[valid], atlas_xs[valid], atlas_zs[valid]]\n",
    "\n",
    "\n",
    "    del atlas_nzs_projected_to_test\n",
    "\n",
    "    bp.pack_ndarray_file(test_volume_atlas_projected, \n",
    "                         volume_dir + '/%(stack)s_volume_atlasProjected.bp'%{'stack':stack})\n",
    "\n",
    "    with open(os.path.join(atlasAlignParams_dir, '%(stack)s_3dAlignParams.txt' % {'stack':stack}), 'w') as f:\n",
    "        f.writelines(' '.join(['%f']*len(params_best_upToNow)) % tuple(params_best_upToNow) + '\\n')\n",
    "        f.writelines(' '.join(['%f']*len(best_gradient_descent_params)) % tuple(best_gradient_descent_params) + '\\n')\n",
    "        f.writelines(' '.join(['%f']*len(lr)) % tuple(lr) + '\\n')\n",
    "        f.writelines('%d' % max_iter_num + '\\n')\n",
    "\n",
    "    annotationsViz_dir = annotationsViz_rootdir + '/' + stack\n",
    "    if not os.path.exists(annotationsViz_dir):\n",
    "        os.makedirs(annotationsViz_dir)\n",
    "\n",
    "    for z in range(0, test_zdim, 10):\n",
    "        print z\n",
    "\n",
    "        dm = DataManager(stack=stack, section=map_z_to_section[z])\n",
    "        dm._load_image(versions=['rgb-jpg'])\n",
    "        viz = dm.image_rgb_jpg[::downsample_factor, ::downsample_factor][volume_ymin:volume_ymax+1, \n",
    "                                                                         volume_xmin:volume_xmax+1].copy()\n",
    "\n",
    "        projected_cnts = find_contour_points(test_volume_atlas_projected[...,z])\n",
    "\n",
    "        for label_ind, cnts in projected_cnts.iteritems():\n",
    "            for cnt in cnts:\n",
    "                cv2.polylines(viz, [cnt.astype(np.int)], True, tuple((colors[label_ind]*255).astype(np.int)), 2)\n",
    "\n",
    "        cv2.imwrite(annotationsViz_dir + '/%(stack)s_%(sec)04d_annotationsProjectedViz_z%(z)04d.jpg' % \\\n",
    "                    {'stack': stack, 'sec': map_z_to_section[z], 'z': z}, \n",
    "                    img_as_ubyte(viz[..., [2,1,0]]))\n",
    "\n",
    "        del viz\n",
    "\n",
    "\n",
    "    del test_volume_atlas_projected\n",
    "    \n",
    "    logger.removeHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
