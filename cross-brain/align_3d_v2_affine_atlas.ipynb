{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Aligns a score volume with an annotation volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.environ['REPO_DIR'] + '/utilities')\n",
    "from utilities2015 import *\n",
    "from registration_utilities import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import time\n",
    "\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "volume_dir = '/oasis/projects/nsf/csd395/yuncong/CSHL_volumes/'\n",
    "\n",
    "atlasAlignOptLogs_dir = create_if_not_exists('/oasis/projects/nsf/csd395/yuncong/CSHL_atlasAlignOptLogs_atlas')\n",
    "atlasAlignParams_dir = create_if_not_exists('/oasis/projects/nsf/csd395/yuncong/CSHL_atlasAlignParams_atlas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "volume_landmark_names_unsided = ['12N', '5N', '6N', '7N', '7n', 'AP', 'Amb', 'LC',\n",
    "                                 'LRt', 'Pn', 'R', 'RtTg', 'Tz', 'VLL', 'sp5']\n",
    "linear_landmark_names_unsided = ['outerContour']\n",
    "\n",
    "labels_unsided = volume_landmark_names_unsided + linear_landmark_names_unsided\n",
    "labels_unsided_indices = dict((j, i+1) for i, j in enumerate(labels_unsided))  # BackG always 0\n",
    "\n",
    "labelMap_unsidedToSided = {'12N': ['12N'],\n",
    "                            '5N': ['5N_L', '5N_R'],\n",
    "                            '6N': ['6N_L', '6N_R'],\n",
    "                            '7N': ['7N_L', '7N_R'],\n",
    "                            '7n': ['7n_L', '7n_R'],\n",
    "                            'AP': ['AP'],\n",
    "                            'Amb': ['Amb_L', 'Amb_R'],\n",
    "                            'LC': ['LC_L', 'LC_R'],\n",
    "                            'LRt': ['LRt_L', 'LRt_R'],\n",
    "                            'Pn': ['Pn_L', 'Pn_R'],\n",
    "                            'R': ['R_L', 'R_R'],\n",
    "                            'RtTg': ['RtTg'],\n",
    "                            'Tz': ['Tz_L', 'Tz_R'],\n",
    "                            'VLL': ['VLL_L', 'VLL_R'],\n",
    "                            'sp5': ['sp5'],\n",
    "                           'outerContour': ['outerContour']}\n",
    "\n",
    "labelMap_sidedToUnsided = {n: nu for nu, ns in labelMap_unsidedToSided.iteritems() for n in ns}\n",
    "\n",
    "from itertools import chain\n",
    "labels_sided = list(chain(*(labelMap_unsidedToSided[name_u] for name_u in labels_unsided)))\n",
    "labels_sided_indices = dict((j, i+1) for i, j in enumerate(labels_sided)) # BackG always 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 303.   200.5  265.5]\n"
     ]
    }
   ],
   "source": [
    "# atlas_volume = bp.unpack_ndarray_file(os.path.join(volume_dir, 'MD589/volume_MD589_annotation_withOuterContour.bp'))\n",
    "atlas_volume = bp.unpack_ndarray_file(volume_dir + '/atlasVolume_icp.bp')\n",
    "\n",
    "atlas_ydim, atlas_xdim, atlas_zdim = atlas_volume.shape\n",
    "atlas_centroid = np.array([.5*atlas_xdim, .5*atlas_ydim, .5*atlas_zdim])\n",
    "print atlas_centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "available_labels_sided = [labels_sided[i-1] for i in np.unique(atlas_volume) if i > 0]\n",
    "available_labels_unsided = set([labelMap_sidedToUnsided[name] for name in available_labels_sided ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load atlas: 2.121395 seconds\n"
     ]
    }
   ],
   "source": [
    "def parallel_where(name, num_samples=None):\n",
    "    \n",
    "    w = np.where(atlas_volume == labels_sided_indices[name])\n",
    "    \n",
    "    if num_samples is not None:\n",
    "        n = len(w[0])\n",
    "        sample_indices = np.random.choice(range(n), min(num_samples, n), replace=False)\n",
    "        return np.c_[w[1][sample_indices].astype(np.int16), \n",
    "                     w[0][sample_indices].astype(np.int16), \n",
    "                     w[2][sample_indices].astype(np.int16)]\n",
    "    else:\n",
    "        return np.c_[w[1].astype(np.int16), w[0].astype(np.int16), w[2].astype(np.int16)]\n",
    "\n",
    "t = time.time()\n",
    "\n",
    "atlas_nzs = Parallel(n_jobs=16)(delayed(parallel_where)(name_s, num_samples=int(1e5)) for name_s in available_labels_sided)\n",
    "atlas_nzs = dict(zip(available_labels_sided, atlas_nzs))\n",
    "\n",
    "sys.stderr.write('load atlas: %f seconds\\n' % (time.time() - t)) #~ 7s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pts_centered = {name: (np.concatenate([atlas_nzs[n] for n in labelMap_unsidedToSided[name]]) - atlas_centroid).astype(np.int16) \n",
    "                         for name in available_labels_unsided}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# label_weights = {name: 0 if name == 'outerContour' else 1. for name in labels_unsided[1:]}\n",
    "label_weights = {name: .1 if name == 'outerContour' else 1. for name in available_labels_unsided}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_score_and_gradient(T):\n",
    "    global pts_centered\n",
    "    \n",
    "    score = 0\n",
    "    dMdA = np.zeros((12,))\n",
    "    \n",
    "    for name in available_labels_unsided:\n",
    "#         t1 = time.time()\n",
    "    \n",
    "        pts_prime = transform_points(T, pts_centered=pts_centered[name], c_prime=test_centroid)\n",
    "        \n",
    "        xs_prime, ys_prime, zs_prime = pts_prime.T.astype(np.int16)\n",
    "\n",
    "        valid = (xs_prime >= 0) & (ys_prime >= 0) & (zs_prime >= 0) & \\\n",
    "                (xs_prime < test_xdim) & (ys_prime < test_ydim) & (zs_prime < test_zdim)\n",
    "                   \n",
    "        if np.count_nonzero(valid) > 0:\n",
    "\n",
    "            xs_prime_valid = xs_prime[valid]\n",
    "            ys_prime_valid = ys_prime[valid]\n",
    "            zs_prime_valid = zs_prime[valid]\n",
    "            \n",
    "            voxel_probs_valid = volume2_allLabels[name][ys_prime_valid, xs_prime_valid, zs_prime_valid] / 1e4\n",
    "\n",
    "            score += label_weights[name] * voxel_probs_valid.sum()\n",
    "            \n",
    "            Sx = dSdxyz[name][0, ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "            Sy = dSdxyz[name][1, ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "            Sz = dSdxyz[name][2, ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "            \n",
    "            dxs, dys, dzs = pts_centered[name][valid].T\n",
    "\n",
    "            q = np.c_[Sx*dxs, Sx*dys, Sx*dzs, Sx, \n",
    "                          Sy*dxs, Sy*dys, Sy*dzs, Sy,\n",
    "                          Sz*dxs, Sz*dys, Sz*dzs, Sz]        \n",
    "            \n",
    "            dMdA += label_weights[name] * q.sum(axis=0)\n",
    "            \n",
    "            del voxel_probs_valid, q, Sx, Sy, Sz, dxs, dys, dzs, xs_prime_valid, ys_prime_valid, zs_prime_valid\n",
    "        \n",
    "#         sys.stderr.write('########### %s: %f seconds\\n' % (labels[l], time.time() - t1))\n",
    "        \n",
    "        del valid, xs_prime, ys_prime, zs_prime, pts_prime\n",
    "        \n",
    "    return score, dMdA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_score(T):\n",
    "    \n",
    "    score = 0\n",
    "    for name in available_labels_unsided:\n",
    "        \n",
    "        pts_prime = transform_points(T, pts_centered=pts_centered[name], c_prime=test_centroid)\n",
    "    \n",
    "        xs_prime, ys_prime, zs_prime = pts_prime.T.astype(np.int16)\n",
    "        \n",
    "        valid = (xs_prime >= 0) & (ys_prime >= 0) & (zs_prime >= 0) & \\\n",
    "            (xs_prime < test_xdim) & (ys_prime < test_ydim) & (zs_prime < test_zdim)\n",
    "            \n",
    "        voxel_probs_valid = volume2_allLabels[name][ys_prime[valid], xs_prime[valid], zs_prime[valid]] / 1e4\n",
    "\n",
    "        score += label_weights[name] * voxel_probs_valid.sum()\n",
    "                \n",
    "        del voxel_probs_valid, valid, xs_prime, ys_prime, zs_prime, pts_prime\n",
    "                \n",
    "    return score\n",
    "\n",
    "def compute_score_gradient(T):\n",
    "\n",
    "    dMdA = np.zeros((12,))\n",
    "\n",
    "    for name in available_labels_unsided:\n",
    "#       \n",
    "        pts_prime = transform_points(T, pts_centered=pts_centered[name], c_prime=test_centroid)\n",
    "\n",
    "        xs_prime, ys_prime, zs_prime = pts_prime.T.astype(np.int16)\n",
    "\n",
    "        valid = (xs_prime >= 0) & (ys_prime >= 0) & (zs_prime >= 0) & \\\n",
    "            (xs_prime < test_xdim) & (ys_prime < test_ydim) & (zs_prime < test_zdim)\n",
    "            \n",
    "        if np.count_nonzero(valid) > 0:\n",
    "            \n",
    "            xs_prime_valid = xs_prime[valid]\n",
    "            ys_prime_valid = ys_prime[valid]\n",
    "            zs_prime_valid = zs_prime[valid]\n",
    "            \n",
    "            Sx = dSdxyz[name][0, ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "            Sy = dSdxyz[name][1, ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "            Sz = dSdxyz[name][2, ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "               \n",
    "            dxs, dys, dzs = pts_centered[name][valid].T\n",
    "                        \n",
    "            dMdA += label_weights[name] * np.c_[Sx*dxs, Sx*dys, Sx*dzs, Sx, \n",
    "                          Sy*dxs, Sy*dys, Sy*dzs, Sy,\n",
    "                          Sz*dxs, Sz*dys, Sz*dzs, Sz].sum(axis=0)\n",
    "            \n",
    "    return dMdA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load score volumes: 33.129031 seconds\n",
      "load gradient RtTg: 8.678933 seconds\n",
      "load gradient VLL: 8.766556 seconds\n",
      "load gradient Tz: 6.795144 seconds\n",
      "load gradient LC: 7.191441 seconds\n",
      "load gradient 7N: 7.374749 seconds\n",
      "load gradient Amb: 6.503481 seconds\n",
      "load gradient 6N: 14.649255 seconds\n",
      "load gradient AP: 8.815282 seconds\n",
      "load gradient 5N: 13.104009 seconds\n",
      "load gradient 12N: 11.023642 seconds\n",
      "load gradient 7n: 11.301693 seconds\n",
      "load gradient R: 14.008791 seconds\n",
      "load gradient Pn: 17.779434 seconds\n",
      "load gradient LRt: 15.594274 seconds\n",
      "overall: 151.592230 seconds\n",
      "INFO:__main__:grid search iteration 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_xdim, test_ydim, test_zdim: 1056 472 437\n",
      "test_centroid: [ 528.   236.   218.5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "grid search: 28.949753 seconds\n",
      "INFO:__main__:0.000000 18.598332\n",
      "INFO:__main__:-32.637393 32.914892 -27.375946\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:grid search iteration 1\n",
      "grid search: 22.733895 seconds\n",
      "INFO:__main__:18.598332 20.424042\n",
      "INFO:__main__:-58.801094 13.847452 6.066489\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:grid search iteration 2\n",
      "grid search: 17.753923 seconds\n",
      "INFO:__main__:20.424042 20.483360\n",
      "INFO:__main__:-37.485847 23.766837 7.384356\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:grid search iteration 3\n",
      "grid search: 13.520829 seconds\n",
      "INFO:__main__:20.483360 23.471802\n",
      "INFO:__main__:-55.335922 17.154116 -7.921151\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:grid search iteration 4\n",
      "grid search: 10.277319 seconds\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 0\n",
      "INFO:__main__:score: 23.471802\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 1\n",
      "INFO:__main__:score: 28.264053\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 2\n",
      "INFO:__main__:score: 32.149796\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 3\n",
      "INFO:__main__:score: 33.800346\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 4\n",
      "INFO:__main__:score: 36.852661\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 5\n",
      "INFO:__main__:score: 44.465404\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 6\n",
      "INFO:__main__:score: 45.053482\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 7\n",
      "INFO:__main__:score: 46.381161\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 8\n",
      "INFO:__main__:score: 45.566795\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 9\n",
      "INFO:__main__:score: 52.392242\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 10\n",
      "INFO:__main__:score: 53.484066\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 11\n",
      "INFO:__main__:score: 53.500137\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 12\n",
      "INFO:__main__:score: 53.590996\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 13\n",
      "INFO:__main__:score: 54.221024\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 14\n",
      "INFO:__main__:score: 54.739075\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 15\n",
      "INFO:__main__:score: 55.047760\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 16\n",
      "INFO:__main__:score: 55.711533\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 17\n",
      "INFO:__main__:score: 55.737915\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 18\n",
      "INFO:__main__:score: 56.324203\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 19\n",
      "INFO:__main__:score: 56.172791\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 20\n",
      "INFO:__main__:score: 56.562225\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 21\n",
      "INFO:__main__:score: 56.566223\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 22\n",
      "INFO:__main__:score: 56.738556\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 23\n",
      "INFO:__main__:score: 56.646179\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 24\n",
      "INFO:__main__:score: 56.787476\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 25\n",
      "INFO:__main__:score: 56.749573\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 26\n",
      "INFO:__main__:score: 56.779144\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 27\n",
      "INFO:__main__:score: 56.757751\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 28\n",
      "INFO:__main__:score: 56.913391\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 29\n",
      "INFO:__main__:score: 56.786316\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 30\n",
      "INFO:__main__:score: 56.902588\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 31\n",
      "INFO:__main__:score: 56.789124\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 32\n",
      "INFO:__main__:score: 56.935974\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 33\n",
      "INFO:__main__:score: 56.799561\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 34\n",
      "INFO:__main__:score: 56.959656\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 35\n",
      "INFO:__main__:score: 56.775146\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 36\n",
      "INFO:__main__:score: 56.952393\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 37\n",
      "INFO:__main__:score: 56.772095\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 38\n",
      "INFO:__main__:score: 56.930298\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 39\n",
      "INFO:__main__:score: 56.775085\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 40\n",
      "INFO:__main__:score: 56.931519\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 41\n",
      "INFO:__main__:score: 56.826904\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 42\n",
      "INFO:__main__:score: 56.957825\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 43\n",
      "INFO:__main__:score: 56.840332\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 44\n",
      "INFO:__main__:score: 56.856201\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 45\n",
      "INFO:__main__:score: 56.749207\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 46\n",
      "INFO:__main__:score: 56.916748\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 47\n",
      "INFO:__main__:score: 56.767029\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 48\n",
      "INFO:__main__:score: 56.944580\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 49\n",
      "INFO:__main__:score: 56.770264\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 50\n",
      "INFO:__main__:score: 56.951538\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 51\n",
      "INFO:__main__:score: 56.817810\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 52\n",
      "INFO:__main__:score: 56.939758\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 53\n",
      "INFO:__main__:score: 56.881836\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 54\n",
      "INFO:__main__:score: 56.968628\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 55\n",
      "INFO:__main__:score: 56.880859\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 56\n",
      "INFO:__main__:score: 56.959900\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 57\n",
      "INFO:__main__:score: 56.794983\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 58\n",
      "INFO:__main__:score: 56.965820\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 59\n",
      "INFO:__main__:score: 56.912048\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 60\n",
      "INFO:__main__:score: 56.919800\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 61\n",
      "INFO:__main__:score: 56.918457\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 62\n",
      "INFO:__main__:score: 56.862488\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 63\n",
      "INFO:__main__:score: 56.937134\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 64\n",
      "INFO:__main__:score: 56.935852\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 65\n",
      "INFO:__main__:score: 56.878357\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 66\n",
      "INFO:__main__:score: 56.970520\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 67\n",
      "INFO:__main__:score: 56.873779\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 68\n",
      "INFO:__main__:score: 56.970825\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 69\n",
      "INFO:__main__:score: 56.833374\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 70\n",
      "INFO:__main__:score: 56.938171\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 71\n",
      "INFO:__main__:score: 56.869629\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 72\n",
      "INFO:__main__:score: 56.948914\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 73\n",
      "INFO:__main__:score: 56.902039\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 74\n",
      "INFO:__main__:score: 56.974060\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 75\n",
      "INFO:__main__:score: 56.886169\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 76\n",
      "INFO:__main__:score: 56.953674\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 77\n",
      "INFO:__main__:score: 56.933655\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 78\n",
      "INFO:__main__:score: 56.904846\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 79\n",
      "INFO:__main__:score: 56.922241\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 80\n",
      "INFO:__main__:score: 56.904968\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 81\n",
      "INFO:__main__:score: 56.917664\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 82\n",
      "INFO:__main__:score: 56.938965\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 83\n",
      "INFO:__main__:score: 56.979431\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 84\n",
      "INFO:__main__:score: 56.899231\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 85\n",
      "INFO:__main__:score: 56.937439\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 86\n",
      "INFO:__main__:score: 56.948914\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 87\n",
      "INFO:__main__:score: 56.924316\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 88\n",
      "INFO:__main__:score: 56.966309\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 89\n",
      "INFO:__main__:score: 56.926575\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 90\n",
      "INFO:__main__:score: 56.951111\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 91\n",
      "INFO:__main__:score: 56.936462\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 92\n",
      "INFO:__main__:score: 56.922241\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 93\n",
      "INFO:__main__:score: 56.911316\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 94\n",
      "INFO:__main__:score: 56.915405\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 95\n",
      "INFO:__main__:score: 56.898865\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 96\n",
      "INFO:__main__:score: 56.878052\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 97\n",
      "INFO:__main__:score: 56.837585\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 98\n",
      "INFO:__main__:score: 56.916077\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 99\n",
      "INFO:__main__:score: 56.880005\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 100\n",
      "INFO:__main__:score: 56.898438\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 101\n",
      "INFO:__main__:score: 56.928467\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 102\n",
      "INFO:__main__:score: 56.909058\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 103\n",
      "INFO:__main__:score: 56.915405\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 104\n",
      "INFO:__main__:score: 56.912048\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 105\n",
      "INFO:__main__:score: 56.978760\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 106\n",
      "INFO:__main__:score: 56.918518\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 107\n",
      "INFO:__main__:score: 56.927368\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 108\n",
      "INFO:__main__:score: 56.900269\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 109\n",
      "INFO:__main__:score: 56.922363\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 110\n",
      "INFO:__main__:score: 56.871399\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 111\n",
      "INFO:__main__:score: 56.880798\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 112\n",
      "INFO:__main__:score: 56.916687\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 113\n",
      "INFO:__main__:score: 56.956726\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 114\n",
      "INFO:__main__:score: 56.892517\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 115\n",
      "INFO:__main__:score: 56.967468\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 116\n",
      "INFO:__main__:score: 56.917358\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 117\n",
      "INFO:__main__:score: 56.904724\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 118\n",
      "INFO:__main__:score: 56.881287\n",
      "INFO:__main__:\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEKCAYAAADpfBXhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x62206d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For all stacks\n",
    "\n",
    "# for stack in ['MD594', 'MD593', 'MD585', 'MD592', 'MD590', 'MD591', 'MD595', 'MD598', 'MD602']:\n",
    "for stack in ['MD603']:\n",
    "    # will do for MD589, MD603 later\n",
    "    \n",
    "    ################# Load Test Volume ######################\n",
    "\n",
    "    t = time.time()\n",
    "\n",
    "    volume2_allLabels = {}\n",
    "\n",
    "    for name in available_labels_unsided:\n",
    "\n",
    "        if name == 'BackG':\n",
    "            continue\n",
    "\n",
    "        volume2_roi = bp.unpack_ndarray_file(os.path.join(volume_dir, '%(stack)s/%(stack)s_scoreVolume_%(label)s.bp' % \\\n",
    "                                                          {'stack': stack, 'label': name})).astype(np.float16)\n",
    "        volume2_allLabels[name] = volume2_roi\n",
    "        del volume2_roi\n",
    "\n",
    "    test_ydim, test_xdim, test_zdim = volume2_allLabels.values()[0].shape\n",
    "    test_centroid = np.r_[.5*test_xdim, .5*test_ydim, .5*test_zdim]\n",
    "\n",
    "    print 'test_xdim, test_ydim, test_zdim:', test_xdim, test_ydim, test_zdim\n",
    "    print 'test_centroid:', test_centroid\n",
    "\n",
    "    sys.stderr.write('load score volumes: %f seconds\\n' % (time.time() - t))\n",
    "\n",
    "    ###################### Load Gradient #####################\n",
    "\n",
    "    dSdxyz = {name: np.empty((3, test_ydim, test_xdim, test_zdim), dtype=np.float16) for name in available_labels_unsided}\n",
    "\n",
    "    t1 = time.time()\n",
    "\n",
    "    for name in available_labels_unsided:\n",
    "\n",
    "        if name == 'BackG':\n",
    "            continue\n",
    "\n",
    "        t = time.time()\n",
    "\n",
    "        dSdxyz[name][0] = bp.unpack_ndarray_file(volume_dir + '/%(stack)s/%(stack)s_scoreVolume_%(label)s_gx.bp' % {'stack':stack, 'label':name})\n",
    "        dSdxyz[name][1] = bp.unpack_ndarray_file(volume_dir + '/%(stack)s/%(stack)s_scoreVolume_%(label)s_gy.bp' % {'stack':stack, 'label':name})\n",
    "        dSdxyz[name][2] = bp.unpack_ndarray_file(volume_dir + '/%(stack)s/%(stack)s_scoreVolume_%(label)s_gz.bp' % {'stack':stack, 'label':name})\n",
    "\n",
    "        sys.stderr.write('load gradient %s: %f seconds\\n' % (name, time.time() - t)) # ~6s\n",
    "\n",
    "    sys.stderr.write('overall: %f seconds\\n' % (time.time() - t1)) # ~100s\n",
    "    \n",
    "    handler = logging.FileHandler(atlasAlignOptLogs_dir + '/%(stack)s_atlasAlignOpt.log' % {'stack': stack})\n",
    "    handler.setLevel(logging.INFO)\n",
    "    logger.addHandler(handler)\n",
    "\n",
    "    ################# Random Grid Search ######################\n",
    "\n",
    "    grid_search_iteration_number = 5\n",
    "    # grid_search_iteration_number = 1\n",
    "\n",
    "    params_best_upToNow = (0, 0, 0)\n",
    "    score_best_upToNow = 0\n",
    "\n",
    "    init_n = 1000\n",
    "\n",
    "    for iteration in range(grid_search_iteration_number):\n",
    "\n",
    "        logger.info('grid search iteration %d', iteration)\n",
    "\n",
    "        init_tx, init_ty, init_tz  = params_best_upToNow\n",
    "\n",
    "        n = int(init_n*np.exp(-iteration/3.))\n",
    "\n",
    "        sigma_tx = 300*np.exp(-iteration/3.)\n",
    "        sigma_ty = 300*np.exp(-iteration/3.)\n",
    "        sigma_tz = 100*np.exp(-iteration/3.)\n",
    "\n",
    "        tx_grid = init_tx + sigma_tx * (2 * np.random.random(n) - 1)\n",
    "        ty_grid = init_ty + sigma_ty * (2 * np.random.random(n) - 1)\n",
    "        tz_grid = init_tz + sigma_tz * (2 * np.random.random(n) - 1)\n",
    "\n",
    "        samples = np.c_[tx_grid, ty_grid, tz_grid]\n",
    "\n",
    "        import time\n",
    "\n",
    "        t = time.time()\n",
    "        # num jobs * memory each job\n",
    "\n",
    "        scores = Parallel(n_jobs=8)(delayed(compute_score)(np.r_[1, 0, 0, tx, 0, 1, 0, ty, 0, 0, 1, tz])\n",
    "                                    for tx, ty, tz in samples)\n",
    "\n",
    "    #     scores = []\n",
    "    #     for tx, ty, tz in samples:\n",
    "    #         scores.append(compute_score([1, 0, 0, tx, 0, 1, 0, ty, 0, 0, 1, tz]))\n",
    "\n",
    "        sys.stderr.write('grid search: %f seconds\\n' % (time.time() - t)) # ~23s\n",
    "\n",
    "        score_best = np.max(scores)\n",
    "\n",
    "        tx_best, ty_best, tz_best = samples[np.argmax(scores)]\n",
    "\n",
    "        if score_best > score_best_upToNow:\n",
    "            logger.info('%f %f', score_best_upToNow, score_best)\n",
    "\n",
    "            score_best_upToNow = score_best\n",
    "            params_best_upToNow = tx_best, ty_best, tz_best\n",
    "\n",
    "            logger.info('%f %f %f', tx_best, ty_best, tz_best)\n",
    "\n",
    "        logger.info('\\n')\n",
    "        \n",
    "    ################# Gradient Descent ######################\n",
    "\n",
    "    lr1, lr2 = (10., 1e-1)\n",
    "    # lr1, lr2 = (1., 1e-3)\n",
    "\n",
    "    # auto_corr = .95\n",
    "\n",
    "    max_iter_num = 1000\n",
    "    fudge_factor = 1e-6 #for numerical stability\n",
    "    dMdA_historical = np.zeros((12,))\n",
    "\n",
    "    tx_best, ty_best, tz_best = params_best_upToNow\n",
    "    T_best = np.r_[1,0,0, tx_best, 0,1,0, ty_best, 0,0,1, tz_best]\n",
    "\n",
    "    lr = np.r_[lr2, lr2, lr2, lr1, lr2, lr2, lr2, lr1, lr2, lr2, lr2, lr1]\n",
    "\n",
    "    score_best = 0\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    for iteration in range(max_iter_num):\n",
    "\n",
    "        logger.info('iteration %d', iteration)\n",
    "\n",
    "    #     t = time.time()\n",
    "        s, dMdA = compute_score_and_gradient(T_best)\n",
    "    #     sys.stderr.write('compute_score_and_gradient: %f seconds\\n' % (time.time() - t)) #~ 2s/iteration or ~.5s: 1e5 samples per landmark\n",
    "\n",
    "        dMdA_historical += dMdA**2\n",
    "    #     dMdA_historical = auto_corr * dMdA_historical + (1-auto_corr) * dMdA**2\n",
    "\n",
    "        dMdA_adjusted = dMdA / (fudge_factor + np.sqrt(dMdA_historical))\n",
    "\n",
    "        T_best += lr*dMdA_adjusted\n",
    "\n",
    "    #         logger.info('A: ' + ' '.join(['%f']*12) % tuple(A_best))\n",
    "    #         logger.info('dMdA adjusted: ' + ' '.join(['%f']*12) % tuple(dMdA_adjusted))\n",
    "\n",
    "        logger.info('score: %f', s)\n",
    "        scores.append(s)\n",
    "\n",
    "        logger.info('\\n')\n",
    "\n",
    "        history_len = 50\n",
    "        if iteration > 100:\n",
    "            if np.abs(np.mean(scores[iteration-history_len:iteration]) - \\\n",
    "                      np.mean(scores[iteration-2*history_len:iteration-history_len])) < 1e-1:\n",
    "                break\n",
    "\n",
    "        if s > score_best:\n",
    "    #             logger.info('Current best')\n",
    "            best_gradient_descent_params = T_best\n",
    "            score_best = s\n",
    "\n",
    "    plt.title('%s' % stack);\n",
    "    plt.plot(scores);\n",
    "    plt.show();\n",
    "    \n",
    "    del volume2_allLabels, dSdxyz\n",
    "    \n",
    "    ################# Save results ###############\n",
    "    \n",
    "    np.save(atlasAlignOptLogs_dir + '/%(stack)s_scoreEvolutions.npy' % {'stack':stack}, scores)\n",
    "    \n",
    "    create_if_not_exists(os.path.join(atlasAlignParams_dir + '/' + stack))\n",
    "    with open(os.path.join(atlasAlignParams_dir, '%(stack)s/%(stack)s_3dAlignParams.txt' % {'stack':stack}), 'w') as f:\n",
    "\n",
    "        f.writelines(' '.join(['%f']*len(best_gradient_descent_params)) % tuple(best_gradient_descent_params) + '\\n')\n",
    "        f.write((' '.join(['%d']*3)+'\\n') % tuple([atlas_xdim, atlas_ydim, atlas_zdim]))\n",
    "        f.write((' '.join(['%.1f']*3)+'\\n') % tuple(atlas_centroid))    \n",
    "        f.write((' '.join(['%d']*3)+'\\n') % tuple([test_xdim, test_ydim, test_zdim]))\n",
    "        f.write((' '.join(['%.1f']*3)+'\\n') % tuple(test_centroid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# single stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack = 'MD585'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "################# Load Test Volume ######################\n",
    "\n",
    "t = time.time()\n",
    "\n",
    "volume2_allLabels = {}\n",
    "\n",
    "for name in available_labels_unsided:\n",
    "\n",
    "    if name == 'BackG':\n",
    "        continue\n",
    "\n",
    "    volume2_roi = bp.unpack_ndarray_file(os.path.join(volume_dir, '%(stack)s/%(stack)s_scoreVolume_%(label)s.bp' % \\\n",
    "                                                      {'stack': stack, 'label': name})).astype(np.float16)\n",
    "    volume2_allLabels[name] = volume2_roi\n",
    "    del volume2_roi\n",
    "\n",
    "test_ydim, test_xdim, test_zdim = volume2_allLabels.values()[0].shape\n",
    "test_centroid = np.r_[.5*test_xdim, .5*test_ydim, .5*test_zdim]\n",
    "\n",
    "print 'test_xdim, test_ydim, test_zdim:', test_xdim, test_ydim, test_zdim\n",
    "print 'test_centroid:', test_centroid\n",
    "\n",
    "# test_xdim = volume_xmax - volume_xmin + 1\n",
    "# test_ydim = volume_ymax - volume_ymin + 1\n",
    "# test_zdim = volume_zmax - volume_zmin + 1\n",
    "\n",
    "sys.stderr.write('load score volumes: %f seconds\\n' % (time.time() - t))\n",
    "\n",
    "###################### Load Gradient #####################\n",
    "\n",
    "dSdxyz = {name: np.empty((3, test_ydim, test_xdim, test_zdim), dtype=np.float16) for name in available_labels_unsided}\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "for name in available_labels_unsided:\n",
    "\n",
    "    if name == 'BackG':\n",
    "        continue\n",
    "\n",
    "    t = time.time()\n",
    "\n",
    "    dSdxyz[name][0] = bp.unpack_ndarray_file(volume_dir + '/%(stack)s/%(stack)s_scoreVolume_%(label)s_gx.bp' % {'stack':stack, 'label':name})\n",
    "    dSdxyz[name][1] = bp.unpack_ndarray_file(volume_dir + '/%(stack)s/%(stack)s_scoreVolume_%(label)s_gy.bp' % {'stack':stack, 'label':name})\n",
    "    dSdxyz[name][2] = bp.unpack_ndarray_file(volume_dir + '/%(stack)s/%(stack)s_scoreVolume_%(label)s_gz.bp' % {'stack':stack, 'label':name})\n",
    "\n",
    "    sys.stderr.write('load gradient %s: %f seconds\\n' % (name, time.time() - t)) # ~6s\n",
    "\n",
    "sys.stderr.write('overall: %f seconds\\n' % (time.time() - t1)) # ~100s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "handler = logging.FileHandler(atlasAlignOptLogs_dir + '/%(stack)s_atlasAlignOpt.log' % {'stack': stack})\n",
    "handler.setLevel(logging.INFO)\n",
    "logger.addHandler(handler)\n",
    "\n",
    "################# Random Grid Search ######################\n",
    "\n",
    "grid_search_iteration_number = 5\n",
    "# grid_search_iteration_number = 1\n",
    "\n",
    "params_best_upToNow = (0, 0, 0)\n",
    "score_best_upToNow = 0\n",
    "\n",
    "init_n = 1000\n",
    "\n",
    "for iteration in range(grid_search_iteration_number):\n",
    "\n",
    "    logger.info('grid search iteration %d', iteration)\n",
    "\n",
    "    init_tx, init_ty, init_tz  = params_best_upToNow\n",
    "\n",
    "    n = int(init_n*np.exp(-iteration/3.))\n",
    "\n",
    "    sigma_tx = 300*np.exp(-iteration/3.)\n",
    "    sigma_ty = 300*np.exp(-iteration/3.)\n",
    "    sigma_tz = 100*np.exp(-iteration/3.)\n",
    "\n",
    "    tx_grid = init_tx + sigma_tx * (2 * np.random.random(n) - 1)\n",
    "    ty_grid = init_ty + sigma_ty * (2 * np.random.random(n) - 1)\n",
    "    tz_grid = init_tz + sigma_tz * (2 * np.random.random(n) - 1)\n",
    "\n",
    "    samples = np.c_[tx_grid, ty_grid, tz_grid]\n",
    "\n",
    "    import time\n",
    "\n",
    "    t = time.time()\n",
    "    # num jobs * memory each job\n",
    "    \n",
    "    scores = Parallel(n_jobs=8)(delayed(compute_score)(np.r_[1, 0, 0, tx, 0, 1, 0, ty, 0, 0, 1, tz])\n",
    "                                for tx, ty, tz in samples)\n",
    "\n",
    "#     scores = []\n",
    "#     for tx, ty, tz in samples:\n",
    "#         scores.append(compute_score([1, 0, 0, tx, 0, 1, 0, ty, 0, 0, 1, tz]))\n",
    "                                \n",
    "    sys.stderr.write('grid search: %f seconds\\n' % (time.time() - t)) # ~23s\n",
    "    \n",
    "    score_best = np.max(scores)\n",
    "\n",
    "    tx_best, ty_best, tz_best = samples[np.argmax(scores)]\n",
    "\n",
    "    if score_best > score_best_upToNow:\n",
    "        logger.info('%f %f', score_best_upToNow, score_best)\n",
    "\n",
    "        score_best_upToNow = score_best\n",
    "        params_best_upToNow = tx_best, ty_best, tz_best\n",
    "\n",
    "        logger.info('%f %f %f', tx_best, ty_best, tz_best)\n",
    "    \n",
    "    logger.info('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "################# Gradient Descent ######################\n",
    "\n",
    "lr1, lr2 = (10., 1e-1)\n",
    "# lr1, lr2 = (1., 1e-3)\n",
    "\n",
    "# auto_corr = .95\n",
    "\n",
    "max_iter_num = 1000\n",
    "fudge_factor = 1e-6 #for numerical stability\n",
    "dMdA_historical = np.zeros((12,))\n",
    "\n",
    "tx_best, ty_best, tz_best = params_best_upToNow\n",
    "T_best = np.r_[1,0,0, tx_best, 0,1,0, ty_best, 0,0,1, tz_best]\n",
    "\n",
    "lr = np.r_[lr2, lr2, lr2, lr1, lr2, lr2, lr2, lr1, lr2, lr2, lr2, lr1]\n",
    "\n",
    "score_best = 0\n",
    "\n",
    "scores = []\n",
    "\n",
    "for iteration in range(max_iter_num):\n",
    "\n",
    "    logger.info('iteration %d', iteration)\n",
    "\n",
    "#     t = time.time()\n",
    "    s, dMdA = compute_score_and_gradient(T_best)\n",
    "#     sys.stderr.write('compute_score_and_gradient: %f seconds\\n' % (time.time() - t)) #~ 2s/iteration or ~.5s: 1e5 samples per landmark\n",
    "\n",
    "    dMdA_historical += dMdA**2\n",
    "#     dMdA_historical = auto_corr * dMdA_historical + (1-auto_corr) * dMdA**2\n",
    "\n",
    "    dMdA_adjusted = dMdA / (fudge_factor + np.sqrt(dMdA_historical))\n",
    "\n",
    "    T_best += lr*dMdA_adjusted\n",
    "\n",
    "#         logger.info('A: ' + ' '.join(['%f']*12) % tuple(A_best))\n",
    "#         logger.info('dMdA adjusted: ' + ' '.join(['%f']*12) % tuple(dMdA_adjusted))\n",
    "\n",
    "    logger.info('score: %f', s)\n",
    "    scores.append(s)\n",
    "\n",
    "    logger.info('\\n')\n",
    "\n",
    "    history_len = 50\n",
    "    if iteration > 100:\n",
    "        if np.abs(np.mean(scores[iteration-history_len:iteration]) - \\\n",
    "                  np.mean(scores[iteration-2*history_len:iteration-history_len])) < 1e-1:\n",
    "            break\n",
    "\n",
    "    if s > score_best:\n",
    "#             logger.info('Current best')\n",
    "        best_gradient_descent_params = T_best\n",
    "        score_best = s\n",
    "\n",
    "plt.plot(scores);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(atlasAlignOptLogs_dir + '/%(stack)s_scoreEvolutions.npy' % {'stack':stack}, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(atlasAlignParams_dir, '%(stack)s/%(stack)s_3dAlignParams.txt' % {'stack':stack}), 'w') as f:\n",
    "\n",
    "    f.writelines(' '.join(['%f']*len(best_gradient_descent_params)) % tuple(best_gradient_descent_params) + '\\n')\n",
    "    f.write((' '.join(['%d']*3)+'\\n') % tuple([atlas_xdim, atlas_ydim, atlas_zdim]))\n",
    "    f.write((' '.join(['%.1f']*3)+'\\n') % tuple(atlas_centroid))    \n",
    "    f.write((' '.join(['%d']*3)+'\\n') % tuple([test_xdim, test_ydim, test_zdim]))\n",
    "    f.write((' '.join(['%.1f']*3)+'\\n') % tuple(test_centroid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
