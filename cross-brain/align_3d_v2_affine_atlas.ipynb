{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Aligns a score volume with an annotation volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.environ['REPO_DIR'] + '/utilities')\n",
    "from utilities2015 import *\n",
    "from registration_utilities import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import time\n",
    "\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "volume_dir = '/oasis/projects/nsf/csd395/yuncong/CSHL_volumes/'\n",
    "\n",
    "atlasAlignOptLogs_dir = create_if_not_exists('/oasis/projects/nsf/csd395/yuncong/CSHL_atlasAlignOptLogs_atlas')\n",
    "atlasAlignParams_dir = create_if_not_exists('/oasis/projects/nsf/csd395/yuncong/CSHL_atlasAlignParams_atlas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "volume_landmark_names_unsided = ['12N', '5N', '6N', '7N', '7n', 'AP', 'Amb', 'LC',\n",
    "                                 'LRt', 'Pn', 'R', 'RtTg', 'Tz', 'VLL', 'sp5']\n",
    "linear_landmark_names_unsided = ['outerContour']\n",
    "\n",
    "labels_unsided = volume_landmark_names_unsided + linear_landmark_names_unsided\n",
    "labels_unsided_indices = dict((j, i+1) for i, j in enumerate(labels_unsided))  # BackG always 0\n",
    "\n",
    "labelMap_unsidedToSided = {'12N': ['12N'],\n",
    "                            '5N': ['5N_L', '5N_R'],\n",
    "                            '6N': ['6N_L', '6N_R'],\n",
    "                            '7N': ['7N_L', '7N_R'],\n",
    "                            '7n': ['7n_L', '7n_R'],\n",
    "                            'AP': ['AP'],\n",
    "                            'Amb': ['Amb_L', 'Amb_R'],\n",
    "                            'LC': ['LC_L', 'LC_R'],\n",
    "                            'LRt': ['LRt_L', 'LRt_R'],\n",
    "                            'Pn': ['Pn_L', 'Pn_R'],\n",
    "                            'R': ['R_L', 'R_R'],\n",
    "                            'RtTg': ['RtTg'],\n",
    "                            'Tz': ['Tz_L', 'Tz_R'],\n",
    "                            'VLL': ['VLL_L', 'VLL_R'],\n",
    "                            'sp5': ['sp5'],\n",
    "                           'outerContour': ['outerContour']}\n",
    "\n",
    "labelMap_sidedToUnsided = {n: nu for nu, ns in labelMap_unsidedToSided.iteritems() for n in ns}\n",
    "\n",
    "from itertools import chain\n",
    "labels_sided = list(chain(*(labelMap_unsidedToSided[name_u] for name_u in labels_unsided)))\n",
    "labels_sided_indices = dict((j, i+1) for i, j in enumerate(labels_sided)) # BackG always 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 303.   200.5  265.5]\n"
     ]
    }
   ],
   "source": [
    "# atlas_volume = bp.unpack_ndarray_file(os.path.join(volume_dir, 'MD589/volume_MD589_annotation_withOuterContour.bp'))\n",
    "atlas_volume = bp.unpack_ndarray_file(volume_dir + '/atlasVolume_icp.bp')\n",
    "\n",
    "atlas_ydim, atlas_xdim, atlas_zdim = atlas_volume.shape\n",
    "atlas_centroid = np.array([.5*atlas_xdim, .5*atlas_ydim, .5*atlas_zdim])\n",
    "print atlas_centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "available_labels_sided = [labels_sided[i-1] for i in np.unique(atlas_volume) if i > 0]\n",
    "available_labels_unsided = set([labelMap_sidedToUnsided[name] for name in available_labels_sided ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load atlas: 2.016316 seconds\n"
     ]
    }
   ],
   "source": [
    "def parallel_where(name, num_samples=None):\n",
    "    \n",
    "    w = np.where(atlas_volume == labels_sided_indices[name])\n",
    "    \n",
    "    if num_samples is not None:\n",
    "        n = len(w[0])\n",
    "        sample_indices = np.random.choice(range(n), min(num_samples, n), replace=False)\n",
    "        return np.c_[w[1][sample_indices].astype(np.int16), \n",
    "                     w[0][sample_indices].astype(np.int16), \n",
    "                     w[2][sample_indices].astype(np.int16)]\n",
    "    else:\n",
    "        return np.c_[w[1].astype(np.int16), w[0].astype(np.int16), w[2].astype(np.int16)]\n",
    "\n",
    "t = time.time()\n",
    "\n",
    "atlas_nzs = Parallel(n_jobs=16)(delayed(parallel_where)(name_s, num_samples=int(1e5)) for name_s in available_labels_sided)\n",
    "atlas_nzs = dict(zip(available_labels_sided, atlas_nzs))\n",
    "\n",
    "sys.stderr.write('load atlas: %f seconds\\n' % (time.time() - t)) #~ 7s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pts_centered = {name: (np.concatenate([atlas_nzs[n] for n in labelMap_unsidedToSided[name]]) - atlas_centroid).astype(np.int16) \n",
    "                         for name in available_labels_unsided}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# label_weights = {name: 0 if name == 'outerContour' else 1. for name in labels_unsided[1:]}\n",
    "label_weights = {name: .1 if name == 'outerContour' else 1. for name in available_labels_unsided}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_score_and_gradient(T):\n",
    "    global pts_centered\n",
    "    \n",
    "    score = 0\n",
    "    dMdA = np.zeros((12,))\n",
    "    \n",
    "    for name in available_labels_unsided:\n",
    "#         t1 = time.time()\n",
    "    \n",
    "        pts_prime = transform_points(T, pts_centered=pts_centered[name], c_prime=test_centroid)\n",
    "        \n",
    "        xs_prime, ys_prime, zs_prime = pts_prime.T.astype(np.int16)\n",
    "\n",
    "        valid = (xs_prime >= 0) & (ys_prime >= 0) & (zs_prime >= 0) & \\\n",
    "                (xs_prime < test_xdim) & (ys_prime < test_ydim) & (zs_prime < test_zdim)\n",
    "                   \n",
    "        if np.count_nonzero(valid) > 0:\n",
    "\n",
    "            xs_prime_valid = xs_prime[valid]\n",
    "            ys_prime_valid = ys_prime[valid]\n",
    "            zs_prime_valid = zs_prime[valid]\n",
    "            \n",
    "            voxel_probs_valid = volume2_allLabels[name][ys_prime_valid, xs_prime_valid, zs_prime_valid] / 1e4\n",
    "\n",
    "            score += label_weights[name] * voxel_probs_valid.sum()\n",
    "            \n",
    "            Sx = dSdxyz[name][0, ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "            Sy = dSdxyz[name][1, ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "            Sz = dSdxyz[name][2, ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "            \n",
    "            dxs, dys, dzs = pts_centered[name][valid].T\n",
    "\n",
    "            q = np.c_[Sx*dxs, Sx*dys, Sx*dzs, Sx, \n",
    "                          Sy*dxs, Sy*dys, Sy*dzs, Sy,\n",
    "                          Sz*dxs, Sz*dys, Sz*dzs, Sz]        \n",
    "            \n",
    "            dMdA += label_weights[name] * q.sum(axis=0)\n",
    "            \n",
    "            del voxel_probs_valid, q, Sx, Sy, Sz, dxs, dys, dzs, xs_prime_valid, ys_prime_valid, zs_prime_valid\n",
    "        \n",
    "#         sys.stderr.write('########### %s: %f seconds\\n' % (labels[l], time.time() - t1))\n",
    "        \n",
    "        del valid, xs_prime, ys_prime, zs_prime, pts_prime\n",
    "        \n",
    "    return score, dMdA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_score(T):\n",
    "    \n",
    "    score = 0\n",
    "    for name in available_labels_unsided:\n",
    "        \n",
    "        pts_prime = transform_points(T, pts_centered=pts_centered[name], c_prime=test_centroid)\n",
    "    \n",
    "        xs_prime, ys_prime, zs_prime = pts_prime.T.astype(np.int16)\n",
    "        \n",
    "        valid = (xs_prime >= 0) & (ys_prime >= 0) & (zs_prime >= 0) & \\\n",
    "            (xs_prime < test_xdim) & (ys_prime < test_ydim) & (zs_prime < test_zdim)\n",
    "            \n",
    "        voxel_probs_valid = volume2_allLabels[name][ys_prime[valid], xs_prime[valid], zs_prime[valid]] / 1e4\n",
    "\n",
    "        score += label_weights[name] * voxel_probs_valid.sum()\n",
    "                \n",
    "        del voxel_probs_valid, valid, xs_prime, ys_prime, zs_prime, pts_prime\n",
    "                \n",
    "    return score\n",
    "\n",
    "def compute_score_gradient(T):\n",
    "\n",
    "    dMdA = np.zeros((12,))\n",
    "\n",
    "    for name in available_labels_unsided:\n",
    "#       \n",
    "        pts_prime = transform_points(T, pts_centered=pts_centered[name], c_prime=test_centroid)\n",
    "\n",
    "        xs_prime, ys_prime, zs_prime = pts_prime.T.astype(np.int16)\n",
    "\n",
    "        valid = (xs_prime >= 0) & (ys_prime >= 0) & (zs_prime >= 0) & \\\n",
    "            (xs_prime < test_xdim) & (ys_prime < test_ydim) & (zs_prime < test_zdim)\n",
    "            \n",
    "        if np.count_nonzero(valid) > 0:\n",
    "            \n",
    "            xs_prime_valid = xs_prime[valid]\n",
    "            ys_prime_valid = ys_prime[valid]\n",
    "            zs_prime_valid = zs_prime[valid]\n",
    "            \n",
    "            Sx = dSdxyz[name][0, ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "            Sy = dSdxyz[name][1, ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "            Sz = dSdxyz[name][2, ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "               \n",
    "            dxs, dys, dzs = pts_centered[name][valid].T\n",
    "                        \n",
    "            dMdA += label_weights[name] * np.c_[Sx*dxs, Sx*dys, Sx*dzs, Sx, \n",
    "                          Sy*dxs, Sy*dys, Sy*dzs, Sy,\n",
    "                          Sz*dxs, Sz*dys, Sz*dzs, Sz].sum(axis=0)\n",
    "            \n",
    "    return dMdA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load score volumes: 27.742517 seconds\n",
      "load gradient RtTg: 7.415765 seconds\n",
      "load gradient VLL: 9.908574 seconds\n",
      "load gradient Tz: 6.721036 seconds\n",
      "load gradient LC: 6.508395 seconds\n",
      "load gradient 7N: 7.099178 seconds\n",
      "load gradient Amb: 5.500979 seconds\n",
      "load gradient 6N: 7.024877 seconds\n",
      "load gradient AP: 6.568973 seconds\n",
      "load gradient 5N: 7.919946 seconds\n",
      "load gradient 12N: 16.073809 seconds\n",
      "load gradient 7n: 15.935724 seconds\n"
     ]
    }
   ],
   "source": [
    "# For all stacks\n",
    "\n",
    "for stack in ['MD594', 'MD593', 'MD585', 'MD592', 'MD590', 'MD591', 'MD595', 'MD598', 'MD602']:\n",
    "    # will do for MD589, MD603 later\n",
    "    \n",
    "    ################# Load Test Volume ######################\n",
    "\n",
    "    t = time.time()\n",
    "\n",
    "    volume2_allLabels = {}\n",
    "\n",
    "    for name in available_labels_unsided:\n",
    "\n",
    "        if name == 'BackG':\n",
    "            continue\n",
    "\n",
    "        volume2_roi = bp.unpack_ndarray_file(os.path.join(volume_dir, '%(stack)s/%(stack)s_scoreVolume_%(label)s.bp' % \\\n",
    "                                                          {'stack': stack, 'label': name})).astype(np.float16)\n",
    "        volume2_allLabels[name] = volume2_roi\n",
    "        del volume2_roi\n",
    "\n",
    "    test_ydim, test_xdim, test_zdim = volume2_allLabels.values()[0].shape\n",
    "    test_centroid = np.r_[.5*test_xdim, .5*test_ydim, .5*test_zdim]\n",
    "\n",
    "    print 'test_xdim, test_ydim, test_zdim:', test_xdim, test_ydim, test_zdim\n",
    "    print 'test_centroid:', test_centroid\n",
    "\n",
    "    sys.stderr.write('load score volumes: %f seconds\\n' % (time.time() - t))\n",
    "\n",
    "    ###################### Load Gradient #####################\n",
    "\n",
    "    dSdxyz = {name: np.empty((3, test_ydim, test_xdim, test_zdim), dtype=np.float16) for name in available_labels_unsided}\n",
    "\n",
    "    t1 = time.time()\n",
    "\n",
    "    for name in available_labels_unsided:\n",
    "\n",
    "        if name == 'BackG':\n",
    "            continue\n",
    "\n",
    "        t = time.time()\n",
    "\n",
    "        dSdxyz[name][0] = bp.unpack_ndarray_file(volume_dir + '/%(stack)s/%(stack)s_scoreVolume_%(label)s_gx.bp' % {'stack':stack, 'label':name})\n",
    "        dSdxyz[name][1] = bp.unpack_ndarray_file(volume_dir + '/%(stack)s/%(stack)s_scoreVolume_%(label)s_gy.bp' % {'stack':stack, 'label':name})\n",
    "        dSdxyz[name][2] = bp.unpack_ndarray_file(volume_dir + '/%(stack)s/%(stack)s_scoreVolume_%(label)s_gz.bp' % {'stack':stack, 'label':name})\n",
    "\n",
    "        sys.stderr.write('load gradient %s: %f seconds\\n' % (name, time.time() - t)) # ~6s\n",
    "\n",
    "    sys.stderr.write('overall: %f seconds\\n' % (time.time() - t1)) # ~100s\n",
    "    \n",
    "    handler = logging.FileHandler(atlasAlignOptLogs_dir + '/%(stack)s_atlasAlignOpt.log' % {'stack': stack})\n",
    "    handler.setLevel(logging.INFO)\n",
    "    logger.addHandler(handler)\n",
    "\n",
    "    ################# Random Grid Search ######################\n",
    "\n",
    "    grid_search_iteration_number = 5\n",
    "    # grid_search_iteration_number = 1\n",
    "\n",
    "    params_best_upToNow = (0, 0, 0)\n",
    "    score_best_upToNow = 0\n",
    "\n",
    "    init_n = 1000\n",
    "\n",
    "    for iteration in range(grid_search_iteration_number):\n",
    "\n",
    "        logger.info('grid search iteration %d', iteration)\n",
    "\n",
    "        init_tx, init_ty, init_tz  = params_best_upToNow\n",
    "\n",
    "        n = int(init_n*np.exp(-iteration/3.))\n",
    "\n",
    "        sigma_tx = 300*np.exp(-iteration/3.)\n",
    "        sigma_ty = 300*np.exp(-iteration/3.)\n",
    "        sigma_tz = 100*np.exp(-iteration/3.)\n",
    "\n",
    "        tx_grid = init_tx + sigma_tx * (2 * np.random.random(n) - 1)\n",
    "        ty_grid = init_ty + sigma_ty * (2 * np.random.random(n) - 1)\n",
    "        tz_grid = init_tz + sigma_tz * (2 * np.random.random(n) - 1)\n",
    "\n",
    "        samples = np.c_[tx_grid, ty_grid, tz_grid]\n",
    "\n",
    "        import time\n",
    "\n",
    "        t = time.time()\n",
    "        # num jobs * memory each job\n",
    "\n",
    "        scores = Parallel(n_jobs=8)(delayed(compute_score)(np.r_[1, 0, 0, tx, 0, 1, 0, ty, 0, 0, 1, tz])\n",
    "                                    for tx, ty, tz in samples)\n",
    "\n",
    "    #     scores = []\n",
    "    #     for tx, ty, tz in samples:\n",
    "    #         scores.append(compute_score([1, 0, 0, tx, 0, 1, 0, ty, 0, 0, 1, tz]))\n",
    "\n",
    "        sys.stderr.write('grid search: %f seconds\\n' % (time.time() - t)) # ~23s\n",
    "\n",
    "        score_best = np.max(scores)\n",
    "\n",
    "        tx_best, ty_best, tz_best = samples[np.argmax(scores)]\n",
    "\n",
    "        if score_best > score_best_upToNow:\n",
    "            logger.info('%f %f', score_best_upToNow, score_best)\n",
    "\n",
    "            score_best_upToNow = score_best\n",
    "            params_best_upToNow = tx_best, ty_best, tz_best\n",
    "\n",
    "            logger.info('%f %f %f', tx_best, ty_best, tz_best)\n",
    "\n",
    "        logger.info('\\n')\n",
    "        \n",
    "    ################# Gradient Descent ######################\n",
    "\n",
    "    lr1, lr2 = (10., 1e-1)\n",
    "    # lr1, lr2 = (1., 1e-3)\n",
    "\n",
    "    # auto_corr = .95\n",
    "\n",
    "    max_iter_num = 1000\n",
    "    fudge_factor = 1e-6 #for numerical stability\n",
    "    dMdA_historical = np.zeros((12,))\n",
    "\n",
    "    tx_best, ty_best, tz_best = params_best_upToNow\n",
    "    T_best = np.r_[1,0,0, tx_best, 0,1,0, ty_best, 0,0,1, tz_best]\n",
    "\n",
    "    lr = np.r_[lr2, lr2, lr2, lr1, lr2, lr2, lr2, lr1, lr2, lr2, lr2, lr1]\n",
    "\n",
    "    score_best = 0\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    for iteration in range(max_iter_num):\n",
    "\n",
    "        logger.info('iteration %d', iteration)\n",
    "\n",
    "    #     t = time.time()\n",
    "        s, dMdA = compute_score_and_gradient(T_best)\n",
    "    #     sys.stderr.write('compute_score_and_gradient: %f seconds\\n' % (time.time() - t)) #~ 2s/iteration or ~.5s: 1e5 samples per landmark\n",
    "\n",
    "        dMdA_historical += dMdA**2\n",
    "    #     dMdA_historical = auto_corr * dMdA_historical + (1-auto_corr) * dMdA**2\n",
    "\n",
    "        dMdA_adjusted = dMdA / (fudge_factor + np.sqrt(dMdA_historical))\n",
    "\n",
    "        T_best += lr*dMdA_adjusted\n",
    "\n",
    "    #         logger.info('A: ' + ' '.join(['%f']*12) % tuple(A_best))\n",
    "    #         logger.info('dMdA adjusted: ' + ' '.join(['%f']*12) % tuple(dMdA_adjusted))\n",
    "\n",
    "        logger.info('score: %f', s)\n",
    "        scores.append(s)\n",
    "\n",
    "        logger.info('\\n')\n",
    "\n",
    "        history_len = 50\n",
    "        if iteration > 100:\n",
    "            if np.abs(np.mean(scores[iteration-history_len:iteration]) - \\\n",
    "                      np.mean(scores[iteration-2*history_len:iteration-history_len])) < 1e-1:\n",
    "                break\n",
    "\n",
    "        if s > score_best:\n",
    "    #             logger.info('Current best')\n",
    "            best_gradient_descent_params = T_best\n",
    "            score_best = s\n",
    "\n",
    "    plt.plot(scores);\n",
    "\n",
    "    del volume2_allLabels, dSdxyz\n",
    "    \n",
    "    ################# Save results ###############\n",
    "    \n",
    "    np.save(atlasAlignOptLogs_dir + '/%(stack)s_scoreEvolutions.npy' % {'stack':stack}, scores)\n",
    "    \n",
    "    with open(os.path.join(atlasAlignParams_dir, '%(stack)s/%(stack)s_3dAlignParams.txt' % {'stack':stack}), 'w') as f:\n",
    "\n",
    "        f.writelines(' '.join(['%f']*len(best_gradient_descent_params)) % tuple(best_gradient_descent_params) + '\\n')\n",
    "        f.write((' '.join(['%d']*3)+'\\n') % tuple([atlas_xdim, atlas_ydim, atlas_zdim]))\n",
    "        f.write((' '.join(['%.1f']*3)+'\\n') % tuple(atlas_centroid))    \n",
    "        f.write((' '.join(['%d']*3)+'\\n') % tuple([test_xdim, test_ydim, test_zdim]))\n",
    "        f.write((' '.join(['%.1f']*3)+'\\n') % tuple(test_centroid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# single stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack = 'MD585'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load score volumes: 23.968260 seconds\n",
      "load gradient RtTg: 6.461882 seconds\n",
      "load gradient VLL: 6.439273 seconds\n",
      "load gradient Tz: 6.377892 seconds\n",
      "load gradient LC: 5.804331 seconds\n",
      "load gradient 7N: 5.495186 seconds\n",
      "load gradient Amb: 4.788570 seconds\n",
      "load gradient 6N: 4.944420 seconds\n",
      "load gradient AP: 4.903184 seconds\n",
      "load gradient 5N: 7.497359 seconds\n",
      "load gradient 12N: 11.854280 seconds\n",
      "load gradient 7n: 10.883881 seconds\n",
      "load gradient R: 13.385809 seconds\n",
      "load gradient Pn: 13.219969 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_xdim, test_ydim, test_zdim: 822 450 438\n",
      "test_centroid: [ 411.  225.  219.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load gradient LRt: 11.403092 seconds\n",
      "overall: 113.465947 seconds\n"
     ]
    }
   ],
   "source": [
    "################# Load Test Volume ######################\n",
    "\n",
    "t = time.time()\n",
    "\n",
    "volume2_allLabels = {}\n",
    "\n",
    "for name in available_labels_unsided:\n",
    "\n",
    "    if name == 'BackG':\n",
    "        continue\n",
    "\n",
    "    volume2_roi = bp.unpack_ndarray_file(os.path.join(volume_dir, '%(stack)s/%(stack)s_scoreVolume_%(label)s.bp' % \\\n",
    "                                                      {'stack': stack, 'label': name})).astype(np.float16)\n",
    "    volume2_allLabels[name] = volume2_roi\n",
    "    del volume2_roi\n",
    "\n",
    "test_ydim, test_xdim, test_zdim = volume2_allLabels.values()[0].shape\n",
    "test_centroid = np.r_[.5*test_xdim, .5*test_ydim, .5*test_zdim]\n",
    "\n",
    "print 'test_xdim, test_ydim, test_zdim:', test_xdim, test_ydim, test_zdim\n",
    "print 'test_centroid:', test_centroid\n",
    "\n",
    "# test_xdim = volume_xmax - volume_xmin + 1\n",
    "# test_ydim = volume_ymax - volume_ymin + 1\n",
    "# test_zdim = volume_zmax - volume_zmin + 1\n",
    "\n",
    "sys.stderr.write('load score volumes: %f seconds\\n' % (time.time() - t))\n",
    "\n",
    "###################### Load Gradient #####################\n",
    "\n",
    "dSdxyz = {name: np.empty((3, test_ydim, test_xdim, test_zdim), dtype=np.float16) for name in available_labels_unsided}\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "for name in available_labels_unsided:\n",
    "\n",
    "    if name == 'BackG':\n",
    "        continue\n",
    "\n",
    "    t = time.time()\n",
    "\n",
    "    dSdxyz[name][0] = bp.unpack_ndarray_file(volume_dir + '/%(stack)s/%(stack)s_scoreVolume_%(label)s_gx.bp' % {'stack':stack, 'label':name})\n",
    "    dSdxyz[name][1] = bp.unpack_ndarray_file(volume_dir + '/%(stack)s/%(stack)s_scoreVolume_%(label)s_gy.bp' % {'stack':stack, 'label':name})\n",
    "    dSdxyz[name][2] = bp.unpack_ndarray_file(volume_dir + '/%(stack)s/%(stack)s_scoreVolume_%(label)s_gz.bp' % {'stack':stack, 'label':name})\n",
    "\n",
    "    sys.stderr.write('load gradient %s: %f seconds\\n' % (name, time.time() - t)) # ~6s\n",
    "\n",
    "sys.stderr.write('overall: %f seconds\\n' % (time.time() - t1)) # ~100s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:grid search iteration 0\n",
      "grid search: 26.444694 seconds\n",
      "INFO:__main__:0.000000 32.576698\n",
      "INFO:__main__:-65.656522 32.590676 -8.524103\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:grid search iteration 1\n",
      "grid search: 21.382796 seconds\n",
      "INFO:__main__:32.576698 36.397614\n",
      "INFO:__main__:-74.621319 41.817297 4.514556\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:grid search iteration 2\n",
      "grid search: 16.481953 seconds\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:grid search iteration 3\n",
      "grid search: 12.759929 seconds\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:grid search iteration 4\n",
      "grid search: 9.651541 seconds\n",
      "INFO:__main__:36.397614 36.592834\n",
      "INFO:__main__:-71.769760 40.728042 3.984043\n",
      "INFO:__main__:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "handler = logging.FileHandler(atlasAlignOptLogs_dir + '/%(stack)s_atlasAlignOpt.log' % {'stack': stack})\n",
    "handler.setLevel(logging.INFO)\n",
    "logger.addHandler(handler)\n",
    "\n",
    "################# Random Grid Search ######################\n",
    "\n",
    "grid_search_iteration_number = 5\n",
    "# grid_search_iteration_number = 1\n",
    "\n",
    "params_best_upToNow = (0, 0, 0)\n",
    "score_best_upToNow = 0\n",
    "\n",
    "init_n = 1000\n",
    "\n",
    "for iteration in range(grid_search_iteration_number):\n",
    "\n",
    "    logger.info('grid search iteration %d', iteration)\n",
    "\n",
    "    init_tx, init_ty, init_tz  = params_best_upToNow\n",
    "\n",
    "    n = int(init_n*np.exp(-iteration/3.))\n",
    "\n",
    "    sigma_tx = 300*np.exp(-iteration/3.)\n",
    "    sigma_ty = 300*np.exp(-iteration/3.)\n",
    "    sigma_tz = 100*np.exp(-iteration/3.)\n",
    "\n",
    "    tx_grid = init_tx + sigma_tx * (2 * np.random.random(n) - 1)\n",
    "    ty_grid = init_ty + sigma_ty * (2 * np.random.random(n) - 1)\n",
    "    tz_grid = init_tz + sigma_tz * (2 * np.random.random(n) - 1)\n",
    "\n",
    "    samples = np.c_[tx_grid, ty_grid, tz_grid]\n",
    "\n",
    "    import time\n",
    "\n",
    "    t = time.time()\n",
    "    # num jobs * memory each job\n",
    "    \n",
    "    scores = Parallel(n_jobs=8)(delayed(compute_score)(np.r_[1, 0, 0, tx, 0, 1, 0, ty, 0, 0, 1, tz])\n",
    "                                for tx, ty, tz in samples)\n",
    "\n",
    "#     scores = []\n",
    "#     for tx, ty, tz in samples:\n",
    "#         scores.append(compute_score([1, 0, 0, tx, 0, 1, 0, ty, 0, 0, 1, tz]))\n",
    "                                \n",
    "    sys.stderr.write('grid search: %f seconds\\n' % (time.time() - t)) # ~23s\n",
    "    \n",
    "    score_best = np.max(scores)\n",
    "\n",
    "    tx_best, ty_best, tz_best = samples[np.argmax(scores)]\n",
    "\n",
    "    if score_best > score_best_upToNow:\n",
    "        logger.info('%f %f', score_best_upToNow, score_best)\n",
    "\n",
    "        score_best_upToNow = score_best\n",
    "        params_best_upToNow = tx_best, ty_best, tz_best\n",
    "\n",
    "        logger.info('%f %f %f', tx_best, ty_best, tz_best)\n",
    "    \n",
    "    logger.info('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:iteration 0\n",
      "INFO:__main__:score: 36.592834\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 1\n",
      "INFO:__main__:score: 35.684402\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 2\n",
      "INFO:__main__:score: 52.193942\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 3\n",
      "INFO:__main__:score: 41.822372\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 4\n",
      "INFO:__main__:score: 57.314354\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 5\n",
      "INFO:__main__:score: 55.180454\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 6\n",
      "INFO:__main__:score: 59.713005\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 7\n",
      "INFO:__main__:score: 58.342686\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 8\n",
      "INFO:__main__:score: 61.309151\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 9\n",
      "INFO:__main__:score: 60.598347\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 10\n",
      "INFO:__main__:score: 62.256023\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 11\n",
      "INFO:__main__:score: 62.031368\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 12\n",
      "INFO:__main__:score: 62.481064\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 13\n",
      "INFO:__main__:score: 62.235142\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 14\n",
      "INFO:__main__:score: 62.746780\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 15\n",
      "INFO:__main__:score: 62.623840\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 16\n",
      "INFO:__main__:score: 63.014729\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 17\n",
      "INFO:__main__:score: 62.950253\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 18\n",
      "INFO:__main__:score: 63.216045\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 19\n",
      "INFO:__main__:score: 63.193806\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 20\n",
      "INFO:__main__:score: 63.284039\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 21\n",
      "INFO:__main__:score: 63.258831\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 22\n",
      "INFO:__main__:score: 63.305931\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 23\n",
      "INFO:__main__:score: 63.362843\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 24\n",
      "INFO:__main__:score: 63.289650\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 25\n",
      "INFO:__main__:score: 63.347954\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 26\n",
      "INFO:__main__:score: 63.212490\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 27\n",
      "INFO:__main__:score: 63.351707\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 28\n",
      "INFO:__main__:score: 63.244125\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 29\n",
      "INFO:__main__:score: 63.356174\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 30\n",
      "INFO:__main__:score: 63.290997\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 31\n",
      "INFO:__main__:score: 63.402515\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 32\n",
      "INFO:__main__:score: 63.218342\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 33\n",
      "INFO:__main__:score: 63.376129\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 34\n",
      "INFO:__main__:score: 63.232971\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 35\n",
      "INFO:__main__:score: 63.392139\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 36\n",
      "INFO:__main__:score: 63.279758\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 37\n",
      "INFO:__main__:score: 63.383144\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 38\n",
      "INFO:__main__:score: 63.247028\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 39\n",
      "INFO:__main__:score: 63.411232\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 40\n",
      "INFO:__main__:score: 63.303890\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 41\n",
      "INFO:__main__:score: 63.424347\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 42\n",
      "INFO:__main__:score: 63.309067\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 43\n",
      "INFO:__main__:score: 63.435638\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 44\n",
      "INFO:__main__:score: 63.290462\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 45\n",
      "INFO:__main__:score: 63.440498\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 46\n",
      "INFO:__main__:score: 63.313587\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 47\n",
      "INFO:__main__:score: 63.462463\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 48\n",
      "INFO:__main__:score: 63.331661\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 49\n",
      "INFO:__main__:score: 63.436836\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 50\n",
      "INFO:__main__:score: 63.326759\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 51\n",
      "INFO:__main__:score: 63.449284\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 52\n",
      "INFO:__main__:score: 63.352146\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 53\n",
      "INFO:__main__:score: 63.461479\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 54\n",
      "INFO:__main__:score: 63.354580\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 55\n",
      "INFO:__main__:score: 63.456867\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 56\n",
      "INFO:__main__:score: 63.347240\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 57\n",
      "INFO:__main__:score: 63.472965\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 58\n",
      "INFO:__main__:score: 63.359764\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 59\n",
      "INFO:__main__:score: 63.476192\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 60\n",
      "INFO:__main__:score: 63.344543\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 61\n",
      "INFO:__main__:score: 63.462734\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 62\n",
      "INFO:__main__:score: 63.371220\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 63\n",
      "INFO:__main__:score: 63.485172\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 64\n",
      "INFO:__main__:score: 63.374622\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 65\n",
      "INFO:__main__:score: 63.479156\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 66\n",
      "INFO:__main__:score: 63.374645\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 67\n",
      "INFO:__main__:score: 63.488880\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 68\n",
      "INFO:__main__:score: 63.395641\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 69\n",
      "INFO:__main__:score: 63.486248\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 70\n",
      "INFO:__main__:score: 63.382427\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 71\n",
      "INFO:__main__:score: 63.485695\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 72\n",
      "INFO:__main__:score: 63.400517\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 73\n",
      "INFO:__main__:score: 63.494514\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 74\n",
      "INFO:__main__:score: 63.391708\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 75\n",
      "INFO:__main__:score: 63.484028\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 76\n",
      "INFO:__main__:score: 63.393204\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 77\n",
      "INFO:__main__:score: 63.496010\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 78\n",
      "INFO:__main__:score: 63.427094\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 79\n",
      "INFO:__main__:score: 63.495514\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 80\n",
      "INFO:__main__:score: 63.443687\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 81\n",
      "INFO:__main__:score: 63.508457\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 82\n",
      "INFO:__main__:score: 63.469345\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 83\n",
      "INFO:__main__:score: 63.518021\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 84\n",
      "INFO:__main__:score: 63.465561\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 85\n",
      "INFO:__main__:score: 63.518005\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 86\n",
      "INFO:__main__:score: 63.459904\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 87\n",
      "INFO:__main__:score: 63.528015\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 88\n",
      "INFO:__main__:score: 63.437977\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 89\n",
      "INFO:__main__:score: 63.539974\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 90\n",
      "INFO:__main__:score: 63.492153\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 91\n",
      "INFO:__main__:score: 63.528748\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 92\n",
      "INFO:__main__:score: 63.493843\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 93\n",
      "INFO:__main__:score: 63.524132\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 94\n",
      "INFO:__main__:score: 63.489040\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 95\n",
      "INFO:__main__:score: 63.553196\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 96\n",
      "INFO:__main__:score: 63.490299\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 97\n",
      "INFO:__main__:score: 63.572742\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 98\n",
      "INFO:__main__:score: 63.495140\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 99\n",
      "INFO:__main__:score: 63.544102\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 100\n",
      "INFO:__main__:score: 63.472431\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 101\n",
      "INFO:__main__:score: 63.507008\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 102\n",
      "INFO:__main__:score: 63.493484\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 103\n",
      "INFO:__main__:score: 63.529194\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 104\n",
      "INFO:__main__:score: 63.469028\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 105\n",
      "INFO:__main__:score: 63.541920\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 106\n",
      "INFO:__main__:score: 63.511799\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 107\n",
      "INFO:__main__:score: 63.536312\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 108\n",
      "INFO:__main__:score: 63.510818\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 109\n",
      "INFO:__main__:score: 63.537773\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 110\n",
      "INFO:__main__:score: 63.506897\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 111\n",
      "INFO:__main__:score: 63.519165\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 112\n",
      "INFO:__main__:score: 63.529678\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 113\n",
      "INFO:__main__:score: 63.522812\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 114\n",
      "INFO:__main__:score: 63.516525\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 115\n",
      "INFO:__main__:score: 63.528767\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 116\n",
      "INFO:__main__:score: 63.509602\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 117\n",
      "INFO:__main__:score: 63.548462\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 118\n",
      "INFO:__main__:score: 63.473213\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 119\n",
      "INFO:__main__:score: 63.523590\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 120\n",
      "INFO:__main__:score: 63.525696\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 121\n",
      "INFO:__main__:score: 63.526035\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 122\n",
      "INFO:__main__:score: 63.514973\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 123\n",
      "INFO:__main__:score: 63.547726\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 124\n",
      "INFO:__main__:score: 63.516994\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 125\n",
      "INFO:__main__:score: 63.532848\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 126\n",
      "INFO:__main__:score: 63.504902\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 127\n",
      "INFO:__main__:score: 63.543575\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 128\n",
      "INFO:__main__:score: 63.499813\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 129\n",
      "INFO:__main__:score: 63.535091\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 130\n",
      "INFO:__main__:score: 63.511292\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 131\n",
      "INFO:__main__:score: 63.551640\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 132\n",
      "INFO:__main__:score: 63.508167\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 133\n",
      "INFO:__main__:score: 63.540009\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 134\n",
      "INFO:__main__:score: 63.515686\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 135\n",
      "INFO:__main__:score: 63.535286\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 136\n",
      "INFO:__main__:score: 63.520618\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 137\n",
      "INFO:__main__:score: 63.544304\n",
      "INFO:__main__:\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEACAYAAABI5zaHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nR9O+YwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x4e8ea50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "################# Gradient Descent ######################\n",
    "\n",
    "lr1, lr2 = (10., 1e-1)\n",
    "# lr1, lr2 = (1., 1e-3)\n",
    "\n",
    "# auto_corr = .95\n",
    "\n",
    "max_iter_num = 1000\n",
    "fudge_factor = 1e-6 #for numerical stability\n",
    "dMdA_historical = np.zeros((12,))\n",
    "\n",
    "tx_best, ty_best, tz_best = params_best_upToNow\n",
    "T_best = np.r_[1,0,0, tx_best, 0,1,0, ty_best, 0,0,1, tz_best]\n",
    "\n",
    "lr = np.r_[lr2, lr2, lr2, lr1, lr2, lr2, lr2, lr1, lr2, lr2, lr2, lr1]\n",
    "\n",
    "score_best = 0\n",
    "\n",
    "scores = []\n",
    "\n",
    "for iteration in range(max_iter_num):\n",
    "\n",
    "    logger.info('iteration %d', iteration)\n",
    "\n",
    "#     t = time.time()\n",
    "    s, dMdA = compute_score_and_gradient(T_best)\n",
    "#     sys.stderr.write('compute_score_and_gradient: %f seconds\\n' % (time.time() - t)) #~ 2s/iteration or ~.5s: 1e5 samples per landmark\n",
    "\n",
    "    dMdA_historical += dMdA**2\n",
    "#     dMdA_historical = auto_corr * dMdA_historical + (1-auto_corr) * dMdA**2\n",
    "\n",
    "    dMdA_adjusted = dMdA / (fudge_factor + np.sqrt(dMdA_historical))\n",
    "\n",
    "    T_best += lr*dMdA_adjusted\n",
    "\n",
    "#         logger.info('A: ' + ' '.join(['%f']*12) % tuple(A_best))\n",
    "#         logger.info('dMdA adjusted: ' + ' '.join(['%f']*12) % tuple(dMdA_adjusted))\n",
    "\n",
    "    logger.info('score: %f', s)\n",
    "    scores.append(s)\n",
    "\n",
    "    logger.info('\\n')\n",
    "\n",
    "    history_len = 50\n",
    "    if iteration > 100:\n",
    "        if np.abs(np.mean(scores[iteration-history_len:iteration]) - \\\n",
    "                  np.mean(scores[iteration-2*history_len:iteration-history_len])) < 1e-1:\n",
    "            break\n",
    "\n",
    "    if s > score_best:\n",
    "#             logger.info('Current best')\n",
    "        best_gradient_descent_params = T_best\n",
    "        score_best = s\n",
    "\n",
    "plt.plot(scores);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(atlasAlignOptLogs_dir + '/%(stack)s_scoreEvolutions.npy' % {'stack':stack}, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(atlasAlignParams_dir, '%(stack)s/%(stack)s_3dAlignParams.txt' % {'stack':stack}), 'w') as f:\n",
    "\n",
    "    f.writelines(' '.join(['%f']*len(best_gradient_descent_params)) % tuple(best_gradient_descent_params) + '\\n')\n",
    "    f.write((' '.join(['%d']*3)+'\\n') % tuple([atlas_xdim, atlas_ydim, atlas_zdim]))\n",
    "    f.write((' '.join(['%.1f']*3)+'\\n') % tuple(atlas_centroid))    \n",
    "    f.write((' '.join(['%d']*3)+'\\n') % tuple([test_xdim, test_ydim, test_zdim]))\n",
    "    f.write((' '.join(['%.1f']*3)+'\\n') % tuple(test_centroid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
