{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting environment for AWS compute node\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No vtk\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "sys.path.append(os.path.join(os.environ['REPO_DIR'], 'utilities'))\n",
    "from data_manager import *\n",
    "from metadata import *\n",
    "from distributed_utilities import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute scoremaps for linearly normalized version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running svm classifier ...Child returned 0\n",
      "16 nodes available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n",
      "qsub returned.\n",
      "done in 317.484612 seconds\n",
      "Resampling scoremaps ...Child returned 0\n",
      "16 nodes available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n",
      "qsub returned.\n",
      "done in 70.839120 seconds\n",
      "running svm classifier ...Child returned 0\n",
      "16 nodes available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n",
      "qsub returned.\n",
      "done in 322.478262 seconds\n",
      "Resampling scoremaps ...Child returned 0\n",
      "16 nodes available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n",
      "qsub returned.\n",
      "done in 65.922713 seconds\n"
     ]
    }
   ],
   "source": [
    "stack = 'MD657'\n",
    "\n",
    "for classifier_id in range(83, 85):\n",
    "    t = time.time()\n",
    "    sys.stderr.write('running svm classifier ...')\n",
    "\n",
    "    run_distributed(command='%(script_path)s %(stack)s \\'%%(filenames)s\\' %(classifier_id)d' % \\\n",
    "                    {'script_path': os.path.join(REPO_DIR, 'learning', 'apply_classifiers_v4.py'),\n",
    "                    'stack': stack,\n",
    "                    'classifier_id': classifier_id},\n",
    "    #                 kwargs_list=dict(filenames=metadata_cache['valid_filenames'][stack]),\n",
    "    #                 kwargs_list=dict(filenames=[metadata_cache['sections_to_filenames'][stack][150]]),\n",
    "                    kwargs_list=dict(filenames=[fn for fn in metadata_cache['valid_filenames'][stack]\n",
    "                                               if fn.split('-')[1][0] == 'F']),\n",
    "                    argument_type='list2')\n",
    "\n",
    "    wait_qsub_complete()\n",
    "\n",
    "    sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 302s\n",
    "\n",
    "    t = time.time()\n",
    "    sys.stderr.write('Resampling scoremaps ...')\n",
    "\n",
    "    # downscale = 8\n",
    "    downscale = 32\n",
    "\n",
    "    run_distributed(command='%(script_path)s %(stack)s \\'%%(filenames)s\\' %(classifier_id)d %(downscale)d' % \\\n",
    "                    {'script_path': os.path.join(REPO_DIR, 'learning', 'resample_scoremaps_v4.py'),\n",
    "                    'stack': stack,\n",
    "                    'classifier_id': classifier_id,\n",
    "                    'downscale': downscale},\n",
    "    #                 kwargs_list=dict(filenames=metadata_cache['valid_filenames'][stack]),\n",
    "    #                 kwargs_list=dict(filenames=[metadata_cache['sections_to_filenames'][stack][150]]),\n",
    "                    kwargs_list=dict(filenames=[fn for fn in metadata_cache['valid_filenames'][stack]\n",
    "                               if fn.split('-')[1][0] == 'F']),\n",
    "                    argument_type='list2'\n",
    "                   )\n",
    "\n",
    "\n",
    "    wait_qsub_complete()\n",
    "\n",
    "    sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 277s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regular version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier_id = 38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack = 'MD635'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running svm classifier ...Child returned 0\n",
      "1 nodes available.\n",
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "sys.stderr.write('running svm classifier ...')\n",
    "\n",
    "run_distributed(command='%(script_path)s %(stack)s \\'%%(filenames)s\\' %(classifier_id)d' % \\\n",
    "                {'script_path': os.path.join(REPO_DIR, 'learning', 'apply_classifiers_v4.py'),\n",
    "                'stack': stack,\n",
    "                'classifier_id': classifier_id},\n",
    "                kwargs_list=dict(filenames=metadata_cache['valid_filenames'][stack]),\n",
    "#                 kwargs_list=dict(filenames=[metadata_cache['sections_to_filenames'][stack][208]]),\n",
    "#                 kwargs_list=dict(filenames=[fn for fn in metadata_cache['valid_filenames'][stack]\n",
    "#                                            if fn.split('-')[1][0] == 'F']),\n",
    "                argument_type='list2')\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 302s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature computation window spacing is 56, so the equivalent downscale factor is 56. Still larger than 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "sys.stderr.write('Resampling scoremaps ...')\n",
    "\n",
    "# downscale = 8\n",
    "downscale = 32\n",
    "\n",
    "run_distributed(command='%(script_path)s %(stack)s \\'%%(filenames)s\\' %(classifier_id)d %(downscale)d' % \\\n",
    "                {'script_path': os.path.join(REPO_DIR, 'learning', 'resample_scoremaps_v4.py'),\n",
    "                'stack': stack,\n",
    "                'classifier_id': classifier_id,\n",
    "                'downscale': downscale},\n",
    "                kwargs_list=dict(filenames=metadata_cache['valid_filenames'][stack]),\n",
    "#                 kwargs_list=dict(filenames=[metadata_cache['sections_to_filenames'][stack][209]]),\n",
    "#                 kwargs_list=dict(filenames=[fn for fn in metadata_cache['valid_filenames'][stack]\n",
    "#                            if fn.split('-')[1][0] == 'F']),\n",
    "                argument_type='list2'\n",
    "               )\n",
    "\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 277s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "sys.stderr.write('visualize scoremaps ...')\n",
    "\n",
    "add_label_text = False\n",
    "# viz_downscale = 8\n",
    "viz_downscale = 32\n",
    "\n",
    "run_distributed(command='%(script_path)s %(stack)s \\'%%(filenames)s\\' %(classifier_id)d %(downscale)d %(add_label_text)s' % \\\n",
    "                {'script_path': os.path.join(REPO_DIR, 'learning', 'visualize_scoremaps_v4.py'),\n",
    "                'stack': stack,\n",
    "                 'classifier_id': classifier_id,\n",
    "                'downscale': viz_downscale,\n",
    "                'add_label_text': '-a' if add_label_text else ''},\n",
    "                kwargs_list=dict(filenames=metadata_cache['valid_filenames'][stack]),\n",
    "#                 kwargs_list=dict(filenames=[metadata_cache['sections_to_filenames'][stack][209]]),\n",
    "                argument_type='list2'\n",
    "               )\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "sys.stderr.write('done in %f seconds\\n' % (time.time() - t))  # For one stack, 75s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "constructing score volumes ...Child returned 0\n",
      "14 nodes available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n",
      "qsub returned.\n",
      "done in 146.254704 seconds\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "sys.stderr.write('constructing score volumes ...')\n",
    "\n",
    "use_nissl_only = False\n",
    "volume_downscale = 32\n",
    "\n",
    "run_distributed(command='%(script_path)s %(stack)s %%(structure)s %(classifier_id)d %(downscale)d %(use_nissl_only)s' % \\\n",
    "                {'script_path': os.path.join(REPO_DIR, 'reconstruct', 'construct_score_volume_v4.py'),\n",
    "                'stack': stack,\n",
    "                'classifier_id': classifier_id,\n",
    "                'downscale': volume_downscale,\n",
    "                'use_nissl_only': '-n' if use_nissl_only else ''},\n",
    "                kwargs_list=dict(structure=all_known_structures),\n",
    "                argument_type='single')\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "sys.stderr.write('done in %f seconds\\n' % (time.time() - t))# 116s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "compute score volume gradients...Child returned 0\n",
      "14 nodes available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n",
      "qsub returned.\n",
      "done in 55.756982 seconds\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "sys.stderr.write('compute score volume gradients...')\n",
    "\n",
    "run_distributed(command='ROOT_DIR=/scratch/ %(script_path)s %(stack)s %%(structure)s %(classifier_id)d %(downscale)d' % \\\n",
    "                {'script_path': os.path.join(REPO_DIR, 'reconstruct', 'compute_score_volume_gradients_v4.py'),\n",
    "                'stack': stack,\n",
    "                'classifier_id': classifier_id,\n",
    "                'downscale': volume_downscale},\n",
    "                kwargs_list=dict(structure=all_known_structures),\n",
    "                argument_type='single')\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) \n",
    "\n",
    "# 55 seconds (16 nodes write to respective local /scratch)\n",
    "# More than 1 simul. processes are not beneficial as they cause local write contention.\n",
    "# 156 seconds (16 nodes simul. write to /shared)\n",
    "# 310 seconds (single node, sequential write to /shared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD635/MD635_lossless_alignedTo_MD635-F63-2016.05.19-08.39.03_MD635_2_0188_cropped/MD635-F78-2016.05.19-13.26.25_MD635_1_0232_lossless_alignedTo_MD635-F63-2016.05.19-08.39.03_MD635_2_0188_cropped.tif && mkdir -p /shared/CSHL_data_processed/MD635/MD635_lossless_alignedTo_MD635-F63-2016.05.19-08.39.03_MD635_2_0188_cropped\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_data_processed/MD635/MD635_lossless_alignedTo_MD635-F63-2016.05.19-08.39.03_MD635_2_0188_cropped/MD635-F78-2016.05.19-13.26.25_MD635_1_0232_lossless_alignedTo_MD635-F63-2016.05.19-08.39.03_MD635_2_0188_cropped.tif /shared/CSHL_data_processed/MD635/MD635_lossless_alignedTo_MD635-F63-2016.05.19-08.39.03_MD635_2_0188_cropped/MD635-F78-2016.05.19-13.26.25_MD635_1_0232_lossless_alignedTo_MD635-F63-2016.05.19-08.39.03_MD635_2_0188_cropped.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "Child returned 0\n",
      "4.75 seconds.\n",
      "/usr/local/lib/python2.7/dist-packages/skimage/external/tifffile/tifffile.py:2611: RuntimeWarning: py_decodelzw encountered unexpected end of stream\n",
      "  strip = decompress(strip)\n",
      "/usr/local/lib/python2.7/dist-packages/skimage/external/tifffile/tifffile.py:2546: UserWarning: unpack: string size must be a multiple of element size\n",
      "  warnings.warn(\"unpack: %s\" % e)\n"
     ]
    }
   ],
   "source": [
    "img = DataManager.load_image(stack='MD635', fn='MD635-F78-2016.05.19-13.26.25_MD635_1_0232', resol='lossless', version='cropped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier_setting = 37\n",
    "warp_setting = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# structure_subset = ['7N_L', '7N_R', '12N', '5N_L','5N_R','Pn_L', 'Pn_R', 'SNR_L', 'SNR_R', 'VLL_L', 'VLL_R', '7n_L']\n",
    "structure_subset = ['7N_L', '7N_R', '12N', '5N_L','5N_R','Pn_L', 'Pn_R', 'SNR_L', 'SNR_R', \n",
    "                    'VLL_L', 'VLL_R', '7n_L', '7n_R', 'Tz_L', 'Tz_R', \n",
    "                    'VCA_L', 'VCP_R']\n",
    "# structure_subset = ['7N_L', '7N_R', '12N', '5N_L','5N_R','Pn_L', 'Pn_R', 'SNR_L', 'SNR_R', \n",
    "#                     'VLL_L', 'VLL_R', '7n_L', '7n_R', 'Tz_L', 'Tz_R', \n",
    "#                     'VCA_L', 'VCP_R', 'IC', 'SC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "atlas_name = 'atlasV3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "align all subjects to atlas ...Child returned 0\n",
      "1 nodes available.\n",
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qsub returned.\n",
      "done in 261.050432 seconds\n"
     ]
    }
   ],
   "source": [
    "# Align\n",
    "\n",
    "t = time.time()\n",
    "sys.stderr.write('align all subjects to atlas ...')\n",
    "\n",
    "run_distributed(command='%(script_path)s %%(stack)s %(atlas_name)s %(warp_setting)d %(clf_setting)d --trial_num 1 --structures \\'%(structures)s\\'' % \\\n",
    "                {'script_path': os.path.join(REPO_DIR, 'registration', 'global_registration_v3.py'),\n",
    "                 'atlas_name': atlas_name,\n",
    "                'warp_setting': warp_setting,\n",
    "                'clf_setting': classifier_setting,\n",
    "                'structures': json.dumps(structure_subset)},\n",
    "                 kwargs_list=dict(stack=['MD635']),\n",
    "                argument_type='single')\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # For one stack, 372s (1 trial); 750s (5 trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "transform atlas ...Child returned 0\n",
      "1 nodes available.\n",
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qsub returned.\n",
      "done in 40.204390 seconds\n"
     ]
    }
   ],
   "source": [
    "# Transform\n",
    "\n",
    "t = time.time()\n",
    "sys.stderr.write('transform atlas ...')\n",
    "\n",
    "run_distributed(command='%(script_path)s %%(stack)s %(atlas_name)s %(warp_setting)d %(clf_setting)d' % \\\n",
    "                {'script_path': os.path.join(REPO_DIR, 'registration', 'transform_brains_v4.py'),\n",
    "                'atlas_name': atlas_name,\n",
    "                'clf_setting': classifier_setting,\n",
    "                 'warp_setting': warp_setting\n",
    "                },\n",
    "                kwargs_list={'stack': ['MD635']},\n",
    "                argument_type='single')\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # For one stack, 60 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "visualize aligned atlas overlay ...Child returned 0\n",
      "1 nodes available.\n",
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qsub returned.\n",
      "done in 90.381931 seconds\n"
     ]
    }
   ],
   "source": [
    "# Visualize\n",
    "\n",
    "t = time.time()\n",
    "sys.stderr.write('visualize aligned atlas overlay ...')\n",
    "\n",
    "run_distributed(command='%(script_path)s %%(stack)s %(atlas_name)s %(warp_setting)d %(clf_setting)d' % \\\n",
    "                {'script_path': os.path.join(REPO_DIR, 'registration', 'visualize_registration_v4.py'),\n",
    "                'atlas_name': atlas_name,\n",
    "                'clf_setting': classifier_setting,\n",
    "                 'warp_setting': warp_setting\n",
    "                },\n",
    "                kwargs_list={'stack': ['MD635']},\n",
    "                argument_type='single')\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # For one stack, 110 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier_setting = 37\n",
    "warp_setting = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Local align\n",
    "\n",
    "t = time.time()\n",
    "sys.stderr.write('LOCAL align ...')\n",
    "\n",
    "kwargs_list = \\\n",
    "[dict(stack='MD635', structures=shell_escape(json.dumps(all_known_structures_sided[f:l+1])))\n",
    "for f,l in first_last_tuples_distribute_over(0, len(all_known_structures_sided)-1, get_num_nodes())]\n",
    "\n",
    "run_distributed(command='%(script_path)s %%(stack)s atlasV3 %(warp_setting)d %(clf_setting)d -s %%(structures)s' % \\\n",
    "                {'script_path': os.path.join(REPO_DIR, 'registration', 'local_registration_v3.py'),\n",
    "                'clf_setting': classifier_setting,\n",
    "                 'warp_setting': warp_setting},\n",
    "                 kwargs_list=kwargs_list,\n",
    "                argument_type='single')\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 2047s for 5 trials.\n",
    "# IC and SC are super slow..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "transform atlas ...Child returned 0\n",
      "14 nodes available.\n",
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qsub returned.\n",
      "done in 50.400943 seconds\n"
     ]
    }
   ],
   "source": [
    "# Transform\n",
    "\n",
    "t = time.time()\n",
    "sys.stderr.write('transform atlas ...')\n",
    "\n",
    "run_distributed(command='%(script_path)s %%(stack)s atlasV3 %(warp_setting)d %(clf_setting)d' % \\\n",
    "                {'script_path': os.path.join(REPO_DIR, 'registration', 'transform_brains_v4.py'),\n",
    "                'clf_setting': classifier_setting,\n",
    "                 'warp_setting': warp_setting\n",
    "                },\n",
    "                kwargs_list={'stack': ['MD635']},\n",
    "                argument_type='single')\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # For one stack, 60 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "visualize aligned atlas overlay ...Child returned 0\n",
      "14 nodes available.\n",
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qsub returned.\n",
      "done in 95.670595 seconds\n"
     ]
    }
   ],
   "source": [
    "# Visualize\n",
    "\n",
    "t = time.time()\n",
    "sys.stderr.write('visualize aligned atlas overlay ...')\n",
    "\n",
    "run_distributed(command='%(script_path)s %%(stack)s atlasV3 %(warp_setting)d %(clf_setting)d' % \\\n",
    "                {'script_path': os.path.join(REPO_DIR, 'registration', 'visualize_registration_v4.py'),\n",
    "                'clf_setting': classifier_setting,\n",
    "                 'warp_setting': warp_setting\n",
    "                },\n",
    "                kwargs_list={'stack': ['MD635']},\n",
    "                argument_type='single')\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # For one stack, 110 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Transform locally transformed volumes back to atlas space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier_setting = 2\n",
    "warp_setting = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "sys.stderr.write('transform atlas ...')\n",
    "\n",
    "exclude_nodes = [33]\n",
    "\n",
    "run_distributed4(command='%(script_path)s %%(stack)s atlasV2 %(warp_setting)d %(clf_setting)d' % \\\n",
    "                {'script_path': os.path.join(os.environ['REPO_DIR'], 'registration', 'transform_brains_v3_reverse_global.py'),\n",
    "                 'clf_setting': classifier_setting,\n",
    "                 'warp_setting': warp_setting},\n",
    "                 kwargs_list=dict(stack=['MD603']),\n",
    "#                 kwargs_list=dict(stack=all_nissl_stacks),\n",
    "                exclude_nodes=exclude_nodes,\n",
    "                argument_type='single')\n",
    "\n",
    "sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 200 seconds ~ 4 mins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measure Global Tx Confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "warp_setting = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "sys.stderr.write('Measure confidence ...')\n",
    "\n",
    "exclude_nodes = [33]\n",
    "\n",
    "run_distributed4(command='%(script_path)s %%(stack)s atlasV2 %(warp_setting)d %(clf_setting)d' % \\\n",
    "                {'script_path': os.path.join(os.environ['REPO_DIR'], 'registration', 'measure_confidence_v3_global.py'),\n",
    "                 'clf_setting': classifier_setting,\n",
    "                 'warp_setting': warp_setting},\n",
    "#                  kwargs_list=dict(stack=['MD594']),\n",
    "                kwargs_list=dict(stack=all_nissl_stacks),\n",
    "                exclude_nodes=exclude_nodes,\n",
    "                argument_type='single')\n",
    "\n",
    "sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 650 seconds ~ 10 mins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Measure Local Tx Confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "warp_setting = 5\n",
    "classifier_setting = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "sys.stderr.write('Measure confidence ...')\n",
    "\n",
    "exclude_nodes = [33]\n",
    "\n",
    "run_distributed4(command='%(script_path)s %%(stack)s atlasV2 %(warp_setting)d %(clf_setting)d' % \\\n",
    "                {'script_path': os.path.join(os.environ['REPO_DIR'], 'registration', 'measure_confidence_v3_local.py'),\n",
    "                 'clf_setting': classifier_setting,\n",
    "                 'warp_setting': warp_setting},\n",
    "#                  kwargs_list=dict(stack=['MD592']),\n",
    "                kwargs_list=dict(stack=all_nissl_stacks),\n",
    "                exclude_nodes=exclude_nodes,\n",
    "                argument_type='single')\n",
    "\n",
    "sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 900 s ~ 15 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
