{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting environment for AWS compute node\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No vtk\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "sys.path.append(os.path.join(os.environ['REPO_DIR'], 'utilities'))\n",
    "from data_manager import *\n",
    "from metadata import *\n",
    "from distributed_utilities import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute scoremaps for linearly normalized version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running svm classifier ...Child returned 0\n",
      "16 nodes available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n",
      "qsub returned.\n",
      "done in 317.484612 seconds\n",
      "Resampling scoremaps ...Child returned 0\n",
      "16 nodes available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n",
      "qsub returned.\n",
      "done in 70.839120 seconds\n",
      "running svm classifier ...Child returned 0\n",
      "16 nodes available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n",
      "qsub returned.\n",
      "done in 322.478262 seconds\n",
      "Resampling scoremaps ...Child returned 0\n",
      "16 nodes available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n",
      "qsub returned.\n",
      "done in 65.922713 seconds\n"
     ]
    }
   ],
   "source": [
    "stack = 'MD657'\n",
    "\n",
    "for classifier_id in range(83, 85):\n",
    "    t = time.time()\n",
    "    sys.stderr.write('running svm classifier ...')\n",
    "\n",
    "    run_distributed(command='%(script_path)s %(stack)s \\'%%(filenames)s\\' %(classifier_id)d' % \\\n",
    "                    {'script_path': os.path.join(REPO_DIR, 'learning', 'apply_classifiers_v4.py'),\n",
    "                    'stack': stack,\n",
    "                    'classifier_id': classifier_id},\n",
    "    #                 kwargs_list=dict(filenames=metadata_cache['valid_filenames'][stack]),\n",
    "    #                 kwargs_list=dict(filenames=[metadata_cache['sections_to_filenames'][stack][150]]),\n",
    "                    kwargs_list=dict(filenames=[fn for fn in metadata_cache['valid_filenames'][stack]\n",
    "                                               if fn.split('-')[1][0] == 'F']),\n",
    "                    argument_type='list2')\n",
    "\n",
    "    wait_qsub_complete()\n",
    "\n",
    "    sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 302s\n",
    "\n",
    "    t = time.time()\n",
    "    sys.stderr.write('Resampling scoremaps ...')\n",
    "\n",
    "    # downscale = 8\n",
    "    downscale = 32\n",
    "\n",
    "    run_distributed(command='%(script_path)s %(stack)s \\'%%(filenames)s\\' %(classifier_id)d %(downscale)d' % \\\n",
    "                    {'script_path': os.path.join(REPO_DIR, 'learning', 'resample_scoremaps_v4.py'),\n",
    "                    'stack': stack,\n",
    "                    'classifier_id': classifier_id,\n",
    "                    'downscale': downscale},\n",
    "    #                 kwargs_list=dict(filenames=metadata_cache['valid_filenames'][stack]),\n",
    "    #                 kwargs_list=dict(filenames=[metadata_cache['sections_to_filenames'][stack][150]]),\n",
    "                    kwargs_list=dict(filenames=[fn for fn in metadata_cache['valid_filenames'][stack]\n",
    "                               if fn.split('-')[1][0] == 'F']),\n",
    "                    argument_type='list2'\n",
    "                   )\n",
    "\n",
    "\n",
    "    wait_qsub_complete()\n",
    "\n",
    "    sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 277s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regular version - different stacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "detector_id = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running svm classifier ...5 nodes available.\n",
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qsub returned.\n",
      "done in 391.731642 seconds\n",
      "Resampling scoremaps ...5 nodes available.\n",
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qsub returned.\n",
      "done in 125.535488 seconds\n",
      "visualize scoremaps ...5 nodes available.\n",
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    }
   ],
   "source": [
    "for stack in [\n",
    "# 'MD585',\n",
    " 'MD589',\n",
    " 'MD590',\n",
    " 'MD591',\n",
    " 'MD592',\n",
    " 'MD593',\n",
    " 'MD594',\n",
    " 'MD595',\n",
    " 'MD598',\n",
    " 'MD599',\n",
    " 'MD602',\n",
    " 'MD603',\n",
    "]:\n",
    "    \n",
    "    t = time.time()\n",
    "    sys.stderr.write('running svm classifier ...')\n",
    "\n",
    "    run_distributed(command='%(script_path)s %(stack)s \\'%%(filenames)s\\' %(detector_id)d' % \\\n",
    "                    {'script_path': os.path.join(REPO_DIR, 'learning', 'apply_classifiers_v5.py'),\n",
    "                    'stack': stack,\n",
    "                    'detector_id': detector_id},\n",
    "                    kwargs_list=dict(filenames=metadata_cache['valid_filenames'][stack]),\n",
    "    #                 kwargs_list=dict(filenames=[fn for fn in metadata_cache['valid_filenames'][stack]\n",
    "    #                                             if fn.split('-')[1][0] == 'F']),\n",
    "    #                 kwargs_list=dict(filenames=q),\n",
    "                    argument_type='list2')\n",
    "\n",
    "    wait_qsub_complete()\n",
    "\n",
    "    sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) \n",
    "\n",
    "    # 16 m4.4xlarge, 411s/140s\n",
    "    \n",
    "    ########################################################\n",
    "    \n",
    "    # Feature computation window spacing is 56, so the equivalent downscale factor is 56. Still larger than 32.\n",
    "    # It does not seems necessary to generate down8 score maps because the extra data is interpolated anyway.\n",
    "    t = time.time()\n",
    "    sys.stderr.write('Resampling scoremaps ...')\n",
    "\n",
    "    # downsample = 8\n",
    "    downsample = 32\n",
    "\n",
    "    run_distributed(command='%(script_path)s %(stack)s \\'%%(filenames)s\\' %(detector_id)d %(downsample)d' % \\\n",
    "                    {'script_path': os.path.join(REPO_DIR, 'learning', 'resample_scoremaps_v5.py'),\n",
    "                    'stack': stack,\n",
    "                    'detector_id': detector_id,\n",
    "                    'downsample': downsample},\n",
    "                    kwargs_list=dict(filenames=metadata_cache['valid_filenames'][stack]),\n",
    "    #                 kwargs_list=dict(filenames=[fn for fn in metadata_cache['valid_filenames'][stack]\n",
    "    #                            if fn.split('-')[1][0] == 'F']),\n",
    "                    argument_type='list2'\n",
    "                   )\n",
    "\n",
    "\n",
    "    wait_qsub_complete()\n",
    "\n",
    "    sys.stderr.write('done in %f seconds\\n' % (time.time() - t))\n",
    "\n",
    "    # down32, 16 m4.4xlarge, 60s\n",
    "    # down8, 16 m4.4xlarge, 246s\n",
    "    \n",
    "    ##############################################################\n",
    "    \n",
    "    # Must generate down32 scoremap first, \n",
    "    # because even if viz_downsample=8 the scoermaps the script trying to load are still down32.\n",
    "\n",
    "    t = time.time()\n",
    "    sys.stderr.write('visualize scoremaps ...')\n",
    "\n",
    "    add_label_text = False\n",
    "    viz_downsample = 8\n",
    "    # viz_downsample = 32\n",
    "    cmap = 'jet'\n",
    "#     background_image_version = 'grayDefaultJpeg'\n",
    "    background_image_version = 'grayJpeg'\n",
    "    # background_image_version = 'contrastStretched'\n",
    "\n",
    "    run_distributed(command='ROOT_DIR=/scratch/ %(script_path)s %(stack)s \\'%%(filenames)s\\' %(detector_id)d %(downsample)d --cmap %(cmap)s %(add_label_text)s -b %(bg_img_ver)s' % \\\n",
    "                    {'script_path': os.path.join(REPO_DIR, 'learning', 'visualize_scoremaps_v5.py'),\n",
    "                    'stack': stack,\n",
    "                     'detector_id': detector_id,\n",
    "                    'downsample': viz_downsample,\n",
    "                     'cmap': cmap,\n",
    "                    'add_label_text': '-a' if add_label_text else '',\n",
    "                    'bg_img_ver': background_image_version},\n",
    "                    kwargs_list=dict(filenames=metadata_cache['valid_filenames'][stack]),\n",
    "    #                 kwargs_list=dict(filenames=[fn for fn in metadata_cache['valid_filenames'][stack]\n",
    "    #                            if fn.split('-')[1][0] == 'F']),\n",
    "                    argument_type='list2'\n",
    "                   )\n",
    "\n",
    "    wait_qsub_complete()\n",
    "\n",
    "    sys.stderr.write('done in %f seconds\\n' % (time.time() - t))\n",
    "\n",
    "    # For one stack\n",
    "    # 16 nodes, downsample 32, 75s\n",
    "    # 8 nodes, downscale 8, 6000s\n",
    "    # 8 nodes, downscale 8, scratch/ 1510s\n",
    "    # 16 m4.4xlarge, downscale 8, scratch/ 700s\n",
    "    \n",
    "    ####################################################################################\n",
    "    \n",
    "    \n",
    "    t = time.time()\n",
    "    sys.stderr.write('constructing score volumes ...')\n",
    "\n",
    "    use_nissl_only = False\n",
    "    volume_downscale = 32\n",
    "\n",
    "    run_distributed(command='%(script_path)s %(stack)s %%(structure)s %(detector_id)d %(downscale)d %(use_nissl_only)s' % \\\n",
    "                    {'script_path': os.path.join(REPO_DIR, 'reconstruct', 'construct_score_volume_v5.py'),\n",
    "                    'stack': stack,\n",
    "                    'detector_id': detector_id,\n",
    "                    'downscale': volume_downscale,\n",
    "                    'use_nissl_only': '-n' if use_nissl_only else ''},\n",
    "                    kwargs_list=dict(structure=all_known_structures),\n",
    "    #                 kwargs_list=dict(structure=['VLL']),\n",
    "                    argument_type='single')\n",
    "\n",
    "    wait_qsub_complete()\n",
    "\n",
    "    sys.stderr.write('done in %f seconds\\n' % (time.time() - t))\n",
    "\n",
    "    # 16 m4.4xlarge, downscale 32, 55s\n",
    "    \n",
    "    ####################################################################################\n",
    "    \n",
    "    t = time.time()\n",
    "    sys.stderr.write('compute score volume gradients...')\n",
    "\n",
    "    run_distributed(command='ROOT_DIR=/scratch/ %(script_path)s %(stack)s %%(structure)s %(detector_id)d %(downscale)d' % \\\n",
    "                    {'script_path': os.path.join(REPO_DIR, 'reconstruct', 'compute_score_volume_gradients_v5.py'),\n",
    "                    'stack': stack,\n",
    "                    'detector_id': detector_id,\n",
    "                    'downscale': volume_downscale},\n",
    "                    kwargs_list=dict(structure=all_known_structures),\n",
    "    #                 kwargs_list=dict(structure=['VLL']),\n",
    "                    argument_type='single')\n",
    "\n",
    "    wait_qsub_complete()\n",
    "\n",
    "    sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) \n",
    "\n",
    "    # 55 seconds (16 nodes write to respective local /scratch)\n",
    "    # More than 1 simul. processes are not beneficial as they cause local write contention.\n",
    "    # 156 seconds (16 nodes simul. write to /shared)\n",
    "    # 310 seconds (single node, sequential write to /shared)\n",
    "    # 16 m4.4xlarge, downscale 32, 55s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regular version - one stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# classifier_id = 38\n",
    "stack = 'MD658'\n",
    "detector_id = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# m = check_output(\"aws s3 ls s3://mousebrainatlas-data/CSHL_patch_scores/MD589/\".split()).split('\\n')\n",
    "# q = list(set(metadata_cache['valid_filenames'][stack]) - set([f.strip()[4:-12] for f in m]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting autoscaling group cfncluster-yuncongcluster-ComputeFleet-15GRGL8BMOLW2 capaticy to 16...it may take more than 5 minutes for SGE to know new hosts.\n"
     ]
    }
   ],
   "source": [
    "request_compute_nodes(16, 'yuncong')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_num_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running svm classifier ...16 nodes available.\n",
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qsub returned.\n",
      "done in 140.688367 seconds\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "sys.stderr.write('running svm classifier ...')\n",
    "\n",
    "run_distributed(command='%(script_path)s %(stack)s \\'%%(filenames)s\\' %(detector_id)d' % \\\n",
    "                {'script_path': os.path.join(REPO_DIR, 'learning', 'apply_classifiers_v5.py'),\n",
    "                'stack': stack,\n",
    "                'detector_id': detector_id},\n",
    "                kwargs_list=dict(filenames=metadata_cache['valid_filenames'][stack]),\n",
    "#                 kwargs_list=dict(filenames=[fn for fn in metadata_cache['valid_filenames'][stack]\n",
    "#                                             if fn.split('-')[1][0] == 'F']),\n",
    "#                 kwargs_list=dict(filenames=q),\n",
    "                argument_type='list2')\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) \n",
    "\n",
    "# 16 m4.4xlarge, 411s/140s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resampling scoremaps ...16 nodes available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n",
      "qsub returned.\n",
      "done in 55.400345 seconds\n"
     ]
    }
   ],
   "source": [
    "# Feature computation window spacing is 56, so the equivalent downscale factor is 56. Still larger than 32.\n",
    "# It does not seems necessary to generate down8 score maps because the extra data is interpolated anyway.\n",
    "\n",
    "t = time.time()\n",
    "sys.stderr.write('Resampling scoremaps ...')\n",
    "\n",
    "# downsample = 8\n",
    "downsample = 32\n",
    "\n",
    "run_distributed(command='%(script_path)s %(stack)s \\'%%(filenames)s\\' %(detector_id)d %(downsample)d' % \\\n",
    "                {'script_path': os.path.join(REPO_DIR, 'learning', 'resample_scoremaps_v5.py'),\n",
    "                'stack': stack,\n",
    "                'detector_id': detector_id,\n",
    "                'downsample': downsample},\n",
    "                kwargs_list=dict(filenames=metadata_cache['valid_filenames'][stack]),\n",
    "#                 kwargs_list=dict(filenames=[fn for fn in metadata_cache['valid_filenames'][stack]\n",
    "#                            if fn.split('-')[1][0] == 'F']),\n",
    "                argument_type='list2'\n",
    "               )\n",
    "\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "sys.stderr.write('done in %f seconds\\n' % (time.time() - t))\n",
    "\n",
    "# down32, 16 m4.4xlarge, 60s\n",
    "# down8, 16 m4.4xlarge, 246s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "visualize scoremaps ...16 nodes available.\n",
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qsub returned.\n",
      "done in 446.751777 seconds\n"
     ]
    }
   ],
   "source": [
    "# Must generate down32 scoremap first, \n",
    "# because even if viz_downsample=8 the scoermaps the script trying to load are still down32.\n",
    "\n",
    "# This requires having grayJpeg output available first.\n",
    "\n",
    "t = time.time()\n",
    "sys.stderr.write('visualize scoremaps ...')\n",
    "\n",
    "add_label_text = False\n",
    "viz_downsample = 8\n",
    "# viz_downsample = 32\n",
    "cmap = 'jet'\n",
    "background_image_version = 'grayDefaultJpeg'\n",
    "# background_image_version = 'grayJpeg'\n",
    "# background_image_version = 'contrastStretched'\n",
    "\n",
    "run_distributed(command='ROOT_DIR=/scratch/ %(script_path)s %(stack)s \\'%%(filenames)s\\' %(detector_id)d %(downsample)d --cmap %(cmap)s %(add_label_text)s -b %(bg_img_ver)s' % \\\n",
    "                {'script_path': os.path.join(REPO_DIR, 'learning', 'visualize_scoremaps_v5.py'),\n",
    "                'stack': stack,\n",
    "                 'detector_id': detector_id,\n",
    "                'downsample': viz_downsample,\n",
    "                 'cmap': cmap,\n",
    "                'add_label_text': '-a' if add_label_text else '',\n",
    "                'bg_img_ver': background_image_version},\n",
    "                kwargs_list=dict(filenames=metadata_cache['valid_filenames'][stack]),\n",
    "#                 kwargs_list=dict(filenames=[fn for fn in metadata_cache['valid_filenames'][stack]\n",
    "#                            if fn.split('-')[1][0] == 'F']),\n",
    "                argument_type='list2'\n",
    "               )\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "sys.stderr.write('done in %f seconds\\n' % (time.time() - t))\n",
    "\n",
    "# For one stack\n",
    "# 16 nodes, downsample 32, 75s\n",
    "# 8 nodes, downscale 8, 6000s\n",
    "# 8 nodes, downscale 8, scratch/ 1510s\n",
    "# 16 m4.4xlarge, downscale 8, scratch/ 700s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct score volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack = 'MD589'\n",
    "detector_id = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting autoscaling group cfncluster-yuncongcluster-ComputeFleet-15GRGL8BMOLW2 capaticy to 0...it may take more than 5 minutes for SGE to know new hosts.\n"
     ]
    }
   ],
   "source": [
    "request_compute_nodes(0, 'yuncong')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "constructing score volumes ...16 nodes available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n",
      "qsub returned.\n",
      "done in 55.890324 seconds\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "sys.stderr.write('constructing score volumes ...')\n",
    "\n",
    "use_nissl_only = False\n",
    "volume_downscale = 32\n",
    "\n",
    "run_distributed(command='%(script_path)s %(stack)s %%(structure)s %(detector_id)d %(downscale)d %(use_nissl_only)s' % \\\n",
    "                {'script_path': os.path.join(REPO_DIR, 'reconstruct', 'construct_score_volume_v5.py'),\n",
    "                'stack': stack,\n",
    "                'detector_id': detector_id,\n",
    "                'downscale': volume_downscale,\n",
    "                'use_nissl_only': '-n' if use_nissl_only else ''},\n",
    "                kwargs_list=dict(structure=all_known_structures),\n",
    "#                 kwargs_list=dict(structure=['VLL']),\n",
    "                argument_type='single')\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "sys.stderr.write('done in %f seconds\\n' % (time.time() - t))\n",
    "\n",
    "# 16 m4.4xlarge, downscale 32, 55s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "compute score volume gradients...16 nodes available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n",
      "qsub returned.\n",
      "done in 50.544045 seconds\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "sys.stderr.write('compute score volume gradients...')\n",
    "\n",
    "run_distributed(command='ROOT_DIR=/scratch/ %(script_path)s %(stack)s %%(structure)s %(detector_id)d %(downscale)d' % \\\n",
    "                {'script_path': os.path.join(REPO_DIR, 'reconstruct', 'compute_score_volume_gradients_v5.py'),\n",
    "                'stack': stack,\n",
    "                'detector_id': detector_id,\n",
    "                'downscale': volume_downscale},\n",
    "                kwargs_list=dict(structure=all_known_structures),\n",
    "#                 kwargs_list=dict(structure=['VLL']),\n",
    "                argument_type='single')\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) \n",
    "\n",
    "# 55 seconds (16 nodes write to respective local /scratch)\n",
    "# More than 1 simul. processes are not beneficial as they cause local write contention.\n",
    "# 156 seconds (16 nodes simul. write to /shared)\n",
    "# 310 seconds (single node, sequential write to /shared)\n",
    "# 16 m4.4xlarge, downscale 32, 55s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# classifier_setting = 38\n",
    "detector_id = 15\n",
    "warp_setting = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# structure_subset = ['7N_L', '7N_R', '12N', '5N_L','5N_R','Pn_L', 'Pn_R', 'SNR_L', 'SNR_R', 'VLL_L', 'VLL_R', '7n_L']\n",
    "# structure_subset = ['7N_L', '7N_R', '12N', '5N_L','5N_R','Pn_L', 'Pn_R', 'SNR_L', 'SNR_R', \n",
    "#                     'VLL_L', 'VLL_R', '7n_L', '7n_R', 'Tz_L', 'Tz_R', \n",
    "#                     'VCA_L', 'VCP_R']\n",
    "# structure_subset = ['7N_L', '7N_R', '12N', '5N_L','5N_R','Pn_L', 'Pn_R', 'SNR_L', 'SNR_R', \n",
    "#                     'VLL_L', 'VLL_R', '7n_L', '7n_R', 'Tz_L', 'Tz_R', \n",
    "#                     'VCA_L', 'VCP_R', 'IC', 'SC']\n",
    "# structure_subset = ['7N_L', '7N_R', '12N', '5N_L', '5N_R', 'SNR_L', 'SNR_R', 'Pn_L', 'Pn_R',\n",
    "#                     'VLL_L', 'VLL_R', '7n_L', '7n_R', 'Tz_L', 'Tz_R', \n",
    "#                     'VCA_L', 'VCA_R', 'VCP_L', 'VCP_R']\n",
    "structure_subset = all_known_structures_sided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "atlas_name = 'atlasV5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# request_compute_nodes(5, 'yuncong')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacks = [\n",
    "#  'MD589',\n",
    "#  'MD590',\n",
    "#  'MD591',\n",
    "#  'MD592',\n",
    "#  'MD593',\n",
    "#  'MD594',\n",
    "#  'MD595',\n",
    "#  'MD598',\n",
    "#  'MD599',\n",
    " 'MD602',\n",
    " 'MD603']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "align all subjects to atlas ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/shared/MouseBrainAtlas/registration/global_registration_v4.py MD589 atlasV5 20 15 --trial_num 1 --structures '[\"5N_L\", \"5N_R\", \"6N_L\", \"6N_R\", \"7N_L\", \"7N_R\", \"7n_L\", \"7n_R\", \"Amb_L\", \"Amb_R\", \"LC_L\", \"LC_R\", \"LRt_L\", \"LRt_R\", \"Pn_L\", \"Pn_R\", \"Tz_L\", \"Tz_R\", \"VLL_L\", \"VLL_R\", \"RMC_L\", \"RMC_R\", \"SNC_L\", \"SNC_R\", \"SNR_L\", \"SNR_R\", \"3N_L\", \"3N_R\", \"4N_L\", \"4N_R\", \"Sp5I_L\", \"Sp5I_R\", \"Sp5O_L\", \"Sp5O_R\", \"Sp5C_L\", \"Sp5C_R\", \"PBG_L\", \"PBG_R\", \"10N_L\", \"10N_R\", \"VCA_L\", \"VCA_R\", \"VCP_L\", \"VCP_R\", \"DC_L\", \"DC_R\", \"AP\", \"12N\", \"RtTg\", \"sp5\", \"outerContour\", \"SC\", \"IC\"]'\n",
      "/shared/MouseBrainAtlas/registration/global_registration_v4.py MD590 atlasV5 20 15 --trial_num 1 --structures '[\"5N_L\", \"5N_R\", \"6N_L\", \"6N_R\", \"7N_L\", \"7N_R\", \"7n_L\", \"7n_R\", \"Amb_L\", \"Amb_R\", \"LC_L\", \"LC_R\", \"LRt_L\", \"LRt_R\", \"Pn_L\", \"Pn_R\", \"Tz_L\", \"Tz_R\", \"VLL_L\", \"VLL_R\", \"RMC_L\", \"RMC_R\", \"SNC_L\", \"SNC_R\", \"SNR_L\", \"SNR_R\", \"3N_L\", \"3N_R\", \"4N_L\", \"4N_R\", \"Sp5I_L\", \"Sp5I_R\", \"Sp5O_L\", \"Sp5O_R\", \"Sp5C_L\", \"Sp5C_R\", \"PBG_L\", \"PBG_R\", \"10N_L\", \"10N_R\", \"VCA_L\", \"VCA_R\", \"VCP_L\", \"VCP_R\", \"DC_L\", \"DC_R\", \"AP\", \"12N\", \"RtTg\", \"sp5\", \"outerContour\", \"SC\", \"IC\"]'\n",
      "/shared/MouseBrainAtlas/registration/global_registration_v4.py MD591 atlasV5 20 15 --trial_num 1 --structures '[\"5N_L\", \"5N_R\", \"6N_L\", \"6N_R\", \"7N_L\", \"7N_R\", \"7n_L\", \"7n_R\", \"Amb_L\", \"Amb_R\", \"LC_L\", \"LC_R\", \"LRt_L\", \"LRt_R\", \"Pn_L\", \"Pn_R\", \"Tz_L\", \"Tz_R\", \"VLL_L\", \"VLL_R\", \"RMC_L\", \"RMC_R\", \"SNC_L\", \"SNC_R\", \"SNR_L\", \"SNR_R\", \"3N_L\", \"3N_R\", \"4N_L\", \"4N_R\", \"Sp5I_L\", \"Sp5I_R\", \"Sp5O_L\", \"Sp5O_R\", \"Sp5C_L\", \"Sp5C_R\", \"PBG_L\", \"PBG_R\", \"10N_L\", \"10N_R\", \"VCA_L\", \"VCA_R\", \"VCP_L\", \"VCP_R\", \"DC_L\", \"DC_R\", \"AP\", \"12N\", \"RtTg\", \"sp5\", \"outerContour\", \"SC\", \"IC\"]'\n",
      "/shared/MouseBrainAtlas/registration/global_registration_v4.py MD592 atlasV5 20 15 --trial_num 1 --structures '[\"5N_L\", \"5N_R\", \"6N_L\", \"6N_R\", \"7N_L\", \"7N_R\", \"7n_L\", \"7n_R\", \"Amb_L\", \"Amb_R\", \"LC_L\", \"LC_R\", \"LRt_L\", \"LRt_R\", \"Pn_L\", \"Pn_R\", \"Tz_L\", \"Tz_R\", \"VLL_L\", \"VLL_R\", \"RMC_L\", \"RMC_R\", \"SNC_L\", \"SNC_R\", \"SNR_L\", \"SNR_R\", \"3N_L\", \"3N_R\", \"4N_L\", \"4N_R\", \"Sp5I_L\", \"Sp5I_R\", \"Sp5O_L\", \"Sp5O_R\", \"Sp5C_L\", \"Sp5C_R\", \"PBG_L\", \"PBG_R\", \"10N_L\", \"10N_R\", \"VCA_L\", \"VCA_R\", \"VCP_L\", \"VCP_R\", \"DC_L\", \"DC_R\", \"AP\", \"12N\", \"RtTg\", \"sp5\", \"outerContour\", \"SC\", \"IC\"]'\n",
      "/shared/MouseBrainAtlas/registration/global_registration_v4.py MD593 atlasV5 20 15 --trial_num 1 --structures '[\"5N_L\", \"5N_R\", \"6N_L\", \"6N_R\", \"7N_L\", \"7N_R\", \"7n_L\", \"7n_R\", \"Amb_L\", \"Amb_R\", \"LC_L\", \"LC_R\", \"LRt_L\", \"LRt_R\", \"Pn_L\", \"Pn_R\", \"Tz_L\", \"Tz_R\", \"VLL_L\", \"VLL_R\", \"RMC_L\", \"RMC_R\", \"SNC_L\", \"SNC_R\", \"SNR_L\", \"SNR_R\", \"3N_L\", \"3N_R\", \"4N_L\", \"4N_R\", \"Sp5I_L\", \"Sp5I_R\", \"Sp5O_L\", \"Sp5O_R\", \"Sp5C_L\", \"Sp5C_R\", \"PBG_L\", \"PBG_R\", \"10N_L\", \"10N_R\", \"VCA_L\", \"VCA_R\", \"VCP_L\", \"VCP_R\", \"DC_L\", \"DC_R\", \"AP\", \"12N\", \"RtTg\", \"sp5\", \"outerContour\", \"SC\", \"IC\"]'\n",
      "/shared/MouseBrainAtlas/registration/global_registration_v4.py MD594 atlasV5 20 15 --trial_num 1 --structures '[\"5N_L\", \"5N_R\", \"6N_L\", \"6N_R\", \"7N_L\", \"7N_R\", \"7n_L\", \"7n_R\", \"Amb_L\", \"Amb_R\", \"LC_L\", \"LC_R\", \"LRt_L\", \"LRt_R\", \"Pn_L\", \"Pn_R\", \"Tz_L\", \"Tz_R\", \"VLL_L\", \"VLL_R\", \"RMC_L\", \"RMC_R\", \"SNC_L\", \"SNC_R\", \"SNR_L\", \"SNR_R\", \"3N_L\", \"3N_R\", \"4N_L\", \"4N_R\", \"Sp5I_L\", \"Sp5I_R\", \"Sp5O_L\", \"Sp5O_R\", \"Sp5C_L\", \"Sp5C_R\", \"PBG_L\", \"PBG_R\", \"10N_L\", \"10N_R\", \"VCA_L\", \"VCA_R\", \"VCP_L\", \"VCP_R\", \"DC_L\", \"DC_R\", \"AP\", \"12N\", \"RtTg\", \"sp5\", \"outerContour\", \"SC\", \"IC\"]'\n",
      "/shared/MouseBrainAtlas/registration/global_registration_v4.py MD595 atlasV5 20 15 --trial_num 1 --structures '[\"5N_L\", \"5N_R\", \"6N_L\", \"6N_R\", \"7N_L\", \"7N_R\", \"7n_L\", \"7n_R\", \"Amb_L\", \"Amb_R\", \"LC_L\", \"LC_R\", \"LRt_L\", \"LRt_R\", \"Pn_L\", \"Pn_R\", \"Tz_L\", \"Tz_R\", \"VLL_L\", \"VLL_R\", \"RMC_L\", \"RMC_R\", \"SNC_L\", \"SNC_R\", \"SNR_L\", \"SNR_R\", \"3N_L\", \"3N_R\", \"4N_L\", \"4N_R\", \"Sp5I_L\", \"Sp5I_R\", \"Sp5O_L\", \"Sp5O_R\", \"Sp5C_L\", \"Sp5C_R\", \"PBG_L\", \"PBG_R\", \"10N_L\", \"10N_R\", \"VCA_L\", \"VCA_R\", \"VCP_L\", \"VCP_R\", \"DC_L\", \"DC_R\", \"AP\", \"12N\", \"RtTg\", \"sp5\", \"outerContour\", \"SC\", \"IC\"]'\n",
      "/shared/MouseBrainAtlas/registration/global_registration_v4.py MD598 atlasV5 20 15 --trial_num 1 --structures '[\"5N_L\", \"5N_R\", \"6N_L\", \"6N_R\", \"7N_L\", \"7N_R\", \"7n_L\", \"7n_R\", \"Amb_L\", \"Amb_R\", \"LC_L\", \"LC_R\", \"LRt_L\", \"LRt_R\", \"Pn_L\", \"Pn_R\", \"Tz_L\", \"Tz_R\", \"VLL_L\", \"VLL_R\", \"RMC_L\", \"RMC_R\", \"SNC_L\", \"SNC_R\", \"SNR_L\", \"SNR_R\", \"3N_L\", \"3N_R\", \"4N_L\", \"4N_R\", \"Sp5I_L\", \"Sp5I_R\", \"Sp5O_L\", \"Sp5O_R\", \"Sp5C_L\", \"Sp5C_R\", \"PBG_L\", \"PBG_R\", \"10N_L\", \"10N_R\", \"VCA_L\", \"VCA_R\", \"VCP_L\", \"VCP_R\", \"DC_L\", \"DC_R\", \"AP\", \"12N\", \"RtTg\", \"sp5\", \"outerContour\", \"SC\", \"IC\"]'\n",
      "/shared/MouseBrainAtlas/registration/global_registration_v4.py MD599 atlasV5 20 15 --trial_num 1 --structures '[\"5N_L\", \"5N_R\", \"6N_L\", \"6N_R\", \"7N_L\", \"7N_R\", \"7n_L\", \"7n_R\", \"Amb_L\", \"Amb_R\", \"LC_L\", \"LC_R\", \"LRt_L\", \"LRt_R\", \"Pn_L\", \"Pn_R\", \"Tz_L\", \"Tz_R\", \"VLL_L\", \"VLL_R\", \"RMC_L\", \"RMC_R\", \"SNC_L\", \"SNC_R\", \"SNR_L\", \"SNR_R\", \"3N_L\", \"3N_R\", \"4N_L\", \"4N_R\", \"Sp5I_L\", \"Sp5I_R\", \"Sp5O_L\", \"Sp5O_R\", \"Sp5C_L\", \"Sp5C_R\", \"PBG_L\", \"PBG_R\", \"10N_L\", \"10N_R\", \"VCA_L\", \"VCA_R\", \"VCP_L\", \"VCP_R\", \"DC_L\", \"DC_R\", \"AP\", \"12N\", \"RtTg\", \"sp5\", \"outerContour\", \"SC\", \"IC\"]'\n",
      "/shared/MouseBrainAtlas/registration/global_registration_v4.py MD602 atlasV5 20 15 --trial_num 1 --structures '[\"5N_L\", \"5N_R\", \"6N_L\", \"6N_R\", \"7N_L\", \"7N_R\", \"7n_L\", \"7n_R\", \"Amb_L\", \"Amb_R\", \"LC_L\", \"LC_R\", \"LRt_L\", \"LRt_R\", \"Pn_L\", \"Pn_R\", \"Tz_L\", \"Tz_R\", \"VLL_L\", \"VLL_R\", \"RMC_L\", \"RMC_R\", \"SNC_L\", \"SNC_R\", \"SNR_L\", \"SNR_R\", \"3N_L\", \"3N_R\", \"4N_L\", \"4N_R\", \"Sp5I_L\", \"Sp5I_R\", \"Sp5O_L\", \"Sp5O_R\", \"Sp5C_L\", \"Sp5C_R\", \"PBG_L\", \"PBG_R\", \"10N_L\", \"10N_R\", \"VCA_L\", \"VCA_R\", \"VCP_L\", \"VCP_R\", \"DC_L\", \"DC_R\", \"AP\", \"12N\", \"RtTg\", \"sp5\", \"outerContour\", \"SC\", \"IC\"]'\n",
      "/shared/MouseBrainAtlas/registration/global_registration_v4.py MD603 atlasV5 20 15 --trial_num 1 --structures '[\"5N_L\", \"5N_R\", \"6N_L\", \"6N_R\", \"7N_L\", \"7N_R\", \"7n_L\", \"7n_R\", \"Amb_L\", \"Amb_R\", \"LC_L\", \"LC_R\", \"LRt_L\", \"LRt_R\", \"Pn_L\", \"Pn_R\", \"Tz_L\", \"Tz_R\", \"VLL_L\", \"VLL_R\", \"RMC_L\", \"RMC_R\", \"SNC_L\", \"SNC_R\", \"SNR_L\", \"SNR_R\", \"3N_L\", \"3N_R\", \"4N_L\", \"4N_R\", \"Sp5I_L\", \"Sp5I_R\", \"Sp5O_L\", \"Sp5O_R\", \"Sp5C_L\", \"Sp5C_R\", \"PBG_L\", \"PBG_R\", \"10N_L\", \"10N_R\", \"VCA_L\", \"VCA_R\", \"VCP_L\", \"VCP_R\", \"DC_L\", \"DC_R\", \"AP\", \"12N\", \"RtTg\", \"sp5\", \"outerContour\", \"SC\", \"IC\"]'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done in 23765.596945 seconds\n"
     ]
    }
   ],
   "source": [
    "# Align - Sequential\n",
    "\n",
    "# m4.4xlarge is required.\n",
    "\n",
    "for stack in stacks:\n",
    "    t = time.time()\n",
    "    sys.stderr.write('align subject to atlas ...')\n",
    "\n",
    "    execute_command('%(script_path)s %(stack)s %(atlas_name)s %(warp_setting)d %(detector_id)d --trial_num 1 --structures \\'%(structures)s\\'' % \\\n",
    "        {'script_path': os.path.join(REPO_DIR, 'registration', 'global_registration_v4.py'),\n",
    "         'atlas_name': atlas_name,\n",
    "        'warp_setting': 20,\n",
    "        'detector_id': detector_id,\n",
    "        'structures': json.dumps(structure_subset),\n",
    "        'stack': stack})\n",
    "\n",
    "    sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # For one stack, 372s (1 trial); 750s (5 trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "align all subjects to atlas ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/shared/MouseBrainAtlas/registration/global_registration_v4.py MD602 atlasV5 16 15 --trial_num 1 --structures '[\"5N_L\", \"5N_R\", \"6N_L\", \"6N_R\", \"7N_L\", \"7N_R\", \"7n_L\", \"7n_R\", \"Amb_L\", \"Amb_R\", \"LC_L\", \"LC_R\", \"LRt_L\", \"LRt_R\", \"Pn_L\", \"Pn_R\", \"Tz_L\", \"Tz_R\", \"VLL_L\", \"VLL_R\", \"RMC_L\", \"RMC_R\", \"SNC_L\", \"SNC_R\", \"SNR_L\", \"SNR_R\", \"3N_L\", \"3N_R\", \"4N_L\", \"4N_R\", \"Sp5I_L\", \"Sp5I_R\", \"Sp5O_L\", \"Sp5O_R\", \"Sp5C_L\", \"Sp5C_R\", \"PBG_L\", \"PBG_R\", \"10N_L\", \"10N_R\", \"VCA_L\", \"VCA_R\", \"VCP_L\", \"VCP_R\", \"DC_L\", \"DC_R\", \"AP\", \"12N\", \"RtTg\", \"sp5\", \"outerContour\", \"SC\", \"IC\"]'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done in 18822.409016 seconds\n",
      "align all subjects to atlas ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/shared/MouseBrainAtlas/registration/global_registration_v4.py MD603 atlasV5 16 15 --trial_num 1 --structures '[\"5N_L\", \"5N_R\", \"6N_L\", \"6N_R\", \"7N_L\", \"7N_R\", \"7n_L\", \"7n_R\", \"Amb_L\", \"Amb_R\", \"LC_L\", \"LC_R\", \"LRt_L\", \"LRt_R\", \"Pn_L\", \"Pn_R\", \"Tz_L\", \"Tz_R\", \"VLL_L\", \"VLL_R\", \"RMC_L\", \"RMC_R\", \"SNC_L\", \"SNC_R\", \"SNR_L\", \"SNR_R\", \"3N_L\", \"3N_R\", \"4N_L\", \"4N_R\", \"Sp5I_L\", \"Sp5I_R\", \"Sp5O_L\", \"Sp5O_R\", \"Sp5C_L\", \"Sp5C_R\", \"PBG_L\", \"PBG_R\", \"10N_L\", \"10N_R\", \"VCA_L\", \"VCA_R\", \"VCP_L\", \"VCP_R\", \"DC_L\", \"DC_R\", \"AP\", \"12N\", \"RtTg\", \"sp5\", \"outerContour\", \"SC\", \"IC\"]'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-46b764d279ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;34m'detector_id'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdetector_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;34m'structures'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructure_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         'stack': stack})\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;31m#                     stdout=subprocess.STDOUT,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#                     stderr=subprocess.STDOUT)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared/MouseBrainAtlas/utilities/utilities2015.pyc\u001b[0m in \u001b[0;36mexecute_command\u001b[0;34m(cmd, stdout, stderr)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m         \u001b[0mretcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m         \u001b[0;31m# if retcode < 0:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;31m# print >>sys.stderr, \"Child was terminated by signal\", -retcode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/subprocess.pyc\u001b[0m in \u001b[0;36mcall\u001b[0;34m(*popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0mretcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ls\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"-l\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m     \"\"\"\n\u001b[0;32m--> 523\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/subprocess.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1390\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m                     \u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_eintr_retry_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mECHILD\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/subprocess.pyc\u001b[0m in \u001b[0;36m_eintr_retry_call\u001b[0;34m(func, *args)\u001b[0m\n\u001b[1;32m    474\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEINTR\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Align - Sequential\n",
    "\n",
    "# m4.4xlarge is required.\n",
    "\n",
    "for stack in stacks:\n",
    "    t = time.time()\n",
    "    sys.stderr.write('align all subjects to atlas ...')\n",
    "\n",
    "    execute_command('%(script_path)s %(stack)s %(atlas_name)s %(warp_setting)d %(detector_id)d --trial_num 1 --structures \\'%(structures)s\\'' % \\\n",
    "        {'script_path': os.path.join(REPO_DIR, 'registration', 'global_registration_v4.py'),\n",
    "         'atlas_name': atlas_name,\n",
    "        'warp_setting': 16,\n",
    "        'detector_id': detector_id,\n",
    "        'structures': json.dumps(structure_subset),\n",
    "        'stack': stack})\n",
    "    \n",
    "    sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # For one stack, 372s (1 trial); 750s (5 trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Align\n",
    "\n",
    "# m4.4xlarge is required.\n",
    "\n",
    "t = time.time()\n",
    "sys.stderr.write('align all subjects to atlas ...')\n",
    "\n",
    "run_distributed(command='%(script_path)s %%(stack)s %(atlas_name)s %(warp_setting)d %(detector_id)d --trial_num 5 --structures \\'%(structures)s\\'' % \\\n",
    "                {'script_path': os.path.join(REPO_DIR, 'registration', 'global_registration_v4.py'),\n",
    "                 'atlas_name': atlas_name,\n",
    "                'warp_setting': warp_setting,\n",
    "                'detector_id': detector_id,\n",
    "                'structures': json.dumps(structure_subset)},\n",
    "                 kwargs_list=dict(stack=stacks),\n",
    "                argument_type='single')\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # For one stack, 372s (1 trial); 750s (5 trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "transform atlas ...16 nodes available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n",
      "qsub returned.\n",
      "done in 45.368512 seconds\n"
     ]
    }
   ],
   "source": [
    "# Transform\n",
    "\n",
    "t = time.time()\n",
    "sys.stderr.write('transform atlas ...')\n",
    "\n",
    "run_distributed(command='%(script_path)s %%(stack)s %(atlas_name)s %(warp_setting)d %(detector_id)d' % \\\n",
    "                {'script_path': os.path.join(REPO_DIR, 'registration', 'transform_brains_v4.py'),\n",
    "                'atlas_name': atlas_name,\n",
    "                'detector_id': detector_id,\n",
    "                 'warp_setting': warp_setting\n",
    "                },\n",
    "                kwargs_list={'stack': stacks},\n",
    "                argument_type='single')\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) \n",
    "# For one stack, 60 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "visualize aligned atlas overlay ...16 nodes available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n",
      "qsub returned.\n",
      "done in 111.255946 seconds\n"
     ]
    }
   ],
   "source": [
    "# Visualize\n",
    "\n",
    "t = time.time()\n",
    "sys.stderr.write('visualize aligned atlas overlay ...')\n",
    "\n",
    "# bg_img_version = 'grayDefaultJpeg'\n",
    "bg_img_version = 'grayJpeg'\n",
    "\n",
    "run_distributed(command='%(script_path)s %%(stack)s %(atlas_name)s %(warp_setting)d %(detector_id)d --out_downsample 8 -v %(bg_img_version)s' % \\\n",
    "                {'script_path': os.path.join(REPO_DIR, 'registration', 'visualize_registration_v5.py'),\n",
    "                'atlas_name': atlas_name,\n",
    "                'detector_id': detector_id,\n",
    "                 'warp_setting': warp_setting,\n",
    "                 'bg_img_version': bg_img_version\n",
    "                },\n",
    "                kwargs_list={'stack': stacks},\n",
    "                argument_type='single')\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "sys.stderr.write('done in %f seconds\\n' % (time.time() - t))\n",
    "# 700s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "detector_id = 15\n",
    "warp_setting = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "atlas_name = 'atlasV5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stacks = ['MD585',\n",
    " 'MD589',\n",
    " 'MD590',\n",
    " 'MD591',\n",
    " 'MD592',\n",
    " 'MD593',\n",
    " 'MD594',\n",
    " 'MD595',\n",
    " 'MD598',\n",
    " 'MD599',\n",
    " 'MD602',\n",
    " 'MD603']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL align ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16 nodes available.\n",
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n",
      "qsub returned.\n",
      "done in 58488.887352 seconds\n"
     ]
    }
   ],
   "source": [
    "# Local align\n",
    "\n",
    "t = time.time()\n",
    "sys.stderr.write('LOCAL align ...')\n",
    "\n",
    "# stacks = ['MD642', 'MD652', 'MD653', 'MD657', 'MD658']\n",
    "\n",
    "kwargs_list = \\\n",
    "[dict(stack=stack, structures=shell_escape(json.dumps(all_known_structures_sided[f:l+1])))\n",
    "for f,l in first_last_tuples_distribute_over(0, len(all_known_structures_sided)-1, get_num_nodes())\n",
    "for stack in stacks]\n",
    "\n",
    "# kwargs_list = \\\n",
    "# [dict(stack='MD661', structures=shell_escape(json.dumps(['5N_L']))),\n",
    "#  dict(stack='MD661', structures=shell_escape(json.dumps(['7N_L']))),\n",
    "# dict(stack='MD662', structures=shell_escape(json.dumps(['5N_L']))),\n",
    "# dict(stack='MD662', structures=shell_escape(json.dumps(['7N_L'])))]\n",
    "\n",
    "run_distributed(command='%(script_path)s %%(stack)s %(atlas_name)s %(warp_setting)d %(detector_id)d --trial_num 5 -s %%(structures)s' % \\\n",
    "                {'script_path': os.path.join(REPO_DIR, 'registration', 'local_registration_v4.py'),\n",
    "                'detector_id': detector_id,\n",
    "                 'warp_setting': warp_setting,\n",
    "                'atlas_name': atlas_name},\n",
    "                 kwargs_list=kwargs_list,\n",
    "                argument_type='single')\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 2047s for 5 trials.\n",
    "# IC and SC are super slow...\n",
    "# 58488 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting autoscaling group cfncluster-yuncongcluster-ComputeFleet-1R5OSQE66IOTP capaticy to 12...it may take more than 5 minutes for SGE to know new hosts.\n"
     ]
    }
   ],
   "source": [
    "request_compute_nodes(12, 'yuncong')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "transform atlas ...12 nodes available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n",
      "qsub returned.\n",
      "done in 50.600226 seconds\n"
     ]
    }
   ],
   "source": [
    "# Transform\n",
    "\n",
    "t = time.time()\n",
    "sys.stderr.write('transform atlas ...')\n",
    "\n",
    "run_distributed(command='%(script_path)s %%(stack)s %(atlas_name)s %(warp_setting)d %(detector_id)d' % \\\n",
    "                {'script_path': os.path.join(REPO_DIR, 'registration', 'transform_brains_v4.py'),\n",
    "                'detector_id': detector_id,\n",
    "                 'warp_setting': warp_setting,\n",
    "                'atlas_name': atlas_name\n",
    "                },\n",
    "                kwargs_list={'stack': stacks},\n",
    "                argument_type='single')\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # For one stack, 60 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "visualize aligned atlas overlay ...12 nodes available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n",
      "qsub returned.\n",
      "done in 110.789422 seconds\n"
     ]
    }
   ],
   "source": [
    "# Visualize\n",
    "\n",
    "t = time.time()\n",
    "sys.stderr.write('visualize aligned atlas overlay ...')\n",
    "\n",
    "# bg_img_version = 'grayDefaultJpeg'\n",
    "bg_img_version = 'grayJpeg'\n",
    "\n",
    "run_distributed(command='%(script_path)s %%(stack)s %(atlas_name)s %(warp_setting)d %(detector_id)d --out_downsample 8 -v %(bg_img_version)s' % \\\n",
    "                {'script_path': os.path.join(REPO_DIR, 'registration', 'visualize_registration_v5.py'),\n",
    "                'detector_id': detector_id,\n",
    "                 'warp_setting': warp_setting,\n",
    "                 'bg_img_version': bg_img_version,\n",
    "                'atlas_name': atlas_name\n",
    "                },\n",
    "                kwargs_list={'stack': stacks},\n",
    "                argument_type='single')\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # For one stack, 110 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Transform locally transformed volumes back to atlas space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier_setting = 2\n",
    "warp_setting = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "sys.stderr.write('transform atlas ...')\n",
    "\n",
    "exclude_nodes = [33]\n",
    "\n",
    "run_distributed4(command='%(script_path)s %%(stack)s atlasV2 %(warp_setting)d %(clf_setting)d' % \\\n",
    "                {'script_path': os.path.join(os.environ['REPO_DIR'], 'registration', 'transform_brains_v3_reverse_global.py'),\n",
    "                 'clf_setting': classifier_setting,\n",
    "                 'warp_setting': warp_setting},\n",
    "                 kwargs_list=dict(stack=['MD603']),\n",
    "#                 kwargs_list=dict(stack=all_nissl_stacks),\n",
    "                exclude_nodes=exclude_nodes,\n",
    "                argument_type='single')\n",
    "\n",
    "sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 200 seconds ~ 4 mins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measure Global Tx Confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "warp_setting = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "sys.stderr.write('Measure confidence ...')\n",
    "\n",
    "exclude_nodes = [33]\n",
    "\n",
    "run_distributed4(command='%(script_path)s %%(stack)s atlasV2 %(warp_setting)d %(clf_setting)d' % \\\n",
    "                {'script_path': os.path.join(os.environ['REPO_DIR'], 'registration', 'measure_confidence_v3_global.py'),\n",
    "                 'clf_setting': classifier_setting,\n",
    "                 'warp_setting': warp_setting},\n",
    "#                  kwargs_list=dict(stack=['MD594']),\n",
    "                kwargs_list=dict(stack=all_nissl_stacks),\n",
    "                exclude_nodes=exclude_nodes,\n",
    "                argument_type='single')\n",
    "\n",
    "sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 650 seconds ~ 10 mins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Measure Local Tx Confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "warp_setting = 5\n",
    "classifier_setting = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "sys.stderr.write('Measure confidence ...')\n",
    "\n",
    "exclude_nodes = [33]\n",
    "\n",
    "run_distributed4(command='%(script_path)s %%(stack)s atlasV2 %(warp_setting)d %(clf_setting)d' % \\\n",
    "                {'script_path': os.path.join(os.environ['REPO_DIR'], 'registration', 'measure_confidence_v3_local.py'),\n",
    "                 'clf_setting': classifier_setting,\n",
    "                 'warp_setting': warp_setting},\n",
    "#                  kwargs_list=dict(stack=['MD592']),\n",
    "                kwargs_list=dict(stack=all_nissl_stacks),\n",
    "                exclude_nodes=exclude_nodes,\n",
    "                argument_type='single')\n",
    "\n",
    "sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 900 s ~ 15 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
