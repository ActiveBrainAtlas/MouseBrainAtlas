{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.environ['GORDON_REPO_DIR'] + '/pipeline_scripts')\n",
    "\n",
    "import utilities2014\n",
    "reload(utilities2014)\n",
    "from utilities2014 import *\n",
    "\n",
    "import time\n",
    "\n",
    "from scipy.spatial.distance import cdist, pdist, squareform\n",
    "from scipy.cluster.hierarchy import average, fcluster, single, complete\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from skimage.color import gray2rgb\n",
    "from skimage.measure import find_contours\n",
    "from skimage.util import img_as_float\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "sys.path.append('/home/yuncong/project/opencv-2.4.9/release/lib/python2.7/site-packages')\n",
    "import cv2\n",
    "\n",
    "from networkx import from_dict_of_lists, Graph, adjacency_matrix, dfs_postorder_nodes\n",
    "from networkx.algorithms import node_connected_component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/oasis/projects/nsf/csd181/yuncong/virtualenv-1.9.1/yuncongve/lib/python2.7/site-packages/skimage/filter/__init__.py:6: skimage_deprecation: The `skimage.filter` module has been renamed to `skimage.filters`.  This placeholder module will be removed in v0.13.\n",
      "  warn(skimage_deprecation('The `skimage.filter` module has been renamed '\n"
     ]
    }
   ],
   "source": [
    "# def detect_open_boundaries(sec_ind):\n",
    "    \n",
    "dm = DataManager(generate_hierarchy=False, stack='RS141', resol='x5', section=2)\n",
    "dm._load_image()\n",
    "\n",
    "# Load image and relevant data\n",
    "# im_height, im_width = dm.[:2]\n",
    "\n",
    "texton_hists = dm.load_pipeline_result('texHist', 'npy')\n",
    "segmentation = dm.load_pipeline_result('segmentation', 'npy')\n",
    "n_superpixels = len(np.unique(segmentation)) - 1\n",
    "textonmap = dm.load_pipeline_result('texMap', 'npy')\n",
    "n_texton = len(np.unique(textonmap)) - 1\n",
    "neighbors = dm.load_pipeline_result('neighbors', 'pkl')\n",
    "sp_properties = dm.load_pipeline_result('spProps', 'npy')\n",
    "segmentation_vis = dm.load_pipeline_result('segmentationWithText', 'jpg')\n",
    "\n",
    "# Load region proposals\n",
    "# expansion_clusters_tuples = dm.load_pipeline_result('clusters', 'pkl')\n",
    "# expansion_clusters, expansion_cluster_scores = zip(*expansion_clusters_tuples)\n",
    "# expansion_cluster_scores = np.array(expansion_cluster_scores)\n",
    "\n",
    "# neighbors_dict = dict(zip(np.arange(n_superpixels), [list(i) for i in neighbors]))\n",
    "# neighbor_graph = from_dict_of_lists(neighbors_dict)\n",
    "\n",
    "# surrounds_sps = dm.load_pipeline_result('clusterSurrounds', 'pkl')\n",
    "# frontiers_sps = dm.load_pipeline_result('clusterFrontiers', 'pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "texture_map = dm.load_pipeline_result('textureMap', 'npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grow_region_from_pixel(y,x):\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neighbors_global = None\n",
    "\n",
    "def grow_cluster3(seed, texton_hists, neighbors=None, output=False, all_history=False):\n",
    "    \n",
    "    if neighbors is None:\n",
    "        neighbors = neighbors_global\n",
    "    \n",
    "    visited = set([])\n",
    "    curr_cluster = set([])\n",
    "        \n",
    "    candidate_scores = [0]\n",
    "    candidate_sps = [seed]\n",
    "\n",
    "    score_tuples = []\n",
    "    added_sps = []\n",
    "    \n",
    "    iter_ind = 0\n",
    "        \n",
    "    while len(candidate_sps) > 0:\n",
    "\n",
    "        best_ind = np.argmax(candidate_scores)\n",
    "        \n",
    "        heuristic = candidate_scores[best_ind]\n",
    "        sp = candidate_sps[best_ind]\n",
    "        \n",
    "        del candidate_scores[best_ind]\n",
    "        del candidate_sps[best_ind]\n",
    "        \n",
    "        if sp in curr_cluster:\n",
    "            continue\n",
    "                \n",
    "        iter_ind += 1\n",
    "        curr_cluster.add(sp)\n",
    "        added_sps.append(sp)\n",
    "        \n",
    "        tt = compute_cluster_score(curr_cluster, texton_hists=texton_hists, neighbors=neighbors)\n",
    "        tot, exterior, interior, compactness, surround_pval, interior_pval, size_prior = tt\n",
    "        if np.isnan(tot):\n",
    "            return [seed], -np.inf\n",
    "        score_tuples.append(np.r_[heuristic, tt])\n",
    "        \n",
    "        if output:\n",
    "            print 'iter', iter_ind, 'add', sp\n",
    "\n",
    "        visited.add(sp)\n",
    "        \n",
    "        candidate_sps = (set(candidate_sps) | (neighbors[sp] - set([-1])) | (visited - curr_cluster)) - curr_cluster\n",
    "        candidate_sps = list(candidate_sps)\n",
    "        \n",
    "#         f_avg = texton_freqs[list(curr_cluster)].sum(axis=0)\n",
    "#         candidate_scores = [chi2pval(f_avg, texton_freqs[i])[0] for i in candidate_sps]\n",
    "\n",
    "        h_avg = texton_hists[list(curr_cluster)].mean(axis=0)\n",
    "        candidate_scores = [-chi2(h_avg, texton_hists[i]) for i in candidate_sps]\n",
    "\n",
    "#         candidate_scores = [compute_cluster_score(curr_cluster | set([s])) for s in candidate_sps]\n",
    "                \n",
    "        if len(visited) > int(n_superpixels * 0.03):\n",
    "            break\n",
    "\n",
    "    score_tuples = np.array(score_tuples)\n",
    "    \n",
    "    min_size = 2\n",
    "    scores = score_tuples[:,1]\n",
    "    cutoff = np.argmax(scores[min_size:]) + min_size\n",
    "    \n",
    "    if output:\n",
    "        print 'cutoff', cutoff\n",
    "\n",
    "    final_cluster = added_sps[:cutoff]\n",
    "    final_score = scores[cutoff]\n",
    "    \n",
    "    if all_history:\n",
    "        return list(final_cluster), final_score, added_sps, score_tuples\n",
    "    else:\n",
    "        return list(final_cluster), final_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_cluster_score(cluster, texton_hists, neighbors):\n",
    "    \n",
    "    cluster_list = list(cluster)\n",
    "    cluster_avg = texton_hists[cluster_list].mean(axis=0)\n",
    "    \n",
    "    surrounds = set([i for i in set.union(*[neighbors[c] for c in cluster]) if i not in cluster and i != -1])\n",
    "    if len(surrounds) == 0: # single sp on background\n",
    "        return np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan\n",
    "    \n",
    "    surrounds_list = list(surrounds)\n",
    "    surround_dist = np.squeeze(cdist([cluster_avg], texton_hists[surrounds_list], chi2)).min()\n",
    "\n",
    "    surds, _ = find_boundary_sps([cluster], neighbors=neighbors, neighbor_graph=neighbor_graph)\n",
    "    \n",
    "    compactness = len(surds[0])**2/float(len(cluster))\n",
    "    compactness = .001 * np.maximum(compactness-40,0)**2\n",
    "    \n",
    "    size_prior = .1 * (1-np.exp(-.8*len(cluster)))\n",
    "    \n",
    "    score = surround_dist - compactness + size_prior\n",
    "    \n",
    "    interior_dist = np.nan\n",
    "    interior_pval = np.nan\n",
    "    surround_pval = np.nan\n",
    "    \n",
    "    return score, surround_dist, interior_dist, compactness, surround_pval, interior_pval, size_prior"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
