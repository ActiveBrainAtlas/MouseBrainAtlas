{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "rm -rf /shared/CSHL_data_processed/MD661/MD661_sorted_filenames.txt && mkdir -p /shared/CSHL_data_processed/MD661\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_data_processed/MD661/MD661_sorted_filenames.txt /shared/CSHL_data_processed/MD661/MD661_sorted_filenames.txt\n",
      "rm -rf /shared/CSHL_data_processed/MD661/MD661_anchor.txt && mkdir -p /shared/CSHL_data_processed/MD661\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_data_processed/MD661/MD661_anchor.txt /shared/CSHL_data_processed/MD661/MD661_anchor.txt\n",
      "rm -rf /shared/CSHL_data_processed/MD661/MD661_anchor.txt && mkdir -p /shared/CSHL_data_processed/MD661\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_data_processed/MD661/MD661_anchor.txt /shared/CSHL_data_processed/MD661/MD661_anchor.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File does not exist: /shared/CSHL_data_processed/MD661/MD661_anchor.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD662/MD662_sorted_filenames.txt && mkdir -p /shared/CSHL_data_processed/MD662\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_data_processed/MD662/MD662_sorted_filenames.txt /shared/CSHL_data_processed/MD662/MD662_sorted_filenames.txt\n",
      "rm -rf /shared/CSHL_data_processed/MD662/MD662_anchor.txt && mkdir -p /shared/CSHL_data_processed/MD662\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_data_processed/MD662/MD662_anchor.txt /shared/CSHL_data_processed/MD662/MD662_anchor.txt\n",
      "rm -rf /shared/CSHL_data_processed/MD662/MD662_anchor.txt && mkdir -p /shared/CSHL_data_processed/MD662\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_data_processed/MD662/MD662_anchor.txt /shared/CSHL_data_processed/MD662/MD662_anchor.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File does not exist: /shared/CSHL_data_processed/MD662/MD662_anchor.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD661/MD661_anchor.txt && mkdir -p /shared/CSHL_data_processed/MD661\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_data_processed/MD661/MD661_anchor.txt /shared/CSHL_data_processed/MD661/MD661_anchor.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File does not exist: /shared/CSHL_data_processed/MD661/MD661_anchor.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD661/MD661_anchor.txt && mkdir -p /shared/CSHL_data_processed/MD661\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_data_processed/MD661/MD661_anchor.txt /shared/CSHL_data_processed/MD661/MD661_anchor.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File does not exist: /shared/CSHL_data_processed/MD661/MD661_anchor.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD661/MD661_sorted_filenames.txt && mkdir -p /shared/CSHL_data_processed/MD661\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_data_processed/MD661/MD661_sorted_filenames.txt /shared/CSHL_data_processed/MD661/MD661_sorted_filenames.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File does not exist: /shared/CSHL_data_processed/MD661/MD661_sorted_filenames.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD661/MD661_sorted_filenames.txt && mkdir -p /shared/CSHL_data_processed/MD661\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_data_processed/MD661/MD661_sorted_filenames.txt /shared/CSHL_data_processed/MD661/MD661_sorted_filenames.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File does not exist: /shared/CSHL_data_processed/MD661/MD661_sorted_filenames.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD661/MD661_anchor.txt && mkdir -p /shared/CSHL_data_processed/MD661\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_data_processed/MD661/MD661_anchor.txt /shared/CSHL_data_processed/MD661/MD661_anchor.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File does not exist: /shared/CSHL_data_processed/MD661/MD661_anchor.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD661/MD661_anchor.txt && mkdir -p /shared/CSHL_data_processed/MD661\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_data_processed/MD661/MD661_anchor.txt /shared/CSHL_data_processed/MD661/MD661_anchor.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File does not exist: /shared/CSHL_data_processed/MD661/MD661_anchor.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD662/MD662_anchor.txt && mkdir -p /shared/CSHL_data_processed/MD662\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_data_processed/MD662/MD662_anchor.txt /shared/CSHL_data_processed/MD662/MD662_anchor.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File does not exist: /shared/CSHL_data_processed/MD662/MD662_anchor.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD662/MD662_anchor.txt && mkdir -p /shared/CSHL_data_processed/MD662\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_data_processed/MD662/MD662_anchor.txt /shared/CSHL_data_processed/MD662/MD662_anchor.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File does not exist: /shared/CSHL_data_processed/MD662/MD662_anchor.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD662/MD662_sorted_filenames.txt && mkdir -p /shared/CSHL_data_processed/MD662\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_data_processed/MD662/MD662_sorted_filenames.txt /shared/CSHL_data_processed/MD662/MD662_sorted_filenames.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File does not exist: /shared/CSHL_data_processed/MD662/MD662_sorted_filenames.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD662/MD662_sorted_filenames.txt && mkdir -p /shared/CSHL_data_processed/MD662\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_data_processed/MD662/MD662_sorted_filenames.txt /shared/CSHL_data_processed/MD662/MD662_sorted_filenames.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File does not exist: /shared/CSHL_data_processed/MD662/MD662_sorted_filenames.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD662/MD662_anchor.txt && mkdir -p /shared/CSHL_data_processed/MD662\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_data_processed/MD662/MD662_anchor.txt /shared/CSHL_data_processed/MD662/MD662_anchor.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File does not exist: /shared/CSHL_data_processed/MD662/MD662_anchor.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD662/MD662_anchor.txt && mkdir -p /shared/CSHL_data_processed/MD662\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_data_processed/MD662/MD662_anchor.txt /shared/CSHL_data_processed/MD662/MD662_anchor.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File does not exist: /shared/CSHL_data_processed/MD662/MD662_anchor.txt\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.join(os.environ['REPO_DIR'], 'utilities'))\n",
    "from utilities2015 import *\n",
    "from metadata import *\n",
    "from data_manager import *\n",
    "from distributed_utilities import *\n",
    "from preprocess_utilities import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After receiving data of a new stack, put images and macros in corresponding folder.\n",
    "- Add the stack name to proper variables in `metadata.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack = 'MD661'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tb_fmt = 'png'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use GUI, quality check and sort images.\n",
    "- Upload `sorted_filenames.txt` to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 cp --recursive s3://mousebrainatlas-rawdata/CSHL_data/MD661 /shared/CSHL_data/MD661 --exclude \"*\" --include \"*.png\"\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data', stack), \n",
    "                     from_hostname='s3raw', to_hostname='ec2', is_dir=True, include_only='*.'+tb_fmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD661/MD661_sorted_filenames.txt && mkdir -p /shared/CSHL_data_processed/MD661\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_data_processed/MD661/MD661_sorted_filenames.txt /shared/CSHL_data_processed/MD661/MD661_sorted_filenames.txt\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data_processed', stack, stack + '_sorted_filenames.txt'), \n",
    "                     from_hostname='s3', to_hostname='ec2', is_dir=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_, sections_to_filenames = DataManager.load_sorted_filenames(stack=stack)\n",
    "valid_filenames = [fn for fn in sections_to_filenames.values() if not is_invalid(fn=fn)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "script = os.path.join(REPO_DIR, 'preprocess', 'align_consecutive_v2.py')\n",
    "input_dir = os.path.join(RAW_DATA_DIR, stack)\n",
    "output_dir = os.path.join(DATA_DIR, stack, stack + '_elastix_output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '/shared/CSHL_data_processed/MD661/MD661_elastix_output': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "! rm -r $output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Align...\n",
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8 nodes available.\n",
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1189.16725802 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qsub returned.\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "print 'Align...'\n",
    "\n",
    "run_distributed(\"%(script)s %(stack)s %(input_dir)s %(output_dir)s \\'%%(kwargs_str)s\\' %(fmt)s\" % \\\n",
    "                {'script': script,\n",
    "                'stack': stack,\n",
    "                'input_dir': input_dir,\n",
    "                'output_dir': output_dir,\n",
    "                'fmt': tb_fmt},\n",
    "                kwargs_list=[{'prev_fn': valid_filenames[i-1], 'curr_fn': valid_filenames[i]} for i in range(1, len(valid_filenames))],\n",
    "                argument_type='list',\n",
    "               jobs_per_node=16)\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "print 'done in', time.time() - t, 'seconds' # 252 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 cp --recursive /shared/CSHL_data_processed/MD661/MD661_elastix_output s3://mousebrainatlas-data/CSHL_data_processed/MD661/MD661_elastix_output\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data_processed', stack, stack + '_elastix_output'), \n",
    "                     from_hostname='ec2', to_hostname='s3', is_dir=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check final metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "final_metric = {}\n",
    "for i in range(1, len(valid_filenames)):\n",
    "    prev_fn = valid_filenames[i-1]\n",
    "    curr_fn = valid_filenames[i]\n",
    "    with open(os.path.join(output_dir, curr_fn + '_to_' + prev_fn, 'elastix.log'), 'r') as f:\n",
    "        t = f.read()\n",
    "        g = re.search(\"Final metric value  = (.*?)\\n\", t)\n",
    "#         final_metric[(curr_fn, prev_fn)] = -float(g.groups()[0])\n",
    "        final_metric[i] = float(g.groups()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJsAAACqCAYAAAAKnk4GAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nItI0CjaJiIiIiIiIiEjT/P/c+uNYOD47pAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f87a4ab1890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "metric_arr = np.array(final_metric.values())\n",
    "plt.figure(figsize=(20,2));\n",
    "plt.ylim([-1, metric_arr.max()+.1]);\n",
    "plt.stem(metric_arr);\n",
    "plt.title('Mutual information of pairwise registration');\n",
    "plt.yticks(np.arange(-1, metric_arr.max()+.1, 0.1));\n",
    "plt.xlabel('Image index');\n",
    "plt.ylabel('Mutual info');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worst pair: MD662&661-F136-2017.06.07-22.02.11_MD661_1_0406\n"
     ]
    }
   ],
   "source": [
    "print 'worst pair:', valid_filenames[np.argmin(final_metric.values())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- download `elastix_output/` to local machine, edit consecutive transforms in local GUI, generate `custom_transforms/` to S3, upload to S3.\n",
    "- determine anchor image, upload `anchor.txt` to S3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compose consecutive transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD661/MD661_elastix_output && mkdir -p /shared/CSHL_data_processed/MD661\n",
      "aws s3 cp --recursive s3://mousebrainatlas-data/CSHL_data_processed/MD661/MD661_elastix_output /shared/CSHL_data_processed/MD661/MD661_elastix_output\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data_processed', stack, stack + '_elastix_output'), \n",
    "                     from_hostname='s3', to_hostname='ec2', is_dir=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD661/MD661_custom_transforms && mkdir -p /shared/CSHL_data_processed/MD661\n",
      "aws s3 cp --recursive s3://mousebrainatlas-data/CSHL_data_processed/MD661/MD661_custom_transforms /shared/CSHL_data_processed/MD661/MD661_custom_transforms\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data_processed', stack, stack + '_custom_transforms'), \n",
    "                     from_hostname='s3', to_hostname='ec2', is_dir=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD661/MD661_anchor.txt && mkdir -p /shared/CSHL_data_processed/MD661\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_data_processed/MD661/MD661_anchor.txt /shared/CSHL_data_processed/MD661/MD661_anchor.txt\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data_processed', stack, stack + '_anchor.txt'), \n",
    "                     from_hostname='s3', to_hostname='ec2', is_dir=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "anchor_fn = DataManager.load_anchor_filename(stack=stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "script = os.path.join(REPO_DIR, 'preprocess', 'compose_transform_thumbnail_v2.py')\n",
    "input_dir = os.path.join(DATA_DIR, stack, stack + '_elastix_output')\n",
    "output_fn = os.path.join(DATA_DIR, stack, '%(stack)s_transformsTo_%(anchor_fn)s.pkl' % \\\n",
    "                                                dict(stack=stack, anchor_fn=anchor_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! rm -f {output_fn}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Composing transform...\n",
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8 nodes available.\n",
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 15.1333079338 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qsub returned.\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "print 'Composing transform...'\n",
    "\n",
    "run_distributed(\"%(script)s %(stack)s \\\"%(input_dir)s\\\" \\'%%(kwargs_str)s\\' %(anchor_idx)d \\\"%(output_fn)s\\\"\" % \\\n",
    "            {'stack': stack,\n",
    "            'script': script,\n",
    "            'input_dir': input_dir,\n",
    "            'anchor_idx': valid_filenames.index(anchor_fn),\n",
    "            'output_fn': output_fn},\n",
    "            kwargs_list=[{'filenames': valid_filenames}],\n",
    "            argument_type='list')\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "print 'done in', time.time() - t, 'seconds' # 20 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 cp --recursive /shared/CSHL_data_processed/MD661 s3://mousebrainatlas-data/CSHL_data_processed/MD661 --exclude \"*\" --include \"*.pkl\"\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data_processed', stack), \n",
    "                     from_hostname='ec2', to_hostname='s3', is_dir=True, include_only='*.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 cp --recursive s3://mousebrainatlas-data/CSHL_data_processed/MD661 /shared/CSHL_data_processed/MD661 --exclude \"*\" --include \"*.pkl\"\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data_processed', stack), \n",
    "                     from_hostname='s3', to_hostname='ec2', is_dir=True, include_only='*.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if stack in all_nissl_stacks:\n",
    "    pad_bg_color = 'white'\n",
    "else:\n",
    "    pad_bg_color = 'auto'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prep_id = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_dir = os.path.join(RAW_DATA_DIR, stack)\n",
    "# out_dir = os.path.join(DATA_DIR, stack, stack + '_thumbnail_alignedTo_' + anchor_fn)\n",
    "out_dir = os.path.join(DATA_DIR, stack, stack + '_prep' + str(prep_id) + '_thumbnail')\n",
    "script = os.path.join(REPO_DIR, 'preprocess', 'warp_crop_IM_v2.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: 661-F116-2017.06.07-04.39.41_MD661_1_0346: not found\r\n"
     ]
    }
   ],
   "source": [
    "! rm -rf {out_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warping...\n",
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8 nodes available.\n",
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 277.217124939 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qsub returned.\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "print 'Warping...'\n",
    "\n",
    "# transforms_filename = os.path.join(DATA_DIR, stack, '%(stack)s_transformsTo_%(anchor_fn)s.pkl' % \\\n",
    "#                                    dict(stack=stack, anchor_fn=anchor_fn))\n",
    "# transforms_to_anchor = pickle.load(open(transforms_filename, 'r'))\n",
    "\n",
    "transforms_to_anchor = DataManager.load_transforms(stack=stack, downsample_factor=32, \n",
    "                                                   use_inverse=False, anchor_fn=anchor_fn)\n",
    "\n",
    "if pad_bg_color == 'auto':\n",
    "    run_distributed('%(script)s %(stack)s \\\"%(input_dir)s\\\" \\\"%(out_dir)s\\\" %%(transform)s \\\"%%(filename)s\\\" \\\"%%(output_fn)s\\\" thumbnail 0 0 2000 1500 %%(pad_bg_color)s' % \\\n",
    "                    {'script': script,\n",
    "                    'stack': stack,\n",
    "                    'input_dir': input_dir,\n",
    "                    'out_dir': out_dir\n",
    "                    },\n",
    "                    kwargs_list=[{'transform': ','.join(map(str, transforms_to_anchor[fn].flatten())),\n",
    "                                'filename': fn + '.' + tb_fmt,\n",
    "#                                 'output_fn': fn + '_thumbnail_alignedTo_' + anchor_fn + '.tif',\n",
    "                                  'output_fn': fn + '_prep' + str(prep_id) + '_thumbnail' + '.tif',\n",
    "                                'pad_bg_color': 'black' if fn.split('-')[1][0] == 'F' else 'white'}\n",
    "                                for fn in valid_filenames],\n",
    "                    argument_type='single',\n",
    "                   jobs_per_node=8)\n",
    "else:\n",
    "    run_distributed('%(script)s %(stack)s \\\"%(input_dir)s\\\" \\\"%(out_dir)s\\\" %%(transform)s \\\"%%(filename)s\\\" \\\"%%(output_fn)s\\\" thumbnail 0 0 2000 1500 %(pad_bg_color)s' % \\\n",
    "                    {'script': script,\n",
    "                    'stack': stack,\n",
    "                    'input_dir': input_dir,\n",
    "                    'out_dir': out_dir,\n",
    "                    'pad_bg_color': pad_bg_color},\n",
    "                    kwargs_list=[{'transform': ','.join(map(str, transforms_to_anchor[fn].flatten())),\n",
    "                                'filename': fn + '.' + tb_fmt,\n",
    "#                                 'output_fn': fn + '_thumbnail_alignedTo_' + anchor_fn + '.tif'}\n",
    "                                  'output_fn': fn + '_prep' + str(prep_id) + '_thumbnail' + '.tif'}\n",
    "                                for fn in valid_filenames],\n",
    "                    argument_type='single',\n",
    "                   jobs_per_node=8)\n",
    "\n",
    "wait_qsub_complete()\n",
    "    \n",
    "print 'done in', time.time() - t, 'seconds' # 300 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 cp --recursive /shared/CSHL_data_processed/MD661/MD661_prep1_thumbnail s3://mousebrainatlas-data/CSHL_data_processed/MD661/MD661_prep1_thumbnail\n"
     ]
    }
   ],
   "source": [
    "upload_to_s3(out_dir, is_dir=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of data_manager failed: Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/shared/MouseBrainAtlas/utilities/data_manager.py\", line 1702\n",
      "    def get_image_dir_v2(stack, prep_id, int_id, resol='lossless', ,\n",
      "                                                                   ^\n",
      "SyntaxError: invalid syntax\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# transfer_data_synced(os.path.join('CSHL_data_processed', stack, stack + '_thumbnail_alignedTo_' + anchor_fn),\n",
    "#                     from_hostname='ec2',\n",
    "#                     to_hostname='s3',\n",
    "#                     is_dir=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Download aligned images to local. In GUI, check alignment correctness.\n",
    "- (Recommended) Run `construct_intensity_volume_v3` notebook. Check the smoothness of virtual re-sectioning in brain labeling gui.\n",
    "- Place cropbox. Upload `cropbox.txt` to S3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD635/MD635_alignedTo_MD635-F63-2016.05.19-08.39.03_MD635_2_0188_cropbox.txt && mkdir -p /shared/CSHL_data_processed/MD635\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_data_processed/MD635/MD635_alignedTo_MD635-F63-2016.05.19-08.39.03_MD635_2_0188_cropbox.txt /shared/CSHL_data_processed/MD635/MD635_alignedTo_MD635-F63-2016.05.19-08.39.03_MD635_2_0188_cropbox.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "Child returned 0\n",
      "0.45 seconds.\n"
     ]
    }
   ],
   "source": [
    "download_from_s3(DataManager.get_cropbox_filename(stack), redownload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xmin, xmax, ymin, ymax, first_sec, last_sec = DataManager.load_cropbox(stack=stack)\n",
    "w = xmax + 1 - xmin\n",
    "h = ymax + 1 - ymin\n",
    "x = xmin\n",
    "y = ymin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "first_fn = sections_to_filenames[first_sec]\n",
    "last_fn = sections_to_filenames[last_sec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "first_idx_among_valid = valid_filenames.index(first_fn)\n",
    "last_idx_among_valid = valid_filenames.index(last_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop Thumbnail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data_processed', stack, stack + '_thumbnail_alignedTo_' + anchor_fn),\n",
    "                    from_hostname='s3',\n",
    "                    to_hostname='ec2',\n",
    "                    is_dir=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir -p /shared/CSHL_data_processed/MD635/MD635_thumbnail_alignedTo_MD635-F63-2016.05.19-08.39.03_MD635_2_0188_cropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dir = os.path.join(DATA_DIR, stack, \"%(stack)s_thumbnail_alignedTo_%(anchor_fn)s\" % \\\n",
    "                           {'stack': stack, 'anchor_fn': anchor_fn})\n",
    "\n",
    "output_dir = os.path.join(DATA_DIR, stack, \"%(stack)s_thumbnail_alignedTo_%(anchor_fn)s_cropped\" % \\\n",
    "                           {'stack': stack, 'anchor_fn': anchor_fn})\n",
    "\n",
    "execute_command('mkdir -p ' + output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cropping thumbnail..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mogrify -set filename:name %t -crop 685x448+659+308 -write \"/shared/CSHL_data_processed/MD635/MD635_thumbnail_alignedTo_MD635-F63-2016.05.19-08.39.03_MD635_2_0188_cropped/%[filename:name]_cropped.tif\" /shared/CSHL_data_processed/MD635/MD635_thumbnail_alignedTo_MD635-F63-2016.05.19-08.39.03_MD635_2_0188/*.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "done in 34.986666 seconds\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "sys.stderr.write('cropping thumbnail...')\n",
    "\n",
    "execute_command('mogrify -set filename:name %%t -crop %(w)dx%(h)d+%(x)d+%(y)d -write \"%(output_dir)s/%%[filename:name]_cropped.tif\" %(input_dir)s/*.tif' % \\\n",
    "    {'input_dir': input_dir,\n",
    "     'output_dir': output_dir,\n",
    "    'w':w, 'h':h, 'x':x, 'y':y})\n",
    "\n",
    "sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 100 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 cp --recursive /shared/CSHL_data_processed/MD635/MD635_thumbnail_alignedTo_MD635-F63-2016.05.19-08.39.03_MD635_2_0188_cropped s3://mousebrainatlas-data/CSHL_data_processed/MD635/MD635_thumbnail_alignedTo_MD635-F63-2016.05.19-08.39.03_MD635_2_0188_cropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "3.58 seconds.\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data_processed', stack, stack + '_thumbnail_alignedTo_' + anchor_fn + '_cropped'),\n",
    "                    from_hostname='ec2',\n",
    "                    to_hostname='s3',\n",
    "                    is_dir=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expand lossless JP2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack = 'MD635'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data', stack),\n",
    "                    from_hostname='s3raw',\n",
    "                    to_hostname='ec2',\n",
    "                    is_dir=True,\n",
    "                    include_only='*_lossless.jp2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "sys.stderr.write('expanding...')\n",
    "\n",
    "output_dir = create_if_not_exists(os.path.join(DATA_DIR, stack, stack + '_lossless_tif'))\n",
    "input_dir = os.path.join(RAW_DATA_DIR, stack)\n",
    "\n",
    "# filenames_to_expand = [fn for fn in filenames[first_idx:last_idx+1] if not os.path.exists(os.path.join(input_dir, fn + '_lossless.tif'))]\n",
    "\n",
    "filenames_to_expand = [fn for fn in valid_filenames[first_idx_among_valid:last_idx_among_valid+1] \n",
    "                       if not os.path.exists(os.path.join(input_dir, fn + '_lossless.tif'))]\n",
    "\n",
    "run_distributed('export LD_LIBRARY_PATH=/home/ubuntu/KDU79_Demo_Apps_for_Linux-x86-64_170108:$LD_LIBRARY_PATH; %(kdu_bin)s -i %(input_dir)s/%%(fn)s_lossless.jp2 -o %(output_dir)s/%%(fn)s_lossless.tif' % \\\n",
    "                {'kdu_bin': KDU_EXPAND_BIN,\n",
    "                 'output_dir': output_dir,\n",
    "                'input_dir': input_dir},\n",
    "                kwargs_list={'fn': filenames_to_expand},\n",
    "                argument_type='single',\n",
    "               cluster_size=16)\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 900 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data_processed', stack, stack + '_lossless_tif'),\n",
    "                    from_hostname='ec2',\n",
    "                    to_hostname='s3',\n",
    "                    is_dir=True) # 6000s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warping and cropping lossless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD585/MD585_lossless_tif && mkdir -p /shared/CSHL_data_processed/MD585\n",
      "aws s3 cp --recursive s3://mousebrainatlas-data/CSHL_data_processed/MD585/MD585_lossless_tif /shared/CSHL_data_processed/MD585/MD585_lossless_tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3079.07781506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "3079.08 seconds.\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data_processed', stack, stack + '_lossless_tif'),\n",
    "                    from_hostname='s3',\n",
    "                    to_hostname='ec2',\n",
    "                    is_dir=True)\n",
    "# 3000 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf_filepath = os.path.join(DATA_DIR, stack, '%(stack)s_transformsTo_anchor.pkl' % {'stack':stack})\n",
    "# tfs = pickle.load(open(tf_filepath, 'r'))\n",
    "# Note that the index from trasform pickle file starts at 0, BUT the .._renamed folder index starts at 1.#\n",
    "\n",
    "tfs = DataManager.load_transforms(stack=stack)\n",
    "\n",
    "lossless_tif_dir = os.path.join(DATA_DIR, stack, stack + '_lossless_tif')\n",
    "lossless_aligned_cropped_dir = os.path.join(DATA_DIR, stack, stack + '_lossless_alignedTo_' + anchor_fn + '_cropped')\n",
    "\n",
    "script_fp = os.path.join(REPO_DIR, 'preprocess', 'warp_crop_IM_v2.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! rm -r {lossless_aligned_cropped_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if stack in all_nissl_stacks:\n",
    "    pad_bg_color = 'white'\n",
    "else:\n",
    "    pad_bg_color = 'auto'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "sys.stderr.write('warping and cropping lossless...')\n",
    "\n",
    "# wait_num_nodes(16)\n",
    "                   \n",
    "if pad_bg_color == 'auto':\n",
    "    # If alternating, then black padding for F sections, white padding for N sections.\n",
    "    run_distributed(command='%(script_path)s %(stack)s %(lossless_tif_dir)s %(lossless_aligned_cropped_dir)s %%(transform)s %%(filename)s %%(output_fn)s lossless %(x)d %(y)d %(w)d %(h)d %%(pad_bg_color)s'%\\\n",
    "                    {'script_path': script_fp,\n",
    "                    'stack': stack,\n",
    "                    'lossless_tif_dir': lossless_tif_dir,\n",
    "                    'lossless_aligned_cropped_dir': lossless_aligned_cropped_dir,\n",
    "                    'x': x,\n",
    "                    'y': y,\n",
    "                    'w': w,\n",
    "                    'h': h},\n",
    "                    kwargs_list=[{'transform': ','.join(map(str, tfs[fn].flatten())),\n",
    "                                'filename': fn + '_lossless.tif',\n",
    "                                'output_fn': fn + '_lossless_alignedTo_' + anchor_fn + '_cropped.tif',\n",
    "                                'pad_bg_color': 'black' if fn.split('-')[1][0] == 'F' else 'white'}\n",
    "                                for fn in valid_filenames[first_idx_among_valid:last_idx_among_valid+1]],\n",
    "#                                  for fn in valid_filenames[first_idx_among_valid:first_idx_among_valid+16]],\n",
    "                    argument_type='single',\n",
    "                   cluster_size=16,\n",
    "                   jobs_per_node=4)\n",
    "else:\n",
    "    run_distributed(command='%(script_path)s %(stack)s %(lossless_tif_dir)s %(lossless_aligned_cropped_dir)s %%(transform)s %%(filename)s %%(output_fn)s lossless %(x)d %(y)d %(w)d %(h)d %(pad_bg_color)s'%\\\n",
    "                    {'script_path': script_fp,\n",
    "                    'stack': stack,\n",
    "                    'lossless_tif_dir': lossless_tif_dir,\n",
    "                    'lossless_aligned_cropped_dir': lossless_aligned_cropped_dir,\n",
    "                    'x': x,\n",
    "                    'y': y,\n",
    "                    'w': w,\n",
    "                    'h': h,\n",
    "                    'pad_bg_color': pad_bg_color},\n",
    "                    kwargs_list=[{'transform': ','.join(map(str, tfs[fn].flatten())),\n",
    "                                'filename': fn + '_lossless.tif',\n",
    "                                'output_fn': fn + '_lossless_alignedTo_' + anchor_fn + '_cropped.tif'}\n",
    "                                for fn in valid_filenames[first_idx_among_valid:last_idx_among_valid+1]],\n",
    "#                                  for fn in valid_filenames[first_idx_among_valid:first_idx_among_valid+16]],\n",
    "                    argument_type='single',\n",
    "                   cluster_size=16,\n",
    "                   jobs_per_node=4)\n",
    "\n",
    "wait_qsub_complete()\n",
    "    \n",
    "sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 4140 seconds (AWS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 cp --recursive /shared/CSHL_data_processed/MD658/MD658_lossless_alignedTo_MD658-N58-2017.03.31-19.59.31_MD658_2_0173_cropped s3://mousebrainatlas-data/CSHL_data_processed/MD658/MD658_lossless_alignedTo_MD658-N58-2017.03.31-19.59.31_MD658_2_0173_cropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "1064.17 seconds.\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data_processed', stack, stack + '_lossless_alignedTo_' + anchor_fn + '_cropped'),\n",
    "                    from_hostname='ec2',\n",
    "                    to_hostname='s3',\n",
    "                    is_dir=True) \n",
    "# 512 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expand and Crop together (use /scratch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack = 'MD635'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfs = DataManager.load_transforms(stack=stack, downsample_factor=32, use_inverse=False)\n",
    "anchor_fn = metadata_cache['anchor_fn'][stack]\n",
    "xmin, xmax, ymin, ymax = metadata_cache['cropbox'][stack]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "expanding...Child returned 0\n",
      "13 nodes available...Continuing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "Child returned 0\n",
      "13 nodes available...Continuing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "qsub returned.\n",
      "done in 4222.634601 seconds\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "sys.stderr.write('expanding...')\n",
    "\n",
    "run_distributed('rm -rf /scratch/*', argument_type='single')\n",
    "\n",
    "raw_jp2_dir = DataManager.get_image_dir(stack=stack, resol='lossless', version='original_jp2', raw_data_dir='/scratch/CSHL_data')\n",
    "lossless_tif_dir = create_if_not_exists(DataManager.get_image_dir(stack=stack, resol='lossless', version='uncropped_tif', data_dir='/scratch/CSHL_data_processed'))\n",
    "lossless_aligned_cropped_dir = create_if_not_exists(DataManager.get_image_dir(stack=stack, resol='lossless', version='cropped', data_dir='/scratch/CSHL_data_processed'))\n",
    "\n",
    "warp_crop_script_fp = os.path.join(REPO_DIR, 'preprocess', 'warp_crop_IM_v3.py')\n",
    "\n",
    "run_distributed('aws s3 cp s3://mousebrainatlas-rawdata/CSHL_data/%(stack)s/%%(fn)s_lossless.jp2 %(raw_jp2_dir)s/ && \\\n",
    "mkdir -p %(lossless_tif_dir)s && \\\n",
    "LD_LIBRARY_PATH=/home/ubuntu/KDU79_Demo_Apps_for_Linux-x86-64_170108:$LD_LIBRARY_PATH %(kdu_bin)s -i %(raw_jp2_dir)s/%%(fn)s_lossless.jp2 -o %(lossless_tif_dir)s/%%(fn)s_lossless.tif && \\\n",
    "mkdir -p %(lossless_aligned_cropped_dir)s && \\\n",
    "%(script_path)s %(stack)s %%(lossless_tif_fp)s %%(lossless_aligned_cropped_fp)s %%(transform)s lossless %(x)d %(y)d %(w)d %(h)d %%(pad_bg_color)s && \\\n",
    "aws s3 cp %%(lossless_aligned_cropped_fp)s s3://mousebrainatlas-data/%(s3_dest_dir)s/' % \\\n",
    "                {'stack': stack,\n",
    "                'kdu_bin': KDU_EXPAND_BIN,\n",
    "                'raw_jp2_dir': raw_jp2_dir,\n",
    "                'script_path': warp_crop_script_fp,\n",
    "                'lossless_tif_dir': lossless_tif_dir,\n",
    "                'lossless_aligned_cropped_dir': lossless_aligned_cropped_dir,\n",
    "                 's3_dest_dir': relative_to_local(lossless_aligned_cropped_dir, local_root='/scratch'),\n",
    "                'x': xmin,\n",
    "                'y': ymin,\n",
    "                'w': xmax + 1 - xmin,\n",
    "                'h': ymax + 1 - ymin},\n",
    "                kwargs_list=[{'fn': fn, \n",
    "                              'transform': ','.join(map(str, tfs[fn].flatten())),\n",
    "                                'lossless_tif_fp': DataManager.get_image_filepath(stack=stack, fn=fn, resol='lossless', version='uncropped_tif', data_dir='/scratch/CSHL_data_processed'),\n",
    "                                'lossless_aligned_cropped_fp': DataManager.get_image_filepath(stack=stack, fn=fn, resol='lossless', version='cropped', data_dir='/scratch/CSHL_data_processed'),\n",
    "                                'pad_bg_color': 'black' if fn.split('-')[1][0] == 'F' else 'white'}\n",
    "                             for fn in metadata_cache['valid_filenames'][stack]],\n",
    "                argument_type='single')\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 4222 seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# contrast stretch Neurotrace, convert to 8 bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# stack = 'MD642'\n",
    "\n",
    "# download_from_s3(DataManager.get_sorted_filenames_filename(stack=stack))\n",
    "# _, sections_to_filenames = DataManager.load_sorted_filenames(stack=stack)\n",
    "\n",
    "# valid_filenames = [fn for fn in sections_to_filenames.values() if not is_invalid(fn=fn)]\n",
    "\n",
    "# _, _, _, _, first_sec, last_sec = DataManager.load_cropbox(stack=stack)\n",
    "# first_fn = sections_to_filenames[first_sec]\n",
    "# last_fn = sections_to_filenames[last_sec]\n",
    "# first_idx_among_valid = valid_filenames.index(first_fn)\n",
    "# last_idx_among_valid = valid_filenames.index(last_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# script_fp = os.path.join(REPO_DIR, 'preprocess', 'stretch_contrast_neurotrace.py')\n",
    "# in_dir = os.path.join(DATA_DIR, stack, stack + '_lossless_alignedTo_' + anchor_fn + '_cropped')\n",
    "# out_dir = os.path.join(DATA_DIR, stack, stack + '_lossless_alignedTo_' + anchor_fn + '_cropped_contrast_stretched')\n",
    "# ! mkdir -p {out_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# t = time.time()\n",
    "# sys.stderr.write('Contrast stretch neurotrace images...')\n",
    "               \n",
    "# run_distributed(command='%(script_path)s %%(in_fn)s %%(out_fn)s %(imin)d %(imax)d'%\\\n",
    "#                     {'script_path': script_fp,\n",
    "#                      'imin': 0,\n",
    "#                      'imax': 400\n",
    "#                     },\n",
    "#                     kwargs_list=[{'in_fn': os.path.join(in_dir, fn + '_lossless_alignedTo_' + anchor_fn + '_cropped.tif'),\n",
    "#                                 'out_fn': os.path.join(out_dir, fn + '_lossless_alignedTo_' + anchor_fn + '_cropped_contrast_stretched.tif')}\n",
    "#                                 for fn in valid_filenames[first_idx_among_valid:last_idx_among_valid+1]\n",
    "#                                 if fn.split('-')[1][0] == 'F'],\n",
    "#                     argument_type='single',\n",
    "#                    cluster_size=16)\n",
    "\n",
    "# wait_qsub_complete()\n",
    "\n",
    "# sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 2500 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transfer_data_synced(os.path.join('CSHL_data_processed', stack, stack + '_lossless_alignedTo_' + anchor_fn + '_cropped_contrast_stretched'),\n",
    "#                     from_hostname='ec2',\n",
    "#                     to_hostname='s3',\n",
    "#                     is_dir=True) #700s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert images to nissl-like grayscale - for full nissl stacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Convert nissl images to gray...Child returned 0\n",
      "16 nodes requested, 16 nodes available...Continuing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "qsub returned.\n",
      "done in 1136.945903 seconds\n"
     ]
    }
   ],
   "source": [
    "# for stack in all_nissl_stacks:\n",
    "for stack in ['MD595']:\n",
    "    \n",
    "    download_from_s3(DataManager.get_sorted_filenames_filename(stack=stack))\n",
    "    _, sections_to_filenames = DataManager.load_sorted_filenames(stack=stack)\n",
    "    \n",
    "    valid_filenames = [fn for fn in sections_to_filenames.values() if not is_invalid(fn=fn)]\n",
    "    download_from_s3(DataManager.get_anchor_filename_filename(stack=stack))\n",
    "\n",
    "    _, _, _, _, first_sec, last_sec = DataManager.load_cropbox(stack=stack)\n",
    "    first_fn = sections_to_filenames[first_sec]\n",
    "    last_fn = sections_to_filenames[last_sec]\n",
    "    first_idx_among_valid = valid_filenames.index(first_fn)\n",
    "    last_idx_among_valid = valid_filenames.index(last_fn)\n",
    "\n",
    "    # Convert Nissl images to grayscale\n",
    "    \n",
    "    t = time.time()\n",
    "    sys.stderr.write('Convert nissl images to gray...')\n",
    "\n",
    "    script_fp = os.path.join(REPO_DIR, 'preprocess', 'convert_grayscale_neurotrace_v2.py')\n",
    "\n",
    "    run_distributed(command='%(script_path)s %(stack)s \\'%%(filenames)s\\''%\\\n",
    "                        {'script_path': script_fp, 'stack': stack},\n",
    "                        kwargs_list={'filenames': valid_filenames[first_idx_among_valid:last_idx_among_valid+1]\n",
    "                                    },\n",
    "                        argument_type='list2')\n",
    "\n",
    "    wait_qsub_complete()\n",
    "\n",
    "    sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 900 seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert images to nissl-like grayscale - for alternating nissl/neurotrace stacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Convert nissl images to gray...16 nodes requested, 16 nodes available...Continuing\n",
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "qsub returned.\n",
      "done in 1098.395771 seconds\n",
      "16 nodes requested, 16 nodes available...Continuing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match intensity profile between Neurotrace and Nissl..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "qsub returned.\n",
      "Convert neurotrace images to gray...16 nodes requested, 16 nodes available...Continuing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done in 2371.7916441 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "qsub returned.\n",
      "done in 1008.132029 seconds\n",
      "Convert nissl images to gray...16 nodes requested, 16 nodes available...Continuing\n",
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "qsub returned.\n",
      "done in 1053.684169 seconds\n",
      "16 nodes requested, 16 nodes available...Continuing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match intensity profile between Neurotrace and Nissl..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "qsub returned.\n",
      "Convert neurotrace images to gray...16 nodes requested, 16 nodes available...Continuing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done in 3785.25425816 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "qsub returned.\n",
      "done in 1298.919096 seconds\n"
     ]
    }
   ],
   "source": [
    "# for stack in all_alt_nissl_ntb_stacks + all_alt_nissl_tracing_stacks:\n",
    "for stack in ['MD653', 'MD657']:\n",
    "    \n",
    "    download_from_s3(DataManager.get_sorted_filenames_filename(stack=stack))\n",
    "    _, sections_to_filenames = DataManager.load_sorted_filenames(stack=stack)\n",
    "    \n",
    "    valid_filenames = [fn for fn in sections_to_filenames.values() if not is_invalid(fn=fn)]\n",
    "    download_from_s3(DataManager.get_anchor_filename_filename(stack=stack))\n",
    "\n",
    "    _, _, _, _, first_sec, last_sec = DataManager.load_cropbox(stack=stack)\n",
    "    first_fn = sections_to_filenames[first_sec]\n",
    "    last_fn = sections_to_filenames[last_sec]\n",
    "    first_idx_among_valid = valid_filenames.index(first_fn)\n",
    "    last_idx_among_valid = valid_filenames.index(last_fn)\n",
    "\n",
    "    # Convert Nissl images to grayscale\n",
    "    \n",
    "    t = time.time()\n",
    "    sys.stderr.write('Convert nissl images to gray...')\n",
    "\n",
    "    script_fp = os.path.join(REPO_DIR, 'preprocess', 'convert_grayscale_neurotrace_v2.py')\n",
    "\n",
    "    run_distributed(command='%(script_path)s %(stack)s \\'%%(filenames)s\\''%\\\n",
    "                        {'script_path': script_fp, 'stack': stack},\n",
    "                        kwargs_list={'filenames': \n",
    "                                     [fn for fn in valid_filenames[first_idx_among_valid:last_idx_among_valid+1]\n",
    "                                      if fn.split('-')[1][0] == 'N']\n",
    "                                    },\n",
    "                        argument_type='list2',\n",
    "                       cluster_size=16)\n",
    "\n",
    "    wait_qsub_complete()\n",
    "\n",
    "    sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 900 seconds.\n",
    "    \n",
    "    # Match intensity profile between Neurotrace Blue to Nissl\n",
    "\n",
    "    t = time.time()\n",
    "    sys.stderr.write('Match intensity profile between Neurotrace and Nissl...')\n",
    "\n",
    "    filename_pairs = []\n",
    "    l = valid_filenames[first_idx_among_valid:last_idx_among_valid+1]\n",
    "    for i, fn in enumerate(l):\n",
    "        if l[i].split('-')[1][0] == 'F':\n",
    "            for d in range(1, 99):\n",
    "                if i+d < len(l) and l[i+d].split('-')[1][0] == 'N':\n",
    "                    filename_pairs.append((l[i+d], l[i]))\n",
    "                    break\n",
    "                if i-d >= 0 and l[i-d].split('-')[1][0] == 'N':\n",
    "                    filename_pairs.append((l[i-d], l[i]))\n",
    "                    break\n",
    "            \n",
    "    script_fp = os.path.join(REPO_DIR, 'preprocess', 'match_intensity_profile.py')\n",
    "    \n",
    "    run_distributed(command='%(script_path)s %(stack)s \\'%%(filename_pairs)s\\' ' % \\\n",
    "                    {'script_path': script_fp,\n",
    "                    'stack': stack,\n",
    "                    'filename_pairs': filename_pairs},\n",
    "                    kwargs_list=dict(filename_pairs=filename_pairs),\n",
    "                    argument_type='list2',\n",
    "                   cluster_size=16)\n",
    "\n",
    "    wait_qsub_complete()\n",
    "\n",
    "    sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 2500 seconds. \n",
    "    # TODO: One node is especially slow, investigate.\n",
    "    \n",
    "    # Convert Neurotrace images to grayscale\n",
    "    \n",
    "    t = time.time()\n",
    "    sys.stderr.write('Convert neurotrace images to gray...')\n",
    "    \n",
    "    script_fp = os.path.join(REPO_DIR, 'preprocess', 'convert_grayscale_neurotrace_v2.py')\n",
    "    \n",
    "    run_distributed(command='%(script_path)s %(stack)s \\'%%(filenames)s\\''%\\\n",
    "                        {'script_path': script_fp, \n",
    "                        'stack': stack},\n",
    "                        kwargs_list={'filenames': [fn for fn in valid_filenames[first_idx_among_valid:last_idx_among_valid+1]\n",
    "                                      if fn.split('-')[1][0] == 'F']\n",
    "                                    },\n",
    "                        argument_type='list2',\n",
    "                       cluster_size=16)\n",
    "\n",
    "    wait_qsub_complete()\n",
    "\n",
    "    sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 1200 seconds.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert images to nissl-like grayscale - for full neurotrace stacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Convert neurotrace images to gray...Child returned 0\n",
      "16 nodes available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n",
      "qsub returned.\n",
      "done in 1952.800308 seconds\n"
     ]
    }
   ],
   "source": [
    "for stack in ['MD635']:\n",
    "    \n",
    "    # Convert Neurotrace images to grayscale using a priori intensity mapping.\n",
    "    \n",
    "    t = time.time()\n",
    "    sys.stderr.write('Convert neurotrace images to gray...')\n",
    "    \n",
    "    script_fp = os.path.join(REPO_DIR, 'preprocess', 'convert_grayscale_neurotrace_v2.py')\n",
    "    \n",
    "    run_distributed(command='%(script_path)s %(stack)s \\'%%(filenames)s\\''%\\\n",
    "                        {'script_path': script_fp, \n",
    "                        'stack': stack},\n",
    "                        kwargs_list={'filenames': metadata_cache['valid_filenames'][stack]},\n",
    "                        argument_type='list2')\n",
    "\n",
    "    wait_qsub_complete()\n",
    "\n",
    "    sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 2000 seconds.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contrast stretch all nissl-like grayscale images (deprecated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for stack in ['MD590',\n",
    "#  'MD591',\n",
    "#  'MD592',\n",
    "#  'MD593',\n",
    "#  'MD594',\n",
    "#  'MD595',\n",
    "#  'MD598',\n",
    "#  'MD599',\n",
    "#  'MD602',\n",
    "#  'MD603']:\n",
    "# # for stack in ['MD589']:\n",
    "    \n",
    "#     download_from_s3(DataManager.get_sorted_filenames_filename(stack=stack))\n",
    "#     _, sections_to_filenames = DataManager.load_sorted_filenames(stack=stack)\n",
    "    \n",
    "#     valid_filenames = [fn for fn in sections_to_filenames.values() if not is_invalid(fn=fn)]\n",
    "#     download_from_s3(DataManager.get_anchor_filename_filename(stack=stack))\n",
    "\n",
    "#     _, _, _, _, first_sec, last_sec = DataManager.load_cropbox(stack=stack)\n",
    "#     first_fn = sections_to_filenames[first_sec]\n",
    "#     last_fn = sections_to_filenames[last_sec]\n",
    "#     first_idx_among_valid = valid_filenames.index(first_fn)\n",
    "#     last_idx_among_valid = valid_filenames.index(last_fn)\n",
    "\n",
    "#     # Contrast stretch nissl grayscale image\n",
    "    \n",
    "#     t = time.time()\n",
    "#     sys.stderr.write('Contrast stretch nissl grayscale image...')\n",
    "\n",
    "#     script_fp = os.path.join(REPO_DIR, 'preprocess', 'stretch_contrast_image.py')\n",
    "\n",
    "#     run_distributed(command='ROOT_DIR=/scratch/ %(script_path)s %(stack)s \\'%%(filenames)s\\' 23 160'%\\\n",
    "#                         {'script_path': script_fp, 'stack': stack},\n",
    "#                         kwargs_list={'filenames': valid_filenames[first_idx_among_valid:last_idx_among_valid+1]\n",
    "#                                     },\n",
    "#                         argument_type='list2',\n",
    "#                        cluster_size=16)\n",
    "\n",
    "#     wait_qsub_complete()\n",
    "\n",
    "#     sys.stderr.write('done in %f seconds\\n' % (time.time() - t))\n",
    "        \n",
    "#     run_distributed(command='rm -r /scratch/*',\n",
    "#                         argument_type='single',\n",
    "#                        cluster_size=16)\n",
    "#     wait_qsub_complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONE STACK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Convert Nissl images to grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "sys.stderr.write('Convert nissl images to gray...')\n",
    "               \n",
    "script_fp = os.path.join(REPO_DIR, 'preprocess', 'convert_grayscale_neurotrace_v2.py')\n",
    "\n",
    "run_distributed(command='%(script_path)s %(stack)s \\'%%(filenames)s\\''%\\\n",
    "                    {'script_path': script_fp, 'stack': stack},\n",
    "#                     kwargs_list={'filenames': valid_filenames[first_idx_among_valid:last_idx_among_valid+1]},\n",
    "                    kwargs_list={'filenames':\n",
    "                                 [fn for fn in valid_filenames[first_idx_among_valid:last_idx_among_valid+1]\n",
    "                                  if fn.split('-')[1][0] == 'N']},\n",
    "                    argument_type='list2',\n",
    "                   cluster_size=16)\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 1200 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert contrast-stretched Neurotrace images to grayscale\n",
    "\n",
    "# script_fp = os.path.join(REPO_DIR, 'preprocess', 'convert_grayscale_neurotrace.py')\n",
    "# in_dir = os.path.join(DATA_DIR, stack, stack + '_lossless_alignedTo_' + anchor_fn + '_cropped_contrast_stretched')\n",
    "# out_dir = os.path.join(DATA_DIR, stack, stack + '_lossless_alignedTo_' + anchor_fn + '_cropped_contrast_stretched_blueasgray')\n",
    "# ! mkdir -p {out_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Convert neurotrace images to gray...16 nodes requested, 16 nodes available...Continuing\n",
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "qsub returned.\n",
      "done in 75.575123 seconds\n"
     ]
    }
   ],
   "source": [
    "# t = time.time()\n",
    "# sys.stderr.write('Convert neurotrace images to gray...')\n",
    "               \n",
    "# run_distributed(command='%(script_path)s %%(in_fn)s %%(out_fn)s'%\\\n",
    "#                     {'script_path': script_fp},\n",
    "#                     kwargs_list=[{'in_fn': os.path.join(in_dir, fn + '_lossless_alignedTo_' + anchor_fn + '_cropped_contrast_stretched.tif'),\n",
    "#                                 'out_fn': os.path.join(out_dir, fn + '_lossless_alignedTo_' + anchor_fn + '_cropped_contrast_stretched_blueasgray.tif')}\n",
    "# #                                 for fn in valid_filenames[first_idx_among_valid:last_idx_among_valid+1]\n",
    "#                                  for fn in valid_filenames[150:151]\n",
    "#                                 if fn.split('-')[1][0] == 'F'],\n",
    "#                     argument_type='single',\n",
    "#                    cluster_size=16)\n",
    "\n",
    "# wait_qsub_complete()\n",
    "\n",
    "# sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 2500 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Match intensity profile between Neurotrace Blue to Nissl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match intensity profile between Neurotrace and Nissl... rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "16 nodes available.\n",
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n",
      "qsub returned.\n",
      "Child returned 0\n",
      "16 nodes available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 2790.67252398 seconds\n",
      "Match intensity profile between Neurotrace and Nissl... rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n",
      "qsub returned.\n",
      "Child returned 0\n",
      "16 nodes available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 2554.21281099 seconds\n",
      "Match intensity profile between Neurotrace and Nissl... rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n",
      "qsub returned.\n",
      "Child returned 0\n",
      "16 nodes available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 2655.20303488 seconds\n",
      "Match intensity profile between Neurotrace and Nissl... rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 2363.96758008 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qsub returned.\n"
     ]
    }
   ],
   "source": [
    "# for stack in all_alt_nissl_ntb_stacks + all_alt_nissl_tracing_stacks:\n",
    "for stack in ['MD653', 'MD652', 'MD642', 'MD658']:\n",
    "\n",
    "#     download_from_s3(DataManager.get_sorted_filenames_filename(stack=stack))\n",
    "#     _, sections_to_filenames = DataManager.load_sorted_filenames(stack=stack)\n",
    "#     valid_filenames = [fn for fn in sections_to_filenames.values() if not is_invalid(fn=fn)]\n",
    "#     download_from_s3(DataManager.get_anchor_filename_filename(stack=stack))\n",
    "#     anchor_fn = DataManager.load_anchor_filename(stack=stack)\n",
    "#     download_from_s3(DataManager.get_cropbox_filename(stack=stack))\n",
    "#     xmin, xmax, ymin, ymax, first_sec, last_sec = DataManager.load_cropbox(stack=stack)\n",
    "#     w = xmax + 1 - xmin\n",
    "#     h = ymax + 1 - ymin\n",
    "#     x = xmin\n",
    "#     y = ymin\n",
    "#     first_fn = sections_to_filenames[first_sec]\n",
    "#     last_fn = sections_to_filenames[last_sec]\n",
    "#     first_idx_among_valid = valid_filenames.index(first_fn)\n",
    "#     last_idx_among_valid = valid_filenames.index(last_fn)\n",
    "    \n",
    "    #########################################################\n",
    "    \n",
    "    t = time.time()\n",
    "    print 'Match intensity profile between Neurotrace and Nissl...',\n",
    "    \n",
    "    filename_pairs = []\n",
    "    l = metadata_cache['valid_filenames'][stack]\n",
    "    for i, fn in enumerate(l):\n",
    "        if l[i].split('-')[1][0] == 'F':\n",
    "            for d in range(1, 99):\n",
    "                if i+d < len(l) and l[i+d].split('-')[1][0] == 'N':\n",
    "                    filename_pairs.append((l[i+d], l[i]))\n",
    "                    break\n",
    "                if i-d >= 0 and l[i-d].split('-')[1][0] == 'N':\n",
    "                    filename_pairs.append((l[i-d], l[i]))\n",
    "                    break\n",
    "    \n",
    "    script = os.path.join(REPO_DIR, 'preprocess', 'match_intensity_profile_v2.py')\n",
    "    \n",
    "    run_distributed(command='%(script_path)s %(stack)s \\'%%(filename_pairs)s\\' 100' % \\\n",
    "                    {'script_path': script,\n",
    "                    'stack': stack},\n",
    "#                     kwargs_list=dict(filename_pairs=filename_pairs[37:38]),\n",
    "                    kwargs_list=dict(filename_pairs=filename_pairs),\n",
    "                    argument_type='list2'\n",
    "                   )\n",
    "\n",
    "    wait_qsub_complete()\n",
    "\n",
    "    print 'done in', time.time() - t, 'seconds'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Convert Neurotrace images to grayscale (New, use nonlinear intensity mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "script_fp = os.path.join(REPO_DIR, 'preprocess', 'convert_grayscale_neurotrace_v2.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for fn in valid_filenames[first_idx_among_valid:last_idx_among_valid+1]:\n",
    "#     download_from_s3(DataManager.get_image_filepath(stack=stack, version='cropped', resol='lossless', fn=fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Convert neurotrace images to gray...Child returned 0\n",
      "16 nodes available.\n",
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n",
      "qsub returned.\n",
      "done in 1865.522785 seconds\n"
     ]
    }
   ],
   "source": [
    "# for stack in all_alt_nissl_ntb_stacks + all_alt_nissl_tracing_stacks:\n",
    "for stack in ['MD635']:\n",
    "    \n",
    "    output_dir = create_if_not_exists(DataManager.get_image_dir(stack=stack, version='cropped_gray', resol='lossless'));\n",
    "    ! rm -r {output_dir}\n",
    "\n",
    "    t = time.time()\n",
    "    sys.stderr.write('Convert neurotrace images to gray...')\n",
    "\n",
    "    run_distributed(command='DATA_DIR=/scrtatch %(script_path)s %(stack)s \\'%%(filenames)s\\''%\\\n",
    "                        {'script_path': script_fp, \n",
    "                        'stack': stack},\n",
    "                        kwargs_list={'filenames': \n",
    "                                     [fn for fn in metadata_cache['valid_filenames'][stack]\n",
    "                                      if fn.split('-')[1][0] == 'F']\n",
    "    #                                  ['MD657-F29-2017.02.18-01.04.58_MD657_1_0085']\n",
    "                                    },\n",
    "                        argument_type='list2')\n",
    "\n",
    "    wait_qsub_complete()\n",
    "\n",
    "    sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 1200 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# upload_to_s3(DataManager.get_image_dir(stack=stack, version='cropped_gray', resol='lossless'), is_dir=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2/3: Convert Neurotrace images to grayscale (linear intensity mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack = 'MD657'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# output_dir = create_if_not_exists(DataManager.get_image_dir(stack=stack, version='cropped_gray_linearNormalized', resol='lossless'));\n",
    "# ! rm -r {output_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "script_fp = os.path.join(REPO_DIR, 'preprocess', 'convert_grayscale_neurotrace_v2.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All nodes are ready.\n"
     ]
    }
   ],
   "source": [
    "request_compute_nodes(16, 'preprocesscluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "17 nodes available.\n",
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n",
      "qsub returned.\n"
     ]
    }
   ],
   "source": [
    "run_distributed('rm -rf /scratch/*', argument_type='single')\n",
    "wait_qsub_complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Convert neurotrace images to gray...Child returned 0\n",
      "16 nodes available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n",
      "qsub returned.\n",
      "done in 865.923385 seconds\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "sys.stderr.write('Convert neurotrace images to gray...')\n",
    "\n",
    "# for low in range(500, 3000, 500):\n",
    "for low in [500]:\n",
    "\n",
    "    run_distributed(command='ROOT_DIR=/scratch %(script_path)s %(stack)s \\'%%(filenames)s\\' -l %(low)d -H 0 -o %(output_version)d'%\\\n",
    "                        {'script_path': script_fp, \n",
    "                        'stack': stack,\n",
    "                        'low': low,\n",
    "                        'output_version': 'cropped_gray_linearNormalized' + str(low)},\n",
    "                        kwargs_list={'filenames': [fn for fn in metadata_cache['valid_filenames'][stack]\n",
    "                                                   if fn.split('-')[1][0] == 'F']},\n",
    "    #                     kwargs_list={'filenames': ['MD657-F28-2017.02.18-00.45.02_MD657_2_0083']},\n",
    "                        argument_type='list2',\n",
    "                   node_list=get_node_list())\n",
    "\n",
    "    wait_qsub_complete()\n",
    "\n",
    "    sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) \n",
    "    # /scratch, 133 jobs / 16 nodes: 850 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate JPEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD589/MD589_lossless_alignedTo_MD589-IHC31-2015.07.30-23.26.22_MD589_1_0091_cropped && mkdir -p /shared/CSHL_data_processed/MD589\n",
      "aws s3 cp --recursive s3://mousebrainatlas-data/CSHL_data_processed/MD589/MD589_lossless_alignedTo_MD589-IHC31-2015.07.30-23.26.22_MD589_1_0091_cropped /shared/CSHL_data_processed/MD589/MD589_lossless_alignedTo_MD589-IHC31-2015.07.30-23.26.22_MD589_1_0091_cropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "Child returned 0\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data_processed', stack, stack + '_lossless_alignedTo_' + anchor_fn + '_cropped'),\n",
    "                    from_hostname='s3',\n",
    "                    to_hostname='ec2',\n",
    "                    is_dir=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "script_fp = os.path.join(REPO_DIR, 'preprocess', 'generate_other_versions_v2.py')\n",
    "input_dir = os.path.join(DATA_DIR, stack, stack + '_lossless_alignedTo_' + anchor_fn + '_cropped')\n",
    "output_dir = os.path.join(DATA_DIR, stack, stack + '_lossless_alignedTo_' + anchor_fn + '_cropped_compressed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '/shared/CSHL_data_processed/MD658/MD658_lossless_alignedTo_MD658-N58-2017.03.31-19.59.31_MD658_2_0173_cropped_compressed/*': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "! rm -r {output_dir}/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating compressed image..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16 nodes requested, 18 nodes available...Continuing\n",
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "print 'Generating compressed image...',\n",
    "\n",
    "if stack in all_nissl_stacks:\n",
    "    \n",
    "    run_distributed('%(script)s %(stack)s %(input_dir)s \\'%%(input_filenames)s\\' --output_compressed_dir %(output_compressed_dir)s' % \\\n",
    "                dict(script=script_fp,\n",
    "                     stack=stack,\n",
    "                     input_dir=input_dir,\n",
    "                     output_compressed_dir=output_dir),\n",
    "                    kwargs_list={'input_filenames': \n",
    "                                 [fn + '_lossless_alignedTo_' + anchor_fn + '_cropped.tif' \n",
    "                                  for fn in valid_filenames[first_idx_among_valid:last_idx_among_valid+1]]},\n",
    "                    argument_type='list2',\n",
    "                    cluster_size=16,\n",
    "                   jobs_per_node=16)\n",
    "    \n",
    "else:\n",
    "    run_distributed('%(script)s %(stack)s %(input_dir)s \\'%%(input_filenames)s\\' --output_compressed_dir %(output_compressed_dir)s' % \\\n",
    "                    dict(script=script_fp,\n",
    "                         stack=stack,\n",
    "                         input_dir=input_dir,\n",
    "                         output_compressed_dir=output_dir),\n",
    "                        kwargs_list={'input_filenames': \n",
    "                                     [fn + '_lossless_alignedTo_' + anchor_fn + '_cropped.tif' \n",
    "                                      for fn in valid_filenames[first_idx_among_valid:last_idx_among_valid+1] \n",
    "                                      if fn.split('-')[1].startswith('N')]},\n",
    "                        argument_type='list2',\n",
    "                         cluster_size=16,\n",
    "                       jobs_per_node=16)\n",
    "\n",
    "wait_qsub_complete()\n",
    "    \n",
    "print 'done in', time.time() - t, 'seconds' # 765 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 cp --recursive /shared/CSHL_data_processed/MD658/MD658_lossless_alignedTo_MD658-N58-2017.03.31-19.59.31_MD658_2_0173_cropped_compressed s3://mousebrainatlas-data/CSHL_data_processed/MD658/MD658_lossless_alignedTo_MD658-N58-2017.03.31-19.59.31_MD658_2_0173_cropped_compressed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "36.94 seconds.\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data_processed', stack, stack + '_lossless_alignedTo_' + anchor_fn + '_cropped_compressed'),\n",
    "                    from_hostname='ec2',\n",
    "                    to_hostname='s3',\n",
    "                    is_dir=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate JPEG for neurotrace (obsolete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "script_fp = os.path.join(REPO_DIR, 'preprocess', 'generate_other_versions_v2.py')\n",
    "input_dir = os.path.join(DATA_DIR, stack, stack + '_lossless_alignedTo_' + anchor_fn + '_cropped_contrast_stretched')\n",
    "out_jpeg_dir = os.path.join(DATA_DIR, stack, stack + '_lossless_alignedTo_' + anchor_fn + '_cropped_compressed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating compressed image..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16 nodes requested, 18 nodes available...Continuing\n",
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "print 'Generating compressed image...',\n",
    "\n",
    "run_distributed('%(script)s %(stack)s %(input_dir)s \\'%%(input_filenames)s\\' --output_compressed_dir %(output_compressed_dir)s' % \\\n",
    "                dict(script=script_fp,\n",
    "                     stack=stack,\n",
    "                     input_dir=input_dir,\n",
    "                     output_compressed_dir=out_jpeg_dir),\n",
    "                    kwargs_list={'input_filenames': \n",
    "                                 [fn + '_lossless_alignedTo_' + anchor_fn + '_cropped_contrast_stretched.tif' \n",
    "                                  for fn in valid_filenames[first_idx_among_valid:last_idx_among_valid+1] \n",
    "                                  if fn.split('-')[1].startswith('F')]},\n",
    "                    argument_type='list2',\n",
    "                    cluster_size=16)\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "print 'done in', time.time() - t, 'seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " aws s3 cp --recursive /shared/CSHL_data_processed/MD658/MD658_lossless_alignedTo_MD658-N58-2017.03.31-19.59.31_MD658_2_0173_cropped_compressed s3://mousebrainatlas-data/CSHL_data_processed/MD658/MD658_lossless_alignedTo_MD658-N58-2017.03.31-19.59.31_MD658_2_0173_cropped_compressed --exclude \"*\" --include \"*contrast_stretched*.jpg\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "31.04 seconds.\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data_processed', stack, stack + '_lossless_alignedTo_' + anchor_fn + '_cropped_compressed'),\n",
    "                    from_hostname='ec2',\n",
    "                    to_hostname='s3',\n",
    "                    is_dir=True,\n",
    "                    include_only='*contrast_stretched*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# t = time.time()\n",
    "# print 'Generating saturation image...',\n",
    "\n",
    "# run_distributed4('%(script)s %(stack)s %(input_dir)s \\'%%(input_filenames)s\\' --output_saturation_dir %(output_saturation_dir)s' % \\\n",
    "#                 dict(script=script_fp,\n",
    "#                      stack=stack,\n",
    "#                      input_dir=input_dir,\n",
    "#                      output_saturation_dir=out_sat_dir,\n",
    "#                      kwargs_list={'input_filenames': [fn + '_lossless_alignedTo_' + anchor_fn + '_cropped.tif' for fn in filenames[first_idx:last_idx+1]]},\n",
    "#                     exclude_nodes=exclude_nodes,\n",
    "#                     argument_type='list2')\n",
    "\n",
    "# print 'done in', time.time() - t, 'seconds'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compress nissl gray and normalized fluorescent gray images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating compressed images... rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "16 nodes available.\n",
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "Child returned 0\n",
      "16 nodes available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 242.359697104 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qsub returned.\n"
     ]
    }
   ],
   "source": [
    "# for stack in all_alt_nissl_ntb_stacks + all_alt_nissl_tracing_stacks:\n",
    "for stack in ['MD635']:\n",
    "    \n",
    "    t = time.time()\n",
    "    print 'Generating compressed images...',\n",
    "\n",
    "    script_fp = os.path.join(REPO_DIR, 'preprocess', 'compress_as_jpeg.py')\n",
    "\n",
    "    run_distributed('rm -r /scratch/*', \n",
    "                    argument_type='single')\n",
    "\n",
    "    run_distributed('ROOT_DIR=/scratch/ %(script)s %%(input_fp)s %%(output_fp)s' % \\\n",
    "                    {'script': script_fp},\n",
    "#                     kwargs_list=[{'input_fp': DataManager.get_image_filepath(stack=stack, fn=fn, resol='lossless', version='cropped_gray', data_dir='/scratch/CSHL_data_processed'),\n",
    "#                                   'output_fp': DataManager.get_image_filepath(stack=stack, fn=fn, resol='lossless', version='cropped_gray_jpeg',data_dir='/scratch/CSHL_data_processed')}\n",
    "#                                  for fn in metadata_cache['valid_filenames'][stack]],\n",
    "                        kwargs_list=[{'input_fp': DataManager.get_image_filepath(stack=stack, fn=fn, resol='lossless', version='cropped_gray_linearNormalized', data_dir='/scratch/CSHL_data_processed'),\n",
    "                                  'output_fp': DataManager.get_image_filepath(stack=stack, fn=fn, resol='lossless', version='cropped_gray_linearNormalized_jpeg',data_dir='/scratch/CSHL_data_processed')}\n",
    "                                 for fn in metadata_cache['valid_filenames'][stack]],\n",
    "                        argument_type='single')\n",
    "\n",
    "    wait_qsub_complete()\n",
    "\n",
    "    print 'done in', time.time() - t, 'seconds' # for one stack 300 seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Aligned Masks (new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Download aligned thumbnails to local machine.\n",
    "- Run `mask_editing_gui.py`. Draw initial contours. Upload `init_snake_contours.pkl` to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD635/MD635_thumbnail_alignedTo_MD635-F63-2016.05.19-08.39.03_MD635_2_0188 && mkdir -p /shared/CSHL_data_processed/MD635\n",
      "aws s3 cp --recursive s3://mousebrainatlas-data/CSHL_data_processed/MD635/MD635_thumbnail_alignedTo_MD635-F63-2016.05.19-08.39.03_MD635_2_0188 /shared/CSHL_data_processed/MD635/MD635_thumbnail_alignedTo_MD635-F63-2016.05.19-08.39.03_MD635_2_0188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "Child returned 0\n",
      "4.34 seconds.\n"
     ]
    }
   ],
   "source": [
    "download_from_s3(DataManager.get_image_dir(stack=stack, version='aligned_tif', resol='thumbnail'), is_dir=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "script = os.path.join(REPO_DIR, 'preprocess', 'generate_thumbnail_masks_v5.py')\n",
    "\n",
    "output_dir = create_if_not_exists(DataManager.get_auto_submask_rootdir_filepath(stack=stack))\n",
    "! rm -rf {output_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD635/MD635_alignedTo_MD635-F63-2016.05.19-08.39.03_MD635_2_0188_init_snake_contours.pkl && mkdir -p /shared/CSHL_data_processed/MD635\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_data_processed/MD635/MD635_alignedTo_MD635-F63-2016.05.19-08.39.03_MD635_2_0188_init_snake_contours.pkl /shared/CSHL_data_processed/MD635/MD635_alignedTo_MD635-F63-2016.05.19-08.39.03_MD635_2_0188_init_snake_contours.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "Child returned 0\n",
      "0.52 seconds.\n"
     ]
    }
   ],
   "source": [
    "init_snake_contours_fp = DataManager.get_initial_snake_contours_filepath(stack=stack)\n",
    "download_from_s3(init_snake_contours_fp, redownload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating thumbnail mask... rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "16 nodes available.\n",
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 156.278020144 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qsub returned.\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "print 'Generating thumbnail mask...',\n",
    "\n",
    "run_distributed(command='%(script_path)s %(stack)s \\'%%(filenames)s\\' %(init_snake_contours_fp)s --min_size 500 --default_channel 1' % \\\n",
    "                {'script_path': script,\n",
    "                'stack': stack,\n",
    "                'init_snake_contours_fp': init_snake_contours_fp},\n",
    "                kwargs_list=dict(filenames=[fn for sec, fn in metadata_cache['sections_to_filenames'][stack].items() if not is_invalid(fn)]),\n",
    "                argument_type='list2')\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "print 'done in', time.time() - t, 'seconds' # 300s (aws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- download auto_submasks.\n",
    "- generate `userModified_submasks` and `masks`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "script = os.path.join(REPO_DIR, 'preprocess', 'generate_thumbnail_masks_v4.py')\n",
    "input_dir = os.path.join(RAW_DATA_DIR, stack)\n",
    "output_dir = create_if_not_exists(os.path.join(DATA_DIR, stack, stack + '_submasks'))\n",
    "! rm -f output_dir/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating thumbnail mask... Setting autoscaling group cfncluster-yuncongCluster-ComputeFleet-1LFRACYHLTNL8 capaticy to 16...it may take more than 5 minutes for SGE to know new hosts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Wait for SGE to know all nodes (timeout in 300 seconds)...\n",
      "All nodes are ready.\n",
      "16 nodes requested, 16 nodes available...Continuing\n",
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 403.646880865 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qsub returned.\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "print 'Generating thumbnail mask...',\n",
    "\n",
    "wait_num_nodes(16)\n",
    "\n",
    "run_distributed(command='%(script_path)s %(stack)s %(input_dir)s \\'%%(filenames)s\\' %(output_dir)s --border_dissim_percentile %(border_dissim_percentile)d --min_size %(min_size)d' % \\\n",
    "                {'script_path': script,\n",
    "                'stack': stack,\n",
    "                'input_dir': input_dir,\n",
    "                'output_dir': output_dir,\n",
    "                'border_dissim_percentile': DEFAULT_BORDER_DISSIMILARITY_PERCENTILE,\n",
    "                'min_size': DEFAULT_MINSIZE},\n",
    "                kwargs_list=dict(filenames=valid_filenames),\n",
    "                exclude_nodes=[33],\n",
    "                argument_type='list2',\n",
    "               cluster_size=16,\n",
    "               jobs_per_node=1)\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "print 'done in', time.time() - t, 'seconds' # 300s (aws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 cp --recursive /shared/CSHL_data_processed/MD594/MD594_submasks s3://mousebrainatlas-data/CSHL_data_processed/MD594/MD594_submasks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "3.72 seconds.\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(relative_to_ec2(output_dir),\n",
    "                    from_hostname='ec2',\n",
    "                    to_hostname='s3',\n",
    "                    is_dir=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- download `submasks/` to local machine\n",
    "- review them in GUI\n",
    "- generate `submasks_modified/`, `masks/`, `submasks_finalDecisions.txt`, upload to S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warp Thumbnail Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "script = os.path.join(REPO_DIR, 'preprocess', 'warp_crop_IM_v2.py')\n",
    "input_dir = os.path.join(DATA_DIR, stack, stack + '_masks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD594/MD594_masks && mkdir -p /shared/CSHL_data_processed/MD594\n",
      "aws s3 cp --recursive s3://mousebrainatlas-data/CSHL_data_processed/MD594/MD594_masks /shared/CSHL_data_processed/MD594/MD594_masks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "Child returned 0\n",
      "1.87 seconds.\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(relative_to_ec2(input_dir),\n",
    "                    from_hostname='s3',\n",
    "                    to_hostname='ec2',\n",
    "                    is_dir=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD658/MD658_alignedTo_MD658-N58-2017.03.31-19.59.31_MD658_2_0173_masks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n"
     ]
    }
   ],
   "source": [
    "output_dir = os.path.join(DATA_DIR, stack, stack + '_masks_alignedTo_' + anchor_fn)\n",
    "execute_command('rm -rf ' + output_dir)\n",
    "\n",
    "transforms_to_anchor = load_pickle(DataManager.get_transforms_filename(stack=stack))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warping thumbnail mask... Setting autoscaling group cfncluster-yuncongCluster-ComputeFleet-1LFRACYHLTNL8 capaticy to 16...it may take more than 5 minutes for SGE to know new hosts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16 nodes requested, 1 nodes available...Continuing\n",
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 76.2961359024 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qsub returned.\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "print 'warping thumbnail mask...',\n",
    "\n",
    "run_distributed('%(script)s %(stack)s %(input_dir)s %(output_dir)s %%(transform)s %%(filename)s %%(output_fn)s thumbnail 0 0 2000 1500 black' % \\\n",
    "                {'script': script,\n",
    "                'stack': stack,\n",
    "                'input_dir': input_dir,\n",
    "                'output_dir': output_dir},\n",
    "                kwargs_list=[{'transform': ','.join(map(str, transforms_to_anchor[fn].flatten())),\n",
    "                            'filename': fn + '_mask.png',\n",
    "                            'output_fn': fn + '_mask_alignedTo_' + anchor_fn + '.png'}\n",
    "                            for fn in valid_filenames],\n",
    "                argument_type='single',\n",
    "               cluster_size=16,\n",
    "               jobs_per_node=16)\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "print 'done in', time.time() - t, 'seconds' # 20 seconds (aws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 cp --recursive /shared/CSHL_data_processed/MD594/MD594_masks_alignedTo_MD594-IHC58-2015.08.26-18.48.50_MD594_1_0172 s3://mousebrainatlas-data/CSHL_data_processed/MD594/MD594_masks_alignedTo_MD594-IHC58-2015.08.26-18.48.50_MD594_1_0172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "3.42 seconds.\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(relative_to_ec2(output_dir),\n",
    "                    from_hostname='ec2',\n",
    "                    to_hostname='s3',\n",
    "                    is_dir=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop Thumbnail Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack = 'MD658'\n",
    "\n",
    "# download_from_s3(DataManager.get_sorted_filenames_filename(stack=stack))\n",
    "# _, sections_to_filenames = DataManager.load_sorted_filenames(stack=stack)\n",
    "# valid_filenames = [fn for fn in sections_to_filenames.values() if not is_invalid(fn=fn)]\n",
    "# download_from_s3(DataManager.get_anchor_filename_filename(stack=stack))\n",
    "# anchor_fn = DataManager.load_anchor_filename(stack=stack)\n",
    "# download_from_s3(DataManager.get_cropbox_filename(stack=stack))\n",
    "xmin, xmax, ymin, ymax, first_sec, last_sec = DataManager.load_cropbox(stack=stack)\n",
    "# w = xmax + 1 - xmin\n",
    "# h = ymax + 1 - ymin\n",
    "# x = xmin\n",
    "# y = ymin\n",
    "# first_fn = sections_to_filenames[first_sec]\n",
    "# last_fn = sections_to_filenames[last_sec]\n",
    "# first_idx_among_valid = valid_filenames.index(first_fn)\n",
    "# last_idx_among_valid = valid_filenames.index(last_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack = 'MD635'\n",
    "xmin, xmax, ymin, ymax, _, _ = DataManager.load_cropbox(stack=stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD635/MD635_alignedTo_MD635-F63-2016.05.19-08.39.03_MD635_2_0188_masks && mkdir -p /shared/CSHL_data_processed/MD635\n",
      "aws s3 cp --recursive s3://mousebrainatlas-data/CSHL_data_processed/MD635/MD635_alignedTo_MD635-F63-2016.05.19-08.39.03_MD635_2_0188_masks /shared/CSHL_data_processed/MD635/MD635_alignedTo_MD635-F63-2016.05.19-08.39.03_MD635_2_0188_masks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD635/MD635_alignedTo_MD635-F63-2016.05.19-08.39.03_MD635_2_0188_masks_cropped\n",
      "mkdir -p /shared/CSHL_data_processed/MD635/MD635_alignedTo_MD635-F63-2016.05.19-08.39.03_MD635_2_0188_masks_cropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "2.03 seconds.\n",
      "Child returned 0\n",
      "Child returned 0\n"
     ]
    }
   ],
   "source": [
    "input_dir = DataManager.get_thumbnail_mask_dir_v3(stack=stack, version='aligned')\n",
    "download_from_s3(input_dir, is_dir=True)\n",
    "\n",
    "output_dir = DataManager.get_thumbnail_mask_dir_v3(stack=stack, version='aligned_cropped')\n",
    "\n",
    "execute_command('rm -rf ' + output_dir);\n",
    "execute_command('mkdir -p ' + output_dir);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cropping thumbnail mask..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mogrify -set filename:name %t -crop 685x448+659+308 -write \"/shared/CSHL_data_processed/MD635/MD635_alignedTo_MD635-F63-2016.05.19-08.39.03_MD635_2_0188_masks_cropped/%[filename:name]_cropped.png\" /shared/CSHL_data_processed/MD635/MD635_alignedTo_MD635-F63-2016.05.19-08.39.03_MD635_2_0188_masks/*.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "done in 18.053840 seconds\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "sys.stderr.write('cropping thumbnail mask...')\n",
    "\n",
    "execute_command('mogrify -set filename:name %%t -crop %(w)dx%(h)d+%(x)d+%(y)d -write \"%(output_dir)s/%%[filename:name]_cropped.png\" %(input_dir)s/*.png' % \\\n",
    "    {'stack': stack,\n",
    "    'input_dir': input_dir,\n",
    "    'output_dir': output_dir,\n",
    "    'w':xmax+1-xmin, 'h':ymax+1-ymin, 'x':xmin, 'y':ymin})\n",
    "\n",
    "sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 70s (aws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 cp --recursive /shared/CSHL_data_processed/MD635/MD635_alignedTo_MD635-F63-2016.05.19-08.39.03_MD635_2_0188_masks_cropped s3://mousebrainatlas-data/CSHL_data_processed/MD635/MD635_alignedTo_MD635-F63-2016.05.19-08.39.03_MD635_2_0188_masks_cropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "2.25 seconds.\n"
     ]
    }
   ],
   "source": [
    "upload_to_s3(output_dir, is_dir=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- Run `extract_test_features_cnn.ipynb` on workstation.\n",
    "- Upload to extracted features to S3.\n",
    "- Continue with `learning/pipeline_aws.ipynb`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
