{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "rm -rf /shared/CSHL_data_processed/MD661/MD661_sorted_filenames.txt && mkdir -p /shared/CSHL_data_processed/MD661\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_data_processed/MD661/MD661_sorted_filenames.txt /shared/CSHL_data_processed/MD661/MD661_sorted_filenames.txt\n",
      "rm -rf /shared/CSHL_data_processed/MD661/MD661_anchor.txt && mkdir -p /shared/CSHL_data_processed/MD661\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_data_processed/MD661/MD661_anchor.txt /shared/CSHL_data_processed/MD661/MD661_anchor.txt\n",
      "rm -rf /shared/CSHL_data_processed/MD661/MD661_anchor.txt && mkdir -p /shared/CSHL_data_processed/MD661\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_data_processed/MD661/MD661_anchor.txt /shared/CSHL_data_processed/MD661/MD661_anchor.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File does not exist: /shared/CSHL_data_processed/MD661/MD661_anchor.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD662/MD662_sorted_filenames.txt && mkdir -p /shared/CSHL_data_processed/MD662\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_data_processed/MD662/MD662_sorted_filenames.txt /shared/CSHL_data_processed/MD662/MD662_sorted_filenames.txt\n",
      "rm -rf /shared/CSHL_data_processed/MD662/MD662_anchor.txt && mkdir -p /shared/CSHL_data_processed/MD662\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_data_processed/MD662/MD662_anchor.txt /shared/CSHL_data_processed/MD662/MD662_anchor.txt\n",
      "rm -rf /shared/CSHL_data_processed/MD662/MD662_anchor.txt && mkdir -p /shared/CSHL_data_processed/MD662\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_data_processed/MD662/MD662_anchor.txt /shared/CSHL_data_processed/MD662/MD662_anchor.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File does not exist: /shared/CSHL_data_processed/MD662/MD662_anchor.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD661/MD661_anchor.txt && mkdir -p /shared/CSHL_data_processed/MD661\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_data_processed/MD661/MD661_anchor.txt /shared/CSHL_data_processed/MD661/MD661_anchor.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File does not exist: /shared/CSHL_data_processed/MD661/MD661_anchor.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD661/MD661_anchor.txt && mkdir -p /shared/CSHL_data_processed/MD661\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_data_processed/MD661/MD661_anchor.txt /shared/CSHL_data_processed/MD661/MD661_anchor.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File does not exist: /shared/CSHL_data_processed/MD661/MD661_anchor.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD661/MD661_sorted_filenames.txt && mkdir -p /shared/CSHL_data_processed/MD661\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_data_processed/MD661/MD661_sorted_filenames.txt /shared/CSHL_data_processed/MD661/MD661_sorted_filenames.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File does not exist: /shared/CSHL_data_processed/MD661/MD661_sorted_filenames.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD661/MD661_sorted_filenames.txt && mkdir -p /shared/CSHL_data_processed/MD661\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_data_processed/MD661/MD661_sorted_filenames.txt /shared/CSHL_data_processed/MD661/MD661_sorted_filenames.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File does not exist: /shared/CSHL_data_processed/MD661/MD661_sorted_filenames.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD661/MD661_anchor.txt && mkdir -p /shared/CSHL_data_processed/MD661\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_data_processed/MD661/MD661_anchor.txt /shared/CSHL_data_processed/MD661/MD661_anchor.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File does not exist: /shared/CSHL_data_processed/MD661/MD661_anchor.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD661/MD661_anchor.txt && mkdir -p /shared/CSHL_data_processed/MD661\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_data_processed/MD661/MD661_anchor.txt /shared/CSHL_data_processed/MD661/MD661_anchor.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File does not exist: /shared/CSHL_data_processed/MD661/MD661_anchor.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD662/MD662_anchor.txt && mkdir -p /shared/CSHL_data_processed/MD662\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_data_processed/MD662/MD662_anchor.txt /shared/CSHL_data_processed/MD662/MD662_anchor.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File does not exist: /shared/CSHL_data_processed/MD662/MD662_anchor.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD662/MD662_anchor.txt && mkdir -p /shared/CSHL_data_processed/MD662\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_data_processed/MD662/MD662_anchor.txt /shared/CSHL_data_processed/MD662/MD662_anchor.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File does not exist: /shared/CSHL_data_processed/MD662/MD662_anchor.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD662/MD662_sorted_filenames.txt && mkdir -p /shared/CSHL_data_processed/MD662\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_data_processed/MD662/MD662_sorted_filenames.txt /shared/CSHL_data_processed/MD662/MD662_sorted_filenames.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File does not exist: /shared/CSHL_data_processed/MD662/MD662_sorted_filenames.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD662/MD662_sorted_filenames.txt && mkdir -p /shared/CSHL_data_processed/MD662\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_data_processed/MD662/MD662_sorted_filenames.txt /shared/CSHL_data_processed/MD662/MD662_sorted_filenames.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File does not exist: /shared/CSHL_data_processed/MD662/MD662_sorted_filenames.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD662/MD662_anchor.txt && mkdir -p /shared/CSHL_data_processed/MD662\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_data_processed/MD662/MD662_anchor.txt /shared/CSHL_data_processed/MD662/MD662_anchor.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File does not exist: /shared/CSHL_data_processed/MD662/MD662_anchor.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD662/MD662_anchor.txt && mkdir -p /shared/CSHL_data_processed/MD662\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_data_processed/MD662/MD662_anchor.txt /shared/CSHL_data_processed/MD662/MD662_anchor.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File does not exist: /shared/CSHL_data_processed/MD662/MD662_anchor.txt\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.join(os.environ['REPO_DIR'], 'utilities'))\n",
    "from utilities2015 import *\n",
    "from metadata import *\n",
    "from data_manager import *\n",
    "from distributed_utilities import *\n",
    "from preprocess_utilities import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After receiving data of a new stack, put images and macros in corresponding folder.\n",
    "- Add the stack name to proper variables in `metadata.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack = 'MD661'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tb_fmt = 'png'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use GUI, quality check and sort images.\n",
    "- Upload `sorted_filenames.txt` to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 cp --recursive s3://mousebrainatlas-rawdata/CSHL_data/MD661 /shared/CSHL_data/MD661 --exclude \"*\" --include \"*.png\"\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data', stack), \n",
    "                     from_hostname='s3raw', to_hostname='ec2', is_dir=True, include_only='*.'+tb_fmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD661/MD661_sorted_filenames.txt && mkdir -p /shared/CSHL_data_processed/MD661\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_data_processed/MD661/MD661_sorted_filenames.txt /shared/CSHL_data_processed/MD661/MD661_sorted_filenames.txt\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data_processed', stack, stack + '_sorted_filenames.txt'), \n",
    "                     from_hostname='s3', to_hostname='ec2', is_dir=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ! rm /shared/CSHL_data_processed/MD661/MD661_sorted_filenames.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_, sections_to_filenames = DataManager.load_sorted_filenames(stack=stack) \n",
    "# Note that this could be the human-corrected version, in which case the transforms may not exist.\n",
    "valid_filenames = [fn for fn in sections_to_filenames.values() if not is_invalid(fn=fn)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "script = os.path.join(REPO_DIR, 'preprocess', 'align_consecutive_v2.py')\n",
    "input_dir = os.path.join(RAW_DATA_DIR, stack)\n",
    "output_dir = create_if_not_exists(os.path.join(DATA_DIR, stack, stack + '_elastix_output'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! rm -r {output_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Align...\n",
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16 nodes available.\n",
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 80.5405077934 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qsub returned.\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "print 'Align...'\n",
    "\n",
    "run_distributed(\"%(script)s %(stack)s \\\"%(input_dir)s\\\" \\\"%(output_dir)s\\\" \\'%%(kwargs_str)s\\' %(fmt)s\" % \\\n",
    "                {'script': script,\n",
    "                'stack': stack,\n",
    "                'input_dir': input_dir,\n",
    "                'output_dir': output_dir,\n",
    "                'fmt': tb_fmt},\n",
    "                kwargs_list=[{'prev_fn': valid_filenames[i-1], 'curr_fn': valid_filenames[i]} \n",
    "                             for i in range(1, len(valid_filenames))],\n",
    "                argument_type='list',\n",
    "               jobs_per_node=16)\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "print 'done in', time.time() - t, 'seconds' # 252 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 cp --recursive \"/shared/CSHL_data_processed/MD661/MD661_elastix_output\" \"s3://mousebrainatlas-data/CSHL_data_processed/MD661/MD661_elastix_output\"\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data_processed', stack, stack + '_elastix_output'), \n",
    "                     from_hostname='ec2', to_hostname='s3', is_dir=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check final metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "final_metric = {}\n",
    "for i in range(1, len(valid_filenames)):\n",
    "    prev_fn = valid_filenames[i-1]\n",
    "    curr_fn = valid_filenames[i]\n",
    "    with open(os.path.join(output_dir, curr_fn + '_to_' + prev_fn, 'elastix.log'), 'r') as f:\n",
    "        t = f.read()\n",
    "        g = re.search(\"Final metric value  = (.*?)\\n\", t)\n",
    "#         final_metric[(curr_fn, prev_fn)] = -float(g.groups()[0])\n",
    "        final_metric[i] = float(g.groups()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJsAAACqCAYAAAAKnk4GAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncGsPSB4qAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f87a4ab1d50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "metric_arr = np.array(final_metric.values())\n",
    "plt.figure(figsize=(20,2));\n",
    "plt.ylim([-1, metric_arr.max()+.1]);\n",
    "plt.stem(metric_arr);\n",
    "plt.title('Mutual information of pairwise registration');\n",
    "plt.yticks(np.arange(-1, metric_arr.max()+.1, 0.1));\n",
    "plt.xlabel('Image index');\n",
    "plt.ylabel('Mutual info');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worst pair: MD662&661-F136-2017.06.07-22.02.11_MD661_1_0406\n"
     ]
    }
   ],
   "source": [
    "print 'worst pair:', valid_filenames[np.argmin(final_metric.values())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- download `elastix_output/` to local machine, edit consecutive transforms in local GUI, generate `custom_transforms/` to S3, upload to S3.\n",
    "- determine anchor image, upload `anchor.txt` to S3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compose consecutive transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf \"/shared/CSHL_data_processed/MD661/MD661_elastix_output\" && mkdir -p \"/shared/CSHL_data_processed/MD661\"\n",
      "aws s3 cp --recursive \"s3://mousebrainatlas-data/CSHL_data_processed/MD661/MD661_elastix_output\" \"/shared/CSHL_data_processed/MD661/MD661_elastix_output\"\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data_processed', stack, stack + '_elastix_output'), \n",
    "                     from_hostname='s3', to_hostname='ec2', is_dir=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD661/MD661_custom_transforms && mkdir -p /shared/CSHL_data_processed/MD661\n",
      "aws s3 cp --recursive s3://mousebrainatlas-data/CSHL_data_processed/MD661/MD661_custom_transforms /shared/CSHL_data_processed/MD661/MD661_custom_transforms\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data_processed', stack, stack + '_custom_transforms'), \n",
    "                     from_hostname='s3', to_hostname='ec2', is_dir=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD661/MD661_anchor.txt && mkdir -p /shared/CSHL_data_processed/MD661\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_data_processed/MD661/MD661_anchor.txt /shared/CSHL_data_processed/MD661/MD661_anchor.txt\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data_processed', stack, stack + '_anchor.txt'), \n",
    "                     from_hostname='s3', to_hostname='ec2', is_dir=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "anchor_fn = DataManager.load_anchor_filename(stack=stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "script = os.path.join(REPO_DIR, 'preprocess', 'compose_transform_thumbnail_v2.py')\n",
    "input_dir = os.path.join(DATA_DIR, stack, stack + '_elastix_output')\n",
    "output_fn = os.path.join(DATA_DIR, stack, '%(stack)s_transformsTo_%(anchor_fn)s.pkl' % \\\n",
    "                                                dict(stack=stack, anchor_fn=anchor_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -f \"{output_fn}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Composing transform...\n",
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16 nodes available.\n",
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 5.07249498367 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qsub returned.\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "print 'Composing transform...'\n",
    "\n",
    "run_distributed(\"%(script)s %(stack)s \\\"%(input_dir)s\\\" \\'%%(kwargs_str)s\\' %(anchor_idx)d \\\"%(output_fn)s\\\"\" % \\\n",
    "            {'stack': stack,\n",
    "            'script': script,\n",
    "            'input_dir': input_dir,\n",
    "            'anchor_idx': valid_filenames.index(anchor_fn),\n",
    "            'output_fn': output_fn},\n",
    "            kwargs_list=[{'filenames': valid_filenames}],\n",
    "            argument_type='list')\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "print 'done in', time.time() - t, 'seconds' # 20 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 cp --recursive \"/shared/CSHL_data_processed/MD661\" \"s3://mousebrainatlas-data/CSHL_data_processed/MD661\" --exclude \"*\" --include \"*.pkl\"\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data_processed', stack), \n",
    "                     from_hostname='ec2', to_hostname='s3', is_dir=True, include_only='*.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 cp --recursive s3://mousebrainatlas-data/CSHL_data_processed/MD661 /shared/CSHL_data_processed/MD661 --exclude \"*\" --include \"*.pkl\"\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data_processed', stack), \n",
    "                     from_hostname='s3', to_hostname='ec2', is_dir=True, include_only='*.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if stack in all_nissl_stacks:\n",
    "    pad_bg_color = 'white'\n",
    "else:\n",
    "    pad_bg_color = 'auto'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prep_id = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_dir = os.path.join(RAW_DATA_DIR, stack)\n",
    "out_dir = DataManager.get_image_dir_v2(stack=stack, prep_id=prep_id, resol='thumbnail')\n",
    "script = os.path.join(REPO_DIR, 'preprocess', 'warp_crop_IM_v2.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -rf {out_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warping...\n",
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16 nodes available.\n",
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 289.224753857 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qsub returned.\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "print 'Warping...'\n",
    "\n",
    "transforms_to_anchor = DataManager.load_transforms(stack=stack, downsample_factor=32, \n",
    "                                                   use_inverse=False, anchor_fn=anchor_fn)\n",
    "\n",
    "if pad_bg_color == 'auto':\n",
    "    run_distributed('%(script)s %(stack)s \\\"%(input_dir)s\\\" \\\"%(out_dir)s\\\" %%(transform)s \\\"%%(filename)s\\\" \\\"%%(output_fn)s\\\" thumbnail 0 0 2000 1500 %%(pad_bg_color)s' % \\\n",
    "                    {'script': script,\n",
    "                    'stack': stack,\n",
    "                    'input_dir': input_dir,\n",
    "                    'out_dir': out_dir\n",
    "                    },\n",
    "                    kwargs_list=[{'transform': ','.join(map(str, transforms_to_anchor[fn].flatten())),\n",
    "                                'filename': fn + '.' + tb_fmt,\n",
    "                                  'output_fn': fn + '_prep' + str(prep_id) + '_thumbnail' + '.tif',\n",
    "                                'pad_bg_color': 'black' if fn.split('-')[1][0] == 'F' else 'white'}\n",
    "                                for fn in valid_filenames],\n",
    "                    argument_type='single',\n",
    "                   jobs_per_node=8)\n",
    "else:\n",
    "    run_distributed('%(script)s %(stack)s \\\"%(input_dir)s\\\" \\\"%(out_dir)s\\\" %%(transform)s \\\"%%(filename)s\\\" \\\"%%(output_fn)s\\\" thumbnail 0 0 2000 1500 %(pad_bg_color)s' % \\\n",
    "                    {'script': script,\n",
    "                    'stack': stack,\n",
    "                    'input_dir': input_dir,\n",
    "                    'out_dir': out_dir,\n",
    "                    'pad_bg_color': pad_bg_color},\n",
    "                    kwargs_list=[{'transform': ','.join(map(str, transforms_to_anchor[fn].flatten())),\n",
    "                                'filename': fn + '.' + tb_fmt,\n",
    "                                  'output_fn': fn + '_prep' + str(prep_id) + '_thumbnail' + '.tif'}\n",
    "                                for fn in valid_filenames],\n",
    "                    argument_type='single',\n",
    "                   jobs_per_node=8)\n",
    "\n",
    "wait_qsub_complete()\n",
    "    \n",
    "print 'done in', time.time() - t, 'seconds' # 300 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 cp --recursive \"/shared/CSHL_data_processed/MD661/MD661_prep1_thumbnail\" \"s3://mousebrainatlas-data/CSHL_data_processed/MD661/MD661_prep1_thumbnail\"\n"
     ]
    }
   ],
   "source": [
    "upload_to_s3(out_dir, is_dir=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Download aligned images to local. In GUI, check alignment correctness.\n",
    "- Place cropbox. Upload `cropbox.txt` to S3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (Recommended) Run `reconstruct/construct_thumbnail_volume_v3.ipynb` notebook. Check the smoothness of virtual re-sectioning in brain labeling gui."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf \"/shared/CSHL_data_processed/MD661/MD661_alignedTo_MD662&661-F116-2017.06.07-04.39.41_MD661_1_0346_cropbox.txt\" && mkdir -p \"/shared/CSHL_data_processed/MD661\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_data_processed/MD661/MD661_alignedTo_MD662&661-F116-2017.06.07-04.39.41_MD661_1_0346_cropbox.txt\" \"/shared/CSHL_data_processed/MD661/MD661_alignedTo_MD662&661-F116-2017.06.07-04.39.41_MD661_1_0346_cropbox.txt\"\n"
     ]
    }
   ],
   "source": [
    "download_from_s3(DataManager.get_cropbox_filename(stack), redownload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xmin, xmax, ymin, ymax, first_sec, last_sec = DataManager.load_cropbox(stack=stack)\n",
    "w = xmax + 1 - xmin\n",
    "h = ymax + 1 - ymin\n",
    "x = xmin\n",
    "y = ymin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first_fn = sections_to_filenames[first_sec]\n",
    "# last_fn = sections_to_filenames[last_sec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first_idx_among_valid = valid_filenames.index(first_fn)\n",
    "# last_idx_among_valid = valid_filenames.index(last_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop Thumbnail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir -p /shared/CSHL_data_processed/MD661/MD661_prep2_thumbnail\n"
     ]
    }
   ],
   "source": [
    "# input_dir = os.path.join(DATA_DIR, stack, \"%(stack)s_thumbnail_alignedTo_%(anchor_fn)s\" % \\\n",
    "#                            {'stack': stack, 'anchor_fn': anchor_fn})\n",
    "\n",
    "# output_dir = os.path.join(DATA_DIR, stack, \"%(stack)s_thumbnail_alignedTo_%(anchor_fn)s_cropped\" % \\\n",
    "#                            {'stack': stack, 'anchor_fn': anchor_fn})\n",
    "\n",
    "input_dir = DataManager.get_image_dir_v2(stack=stack, prep_id=1, resol='thumbnail')\n",
    "download_from_s3(input_dir, is_dir=True)\n",
    "\n",
    "output_dir = DataManager.get_image_dir_v2(stack=stack, prep_id=2, resol='thumbnail')\n",
    "\n",
    "execute_command('mkdir -p ' + output_dir);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cropping thumbnail..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mogrify -set filename:name %t -crop 777x492+468+129 -write \"/shared/CSHL_data_processed/MD661/MD661_prep2_thumbnail/%[filename:name]_cropped.tif\" /shared/CSHL_data_processed/MD661/MD661_prep1_thumbnail/*.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done in 37.457080 seconds\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "sys.stderr.write('cropping thumbnail...')\n",
    "\n",
    "execute_command('mogrify -set filename:name %%t -crop %(w)dx%(h)d+%(x)d+%(y)d -write \"%(output_dir)s/%%[filename:name]_cropped.tif\" %(input_dir)s/*.tif' % \\\n",
    "    {'input_dir': input_dir,\n",
    "     'output_dir': output_dir,\n",
    "    'w':w, 'h':h, 'x':x, 'y':y})\n",
    "\n",
    "sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 100 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 cp --recursive \"/shared/CSHL_data_processed/MD661/MD661_prep2_thumbnail\" \"s3://mousebrainatlas-data/CSHL_data_processed/MD661/MD661_prep2_thumbnail\"\n"
     ]
    }
   ],
   "source": [
    "upload_to_s3(output_dir, is_dir=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transfer_data_synced(os.path.join('CSHL_data_processed', stack, stack + '_thumbnail_alignedTo_' + anchor_fn + '_cropped'),\n",
    "#                     from_hostname='ec2',\n",
    "#                     to_hostname='s3',\n",
    "#                     is_dir=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expand lossless JP2 (use /shared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack = 'MD661'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 cp --recursive \"s3://mousebrainatlas-rawdata/CSHL_data/MD661\" \"/shared/CSHL_data/MD661\" --exclude \"*\" --include \"*_lossless.jp2\"\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data', stack),\n",
    "                    from_hostname='s3raw',\n",
    "                    to_hostname='ec2',\n",
    "                    is_dir=True,\n",
    "                    include_only='*_lossless.jp2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_dir = create_if_not_exists(DataManager.get_image_dir_v2(stack=stack, prep_id=1, resol='lossless'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "sys.stderr.write('expanding...')\n",
    "\n",
    "in_fps = [fn + '_lossless.jp2' for fn in metadata_cache['valid_filenames'][stack]]\n",
    "out_fps = [DataManager.get_image_filepath_v2(stack=stack, prep_id=1, resol='lossless', fn=fn) \n",
    "           for fn in metadata_cache['valid_filenames'][stack]]\n",
    "\n",
    "run_distributed('export LD_LIBRARY_PATH=/home/ubuntu/KDU79_Demo_Apps_for_Linux-x86-64_170108:$LD_LIBRARY_PATH; %(kdu_bin)s -i \\\"%%(in_fp)s\\\" -o \\\"%%(out_fp)s\\\"' % \\\n",
    "                {'kdu_bin': KDU_EXPAND_BIN},\n",
    "                kwargs_list={'in_fp': in_fps, 'out_fp': out_fps},\n",
    "                argument_type='single',\n",
    "               cluster_size=16)\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 900 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data_processed', stack, stack + '_lossless_tif'),\n",
    "                    from_hostname='ec2',\n",
    "                    to_hostname='s3',\n",
    "                    is_dir=True) # 6000s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warping and cropping lossless (use /shared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD585/MD585_lossless_tif && mkdir -p /shared/CSHL_data_processed/MD585\n",
      "aws s3 cp --recursive s3://mousebrainatlas-data/CSHL_data_processed/MD585/MD585_lossless_tif /shared/CSHL_data_processed/MD585/MD585_lossless_tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3079.07781506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "3079.08 seconds.\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data_processed', stack, stack + '_lossless_tif'),\n",
    "                    from_hostname='s3',\n",
    "                    to_hostname='ec2',\n",
    "                    is_dir=True)\n",
    "# 3000 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf_filepath = os.path.join(DATA_DIR, stack, '%(stack)s_transformsTo_anchor.pkl' % {'stack':stack})\n",
    "# tfs = pickle.load(open(tf_filepath, 'r'))\n",
    "# Note that the index from trasform pickle file starts at 0, BUT the .._renamed folder index starts at 1.#\n",
    "\n",
    "tfs = DataManager.load_transforms(stack=stack)\n",
    "\n",
    "lossless_tif_dir = os.path.join(DATA_DIR, stack, stack + '_lossless_tif')\n",
    "lossless_aligned_cropped_dir = os.path.join(DATA_DIR, stack, stack + '_lossless_alignedTo_' + anchor_fn + '_cropped')\n",
    "\n",
    "script_fp = os.path.join(REPO_DIR, 'preprocess', 'warp_crop_IM_v2.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! rm -r {lossless_aligned_cropped_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if stack in all_nissl_stacks:\n",
    "    pad_bg_color = 'white'\n",
    "else:\n",
    "    pad_bg_color = 'auto'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "sys.stderr.write('warping and cropping lossless...')\n",
    "\n",
    "# wait_num_nodes(16)\n",
    "                   \n",
    "if pad_bg_color == 'auto':\n",
    "    # If alternating, then black padding for F sections, white padding for N sections.\n",
    "    run_distributed(command='%(script_path)s %(stack)s %(lossless_tif_dir)s %(lossless_aligned_cropped_dir)s %%(transform)s %%(filename)s %%(output_fn)s lossless %(x)d %(y)d %(w)d %(h)d %%(pad_bg_color)s'%\\\n",
    "                    {'script_path': script_fp,\n",
    "                    'stack': stack,\n",
    "                    'lossless_tif_dir': lossless_tif_dir,\n",
    "                    'lossless_aligned_cropped_dir': lossless_aligned_cropped_dir,\n",
    "                    'x': x,\n",
    "                    'y': y,\n",
    "                    'w': w,\n",
    "                    'h': h},\n",
    "                    kwargs_list=[{'transform': ','.join(map(str, tfs[fn].flatten())),\n",
    "                                'filename': fn + '_lossless.tif',\n",
    "                                'output_fn': fn + '_lossless_alignedTo_' + anchor_fn + '_cropped.tif',\n",
    "                                'pad_bg_color': 'black' if fn.split('-')[1][0] == 'F' else 'white'}\n",
    "                                for fn in valid_filenames[first_idx_among_valid:last_idx_among_valid+1]],\n",
    "#                                  for fn in valid_filenames[first_idx_among_valid:first_idx_among_valid+16]],\n",
    "                    argument_type='single',\n",
    "                   cluster_size=16,\n",
    "                   jobs_per_node=4)\n",
    "else:\n",
    "    run_distributed(command='%(script_path)s %(stack)s %(lossless_tif_dir)s %(lossless_aligned_cropped_dir)s %%(transform)s %%(filename)s %%(output_fn)s lossless %(x)d %(y)d %(w)d %(h)d %(pad_bg_color)s'%\\\n",
    "                    {'script_path': script_fp,\n",
    "                    'stack': stack,\n",
    "                    'lossless_tif_dir': lossless_tif_dir,\n",
    "                    'lossless_aligned_cropped_dir': lossless_aligned_cropped_dir,\n",
    "                    'x': x,\n",
    "                    'y': y,\n",
    "                    'w': w,\n",
    "                    'h': h,\n",
    "                    'pad_bg_color': pad_bg_color},\n",
    "                    kwargs_list=[{'transform': ','.join(map(str, tfs[fn].flatten())),\n",
    "                                'filename': fn + '_lossless.tif',\n",
    "                                'output_fn': fn + '_lossless_alignedTo_' + anchor_fn + '_cropped.tif'}\n",
    "                                for fn in valid_filenames[first_idx_among_valid:last_idx_among_valid+1]],\n",
    "#                                  for fn in valid_filenames[first_idx_among_valid:first_idx_among_valid+16]],\n",
    "                    argument_type='single',\n",
    "                   cluster_size=16,\n",
    "                   jobs_per_node=4)\n",
    "\n",
    "wait_qsub_complete()\n",
    "    \n",
    "sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 4140 seconds (AWS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 cp --recursive /shared/CSHL_data_processed/MD658/MD658_lossless_alignedTo_MD658-N58-2017.03.31-19.59.31_MD658_2_0173_cropped s3://mousebrainatlas-data/CSHL_data_processed/MD658/MD658_lossless_alignedTo_MD658-N58-2017.03.31-19.59.31_MD658_2_0173_cropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "1064.17 seconds.\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data_processed', stack, stack + '_lossless_alignedTo_' + anchor_fn + '_cropped'),\n",
    "                    from_hostname='ec2',\n",
    "                    to_hostname='s3',\n",
    "                    is_dir=True) \n",
    "# 512 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expand and Crop together (use /scratch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack = 'MD661'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfs = DataManager.load_transforms(stack=stack, downsample_factor=32, use_inverse=False)\n",
    "xmin, xmax, ymin, ymax = metadata_cache['cropbox'][stack]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_jp2_dir = DataManager.get_image_dir(stack=stack, resol='lossless', version='original_jp2', raw_data_dir='/scratch/CSHL_data')\n",
    "lossless_tif_dir = DataManager.get_image_dir_v2(stack=stack, resol='lossless', prep_id=0, data_dir='/scratch/CSHL_data_processed')\n",
    "lossless_aligned_cropped_dir = DataManager.get_image_dir_v2(stack=stack, resol='lossless', prep_id=2, data_dir='/scratch/CSHL_data_processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "expanding...16 nodes available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n",
      "qsub returned.\n",
      "done in 4130.787299 seconds\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "sys.stderr.write('expanding...')\n",
    "\n",
    "# run_distributed('rm -rf /scratch/*', argument_type='single')\n",
    "\n",
    "warp_crop_script_fp = os.path.join(REPO_DIR, 'preprocess', 'warp_crop_IM_v3.py')\n",
    "\n",
    "run_distributed('aws s3 cp \\\"s3://mousebrainatlas-rawdata/CSHL_data/%(stack)s/%%(fn)s_lossless.jp2\\\" \\\"%(raw_jp2_dir)s\\\"/ && \\\n",
    "mkdir -p \\\"%(lossless_tif_dir)s\\\" && \\\n",
    "LD_LIBRARY_PATH=/home/ubuntu/KDU79_Demo_Apps_for_Linux-x86-64_170108:$LD_LIBRARY_PATH %(kdu_bin)s -i \\\"%%(in_fp)s\\\" -o \\\"%%(lossless_tif_fp)s\\\" && \\\n",
    "mkdir -p \\\"%(lossless_aligned_cropped_dir)s\\\" && \\\n",
    "%(script_path)s %(stack)s \\\"%%(lossless_tif_fp)s\\\" \\\"%%(lossless_aligned_cropped_fp)s\\\" %%(transform)s lossless %(x)d %(y)d %(w)d %(h)d %%(pad_bg_color)s && \\\n",
    "aws s3 cp \\\"%%(lossless_aligned_cropped_fp)s\\\" \\\"s3://mousebrainatlas-data/%(s3_dest_dir)s/\\\"' % \\\n",
    "                {'stack': stack,\n",
    "                'kdu_bin': KDU_EXPAND_BIN,\n",
    "                'raw_jp2_dir': raw_jp2_dir,\n",
    "                'script_path': warp_crop_script_fp,\n",
    "                'lossless_tif_dir': lossless_tif_dir,\n",
    "                'lossless_aligned_cropped_dir': lossless_aligned_cropped_dir,\n",
    "                 's3_dest_dir': relative_to_local(lossless_aligned_cropped_dir, local_root='/scratch'),\n",
    "                'x': xmin,\n",
    "                'y': ymin,\n",
    "                'w': xmax + 1 - xmin,\n",
    "                'h': ymax + 1 - ymin},\n",
    "                kwargs_list=[{'fn': fn, \n",
    "                              'in_fp': os.path.join(raw_jp2_dir, fn + '_lossless.jp2'),\n",
    "                              'transform': ','.join(map(str, tfs[fn].flatten())),\n",
    "                                'lossless_tif_fp': DataManager.get_image_filepath_v2(stack=stack, fn=fn, resol='lossless', prep_id=0, data_dir='/scratch/CSHL_data_processed'),\n",
    "                                'lossless_aligned_cropped_fp': DataManager.get_image_filepath_v2(stack=stack, fn=fn, resol='lossless', prep_id=2, data_dir='/scratch/CSHL_data_processed'),\n",
    "                                'pad_bg_color': 'black' if fn.split('-')[1][0] == 'F' else 'white'}\n",
    "                             for fn in metadata_cache['valid_filenames'][stack]],\n",
    "                argument_type='single')\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 4222 seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# contrast stretch Neurotrace, convert to 8 bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# stack = 'MD642'\n",
    "\n",
    "# download_from_s3(DataManager.get_sorted_filenames_filename(stack=stack))\n",
    "# _, sections_to_filenames = DataManager.load_sorted_filenames(stack=stack)\n",
    "\n",
    "# valid_filenames = [fn for fn in sections_to_filenames.values() if not is_invalid(fn=fn)]\n",
    "\n",
    "# _, _, _, _, first_sec, last_sec = DataManager.load_cropbox(stack=stack)\n",
    "# first_fn = sections_to_filenames[first_sec]\n",
    "# last_fn = sections_to_filenames[last_sec]\n",
    "# first_idx_among_valid = valid_filenames.index(first_fn)\n",
    "# last_idx_among_valid = valid_filenames.index(last_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# script_fp = os.path.join(REPO_DIR, 'preprocess', 'stretch_contrast_neurotrace.py')\n",
    "# in_dir = os.path.join(DATA_DIR, stack, stack + '_lossless_alignedTo_' + anchor_fn + '_cropped')\n",
    "# out_dir = os.path.join(DATA_DIR, stack, stack + '_lossless_alignedTo_' + anchor_fn + '_cropped_contrast_stretched')\n",
    "# ! mkdir -p {out_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# t = time.time()\n",
    "# sys.stderr.write('Contrast stretch neurotrace images...')\n",
    "               \n",
    "# run_distributed(command='%(script_path)s %%(in_fn)s %%(out_fn)s %(imin)d %(imax)d'%\\\n",
    "#                     {'script_path': script_fp,\n",
    "#                      'imin': 0,\n",
    "#                      'imax': 400\n",
    "#                     },\n",
    "#                     kwargs_list=[{'in_fn': os.path.join(in_dir, fn + '_lossless_alignedTo_' + anchor_fn + '_cropped.tif'),\n",
    "#                                 'out_fn': os.path.join(out_dir, fn + '_lossless_alignedTo_' + anchor_fn + '_cropped_contrast_stretched.tif')}\n",
    "#                                 for fn in valid_filenames[first_idx_among_valid:last_idx_among_valid+1]\n",
    "#                                 if fn.split('-')[1][0] == 'F'],\n",
    "#                     argument_type='single',\n",
    "#                    cluster_size=16)\n",
    "\n",
    "# wait_qsub_complete()\n",
    "\n",
    "# sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 2500 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transfer_data_synced(os.path.join('CSHL_data_processed', stack, stack + '_lossless_alignedTo_' + anchor_fn + '_cropped_contrast_stretched'),\n",
    "#                     from_hostname='ec2',\n",
    "#                     to_hostname='s3',\n",
    "#                     is_dir=True) #700s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert images to nissl-like grayscale - for full nissl stacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Convert nissl images to gray...Child returned 0\n",
      "16 nodes requested, 16 nodes available...Continuing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "qsub returned.\n",
      "done in 1136.945903 seconds\n"
     ]
    }
   ],
   "source": [
    "# for stack in all_nissl_stacks:\n",
    "for stack in ['MD595']:\n",
    "    \n",
    "    download_from_s3(DataManager.get_sorted_filenames_filename(stack=stack))\n",
    "    _, sections_to_filenames = DataManager.load_sorted_filenames(stack=stack)\n",
    "    \n",
    "    valid_filenames = [fn for fn in sections_to_filenames.values() if not is_invalid(fn=fn)]\n",
    "    download_from_s3(DataManager.get_anchor_filename_filename(stack=stack))\n",
    "\n",
    "    _, _, _, _, first_sec, last_sec = DataManager.load_cropbox(stack=stack)\n",
    "    first_fn = sections_to_filenames[first_sec]\n",
    "    last_fn = sections_to_filenames[last_sec]\n",
    "    first_idx_among_valid = valid_filenames.index(first_fn)\n",
    "    last_idx_among_valid = valid_filenames.index(last_fn)\n",
    "\n",
    "    # Convert Nissl images to grayscale\n",
    "    \n",
    "    t = time.time()\n",
    "    sys.stderr.write('Convert nissl images to gray...')\n",
    "\n",
    "    script_fp = os.path.join(REPO_DIR, 'preprocess', 'convert_grayscale_neurotrace_v2.py')\n",
    "\n",
    "    run_distributed(command='%(script_path)s %(stack)s \\'%%(filenames)s\\''%\\\n",
    "                        {'script_path': script_fp, 'stack': stack},\n",
    "                        kwargs_list={'filenames': valid_filenames[first_idx_among_valid:last_idx_among_valid+1]\n",
    "                                    },\n",
    "                        argument_type='list2')\n",
    "\n",
    "    wait_qsub_complete()\n",
    "\n",
    "    sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 900 seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert images to nissl-like grayscale - for alternating nissl/neurotrace stacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Convert nissl images to gray...16 nodes requested, 16 nodes available...Continuing\n",
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "qsub returned.\n",
      "done in 1098.395771 seconds\n",
      "16 nodes requested, 16 nodes available...Continuing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match intensity profile between Neurotrace and Nissl..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "qsub returned.\n",
      "Convert neurotrace images to gray...16 nodes requested, 16 nodes available...Continuing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done in 2371.7916441 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "qsub returned.\n",
      "done in 1008.132029 seconds\n",
      "Convert nissl images to gray...16 nodes requested, 16 nodes available...Continuing\n",
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "qsub returned.\n",
      "done in 1053.684169 seconds\n",
      "16 nodes requested, 16 nodes available...Continuing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match intensity profile between Neurotrace and Nissl..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "qsub returned.\n",
      "Convert neurotrace images to gray...16 nodes requested, 16 nodes available...Continuing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done in 3785.25425816 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "qsub returned.\n",
      "done in 1298.919096 seconds\n"
     ]
    }
   ],
   "source": [
    "# for stack in all_alt_nissl_ntb_stacks + all_alt_nissl_tracing_stacks:\n",
    "for stack in ['MD653', 'MD657']:\n",
    "    \n",
    "    download_from_s3(DataManager.get_sorted_filenames_filename(stack=stack))\n",
    "    _, sections_to_filenames = DataManager.load_sorted_filenames(stack=stack)\n",
    "    \n",
    "    valid_filenames = [fn for fn in sections_to_filenames.values() if not is_invalid(fn=fn)]\n",
    "    download_from_s3(DataManager.get_anchor_filename_filename(stack=stack))\n",
    "\n",
    "    _, _, _, _, first_sec, last_sec = DataManager.load_cropbox(stack=stack)\n",
    "    first_fn = sections_to_filenames[first_sec]\n",
    "    last_fn = sections_to_filenames[last_sec]\n",
    "    first_idx_among_valid = valid_filenames.index(first_fn)\n",
    "    last_idx_among_valid = valid_filenames.index(last_fn)\n",
    "\n",
    "    # Convert Nissl images to grayscale\n",
    "    \n",
    "    t = time.time()\n",
    "    sys.stderr.write('Convert nissl images to gray...')\n",
    "\n",
    "    script_fp = os.path.join(REPO_DIR, 'preprocess', 'convert_grayscale_neurotrace_v2.py')\n",
    "\n",
    "    run_distributed(command='%(script_path)s %(stack)s \\'%%(filenames)s\\''%\\\n",
    "                        {'script_path': script_fp, 'stack': stack},\n",
    "                        kwargs_list={'filenames': \n",
    "                                     [fn for fn in valid_filenames[first_idx_among_valid:last_idx_among_valid+1]\n",
    "                                      if fn.split('-')[1][0] == 'N']\n",
    "                                    },\n",
    "                        argument_type='list2',\n",
    "                       cluster_size=16)\n",
    "\n",
    "    wait_qsub_complete()\n",
    "\n",
    "    sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 900 seconds.\n",
    "    \n",
    "    # Match intensity profile between Neurotrace Blue to Nissl\n",
    "\n",
    "    t = time.time()\n",
    "    sys.stderr.write('Match intensity profile between Neurotrace and Nissl...')\n",
    "\n",
    "    filename_pairs = []\n",
    "    l = valid_filenames[first_idx_among_valid:last_idx_among_valid+1]\n",
    "    for i, fn in enumerate(l):\n",
    "        if l[i].split('-')[1][0] == 'F':\n",
    "            for d in range(1, 99):\n",
    "                if i+d < len(l) and l[i+d].split('-')[1][0] == 'N':\n",
    "                    filename_pairs.append((l[i+d], l[i]))\n",
    "                    break\n",
    "                if i-d >= 0 and l[i-d].split('-')[1][0] == 'N':\n",
    "                    filename_pairs.append((l[i-d], l[i]))\n",
    "                    break\n",
    "            \n",
    "    script_fp = os.path.join(REPO_DIR, 'preprocess', 'match_intensity_profile.py')\n",
    "    \n",
    "    run_distributed(command='%(script_path)s %(stack)s \\'%%(filename_pairs)s\\' ' % \\\n",
    "                    {'script_path': script_fp,\n",
    "                    'stack': stack,\n",
    "                    'filename_pairs': filename_pairs},\n",
    "                    kwargs_list=dict(filename_pairs=filename_pairs),\n",
    "                    argument_type='list2',\n",
    "                   cluster_size=16)\n",
    "\n",
    "    wait_qsub_complete()\n",
    "\n",
    "    sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 2500 seconds. \n",
    "    # TODO: One node is especially slow, investigate.\n",
    "    \n",
    "    # Convert Neurotrace images to grayscale\n",
    "    \n",
    "    t = time.time()\n",
    "    sys.stderr.write('Convert neurotrace images to gray...')\n",
    "    \n",
    "    script_fp = os.path.join(REPO_DIR, 'preprocess', 'convert_grayscale_neurotrace_v2.py')\n",
    "    \n",
    "    run_distributed(command='%(script_path)s %(stack)s \\'%%(filenames)s\\''%\\\n",
    "                        {'script_path': script_fp, \n",
    "                        'stack': stack},\n",
    "                        kwargs_list={'filenames': [fn for fn in valid_filenames[first_idx_among_valid:last_idx_among_valid+1]\n",
    "                                      if fn.split('-')[1][0] == 'F']\n",
    "                                    },\n",
    "                        argument_type='list2',\n",
    "                       cluster_size=16)\n",
    "\n",
    "    wait_qsub_complete()\n",
    "\n",
    "    sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 1200 seconds.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert images to nissl-like grayscale - for full neurotrace stacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Convert neurotrace images to gray...Child returned 0\n",
      "16 nodes available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n",
      "qsub returned.\n",
      "done in 1952.800308 seconds\n"
     ]
    }
   ],
   "source": [
    "for stack in ['MD635']:\n",
    "    \n",
    "    # Convert Neurotrace images to grayscale using a priori intensity mapping.\n",
    "    \n",
    "    t = time.time()\n",
    "    sys.stderr.write('Convert neurotrace images to gray...')\n",
    "    \n",
    "    script_fp = os.path.join(REPO_DIR, 'preprocess', 'convert_grayscale_neurotrace_v2.py')\n",
    "    \n",
    "    run_distributed(command='%(script_path)s %(stack)s \\'%%(filenames)s\\''%\\\n",
    "                        {'script_path': script_fp, \n",
    "                        'stack': stack},\n",
    "                        kwargs_list={'filenames': metadata_cache['valid_filenames'][stack]},\n",
    "                        argument_type='list2')\n",
    "\n",
    "    wait_qsub_complete()\n",
    "\n",
    "    sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 2000 seconds.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contrast stretch all nissl-like grayscale images (deprecated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for stack in ['MD590',\n",
    "#  'MD591',\n",
    "#  'MD592',\n",
    "#  'MD593',\n",
    "#  'MD594',\n",
    "#  'MD595',\n",
    "#  'MD598',\n",
    "#  'MD599',\n",
    "#  'MD602',\n",
    "#  'MD603']:\n",
    "# # for stack in ['MD589']:\n",
    "    \n",
    "#     download_from_s3(DataManager.get_sorted_filenames_filename(stack=stack))\n",
    "#     _, sections_to_filenames = DataManager.load_sorted_filenames(stack=stack)\n",
    "    \n",
    "#     valid_filenames = [fn for fn in sections_to_filenames.values() if not is_invalid(fn=fn)]\n",
    "#     download_from_s3(DataManager.get_anchor_filename_filename(stack=stack))\n",
    "\n",
    "#     _, _, _, _, first_sec, last_sec = DataManager.load_cropbox(stack=stack)\n",
    "#     first_fn = sections_to_filenames[first_sec]\n",
    "#     last_fn = sections_to_filenames[last_sec]\n",
    "#     first_idx_among_valid = valid_filenames.index(first_fn)\n",
    "#     last_idx_among_valid = valid_filenames.index(last_fn)\n",
    "\n",
    "#     # Contrast stretch nissl grayscale image\n",
    "    \n",
    "#     t = time.time()\n",
    "#     sys.stderr.write('Contrast stretch nissl grayscale image...')\n",
    "\n",
    "#     script_fp = os.path.join(REPO_DIR, 'preprocess', 'stretch_contrast_image.py')\n",
    "\n",
    "#     run_distributed(command='ROOT_DIR=/scratch/ %(script_path)s %(stack)s \\'%%(filenames)s\\' 23 160'%\\\n",
    "#                         {'script_path': script_fp, 'stack': stack},\n",
    "#                         kwargs_list={'filenames': valid_filenames[first_idx_among_valid:last_idx_among_valid+1]\n",
    "#                                     },\n",
    "#                         argument_type='list2',\n",
    "#                        cluster_size=16)\n",
    "\n",
    "#     wait_qsub_complete()\n",
    "\n",
    "#     sys.stderr.write('done in %f seconds\\n' % (time.time() - t))\n",
    "        \n",
    "#     run_distributed(command='rm -r /scratch/*',\n",
    "#                         argument_type='single',\n",
    "#                        cluster_size=16)\n",
    "#     wait_qsub_complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONE STACK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Convert Nissl images to grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "sys.stderr.write('Convert nissl images to gray...')\n",
    "               \n",
    "script_fp = os.path.join(REPO_DIR, 'preprocess', 'convert_grayscale_neurotrace_v2.py')\n",
    "\n",
    "run_distributed(command='%(script_path)s %(stack)s \\'%%(filenames)s\\''%\\\n",
    "                    {'script_path': script_fp, 'stack': stack},\n",
    "#                     kwargs_list={'filenames': valid_filenames[first_idx_among_valid:last_idx_among_valid+1]},\n",
    "                    kwargs_list={'filenames':\n",
    "                                 [fn for fn in valid_filenames[first_idx_among_valid:last_idx_among_valid+1]\n",
    "                                  if fn.split('-')[1][0] == 'N']},\n",
    "                    argument_type='list2',\n",
    "                   cluster_size=16)\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 1200 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert contrast-stretched Neurotrace images to grayscale\n",
    "\n",
    "# script_fp = os.path.join(REPO_DIR, 'preprocess', 'convert_grayscale_neurotrace.py')\n",
    "# in_dir = os.path.join(DATA_DIR, stack, stack + '_lossless_alignedTo_' + anchor_fn + '_cropped_contrast_stretched')\n",
    "# out_dir = os.path.join(DATA_DIR, stack, stack + '_lossless_alignedTo_' + anchor_fn + '_cropped_contrast_stretched_blueasgray')\n",
    "# ! mkdir -p {out_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Convert neurotrace images to gray...16 nodes requested, 16 nodes available...Continuing\n",
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "qsub returned.\n",
      "done in 75.575123 seconds\n"
     ]
    }
   ],
   "source": [
    "# t = time.time()\n",
    "# sys.stderr.write('Convert neurotrace images to gray...')\n",
    "               \n",
    "# run_distributed(command='%(script_path)s %%(in_fn)s %%(out_fn)s'%\\\n",
    "#                     {'script_path': script_fp},\n",
    "#                     kwargs_list=[{'in_fn': os.path.join(in_dir, fn + '_lossless_alignedTo_' + anchor_fn + '_cropped_contrast_stretched.tif'),\n",
    "#                                 'out_fn': os.path.join(out_dir, fn + '_lossless_alignedTo_' + anchor_fn + '_cropped_contrast_stretched_blueasgray.tif')}\n",
    "# #                                 for fn in valid_filenames[first_idx_among_valid:last_idx_among_valid+1]\n",
    "#                                  for fn in valid_filenames[150:151]\n",
    "#                                 if fn.split('-')[1][0] == 'F'],\n",
    "#                     argument_type='single',\n",
    "#                    cluster_size=16)\n",
    "\n",
    "# wait_qsub_complete()\n",
    "\n",
    "# sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 2500 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Match intensity profile between Neurotrace Blue to Nissl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match intensity profile between Neurotrace and Nissl... rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "16 nodes available.\n",
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n",
      "qsub returned.\n",
      "Child returned 0\n",
      "16 nodes available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 2790.67252398 seconds\n",
      "Match intensity profile between Neurotrace and Nissl... rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n",
      "qsub returned.\n",
      "Child returned 0\n",
      "16 nodes available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 2554.21281099 seconds\n",
      "Match intensity profile between Neurotrace and Nissl... rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n",
      "qsub returned.\n",
      "Child returned 0\n",
      "16 nodes available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 2655.20303488 seconds\n",
      "Match intensity profile between Neurotrace and Nissl... rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 2363.96758008 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qsub returned.\n"
     ]
    }
   ],
   "source": [
    "# for stack in all_alt_nissl_ntb_stacks + all_alt_nissl_tracing_stacks:\n",
    "for stack in ['MD653', 'MD652', 'MD642', 'MD658']:\n",
    "\n",
    "#     download_from_s3(DataManager.get_sorted_filenames_filename(stack=stack))\n",
    "#     _, sections_to_filenames = DataManager.load_sorted_filenames(stack=stack)\n",
    "#     valid_filenames = [fn for fn in sections_to_filenames.values() if not is_invalid(fn=fn)]\n",
    "#     download_from_s3(DataManager.get_anchor_filename_filename(stack=stack))\n",
    "#     anchor_fn = DataManager.load_anchor_filename(stack=stack)\n",
    "#     download_from_s3(DataManager.get_cropbox_filename(stack=stack))\n",
    "#     xmin, xmax, ymin, ymax, first_sec, last_sec = DataManager.load_cropbox(stack=stack)\n",
    "#     w = xmax + 1 - xmin\n",
    "#     h = ymax + 1 - ymin\n",
    "#     x = xmin\n",
    "#     y = ymin\n",
    "#     first_fn = sections_to_filenames[first_sec]\n",
    "#     last_fn = sections_to_filenames[last_sec]\n",
    "#     first_idx_among_valid = valid_filenames.index(first_fn)\n",
    "#     last_idx_among_valid = valid_filenames.index(last_fn)\n",
    "    \n",
    "    #########################################################\n",
    "    \n",
    "    t = time.time()\n",
    "    print 'Match intensity profile between Neurotrace and Nissl...',\n",
    "    \n",
    "    filename_pairs = []\n",
    "    l = metadata_cache['valid_filenames'][stack]\n",
    "    for i, fn in enumerate(l):\n",
    "        if l[i].split('-')[1][0] == 'F':\n",
    "            for d in range(1, 99):\n",
    "                if i+d < len(l) and l[i+d].split('-')[1][0] == 'N':\n",
    "                    filename_pairs.append((l[i+d], l[i]))\n",
    "                    break\n",
    "                if i-d >= 0 and l[i-d].split('-')[1][0] == 'N':\n",
    "                    filename_pairs.append((l[i-d], l[i]))\n",
    "                    break\n",
    "    \n",
    "    script = os.path.join(REPO_DIR, 'preprocess', 'match_intensity_profile_v2.py')\n",
    "    \n",
    "    run_distributed(command='%(script_path)s %(stack)s \\'%%(filename_pairs)s\\' 100' % \\\n",
    "                    {'script_path': script,\n",
    "                    'stack': stack},\n",
    "#                     kwargs_list=dict(filename_pairs=filename_pairs[37:38]),\n",
    "                    kwargs_list=dict(filename_pairs=filename_pairs),\n",
    "                    argument_type='list2'\n",
    "                   )\n",
    "\n",
    "    wait_qsub_complete()\n",
    "\n",
    "    print 'done in', time.time() - t, 'seconds'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Convert Neurotrace images to grayscale (New, use nonlinear intensity mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "script_fp = os.path.join(REPO_DIR, 'preprocess', 'convert_grayscale_neurotrace_v2.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for fn in valid_filenames[first_idx_among_valid:last_idx_among_valid+1]:\n",
    "#     download_from_s3(DataManager.get_image_filepath(stack=stack, version='cropped', resol='lossless', fn=fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Convert neurotrace images to gray...Child returned 0\n",
      "16 nodes available.\n",
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n",
      "qsub returned.\n",
      "done in 1865.522785 seconds\n"
     ]
    }
   ],
   "source": [
    "# for stack in all_alt_nissl_ntb_stacks + all_alt_nissl_tracing_stacks:\n",
    "for stack in ['MD635']:\n",
    "    \n",
    "    output_dir = create_if_not_exists(DataManager.get_image_dir(stack=stack, version='cropped_gray', resol='lossless'));\n",
    "    ! rm -r {output_dir}\n",
    "\n",
    "    t = time.time()\n",
    "    sys.stderr.write('Convert neurotrace images to gray...')\n",
    "\n",
    "    run_distributed(command='DATA_DIR=/scrtatch %(script_path)s %(stack)s \\'%%(filenames)s\\''%\\\n",
    "                        {'script_path': script_fp, \n",
    "                        'stack': stack},\n",
    "                        kwargs_list={'filenames': \n",
    "                                     [fn for fn in metadata_cache['valid_filenames'][stack]\n",
    "                                      if fn.split('-')[1][0] == 'F']\n",
    "    #                                  ['MD657-F29-2017.02.18-01.04.58_MD657_1_0085']\n",
    "                                    },\n",
    "                        argument_type='list2')\n",
    "\n",
    "    wait_qsub_complete()\n",
    "\n",
    "    sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 1200 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# upload_to_s3(DataManager.get_image_dir(stack=stack, version='cropped_gray', resol='lossless'), is_dir=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2/3: Convert Neurotrace images to grayscale (linear intensity mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack = 'MD657'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# output_dir = create_if_not_exists(DataManager.get_image_dir(stack=stack, version='cropped_gray_linearNormalized', resol='lossless'));\n",
    "# ! rm -r {output_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "script_fp = os.path.join(REPO_DIR, 'preprocess', 'convert_grayscale_neurotrace_v2.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All nodes are ready.\n"
     ]
    }
   ],
   "source": [
    "request_compute_nodes(16, 'preprocesscluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "17 nodes available.\n",
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n",
      "qsub returned.\n"
     ]
    }
   ],
   "source": [
    "run_distributed('rm -rf /scratch/*', argument_type='single')\n",
    "wait_qsub_complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Convert neurotrace images to gray...Child returned 0\n",
      "16 nodes available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n",
      "qsub returned.\n",
      "done in 865.923385 seconds\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "sys.stderr.write('Convert neurotrace images to gray...')\n",
    "\n",
    "# for low in range(500, 3000, 500):\n",
    "for low in [500]:\n",
    "\n",
    "    run_distributed(command='ROOT_DIR=/scratch %(script_path)s %(stack)s \\'%%(filenames)s\\' -l %(low)d -H 0 -o %(output_version)d'%\\\n",
    "                        {'script_path': script_fp, \n",
    "                        'stack': stack,\n",
    "                        'low': low,\n",
    "                        'output_version': 'cropped_gray_linearNormalized' + str(low)},\n",
    "                        kwargs_list={'filenames': [fn for fn in metadata_cache['valid_filenames'][stack]\n",
    "                                                   if fn.split('-')[1][0] == 'F']},\n",
    "    #                     kwargs_list={'filenames': ['MD657-F28-2017.02.18-00.45.02_MD657_2_0083']},\n",
    "                        argument_type='list2',\n",
    "                   node_list=get_node_list())\n",
    "\n",
    "    wait_qsub_complete()\n",
    "\n",
    "    sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) \n",
    "    # /scratch, 133 jobs / 16 nodes: 850 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate JPEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD589/MD589_lossless_alignedTo_MD589-IHC31-2015.07.30-23.26.22_MD589_1_0091_cropped && mkdir -p /shared/CSHL_data_processed/MD589\n",
      "aws s3 cp --recursive s3://mousebrainatlas-data/CSHL_data_processed/MD589/MD589_lossless_alignedTo_MD589-IHC31-2015.07.30-23.26.22_MD589_1_0091_cropped /shared/CSHL_data_processed/MD589/MD589_lossless_alignedTo_MD589-IHC31-2015.07.30-23.26.22_MD589_1_0091_cropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "Child returned 0\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data_processed', stack, stack + '_lossless_alignedTo_' + anchor_fn + '_cropped'),\n",
    "                    from_hostname='s3',\n",
    "                    to_hostname='ec2',\n",
    "                    is_dir=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "script_fp = os.path.join(REPO_DIR, 'preprocess', 'generate_other_versions_v2.py')\n",
    "input_dir = os.path.join(DATA_DIR, stack, stack + '_lossless_alignedTo_' + anchor_fn + '_cropped')\n",
    "output_dir = os.path.join(DATA_DIR, stack, stack + '_lossless_alignedTo_' + anchor_fn + '_cropped_compressed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '/shared/CSHL_data_processed/MD658/MD658_lossless_alignedTo_MD658-N58-2017.03.31-19.59.31_MD658_2_0173_cropped_compressed/*': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "! rm -r {output_dir}/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating compressed image..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16 nodes requested, 18 nodes available...Continuing\n",
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "print 'Generating compressed image...',\n",
    "\n",
    "if stack in all_nissl_stacks:\n",
    "    \n",
    "    run_distributed('%(script)s %(stack)s %(input_dir)s \\'%%(input_filenames)s\\' --output_compressed_dir %(output_compressed_dir)s' % \\\n",
    "                dict(script=script_fp,\n",
    "                     stack=stack,\n",
    "                     input_dir=input_dir,\n",
    "                     output_compressed_dir=output_dir),\n",
    "                    kwargs_list={'input_filenames': \n",
    "                                 [fn + '_lossless_alignedTo_' + anchor_fn + '_cropped.tif' \n",
    "                                  for fn in valid_filenames[first_idx_among_valid:last_idx_among_valid+1]]},\n",
    "                    argument_type='list2',\n",
    "                    cluster_size=16,\n",
    "                   jobs_per_node=16)\n",
    "    \n",
    "else:\n",
    "    run_distributed('%(script)s %(stack)s %(input_dir)s \\'%%(input_filenames)s\\' --output_compressed_dir %(output_compressed_dir)s' % \\\n",
    "                    dict(script=script_fp,\n",
    "                         stack=stack,\n",
    "                         input_dir=input_dir,\n",
    "                         output_compressed_dir=output_dir),\n",
    "                        kwargs_list={'input_filenames': \n",
    "                                     [fn + '_lossless_alignedTo_' + anchor_fn + '_cropped.tif' \n",
    "                                      for fn in valid_filenames[first_idx_among_valid:last_idx_among_valid+1] \n",
    "                                      if fn.split('-')[1].startswith('N')]},\n",
    "                        argument_type='list2',\n",
    "                         cluster_size=16,\n",
    "                       jobs_per_node=16)\n",
    "\n",
    "wait_qsub_complete()\n",
    "    \n",
    "print 'done in', time.time() - t, 'seconds' # 765 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 cp --recursive /shared/CSHL_data_processed/MD658/MD658_lossless_alignedTo_MD658-N58-2017.03.31-19.59.31_MD658_2_0173_cropped_compressed s3://mousebrainatlas-data/CSHL_data_processed/MD658/MD658_lossless_alignedTo_MD658-N58-2017.03.31-19.59.31_MD658_2_0173_cropped_compressed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "36.94 seconds.\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data_processed', stack, stack + '_lossless_alignedTo_' + anchor_fn + '_cropped_compressed'),\n",
    "                    from_hostname='ec2',\n",
    "                    to_hostname='s3',\n",
    "                    is_dir=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate JPEG for neurotrace (obsolete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "script_fp = os.path.join(REPO_DIR, 'preprocess', 'generate_other_versions_v2.py')\n",
    "input_dir = os.path.join(DATA_DIR, stack, stack + '_lossless_alignedTo_' + anchor_fn + '_cropped_contrast_stretched')\n",
    "out_jpeg_dir = os.path.join(DATA_DIR, stack, stack + '_lossless_alignedTo_' + anchor_fn + '_cropped_compressed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating compressed image..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16 nodes requested, 18 nodes available...Continuing\n",
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "print 'Generating compressed image...',\n",
    "\n",
    "run_distributed('%(script)s %(stack)s %(input_dir)s \\'%%(input_filenames)s\\' --output_compressed_dir %(output_compressed_dir)s' % \\\n",
    "                dict(script=script_fp,\n",
    "                     stack=stack,\n",
    "                     input_dir=input_dir,\n",
    "                     output_compressed_dir=out_jpeg_dir),\n",
    "                    kwargs_list={'input_filenames': \n",
    "                                 [fn + '_lossless_alignedTo_' + anchor_fn + '_cropped_contrast_stretched.tif' \n",
    "                                  for fn in valid_filenames[first_idx_among_valid:last_idx_among_valid+1] \n",
    "                                  if fn.split('-')[1].startswith('F')]},\n",
    "                    argument_type='list2',\n",
    "                    cluster_size=16)\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "print 'done in', time.time() - t, 'seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " aws s3 cp --recursive /shared/CSHL_data_processed/MD658/MD658_lossless_alignedTo_MD658-N58-2017.03.31-19.59.31_MD658_2_0173_cropped_compressed s3://mousebrainatlas-data/CSHL_data_processed/MD658/MD658_lossless_alignedTo_MD658-N58-2017.03.31-19.59.31_MD658_2_0173_cropped_compressed --exclude \"*\" --include \"*contrast_stretched*.jpg\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "31.04 seconds.\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data_processed', stack, stack + '_lossless_alignedTo_' + anchor_fn + '_cropped_compressed'),\n",
    "                    from_hostname='ec2',\n",
    "                    to_hostname='s3',\n",
    "                    is_dir=True,\n",
    "                    include_only='*contrast_stretched*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# t = time.time()\n",
    "# print 'Generating saturation image...',\n",
    "\n",
    "# run_distributed4('%(script)s %(stack)s %(input_dir)s \\'%%(input_filenames)s\\' --output_saturation_dir %(output_saturation_dir)s' % \\\n",
    "#                 dict(script=script_fp,\n",
    "#                      stack=stack,\n",
    "#                      input_dir=input_dir,\n",
    "#                      output_saturation_dir=out_sat_dir,\n",
    "#                      kwargs_list={'input_filenames': [fn + '_lossless_alignedTo_' + anchor_fn + '_cropped.tif' for fn in filenames[first_idx:last_idx+1]]},\n",
    "#                     exclude_nodes=exclude_nodes,\n",
    "#                     argument_type='list2')\n",
    "\n",
    "# print 'done in', time.time() - t, 'seconds'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compress nissl gray and normalized fluorescent gray images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating compressed images... rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "16 nodes available.\n",
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized, lossless). So using the default image filepath composition rule.\n",
      "No special rule for (cropped_gray_linearNormalized_jpeg, lossless). So using the default image filepath composition rule.\n",
      "Child returned 0\n",
      "16 nodes available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 242.359697104 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qsub returned.\n"
     ]
    }
   ],
   "source": [
    "# for stack in all_alt_nissl_ntb_stacks + all_alt_nissl_tracing_stacks:\n",
    "for stack in ['MD635']:\n",
    "    \n",
    "    t = time.time()\n",
    "    print 'Generating compressed images...',\n",
    "\n",
    "    script_fp = os.path.join(REPO_DIR, 'preprocess', 'compress_as_jpeg.py')\n",
    "\n",
    "    run_distributed('rm -r /scratch/*', \n",
    "                    argument_type='single')\n",
    "\n",
    "    run_distributed('ROOT_DIR=/scratch/ %(script)s %%(input_fp)s %%(output_fp)s' % \\\n",
    "                    {'script': script_fp},\n",
    "#                     kwargs_list=[{'input_fp': DataManager.get_image_filepath(stack=stack, fn=fn, resol='lossless', version='cropped_gray', data_dir='/scratch/CSHL_data_processed'),\n",
    "#                                   'output_fp': DataManager.get_image_filepath(stack=stack, fn=fn, resol='lossless', version='cropped_gray_jpeg',data_dir='/scratch/CSHL_data_processed')}\n",
    "#                                  for fn in metadata_cache['valid_filenames'][stack]],\n",
    "                        kwargs_list=[{'input_fp': DataManager.get_image_filepath(stack=stack, fn=fn, resol='lossless', version='cropped_gray_linearNormalized', data_dir='/scratch/CSHL_data_processed'),\n",
    "                                  'output_fp': DataManager.get_image_filepath(stack=stack, fn=fn, resol='lossless', version='cropped_gray_linearNormalized_jpeg',data_dir='/scratch/CSHL_data_processed')}\n",
    "                                 for fn in metadata_cache['valid_filenames'][stack]],\n",
    "                        argument_type='single')\n",
    "\n",
    "    wait_qsub_complete()\n",
    "\n",
    "    print 'done in', time.time() - t, 'seconds' # for one stack 300 seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Aligned Masks (new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Download aligned thumbnails to local machine.\n",
    "- Run `mask_editing_gui.py`. Draw initial contours. Upload `initSnakeContours.pkl` to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "download_from_s3(DataManager.get_image_dir_v2(stack=stack, prep_id=1, resol='thumbnail'), is_dir=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "script = os.path.join(REPO_DIR, 'preprocess', 'generate_thumbnail_masks_v5.py')\n",
    "\n",
    "output_dir = create_if_not_exists(DataManager.get_auto_submask_rootdir_filepath(stack=stack))\n",
    "! rm -rf {output_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf \"/shared/CSHL_data_processed/MD661/MD661_prep1_thumbnail_initSnakeContours.pkl\" && mkdir -p \"/shared/CSHL_data_processed/MD661\"\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_data_processed/MD661/MD661_prep1_thumbnail_initSnakeContours.pkl\" \"/shared/CSHL_data_processed/MD661/MD661_prep1_thumbnail_initSnakeContours.pkl\"\n"
     ]
    }
   ],
   "source": [
    "init_snake_contours_fp = DataManager.get_initial_snake_contours_filepath(stack=stack)\n",
    "download_from_s3(init_snake_contours_fp, redownload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating thumbnail mask... rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16 nodes available.\n",
      "Jobs submitted. Use wait_qsub_complete() to wait for all execution to finish.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 858.656265974 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qsub returned.\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "print 'Generating thumbnail mask...',\n",
    "\n",
    "run_distributed(command='%(script_path)s %(stack)s \\'%%(filenames)s\\' %(init_snake_contours_fp)s --min_size 500 --default_channel 1' % \\\n",
    "                {'script_path': script,\n",
    "                'stack': stack,\n",
    "                'init_snake_contours_fp': init_snake_contours_fp},\n",
    "                kwargs_list={'filenames': metadata_cache['valid_filenames_all'][stack]},\n",
    "                argument_type='list2')\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "print 'done in', time.time() - t, 'seconds' # 300s (aws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- download the folder `autoSubmasks` from S3.\n",
    "- Use local mask editing tool, generate `userModifiedSubmasks` and `masks`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "script = os.path.join(REPO_DIR, 'preprocess', 'generate_thumbnail_masks_v4.py')\n",
    "input_dir = os.path.join(RAW_DATA_DIR, stack)\n",
    "output_dir = create_if_not_exists(os.path.join(DATA_DIR, stack, stack + '_submasks'))\n",
    "! rm -f output_dir/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating thumbnail mask... Setting autoscaling group cfncluster-yuncongCluster-ComputeFleet-1LFRACYHLTNL8 capaticy to 16...it may take more than 5 minutes for SGE to know new hosts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Wait for SGE to know all nodes (timeout in 300 seconds)...\n",
      "All nodes are ready.\n",
      "16 nodes requested, 16 nodes available...Continuing\n",
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 403.646880865 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qsub returned.\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "print 'Generating thumbnail mask...',\n",
    "\n",
    "wait_num_nodes(16)\n",
    "\n",
    "run_distributed(command='%(script_path)s %(stack)s %(input_dir)s \\'%%(filenames)s\\' %(output_dir)s --border_dissim_percentile %(border_dissim_percentile)d --min_size %(min_size)d' % \\\n",
    "                {'script_path': script,\n",
    "                'stack': stack,\n",
    "                'input_dir': input_dir,\n",
    "                'output_dir': output_dir,\n",
    "                'border_dissim_percentile': DEFAULT_BORDER_DISSIMILARITY_PERCENTILE,\n",
    "                'min_size': DEFAULT_MINSIZE},\n",
    "                kwargs_list=dict(filenames=valid_filenames),\n",
    "                exclude_nodes=[33],\n",
    "                argument_type='list2',\n",
    "               cluster_size=16,\n",
    "               jobs_per_node=1)\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "print 'done in', time.time() - t, 'seconds' # 300s (aws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 cp --recursive /shared/CSHL_data_processed/MD594/MD594_submasks s3://mousebrainatlas-data/CSHL_data_processed/MD594/MD594_submasks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "3.72 seconds.\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(relative_to_ec2(output_dir),\n",
    "                    from_hostname='ec2',\n",
    "                    to_hostname='s3',\n",
    "                    is_dir=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- download `submasks/` to local machine\n",
    "- review them in GUI\n",
    "- generate `submasks_modified/`, `masks/`, `submasks_finalDecisions.txt`, upload to S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warp Thumbnail Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "script = os.path.join(REPO_DIR, 'preprocess', 'warp_crop_IM_v2.py')\n",
    "input_dir = os.path.join(DATA_DIR, stack, stack + '_masks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD594/MD594_masks && mkdir -p /shared/CSHL_data_processed/MD594\n",
      "aws s3 cp --recursive s3://mousebrainatlas-data/CSHL_data_processed/MD594/MD594_masks /shared/CSHL_data_processed/MD594/MD594_masks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "Child returned 0\n",
      "1.87 seconds.\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(relative_to_ec2(input_dir),\n",
    "                    from_hostname='s3',\n",
    "                    to_hostname='ec2',\n",
    "                    is_dir=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD658/MD658_alignedTo_MD658-N58-2017.03.31-19.59.31_MD658_2_0173_masks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n"
     ]
    }
   ],
   "source": [
    "output_dir = os.path.join(DATA_DIR, stack, stack + '_masks_alignedTo_' + anchor_fn)\n",
    "execute_command('rm -rf ' + output_dir)\n",
    "\n",
    "transforms_to_anchor = load_pickle(DataManager.get_transforms_filename(stack=stack))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warping thumbnail mask... Setting autoscaling group cfncluster-yuncongCluster-ComputeFleet-1LFRACYHLTNL8 capaticy to 16...it may take more than 5 minutes for SGE to know new hosts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16 nodes requested, 1 nodes available...Continuing\n",
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 76.2961359024 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qsub returned.\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "print 'warping thumbnail mask...',\n",
    "\n",
    "run_distributed('%(script)s %(stack)s %(input_dir)s %(output_dir)s %%(transform)s %%(filename)s %%(output_fn)s thumbnail 0 0 2000 1500 black' % \\\n",
    "                {'script': script,\n",
    "                'stack': stack,\n",
    "                'input_dir': input_dir,\n",
    "                'output_dir': output_dir},\n",
    "                kwargs_list=[{'transform': ','.join(map(str, transforms_to_anchor[fn].flatten())),\n",
    "                            'filename': fn + '_mask.png',\n",
    "                            'output_fn': fn + '_mask_alignedTo_' + anchor_fn + '.png'}\n",
    "                            for fn in valid_filenames],\n",
    "                argument_type='single',\n",
    "               cluster_size=16,\n",
    "               jobs_per_node=16)\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "print 'done in', time.time() - t, 'seconds' # 20 seconds (aws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 cp --recursive /shared/CSHL_data_processed/MD594/MD594_masks_alignedTo_MD594-IHC58-2015.08.26-18.48.50_MD594_1_0172 s3://mousebrainatlas-data/CSHL_data_processed/MD594/MD594_masks_alignedTo_MD594-IHC58-2015.08.26-18.48.50_MD594_1_0172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "3.42 seconds.\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(relative_to_ec2(output_dir),\n",
    "                    from_hostname='ec2',\n",
    "                    to_hostname='s3',\n",
    "                    is_dir=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop Thumbnail Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack = 'MD658'\n",
    "\n",
    "# download_from_s3(DataManager.get_sorted_filenames_filename(stack=stack))\n",
    "# _, sections_to_filenames = DataManager.load_sorted_filenames(stack=stack)\n",
    "# valid_filenames = [fn for fn in sections_to_filenames.values() if not is_invalid(fn=fn)]\n",
    "# download_from_s3(DataManager.get_anchor_filename_filename(stack=stack))\n",
    "# anchor_fn = DataManager.load_anchor_filename(stack=stack)\n",
    "# download_from_s3(DataManager.get_cropbox_filename(stack=stack))\n",
    "xmin, xmax, ymin, ymax, first_sec, last_sec = DataManager.load_cropbox(stack=stack)\n",
    "# w = xmax + 1 - xmin\n",
    "# h = ymax + 1 - ymin\n",
    "# x = xmin\n",
    "# y = ymin\n",
    "# first_fn = sections_to_filenames[first_sec]\n",
    "# last_fn = sections_to_filenames[last_sec]\n",
    "# first_idx_among_valid = valid_filenames.index(first_fn)\n",
    "# last_idx_among_valid = valid_filenames.index(last_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack = 'MD635'\n",
    "xmin, xmax, ymin, ymax, _, _ = DataManager.load_cropbox(stack=stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD635/MD635_alignedTo_MD635-F63-2016.05.19-08.39.03_MD635_2_0188_masks && mkdir -p /shared/CSHL_data_processed/MD635\n",
      "aws s3 cp --recursive s3://mousebrainatlas-data/CSHL_data_processed/MD635/MD635_alignedTo_MD635-F63-2016.05.19-08.39.03_MD635_2_0188_masks /shared/CSHL_data_processed/MD635/MD635_alignedTo_MD635-F63-2016.05.19-08.39.03_MD635_2_0188_masks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD635/MD635_alignedTo_MD635-F63-2016.05.19-08.39.03_MD635_2_0188_masks_cropped\n",
      "mkdir -p /shared/CSHL_data_processed/MD635/MD635_alignedTo_MD635-F63-2016.05.19-08.39.03_MD635_2_0188_masks_cropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "2.03 seconds.\n",
      "Child returned 0\n",
      "Child returned 0\n"
     ]
    }
   ],
   "source": [
    "input_dir = DataManager.get_thumbnail_mask_dir_v3(stack=stack, version='aligned')\n",
    "download_from_s3(input_dir, is_dir=True)\n",
    "\n",
    "output_dir = DataManager.get_thumbnail_mask_dir_v3(stack=stack, version='aligned_cropped')\n",
    "\n",
    "execute_command('rm -rf ' + output_dir);\n",
    "execute_command('mkdir -p ' + output_dir);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cropping thumbnail mask..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mogrify -set filename:name %t -crop 685x448+659+308 -write \"/shared/CSHL_data_processed/MD635/MD635_alignedTo_MD635-F63-2016.05.19-08.39.03_MD635_2_0188_masks_cropped/%[filename:name]_cropped.png\" /shared/CSHL_data_processed/MD635/MD635_alignedTo_MD635-F63-2016.05.19-08.39.03_MD635_2_0188_masks/*.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "done in 18.053840 seconds\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "sys.stderr.write('cropping thumbnail mask...')\n",
    "\n",
    "execute_command('mogrify -set filename:name %%t -crop %(w)dx%(h)d+%(x)d+%(y)d -write \"%(output_dir)s/%%[filename:name]_cropped.png\" %(input_dir)s/*.png' % \\\n",
    "    {'stack': stack,\n",
    "    'input_dir': input_dir,\n",
    "    'output_dir': output_dir,\n",
    "    'w':xmax+1-xmin, 'h':ymax+1-ymin, 'x':xmin, 'y':ymin})\n",
    "\n",
    "sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 70s (aws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 cp --recursive /shared/CSHL_data_processed/MD635/MD635_alignedTo_MD635-F63-2016.05.19-08.39.03_MD635_2_0188_masks_cropped s3://mousebrainatlas-data/CSHL_data_processed/MD635/MD635_alignedTo_MD635-F63-2016.05.19-08.39.03_MD635_2_0188_masks_cropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "2.25 seconds.\n"
     ]
    }
   ],
   "source": [
    "upload_to_s3(output_dir, is_dir=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- Run `extract_test_features_cnn.ipynb` on workstation.\n",
    "- Upload to extracted features to S3.\n",
    "- Continue with `learning/pipeline_aws.ipynb`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
