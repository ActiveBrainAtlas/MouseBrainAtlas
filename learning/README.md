This folder contains code related to learning texture detectors. This include extracting patches, transforming to feature vectors, and training classifiers.


## Naming Convention ##

A classifier is uniquely determined by (1) training set and (2) model.
The training set further depends on (a) feature extractor (b) the positive/negative patch selection strategy ( c) the image type (stain protocol etc.) and (d) the structure name.
Therefore the name of a classifier is composed of five parts: `[stain_type]_[structure_name]_[network_name]_[patch_strategy]_[model]`.
This can be shortened into `[stain_type]_[structure_name]_classifier` once the other parameters are fixed after experiments. For example `Nissl_7N_Sat16ClassFinetunedV2_1_LR` becomes `Nissl_7N_classifier`.

Each classifier has its own folder under `$CLF_ROOTDIR`.


## Training/Test Set Settings ##

1:
- Feature generated by neural network `Sat16ClassFinetunedV2`
- Patch labels include: `X`, `X_surround_[margin]_noclass`, `X_surround_[margin]_Y`, `noclass`
- margin = [100,200,300,400,5,6,7,8,9,1000]
- Image type: `Nissl`
- 3000 per label = 1000 per label per stack x 3 stacks (MD585, MD589, MD594)

2:
- Feature generated by neural network `Sat16ClassFinetunedV2`
- Patch labels include: `X`, `X_surround_[margin]_noclass`, `X_surround_[margin]_Y`, `noclass`
- margin = [200,500]
- Image type: `Nissl`
- 300 per label = 100 per label per stack x 3 stacks (MD585, MD589, MD594)


## Classifier Settings ##

1: negatives are surrounding patches that are not of other positive classes
LogisticRegression(penalty='l2')
margin = 500
Training set = 1
train: 0.88, test acc: 0.84

2: negatives are surrounding patches (margin=500) that include other positive classes
LogisticRegression(penalty='l2')
margin = 500
Training set = 1
train .87, test acc: 0.818

3: negatives are surrounding patches that are not of other positive classes
SVC(kernel='linear')
# Slow - train acc: 0.69, test acc: 0.68
margin = 500
Training set = 1

4: negatives are surrounding patches that are not of other positive classes
LinearSVC(kernel='linear') + CalibratedClassifierCV
# train 0.75, test 0.74
margin = 500
Training set = 1

5: negatives are surrounding patches that are not of other positive classes
XGBClassifier
# http://xgboost.readthedocs.io/en/latest/python/python_api.html
margin = 500
Training set = 1

6: negatives are surrounding patches that are not of other positive classes
sklearn.ensemble.GradientBoostingClassifier, max_depth=3, n_estimators=200
# acc: 0.96/0.85
# http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html
margin = 500
Training set = 1

7: negatives are surrounding patches that are not of other positive classes
sklearn.ensemble.GradientBoostingClassifier, max_depth=5, n_estimators=100
# acc: 0.98/0.87
# http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html
margin = 500
Training set = 1

8: negatives are all outside patches, including other positive classes
LogisticRegression(penalty='l2')
Training set = 1

9: negatives are all outside patches, including other positive classes, weighted according to distance to the center of
the structure of interest.
All surrounds are used as negative, other outside patches are randomly sampled to be negative.
LogisticRegression(penalty='l2')
thresh = 1500
def diminishing(x):
   return np.exp(-(x-thresh)/3000.)
Training set = 1
margin = 500

## Timing ##

Applying classifier: 4 min
Interpolate: 40 min
- each section (x 250): 120s
  - preprocess: 3s
  - evaluate spline (x 28): 5s for shrink=4; doubling shrink reduces time quadratically
  - upscale (x 28): 10s
  - save to hdf (x 28): 4s
Generate score map visualization: 15 min


## Feature extraction ##

`extract_test_features_dnn.ipynb` runs on the Workstation equipped with GPU. It calls MXNet to compute features for patches through forward pass over a deep neural network.

The generated features are place in `PATCH_FEATURES_ROOTDIR`. By default this is
`/media/yuncong/BstemAtlasData/CSHL_patch_features_Sat16ClassFinetuned_v2`.
The
`<stack>/<fn>_lossless_alignedTo_<anchor_fn>_cropped`. The features as n x 1024 array are stored in `<fn>_lossless_alignedTo_<anchor_fn>_cropped_features.hdf`. The locations of corresponding n patches are stored in `<fn>_lossless_alignedTo_<anchor_fn>_cropped_patch_locations.txt`.

This step takes 80 seconds per section (~25k patches).

## Train ##

Code for training classifiers is in `train_classifier_v2.ipynb`.
It works for both regular nissl and Neurotrace blue.

Store in `SVM_DIR`. By default this is `CSHL_patch_features_Sat16ClassFinetuned_v2_classifiers`. The classifiers are `<label>_svm.pkl`.

`Cluster executable`
`svm_v2.py`

Performance of trained classifiers can be visually analyzed in `test_classifier_performance.ipynb`.

We tried different versions of training dataset.
Testing uses inside vs. all surround

## Pipeline ##

The pipeline takes as input a stack whose DNN features are available.
It goes through the following stages:
- apply classifiers, generate score volumes
- global alignment with atlas
- local alignment with atlas

The pipeline can be controlled by `pipeline_features_to_scoremaps.ipynb`. It launches the proper
executable for each task on the computing cluster.

## Predict ##

Run `svm_v2.ipynb`

Load pre-trained classifiers. Apply every classifier to every feature file.

Predicted sparse scores are stored in `PREDICTIONS_ROOTDIR`.
By default this is `CSHL_patch_Sat16ClassFinetuned_v2_predictions`.

Under `<stack>/<fn>_lossless_alignedTo_<anchor_fn>_cropped`,
each sparse score file, as n x 1 array, is `<fn>_lossless_alignedTo_<anchor_fn>_cropped_<label>_sparseScores.hdf`

This step takes 900 seconds per stack.

## Interpolate ##

Run `interpolated_scoremaps_v2_distributed.ipynb`.

Script is `interpolated_scoremaps_v2.py`.
`interpolated_scoremaps_v2.py stack first_sec last_sec`.

Dense scoremaps are stored in `SCOREMAPS_ROOTDIR`. By default `CSHL_lossless_scoremaps_Sat16ClassFinetuned_v2`.
Under `<stack>/<fn>_lossless_alignedTo_<anchor_fn>_cropped`,
each dense score file is `<fn>_lossless_alignedTo_<anchor_fn>_cropped_<label>_denseScoreMap.hdf`,
and associated bounding box file `<fn>_lossless_alignedTo_<anchor_fn>_cropped_<label>_denseScoreMap_interpBox.txt`.

This step takes ? seconds per stack.

## Visualize ##

Run `visualize_scoremaps_v2_distributed.ipynb`.

Script is `visualize_scoremaps_v2.py`
`visualize_scoremaps_v2.py stack -b first_sec -e last_sec -a`

Score map visualizations are stored in `SCOREMAPVIZ_ROOTDIR`.
By default is `CSHL_scoremap_viz_Sat16ClassFinetuned_v2`.

Under `<label>/<stack>/<fn>_alignedTo_<anchor_fn>_scoremapViz_<label>.jpg`.

This step takes 500 seconds per stack.


## Evaluation / Analysis ##

The algorithm's goal is texture classification. The tasks are to separate textures inside a structure from textures outside the structure. Because we already have a strong location prior, we don't need strong texture score signal at places far from the structure's true location, so we take as negative examples only textures at the surrounding of the structure.

If annotations are available, we can compute the true positive, true negative, false positive and false negative rates of classifying each structure. We plot ACC as a function of the margin of the surrounding where negative samples are collected.
