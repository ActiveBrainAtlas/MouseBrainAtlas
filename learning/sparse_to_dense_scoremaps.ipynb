{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.environ['REPO_DIR'] + '/utilities')\n",
    "from utilities2015 import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = ['BackG', '5N', '7n', '7N', '12N', 'Pn', 'VLL', \n",
    "          '6N', 'Amb', 'R', 'Tz', 'RtTg', 'LRt', 'LC', 'AP', 'sp5']\n",
    "\n",
    "label_dict = dict([(l,i) for i, l in enumerate(labels)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.interpolate import RectBivariateSpline\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patches_rootdir = '/home/yuncong/CSHL_data_patches'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scoremaps_rootdir = '/home/yuncong/CSHL_scoremaps_lossless_inceptionModel'\n",
    "scoremaps_rootdir = '/oasis/projects/nsf/csd395/yuncong/CSHL_scoremaps_lossless_svm'\n",
    "if not os.path.exists(scoremaps_rootdir):\n",
    "    os.makedirs(scoremaps_rootdir)\n",
    "    \n",
    "# predictions_rootdir = '/home/yuncong/CSHL_patch_predictions_inceptionModel'\n",
    "predictions_rootdir = '/oasis/projects/nsf/csd395/yuncong/CSHL_patch_predictions_svm'\n",
    "if not os.path.exists(predictions_rootdir):\n",
    "    os.makedirs(predictions_rootdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "preprocess: 0.63 seconds\n",
      "interpolate: 18.00 seconds\n",
      "preprocess: 0.65 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No 6N is detected on section 133\n",
      "interpolate: 17.70 seconds\n",
      "preprocess: 0.70 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No 6N is detected on section 134\n",
      "interpolate: 16.91 seconds\n",
      "preprocess: 0.80 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No 6N is detected on section 135\n",
      "No 7n is detected on section 135\n",
      "No 12N is detected on section 135\n",
      "interpolate: 17.92 seconds\n",
      "preprocess: 0.48 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No 6N is detected on section 136\n",
      "interpolate: 17.90 seconds\n",
      "preprocess: 0.75 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No 6N is detected on section 137\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-8af4de682de8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m         \u001b[1;31m# if too many disk saves are simultaneous, they will be conflicting, so split into two sessions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m         \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerate_score_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m         \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerate_score_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/oasis/projects/nsf/csd181/yuncong/virtualenv-1.9.1/yuncongve/lib/python2.7/site-packages/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    808\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 810\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    811\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    812\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/oasis/projects/nsf/csd181/yuncong/virtualenv-1.9.1/yuncongve/lib/python2.7/site-packages/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m                     \u001b[1;31m# a working pool as they expect.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize_pool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 757\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    758\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    759\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# for stack in ['MD589']:\n",
    "for stack in ['MD585']:\n",
    "# for stack in ['MD585', 'MD593', 'MD592', 'MD590', 'MD591', 'MD595', 'MD598', 'MD602', 'MD594]:\n",
    "# for stack in ['MD585', 'MD593', 'MD592', 'MD590']:\n",
    "    \n",
    "    first_bs_sec, last_bs_sec = section_range_lookup[stack]\n",
    "\n",
    "    table_filepath = os.path.join(patches_rootdir, '%(stack)s_indices_allROIs_allSections.h5'%{'stack':stack})\n",
    "    indices_allROIs_allSections = pd.read_hdf(table_filepath, 'indices_allROIs_allSections')\n",
    "    grid_parameters = pd.read_hdf(table_filepath, 'grid_parameters')\n",
    "\n",
    "    patch_size, stride, w, h = grid_parameters.tolist()\n",
    "    half_size = patch_size/2\n",
    "\n",
    "    ys, xs = np.meshgrid(np.arange(half_size, h-half_size, stride), np.arange(half_size, w-half_size, stride),\n",
    "                     indexing='xy')\n",
    "\n",
    "    sample_locations = np.c_[xs.flat, ys.flat]\n",
    "    \n",
    "    first_detect_sec, last_detect_sec = detect_bbox_range_lookup[stack]\n",
    "\n",
    "    for sec in range(first_detect_sec, last_detect_sec+1):\n",
    "\n",
    "        if sec not in indices_allROIs_allSections.columns:\n",
    "            continue\n",
    "\n",
    "        print sec\n",
    "\n",
    "        indices_roi = indices_allROIs_allSections[sec]['roi1']\n",
    "\n",
    "        predictions_dir = os.path.join(predictions_rootdir, stack, '%04d'%sec)\n",
    "        if not os.path.exists(predictions_dir):\n",
    "            os.makedirs(predictions_dir)\n",
    "\n",
    "        scoremaps_dir = os.path.join(scoremaps_rootdir, stack, '%04d'%sec)\n",
    "        if not os.path.exists(scoremaps_dir):\n",
    "            os.makedirs(scoremaps_dir)\n",
    "\n",
    "        ## define grid, generate patches\n",
    "\n",
    "        t = time.time()\n",
    "\n",
    "        sample_locations_roi = sample_locations[indices_roi]\n",
    "        \n",
    "        ## interpolate\n",
    "        \n",
    "        interpolation_xmin, interpolation_ymin = sample_locations_roi.min(axis=0)\n",
    "        interpolation_xmax, interpolation_ymax = sample_locations_roi.max(axis=0)\n",
    "        interpolation_w = interpolation_xmax - interpolation_xmin + 1\n",
    "        interpolation_h = interpolation_ymax - interpolation_ymin + 1\n",
    "\n",
    "        ##### sample_locations_roi + scores to dense_score_map #####\n",
    "\n",
    "        shrink_factor = 4 # do interpolation on a smaller grid, then resize to original dimension\n",
    "\n",
    "        sample_locations_unique_xs = np.unique(sample_locations_roi[:,0])\n",
    "        sample_locations_unique_ys = np.unique(sample_locations_roi[:,1])\n",
    "\n",
    "        n_sample_x = sample_locations_unique_xs.size\n",
    "        n_sample_y = sample_locations_unique_ys.size\n",
    "\n",
    "        index_x = dict([(j,i) for i,j in enumerate(sample_locations_unique_xs)])\n",
    "        index_y = dict([(j,i) for i,j in enumerate(sample_locations_unique_ys)])\n",
    "        sample_location_indices = np.asarray([(index_x[x], index_y[y]) for x, y in sample_locations_roi])\n",
    "\n",
    "        sample_locations_interpolatedArea_ys_matrix, \\\n",
    "        sample_locations_interpolatedArea_xs_matrix = np.meshgrid(range(interpolation_ymin/shrink_factor, \n",
    "                                                                        interpolation_ymax/shrink_factor), \n",
    "                                                                  range(interpolation_xmin/shrink_factor, \n",
    "                                                                        interpolation_xmax/shrink_factor), \n",
    "                                                                  indexing='ij')\n",
    "        \n",
    "        dataset = '%(stack)s_%(sec)04d_roi1' % {'stack': stack, 'sec': sec}\n",
    "    \n",
    "        probs_allClasses = dict([(label, np.load(predictions_dir + '/%(dataset)s_%(label)s_scores.npy' % \\\n",
    "                                                 {'dataset': dataset, 'label': label}))\n",
    "                                 for label in labels[1:]])\n",
    "\n",
    "        sys.stderr.write('preprocess: %.2f seconds\\n' % (time.time() - t))\n",
    "        \n",
    "        def generate_score_map(label):\n",
    "\n",
    "            if label == 'BackG':\n",
    "                return None\n",
    "            \n",
    "#             probs = np.load(predictions_dir + '/%(dataset)s_%(label)s_scores.npy'% {'dataset': dataset, 'label': label})\n",
    "#             probs = probs_allClasses[label]\n",
    "            \n",
    "            score_matrix = np.zeros((n_sample_x, n_sample_y))\n",
    "            score_matrix[sample_location_indices[:,0], sample_location_indices[:,1]] = probs_allClasses[label]\n",
    "\n",
    "            spline = RectBivariateSpline(sample_locations_unique_xs/shrink_factor, \n",
    "                                         sample_locations_unique_ys/shrink_factor, \n",
    "                                         score_matrix, \n",
    "                                         bbox=[interpolation_xmin/shrink_factor, \n",
    "                                               interpolation_xmax/shrink_factor, \n",
    "                                               interpolation_ymin/shrink_factor, \n",
    "                                               interpolation_ymax/shrink_factor])\n",
    "\n",
    "#             t = time.time()\n",
    "            dense_score_map = spline.ev(sample_locations_interpolatedArea_xs_matrix, \n",
    "                                        sample_locations_interpolatedArea_ys_matrix)\n",
    "#             sys.stderr.write('evaluate spline: %.2f seconds\\n' % (time.time() - t))\n",
    "            \n",
    "#             t = time.time()\n",
    "            dense_score_map = resize(dense_score_map, (interpolation_h, interpolation_w)) # similar speed as rescale\n",
    "#             dense_score_map = rescale(dense_score_map, shrink_factor)\n",
    "#             sys.stderr.write('scale up: %.2f seconds\\n' % (time.time() - t))\n",
    "\n",
    "#             t = time.time()\n",
    "            dense_score_map[dense_score_map < 1e-1] = 0\n",
    "#             sys.stderr.write('threshold: %.2f seconds\\n' % (time.time() - t))\n",
    "\n",
    "            if np.count_nonzero(dense_score_map) < 1e5:\n",
    "                sys.stderr.write('No %s is detected on section %d\\n' % (label, sec))\n",
    "                return None\n",
    "            \n",
    "#             t = time.time()\n",
    "#             bp.pack_ndarray_file(dense_score_map.astype(np.float32), \n",
    "#                                    os.path.join(scoremaps_dir, '%(dataset)s_denseScoreMapLossless_%(label)s.bp' % \\\n",
    "#                                                 {'dataset': dataset, 'label': label}))\n",
    "            save_hdf(dense_score_map.astype(np.float16), \n",
    "                     os.path.join(scoremaps_dir, '%(dataset)s_denseScoreMapLossless_%(label)s.hdf' % \\\n",
    "                                                {'dataset': dataset, 'label': label}),\n",
    "                    complevel=5)\n",
    "#             sys.stderr.write('save: %.2f seconds\\n' % (time.time() - t))\n",
    "    \n",
    "            np.savetxt(os.path.join(scoremaps_dir, '%(dataset)s_denseScoreMapLossless_%(label)s_interpBox.txt' % \\\n",
    "                                        {'dataset': dataset, 'label': label}),\n",
    "                   np.array((interpolation_xmin, interpolation_xmax, interpolation_ymin, interpolation_ymax))[None], \n",
    "                   fmt='%d')\n",
    "        \n",
    "        t = time.time()\n",
    "\n",
    "        # if too many disk saves are simultaneous, they will be conflicting, so split into two sessions\n",
    "        _ = Parallel(n_jobs=16)(delayed(generate_score_map)(l) for l in labels[1:len(labels)/2])\n",
    "        _ = Parallel(n_jobs=16)(delayed(generate_score_map)(l) for l in labels[len(labels)/2:])\n",
    "\n",
    "        sys.stderr.write('interpolate: %.2f seconds\\n' % (time.time() - t)) # ~20 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
