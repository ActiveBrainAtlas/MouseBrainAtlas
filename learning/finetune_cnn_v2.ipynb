{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No vtk\n",
      "File does not exist: /media/yuncong/BstemAtlasData/CSHL_data_processed//MD653/MD653_anchor.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting environment for Precision WorkStation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File does not exist: /media/yuncong/BstemAtlasData/CSHL_data_processed//MD653/MD653_sorted_filenames.txt\n",
      "File does not exist: /media/yuncong/BstemAtlasData/CSHL_data_processed//MD653/MD653_cropbox.txt\n",
      "File does not exist: /media/yuncong/BstemAtlasData/CSHL_data_processed//MD653/MD653_cropbox.txt\n",
      "File does not exist: /media/yuncong/BstemAtlasData/CSHL_data_processed//MD652/MD652_anchor.txt\n",
      "File does not exist: /media/yuncong/BstemAtlasData/CSHL_data_processed//MD652/MD652_sorted_filenames.txt\n",
      "File does not exist: /media/yuncong/BstemAtlasData/CSHL_data_processed//MD652/MD652_cropbox.txt\n",
      "File does not exist: /media/yuncong/BstemAtlasData/CSHL_data_processed//MD652/MD652_cropbox.txt\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "sys.path.append(os.environ['REPO_DIR'] + '/utilities')\n",
    "from utilities2015 import *\n",
    "from metadata import *\n",
    "from data_manager import *\n",
    "from learning_utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "structures_to_sample = all_known_structures\n",
    "\n",
    "negative_labels_to_sample = [s + '_negative' for s in structures_to_sample]\n",
    "\n",
    "margins_to_sample = [200, 500]\n",
    "surround_labels_to_sample = [convert_to_surround_name(s, margin=m, suffix=surr_l) \n",
    "                             for m in margins_to_sample\n",
    "                             for s in structures_to_sample \n",
    "                             for surr_l in structures_to_sample + ['noclass'] \n",
    "                             if surr_l != s]\n",
    "\n",
    "labels_to_sample = structures_to_sample + negative_labels_to_sample + surround_labels_to_sample + ['noclass']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_ROOTDIR = '/home/yuncong/mxnet_models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:24: DeprecationWarning: \u001b[91mmxnet.model.FeedForward has been deprecated. Please use mxnet.mod.Module instead.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# In order for input to be saturation channel of patches, only use the red channel in the first convolution layer.\n",
    "\n",
    "model_dir_name = 'inception-bn'\n",
    "model_name = 'Inception-BN'\n",
    "model_iteration = 126\n",
    "\n",
    "init_model = mx.model.FeedForward.load(os.path.join(MODEL_ROOTDIR, model_dir_name, model_name), \n",
    "                                       model_iteration, \n",
    "                                       ctx=mx.gpu())\n",
    "\n",
    "arg_params = init_model.arg_params.copy()\n",
    "arg_params.pop('fc1_bias');\n",
    "arg_params.pop('fc1_weight');\n",
    "arg_params['conv_1_weight'] = mx.ndarray.array(init_model.arg_params['conv_1_weight'].asnumpy()[:,[0],:,:])\n",
    "\n",
    "n_class = len(labels_to_sample)\n",
    "flatten_output = init_model.symbol.get_internals()['flatten_output']\n",
    "\n",
    "net = mx.model.FeedForward(ctx=mx.gpu(), \n",
    "                           symbol=flatten_output, \n",
    "                           num_epoch=0,\n",
    "                           arg_params = arg_params, \n",
    "                           aux_params = init_model.aux_params,\n",
    "                           allow_extra_params = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_model_dir_name = 'inception-bn-sat'\n",
    "new_model_name = 'inception-bn-sat'\n",
    "model_fp = os.path.join(MODEL_ROOTDIR, new_model_dir_name, new_model_name)\n",
    "create_parent_dir_if_not_exists(model_fp)\n",
    "net.save(model_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_img = mx.nd.load(os.path.join(MODEL_ROOTDIR, model_dir_name, 'mean_224.nd'))['mean_img'].asnumpy()[0]\n",
    "np.save(os.path.join(MODEL_ROOTDIR, new_model_dir_name, 'mean_224'), mean_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# initial model\n",
    "\n",
    "model_dir_name = 'inception-bn'\n",
    "model_name = 'Inception-BN'\n",
    "model_iteration = 126\n",
    "\n",
    "init_model = mx.model.FeedForward.load(os.path.join(MODEL_ROOTDIR, model_dir_name, model_name), \n",
    "                                       model_iteration, \n",
    "                                       ctx=mx.gpu())\n",
    "\n",
    "arg_params = init_model.arg_params.copy()\n",
    "arg_params.pop('fc1_bias');\n",
    "arg_params.pop('fc1_weight');\n",
    "arg_params['conv_1_weight'] = mx.ndarray.array(init_model.arg_params['conv_1_weight'].asnumpy()[:,[0],:,:])\n",
    "\n",
    "n_class = len(labels_to_sample)\n",
    "flatten_output = init_model.symbol.get_internals()['flatten_output']\n",
    "fc = mx.symbol.FullyConnected(data=flatten_output, name='fullc', num_hidden=n_class)\n",
    "softmax = mx.symbol.SoftmaxOutput(data=fc, name='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = mx.model.FeedForward(ctx=mx.gpu(), \n",
    "                           symbol=softmax, \n",
    "                           num_epoch=n_epoch, optimizer=opt,\n",
    "                           arg_params = arg_params, \n",
    "                           aux_params = init_model.aux_params,\n",
    "                           allow_extra_params = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_epoch = 10\n",
    "l_rate = 0.001\n",
    "checkpoint_prefix = os.path.join(MODEL_ROOTDIR, model_dir_name, 'Sat28ClassFinetuned')\n",
    "\n",
    "opt = mx.optimizer.SGD(learning_rate=l_rate)\n",
    "\n",
    "net = mx.model.FeedForward(ctx=mx.gpu(), \n",
    "                           symbol=softmax, \n",
    "                           num_epoch=n_epoch, optimizer=opt,\n",
    "                           arg_params = arg_params, \n",
    "                           aux_params = init_model.aux_params,\n",
    "                           allow_extra_params = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load training addresses\n",
    "training_addresses = load_pickle(os.path.join(CLF_ROOTDIR, 'datasets', 'dataset_%d' % dataset, 'patch_addresses.pkl'))\n",
    "training_addresses = {l: addrs for l, addrs in training_addresses.iteritems() if l in labels_to_sample}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_patches = {label: extract_patches_given_locations_multiple_sections(addresses[:10], \n",
    "                                                            location_or_grid_index='grid_index',\n",
    "                                                           version='compressed')\n",
    "                    for label, addresses in training_addresses.iteritems()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Below is half-finished ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for stack in ['MD642']:\n",
    "\n",
    "    print stack\n",
    "\n",
    "    section_to_filename = metadata_cache['sections_to_filenames'][stack]\n",
    "    anchor_fn = metadata_cache['anchor_fn'][stack]\n",
    "\n",
    "    image_width, image_height = metadata_cache['image_shape'][stack]\n",
    "    grid_spec = (patch_size, stride, image_width, image_height)\n",
    "\n",
    "    sample_locations = grid_parameters_to_sample_locations(grid_spec=grid_spec)\n",
    "\n",
    "    first_detect_sec, last_detect_sec = metadata_cache['section_limits'][stack]\n",
    "\n",
    "    bar = show_progress_bar(first_detect_sec, last_detect_sec)\n",
    "\n",
    "    for sec in range(first_detect_sec, last_detect_sec):\n",
    "        sat = imread(DataManager.get_image_filepath(stack=stack, section=sec, version='saturation'))\n",
    "    \n",
    "\n",
    "        t = time.time()\n",
    "\n",
    "    #         patches = np.array([sat[y-half_size:y+half_size, x-half_size:x+half_size].copy()\n",
    "    #                             for x, y in sample_locations_roi]) # n x 224 x 224\n",
    "\n",
    "        patches = np.array([sat[y-half_size:y+half_size, x-half_size:x+half_size]\n",
    "                            for x, y in sample_locations_roi]) # n x 224 x 224\n",
    "\n",
    "        patches_mean_subtracted = patches - mean_img\n",
    "\n",
    "        patches_mean_subtracted_input = patches_mean_subtracted[:, None, :, :] # n x 1 x 224 x 224\n",
    "        #         patches = np.rollaxis(patches2, 3, 1)\n",
    "\n",
    "        sys.stderr.write('extract, reshape, normalize: %.2f seconds\\n' % (time.time() - t)) # ~ 4s / 20k patches\n",
    "\n",
    "    #         batch_size = 256 # increasing to 500 does not save any time\n",
    "        batch_size = 16 # increasing to 500 does not save any time\n",
    "\n",
    "    data_iter = mx.io.NDArrayIter(\n",
    "        patches_mean_subtracted_input, \n",
    "        np.zeros((n, ), np.int), # labels are not important since it is just feed-forward\n",
    "        batch_size = batch_size,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    t = time.time()\n",
    "\n",
    "    features = model.fit(data_iter,\n",
    "                        batch_end_callback=mx.callback.Speedometer(batch_size, 30),\n",
    "                        epoch_end_callback=mx.callback.do_checkpoint(checkpoint_prefix))\n",
    "    net.save(checkpoint_prefix)\n",
    "\n",
    "    sys.stderr.write('predict: %.2f seconds\\n' % (time.time() - t))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
