{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.environ['REPO_DIR'] + '/utilities')\n",
    "from utilities2015 import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import mxnet as mx\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import time\n",
    "\n",
    "progress_bar = FloatProgress(min=0, max=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patches_rootdir = '/home/yuncong/CSHL_data_patches/'\n",
    "model_dir = '/home/yuncong/mxnet_models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = ['BackG', '5N', '7n', '7N', '12N', 'Pn', 'VLL', \n",
    "          '6N', 'Amb', 'R', 'Tz', 'RtTg', 'LRt', 'LC', 'AP', 'sp5']\n",
    "\n",
    "labels_index = dict((j, i) for i, j in enumerate(labels))\n",
    "\n",
    "labels_from_surround = dict( (l+'_surround', l) for l in labels[1:])\n",
    "\n",
    "labels_surroundIncluded_list = labels[1:] + [l+'_surround' for l in labels[1:]]\n",
    "labels_surroundIncluded = set(labels_surroundIncluded_list)\n",
    "\n",
    "labels_surroundIncluded_index = dict((j, i) for i, j in enumerate(labels_surroundIncluded_list))\n",
    "\n",
    "colors = np.random.randint(0, 255, (len(labels_index), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mean_img = mx.nd.load(os.path.join(model_dir, 'mean_224.nd'))['mean_img'].asnumpy()\n",
    "mean_img = np.load(model_dir + '/saturation_mean_224.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name = 'Sat16ClassFinetuned'\n",
    "model_iteration = 10\n",
    "\n",
    "model = mx.model.FeedForward.load(os.path.join(model_dir, model_name), model_iteration, ctx=mx.gpu())\n",
    "\n",
    "flatten_output = model.symbol.get_internals()['flatten_output']\n",
    "\n",
    "model = mx.model.FeedForward(ctx=mx.gpu(), symbol=flatten_output, num_epoch=model_iteration,\n",
    "                            arg_params=model.arg_params, aux_params=model.aux_params,\n",
    "                            allow_extra_params=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/yuncong/CSHL_patch_features_Sat16ClassFinetuned'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features_rootdir = '/home/yuncong/CSHL_patch_features_%(model_name)s' % {'model_name': model_name}\n",
    "create_if_not_exists(test_features_rootdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/yuncong/CSHL_data_saturation/'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat_rootdir = '/home/yuncong/CSHL_data_saturation/'\n",
    "create_if_not_exists(sat_rootdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_to_saturation(fn, out_fn, rescale=True):\n",
    "    \n",
    "    img = imread(fn)\n",
    "    \n",
    "    m = img/255.\n",
    "    ma = m.max(axis=-1)\n",
    "    mi = m.min(axis=-1)\n",
    "    s = (ma-mi)/ma\n",
    "    s = 1-s\n",
    "    \n",
    "    if rescale:\n",
    "        pmax = s.max()\n",
    "        pmin = s.min()\n",
    "        s = (s - pmin) / (pmax - pmin)\n",
    "    \n",
    "    sat = (s*255).astype(np.uint8)    \n",
    "    cv2.imwrite(out_fn, sat)\n",
    "    \n",
    "    del m, ma, mi, s, img, sat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "convert to saturation: 2303.44 seconds\n",
      "convert to saturation: 1654.70 seconds\n",
      "convert to saturation: 1149.62 seconds\n",
      "convert to saturation: 1929.48 seconds\n",
      "convert to saturation: 2364.96 seconds\n",
      "convert to saturation: 2462.03 seconds\n",
      "convert to saturation: 1822.06 seconds\n"
     ]
    }
   ],
   "source": [
    "for stack in ['MD602', 'MD592', 'MD585', 'MD590', 'MD591', 'MD595', 'MD598']:\n",
    "    dm = DataManager(stack=stack, data_dir='/media/yuncong/BstemAtlasData/CSHL_data_processed')\n",
    "\n",
    "    sat_dir = os.path.join(sat_rootdir, '%(stack)s_saturation' % {'stack': stack})\n",
    "    create_if_not_exists(sat_dir)\n",
    "\n",
    "    first_detect_sec, last_detect_sec = detect_bbox_range_lookup[stack]\n",
    "\n",
    "    fns = [dm._get_image_filepath(section=sec, version='rgb-jpg') \n",
    "           for sec in range(first_detect_sec, last_detect_sec+1)]\n",
    "\n",
    "    out_fns = [sat_dir + '/%(stack)s_%(sec)04d_sat.jpg' % {'stack': stack, 'sec': sec}\n",
    "               for sec in range(first_detect_sec, last_detect_sec+1)]\n",
    "\n",
    "    t = time.time()\n",
    "    Parallel(n_jobs=4)(delayed(convert_to_saturation)(fn, out_fn) for fn, out_fn in zip(fns, out_fns))\n",
    "    sys.stderr.write('convert to saturation: %.2f seconds\\n' % (time.time() - t)) # ~2500s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "get true labels: 0.00 seconds\n",
      "load saturation image: 1.66 seconds\n"
     ]
    }
   ],
   "source": [
    "for stack in ['MD593', 'MD602', 'MD592', 'MD585', 'MD590', 'MD591', 'MD595', 'MD598']:\n",
    "# for stack in ['MD589']:\n",
    "    \n",
    "    if stack in ['MD589', 'MD594']:\n",
    "        stack_has_annotation = True\n",
    "    else:\n",
    "        stack_has_annotation = False\n",
    "\n",
    "    dm = DataManager(stack=stack, data_dir='/media/yuncong/BstemAtlasData/CSHL_data_processed')\n",
    "\n",
    "    table_filepath = os.path.join(patches_rootdir, '%(stack)s_indices_allROIs_allSections.h5'%{'stack':stack})\n",
    "    indices_allROIs_allSections = pd.read_hdf(table_filepath, 'indices_allROIs_allSections')\n",
    "    grid_parameters = pd.read_hdf(table_filepath, 'grid_parameters')\n",
    "    \n",
    "    patch_size, stride, w, h = grid_parameters.tolist()\n",
    "    half_size = patch_size/2\n",
    "    ys, xs = np.meshgrid(np.arange(half_size, h-half_size, stride), np.arange(half_size, w-half_size, stride),\n",
    "                     indexing='xy')\n",
    "    sample_locations = np.c_[xs.flat, ys.flat]\n",
    "    \n",
    "    if stack_has_annotation:\n",
    "        table_filepath = os.path.join(patches_rootdir, '%(stack)s_indices_allLandmarks_allSections.h5'%{'stack':stack})\n",
    "        indices_allLandmarks_allSections = pd.read_hdf(table_filepath, 'indices_allLandmarks_allSections')\n",
    "\n",
    "    first_detect_sec, last_detect_sec = detect_bbox_range_lookup[stack]\n",
    "\n",
    "    progress_bar.min = first_detect_sec\n",
    "    progress_bar.max = last_detect_sec\n",
    "    display(progress_bar)\n",
    "    \n",
    "    for sec in range(first_detect_sec, last_detect_sec+1):\n",
    "#     for sec in range(first_detect_sec, first_detect_sec+10):\n",
    "#     for sec in range(first_detect_sec, first_detect_sec+1):\n",
    "        \n",
    "        if sec not in indices_allROIs_allSections.columns:\n",
    "            continue\n",
    "            \n",
    "        progress_bar.value = sec\n",
    "                \n",
    "        indices_roi = indices_allROIs_allSections[sec]['roi1']\n",
    "        \n",
    "        n = len(indices_roi)\n",
    "        print n, 'roi samples'\n",
    "        \n",
    "        ######################\n",
    "        t = time.time()\n",
    "        \n",
    "        true_labels = -1 * np.ones((99999,), np.int)\n",
    "        if stack_has_annotation:\n",
    "            if sec in indices_allLandmarks_allSections:\n",
    "                for l in indices_allLandmarks_allSections[sec].dropna().keys() & labels_surroundIncluded:\n",
    "                    true_labels[indices_allLandmarks_allSections[sec][l]] = labels_surroundIncluded_index[l]\n",
    "        patch_labels = true_labels[indices_roi]\n",
    "        \n",
    "        create_if_not_exists(test_features_rootdir + '/%(stack)s/%(sec)04d' % {'stack': stack, 'sec': sec})\n",
    "        np.save(test_features_rootdir + '/%(stack)s/%(sec)04d/%(stack)s_%(sec)04d_roi1_labels.npy' % \\\n",
    "                {'stack': stack, 'sec': sec}, \n",
    "                patch_labels)\n",
    "        \n",
    "        sys.stderr.write('get true labels: %.2f seconds\\n' % (time.time() - t)) # ~ 0s\n",
    "                \n",
    "        ######################\n",
    "        \n",
    "        sample_locations_roi = sample_locations[indices_roi]\n",
    "\n",
    "        t = time.time()\n",
    "        \n",
    "        sat = imread(sat_rootdir + '/%(stack)s_saturation/%(stack)s_%(sec)04d_sat.jpg' % {'stack': stack, 'sec': sec})\n",
    "            \n",
    "        sys.stderr.write('load saturation image: %.2f seconds\\n' % (time.time() - t)) # ~ 2s\n",
    "    \n",
    "        t = time.time()\n",
    "    \n",
    "        patches = np.array([sat[y-half_size:y+half_size, x-half_size:x+half_size]\n",
    "                            for x, y in sample_locations_roi]) # n x 224 x 224\n",
    "        patches = patches - mean_img\n",
    "        patches = patches[:, None, :, :] # n x 1 x 224 x 224\n",
    "#         patches = np.rollaxis(patches2, 3, 1)\n",
    "    \n",
    "        sys.stderr.write('extract, reshape, normalize: %.2f seconds\\n' % (time.time() - t)) # ~ 6s\n",
    "        \n",
    "        batch_size = 256 # increasing to 500 does not save any time\n",
    "\n",
    "        data_iter = mx.io.NDArrayIter(\n",
    "            patches, \n",
    "            np.zeros((n, ), np.int), # labels are not important since it is just feed-forward\n",
    "            batch_size = batch_size,\n",
    "            shuffle=False\n",
    "        )\n",
    "\n",
    "        t = time.time()\n",
    "\n",
    "        features = model.predict(data_iter)\n",
    "        \n",
    "        sys.stderr.write('predict: %.2f seconds\\n' % (time.time() - t)) # ~40s\n",
    "        \n",
    "        t = time.time()\n",
    "        \n",
    "        save_hdf(features, test_features_rootdir + '/%(stack)s/%(sec)04d/%(stack)s_%(sec)04d_roi1_features.hdf' % \\\n",
    "                 {'stack': stack, 'sec': sec})\n",
    "        \n",
    "        sys.stderr.write('save: %.2f seconds\\n' % (time.time() - t)) # ~.5s\n",
    "        \n",
    "        del sat, patches, sample_locations_roi, features\n",
    "                \n",
    "    del sample_locations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# serial version\n",
    "\n",
    "dm = DataManager(stack=stack)\n",
    "\n",
    "sat_dir = os.path.join(sat_rootdir, '%(stack)s_saturation' % {'stack': stack})\n",
    "create_if_not_exists(sat_dir)\n",
    "\n",
    "first_detect_sec, last_detect_sec = detect_bbox_range_lookup[stack]\n",
    "\n",
    "progress_bar.min = first_detect_sec\n",
    "progress_bar.max = last_detect_sec\n",
    "display(progress_bar)\n",
    "\n",
    "for sec in range(first_detect_sec, last_detect_sec+1, 10):\n",
    "\n",
    "    progress_bar.value = sec\n",
    "    \n",
    "    dm.set_slice(sec)\n",
    "    dm._load_image(['rgb-jpg'])\n",
    "\n",
    "    m = dm.image_rgb_jpg/255.\n",
    "    ma = m.max(axis=-1)\n",
    "    mi = m.min(axis=-1)\n",
    "    s = (ma-mi)/ma\n",
    "    s = 1-s\n",
    "    \n",
    "    pmax = s.max()\n",
    "    pmin = s.min()\n",
    "    s = (s - pmin) / (pmax - pmin)\n",
    "    \n",
    "    sat = (s*255).astype(np.uint8)\n",
    "    \n",
    "    cv2.imwrite(sat_dir + '/%(stack)s_%(sec)04d_sat.jpg' % {'stack': stack, 'sec': sec}, sat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
