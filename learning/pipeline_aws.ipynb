{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting environment for AWS compute node\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No vtk\n",
      "File does not exist: /shared/CSHL_data_processed/MD635/MD635_anchor.txt\n",
      "File does not exist: /shared/CSHL_data_processed/MD635/MD635_sorted_filenames.txt\n",
      "File does not exist: /shared/CSHL_data_processed/MD635/MD635_cropbox.txt\n",
      "File does not exist: /shared/CSHL_data_processed/MD635/MD635_cropbox.txt\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "sys.path.append(os.path.join(os.environ['REPO_DIR'], 'utilities'))\n",
    "from data_manager import *\n",
    "from metadata import *\n",
    "from distributed_utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier_id = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack = 'MD657'\n",
    "first_sec, last_sec = metadata_cache['section_limits'][stack]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting autoscaling group cfncluster-yuncongCluster-ComputeFleet-97ZCW4B5F7TH capaticy to 16...it may take more than 5 minutes for SGE to know new hosts.\n"
     ]
    }
   ],
   "source": [
    "request_compute_nodes(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.50 seconds.\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/shared/MouseBrainAtlas/learning/resample_scoremaps_v3.py\", line 80, in <module>\r\n",
      "    pool.map(resample, range(first_sec, last_sec+1))\r\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/multiprocess/pool.py\", line 251, in map\r\n",
      "    return self.map_async(func, iterable, chunksize).get()\r\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/multiprocess/pool.py\", line 567, in get\r\n",
      "    raise self._value\r\n",
      "IOError: [Errno 2] No such file or directory: '/shared/CSHL_patch_features/Inception-BN/MD657/MD657-F16-2017.02.17-21.02.17_MD657_3_0048_lossless_alignedTo_MD657-F44-2017.02.18-06.06.27_MD657_1_0130_cropped/MD657-F16-2017.02.17-21.02.17_MD657_3_0048_lossless_alignedTo_MD657-F44-2017.02.18-06.06.27_MD657_1_0130_cropped_patch_locations.txt'\r\n",
      "Child returned 0\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File does not exist: /shared/CSHL_data_processed/MD635/MD635_anchor.txt\n",
      "File does not exist: /shared/CSHL_data_processed/MD635/MD635_sorted_filenames.txt\n",
      "File does not exist: /shared/CSHL_data_processed/MD635/MD635_cropbox.txt\n",
      "File does not exist: /shared/CSHL_data_processed/MD635/MD635_cropbox.txt\n"
     ]
    }
   ],
   "source": [
    "! tail /home/ubuntu/stderr_1.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File does not exist: /shared/CSHL_data_processed/MD635/MD635_anchor.txt\n",
      "File does not exist: /shared/CSHL_data_processed/MD635/MD635_sorted_filenames.txt\n",
      "File does not exist: /shared/CSHL_data_processed/MD635/MD635_cropbox.txt\n",
      "File does not exist: /shared/CSHL_data_processed/MD635/MD635_cropbox.txt\n",
      "running svm classifier ...16 nodes requested, 16 nodes available...Continuing\n",
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "qsub returned.\n",
      "done in 503.098089 seconds\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "sys.stderr.write('running svm classifier ...')\n",
    "\n",
    "run_distributed(command='%(script_path)s %(stack)s %%(first_sec)d %%(last_sec)d %(setting)d' % \\\n",
    "                {'script_path': os.path.join(REPO_DIR, 'learning', 'apply_classifiers_v3.py'),\n",
    "                'stack': stack,\n",
    "                'setting': classifier_id},\n",
    "                kwargs_list=dict(sections=range(first_sec, last_sec+1)),\n",
    "                argument_type='partition',\n",
    "               cluster_size=16,\n",
    "               jobs_per_node=1)\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 302s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resampling scoremaps ...16 nodes requested, 16 nodes available...Continuing\n",
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "qsub returned.\n",
      "done in 80.844207 seconds\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "sys.stderr.write('Resampling scoremaps ...')\n",
    "\n",
    "# downscale = 8\n",
    "downscale = 32\n",
    "\n",
    "run_distributed(command='%(script_path)s %(stack)s %%(first_sec)d %%(last_sec)d %(setting)d %(downscale)d' % \\\n",
    "                {'script_path': os.path.join(REPO_DIR, 'learning', 'resample_scoremaps_v3.py'),\n",
    "                'stack': stack,\n",
    "                'setting': classifier_id,\n",
    "                'downscale': downscale},\n",
    "                kwargs_list=dict(sections=range(first_sec, last_sec+1)),\n",
    "                argument_type='partition',\n",
    "                cluster_size=16)\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 277s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "visualize scoremaps ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting autoscaling group cfncluster-yuncongCluster-ComputeFleet-97ZCW4B5F7TH capaticy to 16...it may take more than 5 minutes for SGE to know new hosts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16 nodes requested, 15 nodes available...Continuing\n",
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "qsub returned.\n",
      "done in 76.672999 seconds\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "sys.stderr.write('visualize scoremaps ...')\n",
    "\n",
    "add_label_text = False\n",
    "# viz_downscale = 8\n",
    "viz_downscale = 32\n",
    "\n",
    "run_distributed(command='%(script_path)s %(stack)s %(setting)d -b %%(first_sec)d -e %%(last_sec)d -d %(downscale)d %(add_label_text)s' % \\\n",
    "                {'script_path': os.path.join(REPO_DIR, 'learning', 'visualize_scoremaps_v3.py'),\n",
    "                'stack': stack,\n",
    "                 'setting': classifier_id,\n",
    "                'add_label_text': '-a' if add_label_text else '',\n",
    "                'downscale': viz_downscale},\n",
    "                kwargs_list=dict(sections=range(first_sec, last_sec+1)),\n",
    "                argument_type='partition',\n",
    "                cluster_size=16)\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "sys.stderr.write('done in %f seconds\\n' % (time.time() - t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "constructing score volumes ...16 nodes requested, 16 nodes available...Continuing\n",
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "qsub returned.\n",
      "done in 116.025840 seconds\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "sys.stderr.write('constructing score volumes ...')\n",
    "\n",
    "volume_downscale = 32\n",
    "\n",
    "if stack in all_alt_nissl_ntb_stacks or stack in all_alt_nissl_tracing_stacks:\n",
    "\n",
    "    run_distributed(command='%(script_path)s %(stack)s %%(structure)s %(setting)d %(downscale)d -n' % \\\n",
    "                    {'script_path': os.path.join(REPO_DIR, 'reconstruct', 'construct_score_volume_v4.py'),\n",
    "                    'stack': stack,\n",
    "                    'setting': classifier_id,\n",
    "                    'downscale': volume_downscale},\n",
    "                    kwargs_list=dict(structure=all_known_structures),\n",
    "                    argument_type='single',\n",
    "                    cluster_size=16)\n",
    "\n",
    "else:\n",
    "    \n",
    "    run_distributed(command='%(script_path)s %(stack)s %%(structure)s %(setting)d %(downscale)d' % \\\n",
    "                    {'script_path': os.path.join(REPO_DIR, 'reconstruct', 'construct_score_volume_v4.py'),\n",
    "                    'stack': stack,\n",
    "                    'setting': classifier_id,\n",
    "                    'downscale': volume_downscale},\n",
    "                    kwargs_list=dict(structure=all_known_structures),\n",
    "                    argument_type='single',\n",
    "                    cluster_size=16)\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "sys.stderr.write('done in %f seconds\\n' % (time.time() - t))# 116s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File does not exist: /shared/CSHL_data_processed/MD635/MD635_anchor.txt\n",
      "File does not exist: /shared/CSHL_data_processed/MD635/MD635_sorted_filenames.txt\n",
      "File does not exist: /shared/CSHL_data_processed/MD635/MD635_cropbox.txt\n",
      "File does not exist: /shared/CSHL_data_processed/MD635/MD635_cropbox.txt\n",
      "compute score volume gradients...16 nodes requested, 16 nodes available...Continuing\n",
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "qsub returned.\n",
      "done in 70.765559 seconds\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "sys.stderr.write('compute score volume gradients...')\n",
    "\n",
    "run_distributed(command='ROOT_DIR=/scratch/ %(script_path)s %(stack)s %%(structure)s %(setting)d %(downscale)d' % \\\n",
    "                {'script_path': os.path.join(REPO_DIR, 'reconstruct', 'compute_score_volume_gradients_v4.py'),\n",
    "                'stack': stack,\n",
    "                'setting': classifier_id,\n",
    "                'downscale': volume_downscale},\n",
    "                kwargs_list=dict(structure=all_known_structures),\n",
    "                argument_type='single',\n",
    "                cluster_size=16,\n",
    "               jobs_per_node=1)\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) \n",
    "\n",
    "# 55 seconds (16 nodes write to respective local /scratch)\n",
    "# More than 1 simul. processes are not beneficial as they cause local write contention.\n",
    "# 156 seconds (16 nodes simul. write to /shared)\n",
    "# 310 seconds (single node, sequential write to /shared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier_id = 2\n",
    "warp_setting = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Align\n",
    "\n",
    "t = time.time()\n",
    "sys.stderr.write('align all subjects to atlas ...')\n",
    "\n",
    "run_distributed(command='%(script_path)s %%(stack)s atlasV2 %(warp_setting)d %(clf_setting)d' % \\\n",
    "                {'script_path': os.path.join(REPO_DIR, 'registration', 'global_registration_v3.py'),\n",
    "                'warp_setting': warp_setting,\n",
    "                'clf_setting': classifier_setting},\n",
    "#                 kwargs_list=dict(stack=all_nissl_stacks),\n",
    "                 kwargs_list=dict(stack=['MD591']),\n",
    "                argument_type='single')\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "\n",
    "sys.stderr.write('done in %f seconds\\n' % (time.time() - t))  # 1000 seconds ~ 20 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transform\n",
    "\n",
    "t = time.time()\n",
    "sys.stderr.write('transform atlas ...')\n",
    "\n",
    "run_distributed4(command='%(script_path)s %%(stack)s atlasV2 %(warp_setting)d %(clf_setting)d' % \\\n",
    "                {'script_path': os.path.join(os.environ['REPO_DIR'], 'registration', 'transform_brains_v3_global.py'),\n",
    "                'warp_setting': warp_setting,\n",
    "                'clf_setting': classifier_setting},\n",
    "#                 kwargs_list=dict(stack=all_nissl_stacks),\n",
    "                 kwargs_list=dict(stack=['MD642']),\n",
    "                exclude_nodes=exclude_nodes,\n",
    "                argument_type='single')\n",
    "\n",
    "sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 150 seconds, 300 for with surrounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visualize\n",
    "\n",
    "t = time.time()\n",
    "sys.stderr.write('visualize aligned atlas overlay ...')\n",
    "\n",
    "run_distributed4(command='%(script_path)s %%(stack)s atlasV2 %(warp_setting)d %(clf_setting)d' % \\\n",
    "                {'script_path': os.path.join(os.environ['REPO_DIR'], 'registration', 'visualize_registration_v3.py'),\n",
    "                'clf_setting': classifier_setting,\n",
    "                 'warp_setting': warp_setting},\n",
    "#                  kwargs_list=dict(stack=all_nissl_stacks),\n",
    "                 kwargs_list=dict(stack=['MD642']),\n",
    "                exclude_nodes=exclude_nodes,\n",
    "                argument_type='single')\n",
    "\n",
    "sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 625 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File does not exist: /shared/CSHL_data_processed/MD642/MD642_anchor.txt\r\n",
      "File does not exist: /shared/CSHL_data_processed/MD642/MD642_sorted_filenames.txt\r\n",
      "File does not exist: /shared/CSHL_data_processed/MD642/MD642_cropbox.txt\r\n",
      "File does not exist: /shared/CSHL_data_processed/MD642/MD642_cropbox.txt\r\n",
      "File does not exist: /shared/CSHL_data_processed/MD657/MD657_anchor.txt\r\n",
      "File does not exist: /shared/CSHL_data_processed/MD657/MD657_sorted_filenames.txt\r\n",
      "File does not exist: /shared/CSHL_data_processed/MD657/MD657_cropbox.txt\r\n",
      "File does not exist: /shared/CSHL_data_processed/MD657/MD657_cropbox.txt\r\n",
      "Gradient LC: 1.565091 seconds\r\n",
      "save LC: 46.780748 seconds\r\n"
     ]
    }
   ],
   "source": [
    "! tail /home/ubuntu/stderr_2.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
