{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import sys\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "sys.path.append(os.path.join(os.environ['REPO_DIR'], 'utilities'))\n",
    "from utilities2015 import *\n",
    "\n",
    "from matplotlib.path import Path\n",
    "%matplotlib inline\n",
    "\n",
    "import bloscpack as bp\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_dir = '/home/yuncong/csd395/CSHL_patch_features'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features_dir = '/home/yuncong/csd395/CSHL_patch_features/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = ['BackG', '5N', '7n', '7N', '12N', 'Pn', 'VLL', \n",
    "          '6N', 'Amb', 'R', 'Tz', 'RtTg', 'LRt', 'LC', 'AP', 'sp5']\n",
    "\n",
    "label_dict = dict([(l,i) for i, l in enumerate(labels)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack = 'MD589'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_allClasses_pos = {}\n",
    "features_allClasses_neg = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for label in labels:\n",
    "    if label == 'BackG':\n",
    "        continue\n",
    "    features_allClasses_pos[label] = bp.unpack_ndarray_file(train_features_dir + '/%(stack)s_%(label)s_features.bp' % {'stack': stack, 'label': label})\n",
    "    features_allClasses_neg[label] = bp.unpack_ndarray_file(train_features_dir + '/%(stack)s_%(label)s_surround_features.bp' % {'stack': stack, 'label': label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack = 'MD589'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.makedirs('svm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for label in labels:\n",
    "    \n",
    "    if label == 'BackG':\n",
    "        continue\n",
    "        \n",
    "    print label\n",
    "    \n",
    "    features_allClasses_pos = bp.unpack_ndarray_file(train_features_dir + '/%(stack)s_%(label)s_features.bp' % {'stack': stack, 'label': label})\n",
    "    features_allClasses_neg = bp.unpack_ndarray_file(train_features_dir + '/%(stack)s_%(label)s_surround_features.bp' % {'stack': stack, 'label': label})\n",
    "    \n",
    "    train_data = np.r_[features_allClasses_pos, features_allClasses_neg]\n",
    "    train_labels = np.r_[np.ones((features_allClasses_pos.shape[0], )), \n",
    "                         -np.ones((features_allClasses_neg.shape[0], ))]\n",
    "    \n",
    "    svc = SVC(C=1.0, kernel='rbf', degree=3, gamma='auto', coef0=0.0, shrinking=True, \n",
    "          probability=True, tol=0.001, cache_size=200, class_weight=None, verbose=False, \n",
    "          max_iter=-1, decision_function_shape=None, random_state=None)\n",
    "    \n",
    "    svc.fit(train_data, train_labels)\n",
    "    \n",
    "    joblib.dump(svc, 'svm/%(label)s_svm.pkl' % {'label': label})\n",
    "    \n",
    "    del features_allClasses_pos, features_allClasses_neg, train_data, train_labels, svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svc_allClasses = {}\n",
    "for label_ind, label in enumerate(labels[1:]):\n",
    "    svc_allClasses[label] = joblib.load('svm/%(label)s_svm.pkl' % {'label': label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_rootdir = '/oasis/projects/nsf/csd395/yuncong/CSHL_patch_predictions_svm'\n",
    "if not os.path.exists(predictions_rootdir):\n",
    "    os.makedirs(predictions_rootdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f(stack, sec):\n",
    "    \n",
    "    test_features_dir = features_dir + '/%(stack)s' % {'stack': stack, 'sec': sec}\n",
    "\n",
    "#     features_roi = bp.unpack_ndarray_file(test_features_dir + '/%(stack)s_%(sec)04d_features.bp' % {'stack': stack, 'sec': sec})\n",
    "    features_roi = load_hdf(test_features_dir + '/%(stack)s_%(sec)04d_features.hdf' % {'stack': stack, 'sec': sec})\n",
    "\n",
    "    n = features_roi.shape[0]\n",
    "#     print n\n",
    "\n",
    "#     probs = np.zeros((n, len(labels)-1))\n",
    "\n",
    "#     for label_ind, label in enumerate(labels[1:]):\n",
    "\n",
    "    label = '7N'\n",
    "    svc = svc_allClasses[label]\n",
    "#     probs[:, label_ind] = svc.predict_proba(features_roi)[:, svc.classes_.tolist().index(1.)]\n",
    "\n",
    "    svc.predict_proba(features_roi)[:, svc.classes_.tolist().index(1.)]\n",
    "    \n",
    "#     predictions_dir = predictions_rootdir + '/%(stack)s/%(sec)04d' % {'stack': stack, 'sec': sec}\n",
    "#     if not os.path.exists(predictions_dir):\n",
    "#         os.makedirs(predictions_dir)\n",
    "    \n",
    "#     np.save(predictions_dir + '/%(stack)s_%(sec)04d_roi1_predictions.npy' % {'stack': stack, 'sec': sec}, probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack = 'MD585'\n",
    "first_detect_sec, last_detect_sec = detect_bbox_range_lookup[stack]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "Parallel(n_jobs=16)(delayed(f)(stack=stack, sec=sec) for sec in range(first_detect_sec, first_detect_sec+16))\n",
    "print time.time() - t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stack = 'MD585'\n",
    "first_detect_sec, last_detect_sec = detect_bbox_range_lookup[stack]\n",
    "\n",
    "# sec = 142\n",
    "for sec in range(first_detect_sec, last_detect_sec+1):\n",
    "    \n",
    "# test_features_dir = features_dir + '/%(stack)s/%(sec)04d' % {'stack': stack, 'sec': sec}\n",
    "    test_features_dir = features_dir + '/%(stack)s' % {'stack': stack, 'sec': sec}\n",
    "\n",
    "#     features_roi = bp.unpack_ndarray_file(test_features_dir + '/%(stack)s_%(sec)04d_features.bp' % {'stack': stack, 'sec': sec})\n",
    "    features_roi = load_hdf(test_features_dir + '/%(stack)s_%(sec)04d_features.hdf' % {'stack': stack, 'sec': sec})\n",
    "\n",
    "    n = features_roi.shape[0]\n",
    "\n",
    "    probs = np.zeros((n, len(labels)-1))\n",
    "\n",
    "    for label_ind, label in enumerate(labels[1:]):\n",
    "\n",
    "        print label\n",
    "\n",
    "        svc = svc_allClasses[label]\n",
    "        probs[:, label_ind] = svc.predict_proba(features_roi)[:, svc.classes_.tolist().index(1.)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack = 'MD585'\n",
    "first_detect_sec, last_detect_sec = detect_bbox_range_lookup[stack]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for sec in range(first_detect_sec, last_detect_sec+1):\n",
    "    print sec\n",
    "    \n",
    "# test_features_dir = features_dir + '/%(stack)s/%(sec)04d' % {'stack': stack, 'sec': sec}\n",
    "    test_features_dir = features_dir + '/%(stack)s' % {'stack': stack, 'sec': sec}\n",
    "\n",
    "    features_roi = bp.unpack_ndarray_file(test_features_dir + '/%(stack)s_%(sec)04d_features.bp' % {'stack': stack, 'sec': sec})\n",
    "    \n",
    "    save_hdf(features_roi, test_features_dir + '/%(stack)s_%(sec)04d_features.hdf' % {'stack': stack, 'sec': sec})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
