{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "sys.path.append(os.environ['REPO_DIR'] + '/utilities')\n",
    "from utilities2015 import *\n",
    "from metadata import *\n",
    "from data_manager import *\n",
    "from learning_utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "reload(logging) # This is important for logging to work on workstation jupyter notebook.\n",
    "# See https://stackoverflow.com/questions/18786912/get-output-from-the-logging-module-in-ipython-notebook/21475297#21475297\n",
    "head = '%(asctime)-15s %(message)s'\n",
    "logging.basicConfig(level=logging.DEBUG, format=head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_id = 71\n",
    "classifier_properties = classifier_settings.loc[classifier_id]\n",
    "\n",
    "margin = classifier_properties['margin']\n",
    "# model = classifier_properties['model']\n",
    "sample_weighting = classifier_properties['sample_weighting']\n",
    "neg_composition = classifier_properties['neg_composition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_dir_name = 'inception-bn-blue-softmax'\n",
    "download_from_s3(os.path.join(MXNET_MODEL_ROOTDIR, model_dir_name), is_dir=True)\n",
    "model_name = 'inception-bn-blue-softmax'\n",
    "model_iteration = 0\n",
    "output_symbol_name = 'softmax_output'\n",
    "output_dim = 1024\n",
    "mean_img = np.load(os.path.join(MXNET_MODEL_ROOTDIR, model_dir_name, 'mean_224.npy'))\n",
    "\n",
    "# Reference on how to predict with mxnet model:\n",
    "# https://github.com/dmlc/mxnet-notebooks/blob/master/python/how_to/predict.ipynb\n",
    "model_prefix = os.path.join(MXNET_MODEL_ROOTDIR, model_dir_name, model_name)\n",
    "model0, arg_params, aux_params = mx.model.load_checkpoint(model_prefix, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Finetune\n",
    "# http://mxnet.io/how_to/finetune.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_fine_tune_model(symbol, arg_params, num_classes, layer_name='flatten'):\n",
    "    \"\"\"\n",
    "    symbol: the pretrained network symbol\n",
    "    arg_params: the argument parameters of the pretrained model\n",
    "    num_classes: the number of classes for the fine-tune datasets\n",
    "    layer_name: the layer name before the last fully-connected layer\n",
    "    \"\"\"\n",
    "    all_layers = symbol.get_internals()\n",
    "    net = all_layers[layer_name + '_output']\n",
    "    net = mx.symbol.FullyConnected(data=net, num_hidden=num_classes, name='fc1')\n",
    "    net = mx.symbol.SoftmaxOutput(data=net, name='softmax')\n",
    "    new_args = {k: arg_params[k] for k in arg_params if 'fc1' not in k}\n",
    "    return (net, new_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "(new_sym, new_args) = get_fine_tune_model(model0, arg_params, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit(symbol, arg_params, aux_params, train, val, batch_size, num_gpus, num_epoch, epoch_end_callback):\n",
    "    devs = [mx.gpu(i) for i in range(num_gpus)]\n",
    "    mod = mx.mod.Module(symbol=symbol, context=devs)\n",
    "    mod.fit(train, val,\n",
    "        num_epoch=num_epoch,\n",
    "        arg_params=arg_params,\n",
    "        aux_params=aux_params,\n",
    "        allow_missing=True,\n",
    "        batch_end_callback = mx.callback.Speedometer(batch_size, 10),\n",
    "        kvstore='device',\n",
    "        optimizer='sgd',\n",
    "        optimizer_params={'learning_rate':0.01},\n",
    "        initializer=mx.init.Xavier(rnd_type='gaussian', factor_type=\"in\", magnitude=2),\n",
    "        eval_metric='acc',\n",
    "           epoch_end_callback=epoch_end_callback,\n",
    "           )\n",
    "    metric = mx.metric.Accuracy()\n",
    "    return mod.score(val, metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_per_gpu = 16\n",
    "num_gpus = 1\n",
    "batch_size = batch_per_gpu * num_gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mxnet.model import save_checkpoint\n",
    "\n",
    "def my_epoch_end_callback(prefix, period=1):\n",
    "    def _callback(epoch, sym, arg, aux):    \n",
    "        if epoch % period == 0:\n",
    "            save_checkpoint(prefix, epoch, sym, arg, aux)\n",
    "            symbol_fp = '%s-symbol.json' % prefix\n",
    "            param_fp = '%s-%04d.params' % (prefix, epoch)\n",
    "            upload_to_s3(symbol_fp)\n",
    "            upload_to_s3(param_fp)\n",
    "    return _callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5N\n",
      "rm -rf /home/yuncong/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_6N.hdf && mkdir -p /home/yuncong/CSHL_classifiers/datasets/dataset_60\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_6N.hdf /home/yuncong/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_6N.hdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "Child returned 1\n",
      "0.68 seconds.\n",
      "Cannot load dataset images for label 5N_surround_500_6N: [Errno 2] No such file or directory: '/home/yuncong/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_6N.hdf'\n",
      "Child returned 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /home/yuncong/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_7N.hdf && mkdir -p /home/yuncong/CSHL_classifiers/datasets/dataset_60\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_7N.hdf /home/yuncong/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_7N.hdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 1\n",
      "0.67 seconds.\n",
      "Cannot load dataset images for label 5N_surround_500_7N: [Errno 2] No such file or directory: '/home/yuncong/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_7N.hdf'\n",
      "Child returned 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /home/yuncong/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_7n.hdf && mkdir -p /home/yuncong/CSHL_classifiers/datasets/dataset_60\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_7n.hdf /home/yuncong/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_7n.hdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 1\n",
      "0.72 seconds.\n",
      "Cannot load dataset images for label 5N_surround_500_7n: [Errno 2] No such file or directory: '/home/yuncong/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_7n.hdf'\n",
      "Child returned 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /home/yuncong/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_Amb.hdf && mkdir -p /home/yuncong/CSHL_classifiers/datasets/dataset_60\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_Amb.hdf /home/yuncong/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_Amb.hdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 1\n",
      "0.65 seconds.\n",
      "Cannot load dataset images for label 5N_surround_500_Amb: [Errno 2] No such file or directory: '/home/yuncong/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_Amb.hdf'\n",
      "Child returned 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /home/yuncong/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_LC.hdf && mkdir -p /home/yuncong/CSHL_classifiers/datasets/dataset_60\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_LC.hdf /home/yuncong/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_LC.hdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 1\n",
      "0.66 seconds.\n",
      "Cannot load dataset images for label 5N_surround_500_LC: [Errno 2] No such file or directory: '/home/yuncong/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_LC.hdf'\n",
      "Child returned 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /home/yuncong/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_LRt.hdf && mkdir -p /home/yuncong/CSHL_classifiers/datasets/dataset_60\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_LRt.hdf /home/yuncong/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_LRt.hdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 1\n",
      "0.66 seconds.\n",
      "Cannot load dataset images for label 5N_surround_500_LRt: [Errno 2] No such file or directory: '/home/yuncong/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_LRt.hdf'\n",
      "Child returned 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /home/yuncong/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_Pn.hdf && mkdir -p /home/yuncong/CSHL_classifiers/datasets/dataset_60\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_Pn.hdf /home/yuncong/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_Pn.hdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 1\n",
      "0.66 seconds.\n",
      "Cannot load dataset images for label 5N_surround_500_Pn: [Errno 2] No such file or directory: '/home/yuncong/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_Pn.hdf'\n",
      "Child returned 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /home/yuncong/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_Tz.hdf && mkdir -p /home/yuncong/CSHL_classifiers/datasets/dataset_60\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_Tz.hdf /home/yuncong/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_Tz.hdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 1\n",
      "0.68 seconds.\n",
      "Cannot load dataset images for label 5N_surround_500_Tz: [Errno 2] No such file or directory: '/home/yuncong/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_Tz.hdf'\n",
      "Child returned 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /home/yuncong/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_VLL.hdf && mkdir -p /home/yuncong/CSHL_classifiers/datasets/dataset_60\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_VLL.hdf /home/yuncong/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_VLL.hdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 1\n",
      "0.67 seconds.\n",
      "Cannot load dataset images for label 5N_surround_500_VLL: [Errno 2] No such file or directory: '/home/yuncong/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_VLL.hdf'\n",
      "Child returned 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /home/yuncong/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_RMC.hdf && mkdir -p /home/yuncong/CSHL_classifiers/datasets/dataset_60\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_RMC.hdf /home/yuncong/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_RMC.hdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 1\n",
      "0.66 seconds.\n",
      "Cannot load dataset images for label 5N_surround_500_RMC: [Errno 2] No such file or directory: '/home/yuncong/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_RMC.hdf'\n",
      "Child returned 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /home/yuncong/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_SNC.hdf && mkdir -p /home/yuncong/CSHL_classifiers/datasets/dataset_60\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_SNC.hdf /home/yuncong/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_SNC.hdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 1\n",
      "0.67 seconds.\n",
      "Cannot load dataset images for label 5N_surround_500_SNC: [Errno 2] No such file or directory: '/home/yuncong/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_SNC.hdf'\n",
      "Child returned 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /home/yuncong/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_SNR.hdf && mkdir -p /home/yuncong/CSHL_classifiers/datasets/dataset_60\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_SNR.hdf /home/yuncong/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_SNR.hdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 1\n",
      "0.65 seconds.\n",
      "Cannot load dataset images for label 5N_surround_500_SNR: [Errno 2] No such file or directory: '/home/yuncong/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_SNR.hdf'\n",
      "Child returned 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /home/yuncong/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_3N.hdf && mkdir -p /home/yuncong/CSHL_classifiers/datasets/dataset_60\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_3N.hdf /home/yuncong/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_3N.hdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 1\n",
      "0.66 seconds.\n",
      "Cannot load dataset images for label 5N_surround_500_3N: [Errno 2] No such file or directory: '/home/yuncong/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_3N.hdf'\n",
      "Child returned 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /home/yuncong/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_4N.hdf && mkdir -p /home/yuncong/CSHL_classifiers/datasets/dataset_60\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_4N.hdf /home/yuncong/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_4N.hdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 1\n",
      "0.65 seconds.\n",
      "Cannot load dataset images for label 5N_surround_500_4N: [Errno 2] No such file or directory: '/home/yuncong/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_4N.hdf'\n",
      "Child returned 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /home/yuncong/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_Sp5I.hdf && mkdir -p /home/yuncong/CSHL_classifiers/datasets/dataset_60\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_Sp5I.hdf /home/yuncong/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_Sp5I.hdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 1\n",
      "0.66 seconds.\n",
      "Cannot load dataset images for label 5N_surround_500_Sp5I: [Errno 2] No such file or directory: '/home/yuncong/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_Sp5I.hdf'\n",
      "Child returned 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /home/yuncong/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_Sp5O.hdf && mkdir -p /home/yuncong/CSHL_classifiers/datasets/dataset_60\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_Sp5O.hdf /home/yuncong/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_Sp5O.hdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 1\n",
      "0.67 seconds.\n",
      "Cannot load dataset images for label 5N_surround_500_Sp5O: [Errno 2] No such file or directory: '/home/yuncong/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_Sp5O.hdf'\n",
      "Child returned 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /home/yuncong/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_Sp5C.hdf && mkdir -p /home/yuncong/CSHL_classifiers/datasets/dataset_60\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_Sp5C.hdf /home/yuncong/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_Sp5C.hdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 1\n",
      "0.65 seconds.\n",
      "Cannot load dataset images for label 5N_surround_500_Sp5C: [Errno 2] No such file or directory: '/home/yuncong/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_Sp5C.hdf'\n",
      "Child returned 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /home/yuncong/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_PBG.hdf && mkdir -p /home/yuncong/CSHL_classifiers/datasets/dataset_60\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_PBG.hdf /home/yuncong/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_PBG.hdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 1\n",
      "0.65 seconds.\n",
      "Cannot load dataset images for label 5N_surround_500_PBG: [Errno 2] No such file or directory: '/home/yuncong/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_PBG.hdf'\n",
      "Child returned 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /home/yuncong/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_10N.hdf && mkdir -p /home/yuncong/CSHL_classifiers/datasets/dataset_60\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_10N.hdf /home/yuncong/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_10N.hdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 1\n",
      "0.69 seconds.\n",
      "Cannot load dataset images for label 5N_surround_500_10N: [Errno 2] No such file or directory: '/home/yuncong/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_10N.hdf'\n",
      "Child returned 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /home/yuncong/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_VCA.hdf && mkdir -p /home/yuncong/CSHL_classifiers/datasets/dataset_60\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_VCA.hdf /home/yuncong/CSHL_classifiers/datasets/dataset_60/patch_images_5N_surround_500_VCA.hdf\n"
     ]
    }
   ],
   "source": [
    "# for structure in structures_found:\n",
    "for structure in all_known_structures:\n",
    "# for structure in ['LRt']:\n",
    "\n",
    "    try:\n",
    "\n",
    "        print structure\n",
    "\n",
    "        # Determine which labels to load.\n",
    "\n",
    "        structures_to_sample = [structure]\n",
    "        negative_labels_to_sample = [s + '_negative' for s in structures_to_sample]\n",
    "\n",
    "        margins_to_sample = [margin] # (200: 100 um, 500: 250 um)\n",
    "        surround_positive_labels_to_sample = [convert_to_surround_name(s, margin=m, suffix=surr_l) \n",
    "                                     for m in margins_to_sample\n",
    "                                     for s in structures_to_sample \n",
    "                                     for surr_l in all_known_structures\n",
    "                                     if surr_l != s]\n",
    "        surround_noclass_labels_to_sample = [convert_to_surround_name(s, margin=m, suffix='noclass') \n",
    "                                     for m in margins_to_sample\n",
    "                                     for s in structures_to_sample]\n",
    "\n",
    "        if neg_composition == 'neg_has_everything_else':\n",
    "            labels_to_sample = structures_to_sample + negative_labels_to_sample\n",
    "        elif neg_composition == 'neg_has_only_surround_noclass':\n",
    "            labels_to_sample = structures_to_sample + surround_noclass_labels_to_sample + ['noclass']\n",
    "        elif neg_composition == 'neg_has_all_surround':\n",
    "            labels_to_sample = structures_to_sample + surround_positive_labels_to_sample + surround_noclass_labels_to_sample + ['noclass']\n",
    "\n",
    "        # labels_to_sample = ['Sp5C', 'Sp5C_surround_500_Sp5I', 'Sp5C_surround_500_noclass', 'Sp5C_surround_500_LRt']\n",
    "        # labels_to_sample = ['Sp5O', 'Sp5O_surround_500_Sp5I', 'Sp5O_surround_500_noclass']\n",
    "    #     labels_to_sample = ['SC', 'SC_surround_500_IC', 'SC_surround_500_noclass']\n",
    "\n",
    "        # Load training dataset.\n",
    "\n",
    "        training_set_ids = map(int, str(classifier_properties['train_set_id']).split('/'))\n",
    "        training_features, training_addresses = load_dataset_images(training_set_ids, labels_to_sample=labels_to_sample)\n",
    "\n",
    "        # convert patches data shape to nx1x224x224\n",
    "        training_features = {s: (patches - mean_img)[:, None, :, :] for s, patches in training_features.iteritems()}\n",
    "\n",
    "        # check which labels are collected\n",
    "        labels_found = training_addresses.keys()\n",
    "        structures_found = set([convert_to_original_name(l) for l in labels_found \n",
    "                                if convert_to_original_name(l) in labels_found]) - {'noclass'}\n",
    "\n",
    "        # Load test dataset.\n",
    "\n",
    "#         test_set_ids = [62]\n",
    "#         test_features, test_addresses = load_dataset_images(test_set_ids, labels_to_sample=labels_to_sample)\n",
    "#         test_features = {s: (patches - mean_img)[:, None, :, :] for s, patches in test_features.iteritems()}\n",
    "\n",
    "        #############################################\n",
    "\n",
    "\n",
    "        if neg_composition == 'neg_has_only_surround_noclass':\n",
    "            neg_classes = [convert_to_surround_name(structure, margin=margin, suffix='noclass')]\n",
    "        elif neg_composition == 'neg_has_all_surround':\n",
    "            neg_classes = [convert_to_surround_name(structure, margin=margin, suffix='noclass')]\n",
    "            for surr_s in structures_found:\n",
    "                c = convert_to_surround_name(structure, margin=margin, suffix=surr_s)\n",
    "                if c in labels_found:\n",
    "                    neg_classes.append(c)\n",
    "        elif neg_composition == 'neg_has_everything_else':\n",
    "            neg_classes = [structure + '_negative']\n",
    "        else:\n",
    "            raise Exception('neg_composition %s is not recognized.' % neg_composition)\n",
    "\n",
    "        ###########################\n",
    "        ## Define Sample Weights ##\n",
    "        ###########################\n",
    "\n",
    "    #     if sample_weighting == 'weighted':\n",
    "    #         neg_distances = np.concatenate([distances_to_structures[neg_class][structure] for neg_class in neg_classes])\n",
    "\n",
    "    #         sample_weights_neg = np.ones((n_neg,))\n",
    "    #         sample_weights_neg[neg_distances > thresh] = diminishing(neg_distances[neg_distances > thresh])\n",
    "    #         sample_weights = np.r_[np.ones((n_pos,)), sample_weights_neg]\n",
    "    #     else:\n",
    "    #         sample_weights = None\n",
    "\n",
    "        ###########################################################################################\n",
    "\n",
    "        train_features_pos = training_features[structure]\n",
    "        n_pos = len(train_features_pos)\n",
    "\n",
    "        train_features_neg = np.concatenate([training_features[neg_class] for neg_class in neg_classes])\n",
    "        n_neg = len(train_features_neg)\n",
    "\n",
    "        train_data = np.concatenate([train_features_pos, train_features_neg])\n",
    "        # For cnn, labels must be 0/1 rather than +1/-1\n",
    "        train_labels = np.r_[np.ones((n_pos, )), np.zeros((n_neg, ))]\n",
    "\n",
    "        train_data_iter = mx.io.NDArrayIter(\n",
    "            data=train_data, \n",
    "            batch_size=batch_size,\n",
    "            label=train_labels,\n",
    "            shuffle=True)\n",
    "\n",
    "        #####################################\n",
    "\n",
    "#         test_features_pos = test_features[structure]\n",
    "#         n_pos = len(test_features_pos)\n",
    "\n",
    "#         test_features_neg = np.concatenate([test_features[neg_class] for neg_class in neg_classes \\\n",
    "#                                        if neg_class in test_features])\n",
    "#         n_neg = len(test_features_neg)\n",
    "\n",
    "#         test_data = np.concatenate([test_features_pos, test_features_neg])\n",
    "#         # For cnn, labels must be 0/1 rather than +1/-1\n",
    "#         test_labels = np.r_[np.ones((n_pos, )), np.zeros((n_neg, ))]\n",
    "\n",
    "#         test_data_iter = mx.io.NDArrayIter(\n",
    "#             data=test_data, \n",
    "#             batch_size=batch_size,\n",
    "#             label=test_labels,\n",
    "#             shuffle=True)\n",
    "\n",
    "        t = time.time()\n",
    "        prefix = os.path.join(MXNET_MODEL_ROOTDIR, model_dir_name, model_name + '_' + structure)\n",
    "#         mod_score = fit(new_sym, new_args, aux_params, train_data_iter, test_data_iter, \n",
    "#                         batch_size, num_gpus, num_epoch=10, epoch_end_callback=my_epoch_end_callback(prefix, period=5))\n",
    "        mod_score = fit(new_sym, new_args, aux_params, train_data_iter, train_data_iter, \n",
    "                        batch_size, num_gpus, num_epoch=50, epoch_end_callback=my_epoch_end_callback(prefix, period=5))\n",
    "        sys.stderr.write('Fitting classifier: %.2f seconds\\n' % (time.time() - t))\n",
    "        \n",
    "    #     clf_fp = DataManager.get_classifier_filepath(classifier_id=classifier_id, structure=structure)\n",
    "    #     create_parent_dir_if_not_exists(clf_fp)\n",
    "    #     joblib.dump(clf, clf_fp)\n",
    "    #     upload_to_s3(clf_fp)\n",
    "    except:\n",
    "        sys.stderr.write(\"Skip %s.\\n\" % structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
