{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "sys.path.append(os.path.join(os.environ['REPO_DIR'], 'utilities'))\n",
    "from utilities2015 import *\n",
    "\n",
    "from matplotlib.path import Path\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack = 'MD585'\n",
    "dm = DataManager(stack=stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xmin, ymin, w, h = detect_bbox_lookup[stack]\n",
    "xmin = xmin * 32\n",
    "ymin = ymin * 32\n",
    "w = w * 32\n",
    "h = h * 32\n",
    "xmax = xmin + w - 1\n",
    "ymax = ymin + h - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sift = cv2.SIFT();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "descriptors_pool = []\n",
    "\n",
    "for sec in range(first_detect_sec, last_detect_sec+1, 10):\n",
    "    \n",
    "    print sec\n",
    "    \n",
    "    dm.set_slice(sec)\n",
    "    dm._load_image(versions=['rgb-jpg'])\n",
    "    img = dm.image_rgb_jpg[ymin:ymax+1, xmin:xmax+1]\n",
    "    \n",
    "    keypoints, descriptors = sift.detectAndCompute(img, None)\n",
    "    \n",
    "    n = 1000\n",
    "    random_indices = np.random.choice(range(len(descriptors)), n, replace=False)\n",
    "    \n",
    "    descriptors_pool.append(descriptors[random_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "descriptors_pool_arr = np.vstack(descriptors_pool)\n",
    "print len(descriptors_pool_arr), 'in descriptor pool'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bp.pack_ndarray_file(descriptors_pool_arr, 'sift_descriptors_pool_arr.bp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "descriptors_pool_arr = bp.unpack_ndarray_file('sift_descriptors_pool_arr.bp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "\n",
    "vocabulary = KMeans(init='random', n_clusters=M, n_init=10)\n",
    "vocabulary.fit(descriptors_pool_arr)\n",
    "\n",
    "sys.stderr.write('sift: %.2f seconds\\n' % (time.time() - t)) # 300 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cluster_centers = vocabulary.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(vocabulary, '/oasis/projects/nsf/csd395/yuncong/Brain/learning/sift/vocab.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "vocabulary = joblib.load('/oasis/projects/nsf/csd395/yuncong/Brain/learning/sift/vocab.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "first_detect_sec, last_detect_sec = detect_bbox_range_lookup[stack]\n",
    "\n",
    "# for sec in range(first_detect_sec, last_detect_sec+1):\n",
    "for sec in [first_detect_sec]:\n",
    "    \n",
    "    dm.set_slice(sec)\n",
    "    dm._load_image(versions=['rgb-jpg'])\n",
    "    \n",
    "    img = dm.image_rgb_jpg[ymin:ymax+1, xmin:xmax+1]\n",
    "    \n",
    "    t = time.time()\n",
    "    keypoints, descriptors = sift.detectAndCompute(img, None); # 128 dim descriptor ï½ž 120 seconds\n",
    "    sys.stderr.write('sift: %.2f seconds\\n' % (time.time() - t)) \n",
    "    \n",
    "    keypoints_arr = np.array([k.pt for k in keypoints])\n",
    "    print len(keypoints), 'keypoints'\n",
    "    \n",
    "    t = time.time()\n",
    "    keypoint_labels = vocabulary.predict(descriptors)\n",
    "    sys.stderr.write('predict: %.2f seconds\\n' % (time.time() - t)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colors = np.vstack([(0,0,0), np.random.randint(0, 255, (M, 3))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "viz = img.copy()\n",
    "for (x, y), l in zip(keypoints_arr, keypoint_labels):\n",
    "    cv2.circle(viz, (int(x), int(y)), 3, colors[l], -1)\n",
    "display_image(viz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labelmap = np.zeros(dm.image_rgb_jpg.shape[:2], np.int)\n",
    "keypoints_arr_int = np.floor(keypoints_arr + (xmin, ymin)).astype(np.int)\n",
    "labelmap[keypoints_arr_int[:,1], keypoints_arr_int[:,0]] = keypoint_labels + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('labelmap', labelmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labelmap = np.load('labelmap.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labelmap_viz = colors[labelmap]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display_image(labelmap_viz[5000:5500, 5000:5500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patches_rootdir = '/home/yuncong/CSHL_data_patches/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "table_filepath = os.path.join(patches_rootdir, '%(stack)s_indices_allROIs_allSections.h5'%{'stack':stack})\n",
    "indices_allROIs_allSections = pd.read_hdf(table_filepath, 'indices_allROIs_allSections')\n",
    "grid_parameters = pd.read_hdf(table_filepath, 'grid_parameters')\n",
    "\n",
    "patch_size, stride, w, h = grid_parameters.tolist()\n",
    "half_size = patch_size/2\n",
    "ys, xs = np.meshgrid(np.arange(half_size, h-half_size, stride), np.arange(half_size, w-half_size, stride),\n",
    "                 indexing='xy')\n",
    "sample_locations = np.c_[xs.flat, ys.flat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "first_detect_sec, last_detect_sec = detect_bbox_range_lookup[stack]\n",
    "sec = first_detect_sec\n",
    "indices_roi = indices_allROIs_allSections[sec]['roi1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def f(x,y):\n",
    "    return np.bincount(labelmap[y-half_size:y+half_size-1, x-half_size:x+half_size-1].flat, minlength=M+1)[1:]\n",
    "\n",
    "t = time.time()\n",
    "sample_hists_list = []\n",
    "\n",
    "for s in range(0, len(indices_roi), 100):\n",
    "    res = Parallel(n_jobs=16)(delayed(f)(x,y) for x, y in sample_locations[indices_roi][s:s+100])\n",
    "    sample_hists_list.append(res)\n",
    "\n",
    "sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) ~ # 72 seconds\n",
    "\n",
    "from itertools import chain\n",
    "sample_hists = list(chain(*sample_hists_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_locs_roi = sample_locations[indices_roi]\n",
    "patch_xmin = sample_locs_roi[:,0] - half_size\n",
    "patch_ymin = sample_locs_roi[:,1] - half_size\n",
    "patch_xmax = sample_locs_roi[:,0] + half_size\n",
    "patch_ymax = sample_locs_roi[:,1] + half_size\n",
    "\n",
    "def f(i):\n",
    "    m = (labelmap == i).astype(np.uint8)\n",
    "    mi = cv2.integral(m)\n",
    "    ci = mi[patch_ymin, patch_xmin] + mi[patch_ymax, patch_xmax] - mi[patch_ymax, patch_xmin] - mi[patch_ymin, patch_xmax]\n",
    "    return ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done in 18.805970 seconds\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "hists = Parallel(n_jobs=16)(delayed(f)(i) for i in range(1, M+1))\n",
    "sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # ~ 18 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hists_arr = np.array(hists).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20979, 200)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hists_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_locs_roi = sample_locations[indices_roi]\n",
    "\n",
    "l = 2\n",
    "grid_size = patch_size / 2**l\n",
    "\n",
    "if l == 2:\n",
    "    rx = [-2, -1, 0, 1]\n",
    "    ry = [-2, -1, 0, 1]\n",
    "elif l == 1:\n",
    "    rx = [-1, 0]\n",
    "    ry = [-1, 0]\n",
    "elif l == 0:\n",
    "    rx = [-.5]\n",
    "    ry = [-.5]\n",
    "\n",
    "rxs, rys = np.meshgrid(rx, ry)\n",
    "\n",
    "patch_coords_allGrid = []\n",
    "\n",
    "for grid_i, (rx, ry) in enumerate(np.c_[rxs.flat, rys.flat]):\n",
    "    \n",
    "    patch_xmin = sample_locs_roi[:,0] + rx * grid_size\n",
    "    patch_ymin = sample_locs_roi[:,1] + ry * grid_size\n",
    "    patch_xmax = sample_locs_roi[:,0] + (rx + 1) * grid_size\n",
    "    patch_ymax = sample_locs_roi[:,1] + (ry + 1) * grid_size\n",
    "    \n",
    "    patch_coords_allGrid.append([patch_xmin, patch_ymin, patch_xmax, patch_ymax])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_coords = np.hstack(patch_coords_allGrid)\n",
    "patch_xmin = all_coords[0]\n",
    "patch_ymin = all_coords[1]\n",
    "patch_xmax = all_coords[2]\n",
    "patch_ymax = all_coords[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f(i):\n",
    "    m = (labelmap == i).astype(np.uint8)\n",
    "    mi = cv2.integral(m)\n",
    "    ci = mi[patch_ymin, patch_xmin] + mi[patch_ymax, patch_xmax] - mi[patch_ymax, patch_xmin] - mi[patch_ymin, patch_xmax]\n",
    "    return ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done in 19.476660 seconds\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "hists = Parallel(n_jobs=16)(delayed(f)(i) for i in range(1, M+1))\n",
    "sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # ~ 18 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_grid = (2**l)**2\n",
    "hists_arr2 = np.transpose(np.reshape(hists, (M, n_grid, -1)))\n",
    "\n",
    "print hists_arr2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20979, 16, 200)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hists_arr1 = np.transpose([hists_arr[:, [0,1,4,5], :].sum(axis=1),\n",
    "                           hists_arr[:, [2,3,6,7], :].sum(axis=1),\n",
    "                           hists_arr[:, [8,9,12,13], :].sum(axis=1),\n",
    "                           hists_arr[:, [10,11,14,15], :].sum(axis=1)], \n",
    "                          [1,0,2])\n",
    "print hists_arr1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20979, 200)\n"
     ]
    }
   ],
   "source": [
    "hists_arr0 = hists_arr1.sum(axis=1)\n",
    "print hists_arr0.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
