{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.environ['REPO_DIR'] + '/utilities')\n",
    "from utilities2015 import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patch_dir = '/home/yuncong/CSHL_data_patches/'\n",
    "\n",
    "model_dir = '/home/yuncong/jiaxu_repo/model_publish'\n",
    "model_name='inception-stage1'\n",
    "model_iteration = 6\n",
    "model = mx.model.FeedForward.load(os.path.join(model_dir, model_name), model_iteration, ctx=mx.gpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def interpolate_score(sample_locations_roi, probs):\n",
    "    \n",
    "    interpolation_xmin, interpolation_ymin = sample_locations_roi.min(axis=0)\n",
    "    interpolation_xmax, interpolation_ymax = sample_locations_roi.max(axis=0)\n",
    "    interpolation_w = interpolation_xmax - interpolation_xmin + 1\n",
    "    interpolation_h = interpolation_ymax - interpolation_ymin + 1\n",
    "    \n",
    "    print sample_locations_roi.shape[0], 'samples'\n",
    "    \n",
    "    preds = np.argmax(probs, axis=1).astype(np.int)\n",
    "        \n",
    "    ##### sample_locations_roi + scores to dense_score_map #####\n",
    "    \n",
    "    shrink_factor = 4\n",
    "    \n",
    "    sample_locations_unique_xs = np.unique(sample_locations_roi[:,0])\n",
    "    sample_locations_unique_ys = np.unique(sample_locations_roi[:,1])\n",
    "    \n",
    "    n_sample_x = sample_locations_unique_xs.size\n",
    "    n_sample_y = sample_locations_unique_ys.size\n",
    "    \n",
    "    index_x = dict([(j,i) for i,j in enumerate(sample_locations_unique_xs)])\n",
    "    index_y = dict([(j,i) for i,j in enumerate(sample_locations_unique_ys)])\n",
    "    sample_location_indices = np.asarray([(index_x[x], index_y[y]) for x, y in sample_locations_roi])\n",
    "    \n",
    "    sample_locations_interpolatedArea_ys_matrix, \\\n",
    "    sample_locations_interpolatedArea_xs_matrix = np.meshgrid(range(interpolation_ymin/shrink_factor, \n",
    "                                                                    interpolation_ymax/shrink_factor), \n",
    "                                                              range(interpolation_xmin/shrink_factor, \n",
    "                                                                    interpolation_xmax/shrink_factor), \n",
    "                                                              indexing='ij')\n",
    "\n",
    "    def generate_score_map(l):\n",
    "\n",
    "        score_matrix = np.zeros((n_sample_x, n_sample_y))\n",
    "        score_matrix[sample_location_indices[:,0], sample_location_indices[:,1]] = probs[:,l]\n",
    "\n",
    "        spline = RectBivariateSpline(sample_locations_unique_xs/shrink_factor, \n",
    "                                     sample_locations_unique_ys/shrink_factor, \n",
    "                                     score_matrix, \n",
    "                                     bbox=[interpolation_xmin/shrink_factor, \n",
    "                                           interpolation_xmax/shrink_factor, \n",
    "                                           interpolation_ymin/shrink_factor, \n",
    "                                           interpolation_ymax/shrink_factor])\n",
    "\n",
    "        dense_score_map = spline.ev(sample_locations_interpolatedArea_xs_matrix, sample_locations_interpolatedArea_ys_matrix)\n",
    "        \n",
    "        dense_score_map = resize(dense_score_map, (interpolation_h, interpolation_w))\n",
    "\n",
    "        return dense_score_map\n",
    "\n",
    "\n",
    "    import time\n",
    "    t = time.time()\n",
    "\n",
    "    dense_score_maps = Parallel(n_jobs=12)(delayed(generate_score_map)(l) for l in range(10))\n",
    "\n",
    "    print time.time() - t\n",
    "    \n",
    "    for i, m in enumerate(dense_score_maps):\n",
    "        dense_score_map_lossless = np.pad(m, ((interpolation_ymin, h-interpolation_ymax-1), \n",
    "                                              (interpolation_xmin, w-interpolation_xmax-1)),\n",
    "                                          mode='constant', constant_values=0)\n",
    "        \n",
    "        np.savez_compressed(os.path.join(denseScoreMapLossless_dir, dataset+'_denseScoreMapLossless_%d'%i), \n",
    "                            dense_score_map_lossless)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_dense_scoremap(stack, sec, label, model):\n",
    "    \n",
    "    ## define grid, generate patches\n",
    "    \n",
    "    output_dir = os.path.join(patch_dir, '%s_byROI/%04d/roi1'%(stack, sec))\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    half_size = patch_size/2\n",
    "\n",
    "    dm = DataManager(stack=stack, section=sec)\n",
    "    dm._load_image(['rgb-jpg'])\n",
    "\n",
    "    indices_roi = indices_allROIs_allSections[sec]['roi1']\n",
    "    sample_locations_roi = sample_locations[indices_roi]\n",
    "    \n",
    "    for i, (x,y) in zip(indices_roi, sample_locations_roi):\n",
    "        patch = dm.image_rgb_jpg[y-half_size:y+half_size, x-half_size:x+half_size]\n",
    "        cv2.imwrite(os.path.join(output_dir, '%(stack)s_%(sec)04d_%(gridp_ind)08d.jpg' %\\\n",
    "                                 {'stack':stack, 'sec':sec, 'gridp_ind':i}), \n",
    "                    patch[..., ::-1])\n",
    "        \n",
    "    ## predict for the patches\n",
    "    \n",
    "    data_dir = os.path.join(patch_dir, '%(stack)s_byROI/%(sec)04d/roi1') % {'stack':stack,'sec': sec}\n",
    "    dataset = '%(stack)s_%(sec)04d_roi1' % {'stack': stack, 'sec': sec}\n",
    "    \n",
    "    img_filenames = sorted(os.listdir(data_dir))\n",
    "    \n",
    "    with open(patch_dir+'/%(dataset)s_test.lst' % {'dataset': dataset}, 'w') as lst_file:\n",
    "        for index, img_filename in enumerate(img_filenames):\n",
    "            lst_file.write('%s\\t0\\t%s\\n'%(index, img_filename))\n",
    "            \n",
    "    os.system(os.environ['MXNET_DIR']+'/bin/im2rec %(patch_dir)s/%(dataset)s_test.lst \\\n",
    "    %(data_dir)s %(patch_dir)s/%(dataset)s_test.rec' % \\\n",
    "              {'dataset': dataset, 'data_dir': data_dir, 'patch_dir': patch_dir})\n",
    "        \n",
    "    # feed the network\n",
    "    batch_size = 16\n",
    "\n",
    "    test_iter = mx.io.ImageRecordIter(\n",
    "        path_imgrec = patch_dir + '/%(dataset)s_test.rec' % {'dataset': dataset},\n",
    "        batch_size = batch_size,\n",
    "        data_shape = (3, 224, 224),\n",
    "        mean_img = os.path.join(model_dir, 'mean_224.nd'),\n",
    "    )\n",
    "\n",
    "    t = time.time()\n",
    "    scores = model.predict(test_iter)\n",
    "    print time.time() - t    \n",
    "#     np.save(prediction_dir+'/%(dataset)s_predictions.npy'% {'dataset': dataset}, probs)\n",
    "    \n",
    "    ## interpolate\n",
    "\n",
    "    interpolate_score(sample_locations_roi, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'section_range_lookup' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-5f5f18e6d544>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mstack\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'MD589'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfirst_bs_sec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_bs_sec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msection_range_lookup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'section_range_lookup' is not defined"
     ]
    }
   ],
   "source": [
    "stack = 'MD589'\n",
    "first_bs_sec, last_bs_sec = section_range_lookup[stack]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "table_filepath = os.path.join(patch_dir, '%(stack)s_indices_allROIs_allSections.h5'%{'stack':stack})\n",
    "indices_allROIs_allSections = pd.read_hdf(table_filepath, 'indices_allROIs_allSections')\n",
    "grid_parameters = pd.read_hdf(table_filepath, 'grid_parameters')\n",
    "patch_size, stride, w, h = grid_parameters.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for sec in range(first_bs_sec, last_bs_sec+1):\n",
    "    for l in labels_to_detect:\n",
    "        compute_dense_scoremap(stack, sec, label=l, model=model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
