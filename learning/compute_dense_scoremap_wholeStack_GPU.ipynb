{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.environ['REPO_DIR'] + '/utilities')\n",
    "from utilities2015 import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import mxnet as mx\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03090414,  0.02384725,  0.02575189, -0.00526391,  0.00179554,\n",
       "        0.02151865,  0.00063332,  0.00327504, -0.0225192 , -0.01995471,\n",
       "       -0.01784708,  0.01672307,  0.00459287, -0.00777751, -0.00390967,\n",
       "        0.0100388 ], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patches_rootdir = '/home/yuncong/CSHL_data_patches/'\n",
    "\n",
    "model_dir = '/home/yuncong/mxnet_models/'\n",
    "# model_name='inception-stage1'\n",
    "# model_name = 'experiment0227'\n",
    "# model_iteration = 6\n",
    "\n",
    "model_name = 'experiment0317'\n",
    "model_iteration = 10\n",
    "\n",
    "model = mx.model.FeedForward.load(os.path.join(model_dir, model_name), model_iteration, ctx=mx.gpu())\n",
    "\n",
    "model.arg_params['fullc_bias'].asnumpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fc_output = model.symbol.get_internals()['fc_output']\n",
    "fc_output = model.symbol.get_internals()['fullc_output']\n",
    "sm_output = model.symbol.get_internals()['softmax_output']\n",
    "grouped_output = mx.symbol.Group([fc_output, sm_output])\n",
    "\n",
    "model = mx.model.FeedForward(ctx=mx.gpu(), symbol=grouped_output, num_epoch=model_iteration,\n",
    "                            arg_params=model.arg_params, aux_params=model.aux_params,\n",
    "                            allow_extra_params=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# labels =  ['BackG', '5N', '7n', '7N', '12N', 'Gr', 'LVe', 'Pn', 'SuVe', 'VLL']\n",
    "\n",
    "# labels = ['BackG', '5N', '7n', '7N', '12N', 'Gr', 'LVe', 'Pn', 'SuVe', 'VLL', \n",
    "#                      '6N', 'Amb', 'R', 'Tz', 'Sol', 'RtTg', 'LRt', 'LC', 'AP', 'sp5']\n",
    "\n",
    "labels = ['BackG', '5N', '7n', '7N', '12N', 'Pn', 'VLL', \n",
    "          '6N', 'Amb', 'R', 'Tz', 'RtTg', 'LRt', 'LC', 'AP', 'sp5']\n",
    "\n",
    "label_dict = dict([(l,i) for i, l in enumerate(labels)])\n",
    "\n",
    "# label_dict = dict([(l,i) for i, l in enumerate(labels)] + \\\n",
    "#                   zip(other_labels, range(len(labels), len(labels)+len(other_labels))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.interpolate import RectBivariateSpline\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# scoremaps_rootdir = '/home/yuncong/CSHL_scoremaps_lossless'\n",
    "# if not os.path.exists(scoremaps_rootdir):\n",
    "#     os.makedirs(scoremaps_rootdir)\n",
    "    \n",
    "predictions_rootdir = '/home/yuncong/CSHL_patch_predictions'\n",
    "if not os.path.exists(predictions_rootdir):\n",
    "    os.makedirs(predictions_rootdir)\n",
    "\n",
    "# iterators_rootdir = '/home/yuncong/CSHL_mxnet_iterators'\n",
    "# if not os.path.exists(iterators_rootdir):\n",
    "#     os.makedirs(iterators_rootdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_img = mx.nd.load(os.path.join(model_dir, 'mean_224.nd'))['mean_img'].asnumpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "progress_bar = FloatProgress(min=0, max=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143\n",
      "20161"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating patches: 7.47 seconds\n",
      "predict: 42.20 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " samples\n",
      "144\n",
      "20420"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating patches: 7.63 seconds\n",
      "predict: 42.34 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " samples\n",
      "145\n",
      "20667"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating patches: 7.74 seconds\n",
      "predict: 43.78 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " samples\n",
      "146\n",
      "20758"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating patches: 7.52 seconds\n",
      "predict: 44.33 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " samples\n",
      "147\n",
      "21229"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating patches: 7.89 seconds\n",
      "predict: 46.17 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " samples\n",
      "148\n",
      "21191"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating patches: 7.91 seconds\n",
      "predict: 45.96 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " samples\n",
      "149\n",
      "21568"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating patches: 8.14 seconds\n",
      "predict: 46.60 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " samples\n",
      "150\n",
      "21750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating patches: 7.90 seconds\n",
      "predict: 46.42 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " samples\n",
      "151\n",
      "21819"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating patches: 8.23 seconds\n",
      "predict: 46.78 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " samples\n",
      "152\n",
      "22253"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating patches: 8.26 seconds\n",
      "predict: 48.35 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " samples\n",
      "153\n",
      "22337"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating patches: 8.17 seconds\n",
      "predict: 48.52 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " samples\n",
      "154\n",
      "22404"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating patches: 8.09 seconds\n",
      "predict: 47.83 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " samples\n",
      "155\n",
      "22960"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating patches: 8.64 seconds\n",
      "predict: 49.06 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " samples\n",
      "156\n",
      "23100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating patches: 8.41 seconds\n",
      "predict: 50.31 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " samples\n",
      "157\n",
      "23315"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating patches: 8.76 seconds\n",
      "predict: 50.15 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " samples\n",
      "158\n",
      "23269"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating patches: 8.51 seconds\n",
      "predict: 50.85 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " samples\n",
      "159\n",
      "23241"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating patches: 8.85 seconds\n",
      "predict: 50.75 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " samples\n",
      "160\n",
      "23514"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating patches: 8.57 seconds\n",
      "predict: 50.47 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " samples\n",
      "161\n",
      "23727"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating patches: 8.81 seconds\n",
      "predict: 51.94 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " samples\n",
      "162\n",
      "23925"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating patches: 8.89 seconds\n",
      "predict: 51.59 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " samples\n",
      "163\n",
      "24059"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating patches: 9.10 seconds\n",
      "predict: 52.77 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " samples\n",
      "164\n",
      "24239"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating patches: 8.96 seconds\n",
      "predict: 53.18 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " samples\n",
      "165\n",
      "24356"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating patches: 8.89 seconds\n",
      "predict: 53.81 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " samples\n",
      "166\n",
      "24559"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating patches: 9.19 seconds\n",
      "predict: 52.91 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " samples\n",
      "167\n",
      "24489"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating patches: 9.09 seconds\n",
      "predict: 52.55 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " samples\n",
      "168\n",
      "24628"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating patches: 9.12 seconds\n",
      "predict: 53.68 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " samples\n",
      "169\n",
      "24964"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating patches: 9.07 seconds\n",
      "predict: 53.74 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " samples\n",
      "170\n",
      "24903"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating patches: 9.16 seconds\n",
      "predict: 53.67 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " samples\n",
      "171\n",
      "24910"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating patches: 9.16 seconds\n",
      "predict: 53.40 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " samples\n",
      "172\n",
      "24899"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating patches: 9.12 seconds\n",
      "predict: 54.59 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " samples\n",
      "173\n",
      "25023"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating patches: 9.22 seconds\n",
      "predict: 54.75 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " samples\n",
      "174\n",
      "25120"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating patches: 9.15 seconds\n",
      "predict: 54.88 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " samples\n",
      "175\n",
      "25110"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating patches: 9.47 seconds\n",
      "predict: 54.36 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " samples\n",
      "176\n",
      "25438"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating patches: 9.67 seconds\n",
      "predict: 55.12 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " samples\n",
      "177\n",
      "25445"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating patches: 9.33 seconds\n",
      "predict: 55.73 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " samples\n",
      "178\n",
      "25467"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating patches: 9.35 seconds\n",
      "predict: 55.21 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " samples\n",
      "179\n",
      "25562"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating patches: 9.49 seconds\n",
      "predict: 55.68 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " samples\n",
      "180\n",
      "25899"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating patches: 9.51 seconds\n",
      "predict: 56.75 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " samples\n",
      "181\n",
      "25891"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating patches: 9.63 seconds\n",
      "predict: 56.53 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " samples\n",
      "182\n",
      "25975"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating patches: 9.74 seconds\n",
      "predict: 55.92 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " samples\n",
      "183\n",
      "25747"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating patches: 10.09 seconds\n",
      "predict: 55.63 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " samples\n",
      "184\n",
      "25979"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating patches: 9.88 seconds\n",
      "predict: 55.86 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " samples\n",
      "185\n",
      "25911"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating patches: 10.00 seconds\n",
      "predict: 56.74 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " samples\n",
      "186\n",
      "26009"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating patches: 9.70 seconds\n",
      "predict: 56.98 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " samples\n",
      "187\n",
      "25091"
     ]
    }
   ],
   "source": [
    "# for stack in ['MD585', 'MD593', 'MD592', 'MD590', 'MD591', 'MD595', 'MD598', 'MD602', 'MD594']:\n",
    "# for stack in ['MD591']:\n",
    "# for stack in ['MD591', 'MD595', 'MD598', 'MD602', 'MD594']:\n",
    "# for stack in ['MD594']:\n",
    "for stack in ['MD594']:\n",
    "\n",
    "    first_bs_sec, last_bs_sec = section_range_lookup[stack]\n",
    "\n",
    "    progress_bar.min = first_detect_sec\n",
    "    progress_bar.max = last_detect_sec\n",
    "    display(progress_bar)\n",
    "    \n",
    "    table_filepath = os.path.join(patches_rootdir, '%(stack)s_indices_allROIs_allSections.h5'%{'stack':stack})\n",
    "    indices_allROIs_allSections = pd.read_hdf(table_filepath, 'indices_allROIs_allSections')\n",
    "    grid_parameters = pd.read_hdf(table_filepath, 'grid_parameters')\n",
    "\n",
    "    first_detect_sec, last_detect_sec = detect_bbox_range_lookup[stack]\n",
    "\n",
    "    if stack in ['MD589', 'MD594']:\n",
    "        stack_has_annotation = True\n",
    "    else:\n",
    "        stack_has_annotation = False\n",
    "\n",
    "    if stack_has_annotation:\n",
    "        table_filepath = os.path.join(patches_rootdir, '%(stack)s_indices_allLandmarks_allSections.h5'%{'stack':stack})\n",
    "        indices_allLandmarks_allSections = pd.read_hdf(table_filepath, 'indices_allLandmarks_allSections')\n",
    "    \n",
    "    for sec in range(first_detect_sec, last_detect_sec+1):\n",
    "        \n",
    "        if sec not in indices_allROIs_allSections.columns:\n",
    "            continue\n",
    "\n",
    "        print sec\n",
    "\n",
    "        progress_bar.value = sec\n",
    "\n",
    "        indices_roi = indices_allROIs_allSections[sec]['roi1']\n",
    "\n",
    "        predictions_dir = os.path.join(predictions_rootdir, stack, '%04d'%sec)\n",
    "        if not os.path.exists(predictions_dir):\n",
    "            os.makedirs(predictions_dir)\n",
    "\n",
    "        ## define grid, generate patches\n",
    "\n",
    "        t = time.time()\n",
    "\n",
    "        dm = DataManager(stack=stack, section=sec)\n",
    "        dm._load_image(['rgb-jpg'])\n",
    "\n",
    "        patch_size, stride, w, h = grid_parameters.tolist()\n",
    "        half_size = patch_size/2\n",
    "\n",
    "        ys, xs = np.meshgrid(np.arange(half_size, h-half_size, stride), np.arange(half_size, w-half_size, stride),\n",
    "                         indexing='xy')\n",
    "\n",
    "        sample_locations = np.c_[xs.flat, ys.flat]\n",
    "        sample_locations_roi = sample_locations[indices_roi]\n",
    "\n",
    "        n = len(indices_roi)\n",
    "        print n, 'samples'\n",
    "        \n",
    "        patches = np.asarray([dm.image_rgb_jpg[y-half_size:y+half_size, x-half_size:x+half_size]\n",
    "                              for x, y in sample_locations_roi])\n",
    "\n",
    "        t = time.time()\n",
    "  \n",
    "        patches = np.rollaxis(patches, 3, 1)\n",
    "        patches = patches - mean_img\n",
    "\n",
    "            \n",
    "        dataset = '%(stack)s_%(sec)04d_roi1' % {'stack': stack, 'sec': sec}\n",
    "\n",
    "        true_labels = -1 * np.ones((99999,), np.int)\n",
    "        if stack_has_annotation:\n",
    "            if sec in indices_allLandmarks_allSections:\n",
    "                for l in indices_allLandmarks_allSections[sec].dropna().keys():\n",
    "                    if l == 'bg': continue\n",
    "                    if l.endswith('surround'):\n",
    "                        true_labels[indices_allLandmarks_allSections[sec][l]] = 0\n",
    "                    else:\n",
    "                        true_labels[indices_allLandmarks_allSections[sec][l]] = label_dict[l]\n",
    "    \n",
    "        patch_labels = true_labels[indices_roi]\n",
    "                \n",
    "        np.save(predictions_dir+'/%(dataset)s_patchLabels.npy' % {'dataset': dataset}, patch_labels)\n",
    "        \n",
    "        sys.stderr.write('generating patches: %.2f seconds\\n' % (time.time() - t))\n",
    "                \n",
    "        # feed the network\n",
    "        \n",
    "#         t = time.time()\n",
    "        \n",
    "        batch_size = 512 # increasing to 892 does not save any time\n",
    "        \n",
    "        test_iter = mx.io.NDArrayIter(\n",
    "            patches, \n",
    "            patch_labels,\n",
    "            batch_size = batch_size,\n",
    "            shuffle=False\n",
    "        )\n",
    "\n",
    "#         sys.stderr.write('load iterator: %.2f seconds\\n' % (time.time() - t))\n",
    "\n",
    "        \n",
    "        t = time.time()\n",
    "        probs = model.predict(test_iter)[1] # 0 for fc output, 1 for softmax output\n",
    "        \n",
    "        np.save(predictions_dir + '/%(dataset)s_predictions.npy'% {'dataset': dataset}, probs)\n",
    "        # probs = np.load(predictions_dir + '/%(dataset)s_predictions.npy'% {'dataset': dataset})\n",
    "        sys.stderr.write('predict: %.2f seconds\\n' % (time.time() - t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.unique(np.argmax(probs, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use RecordIO - dump to images, pack into records, then use ImageRecordIte - 80s for gen patch, 80s for packing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for stack in ['MD585', 'MD593', 'MD592', 'MD590', 'MD591', 'MD595', 'MD598', 'MD602']:\n",
    "for stack in ['MD585']:\n",
    "\n",
    "    first_bs_sec, last_bs_sec = section_range_lookup[stack]\n",
    "\n",
    "    table_filepath = os.path.join(patches_rootdir, '%(stack)s_indices_allROIs_allSections.h5'%{'stack':stack})\n",
    "    indices_allROIs_allSections = pd.read_hdf(table_filepath, 'indices_allROIs_allSections')\n",
    "    grid_parameters = pd.read_hdf(table_filepath, 'grid_parameters')\n",
    "\n",
    "    first_detect_sec, last_detect_sec = detect_bbox_range_lookup[stack]\n",
    "\n",
    "    stack_has_annotation = False\n",
    "\n",
    "    if stack_has_annotation:\n",
    "        table_filepath = os.path.join(patches_rootdir, '%(stack)s_indices_allLandmarks_allSections.h5'%{'stack':stack})\n",
    "        indices_allLandmarks_allSections = pd.read_hdf(table_filepath, 'indices_allLandmarks_allSections')\n",
    "\n",
    "#     for sec in range(first_detect_sec, last_detect_sec+1):\n",
    "    for sec in [first_detect_sec]:\n",
    "\n",
    "        if sec not in indices_allROIs_allSections.columns:\n",
    "            continue\n",
    "\n",
    "        print sec\n",
    "\n",
    "        indices_roi = indices_allROIs_allSections[sec]['roi1']\n",
    "\n",
    "        predictions_dir = os.path.join(predictions_rootdir, stack, '%04d'%sec)\n",
    "        if not os.path.exists(predictions_dir):\n",
    "            os.makedirs(predictions_dir)\n",
    "\n",
    "        iterators_dir = os.path.join(iterators_rootdir, stack, '%04d'%sec)\n",
    "        if not os.path.exists(iterators_dir):\n",
    "            os.makedirs(iterators_dir)\n",
    "\n",
    "        scoremaps_dir = os.path.join(scoremaps_rootdir, stack, '%04d'%sec)\n",
    "        if not os.path.exists(scoremaps_dir):\n",
    "            os.makedirs(scoremaps_dir)\n",
    "\n",
    "        patches_dir = os.path.join(patches_rootdir, '%s_byROI/%04d/roi1'%(stack, sec))\n",
    "        if not os.path.exists(patches_dir):\n",
    "            os.makedirs(patches_dir)\n",
    "\n",
    "        ## define grid, generate patches\n",
    "\n",
    "        t = time.time()\n",
    "\n",
    "        dm = DataManager(stack=stack, section=sec)\n",
    "        dm._load_image(['rgb-jpg'])\n",
    "\n",
    "        patch_size, stride, w, h = grid_parameters.tolist()\n",
    "        half_size = patch_size/2\n",
    "\n",
    "        ys, xs = np.meshgrid(np.arange(half_size, h-half_size, stride), np.arange(half_size, w-half_size, stride),\n",
    "                         indexing='xy')\n",
    "\n",
    "        sample_locations = np.c_[xs.flat, ys.flat]\n",
    "        sample_locations_roi = sample_locations[indices_roi]\n",
    "\n",
    "        print len(indices_roi), 'samples'\n",
    "\n",
    "#         for i, (x,y) in zip(indices_roi, sample_locations_roi):\n",
    "#             patch = dm.image_rgb_jpg[y-half_size:y+half_size, x-half_size:x+half_size]\n",
    "#             cv2.imwrite(os.path.join(patches_dir, '%(stack)s_%(sec)04d_%(gridp_ind)08d.jpg' %\\\n",
    "#                                      {'stack':stack, 'sec':sec, 'gridp_ind':i}), \n",
    "#                         patch[..., ::-1])\n",
    "\n",
    "        sys.stderr.write('generating patches: %.2f seconds\\n' % (time.time() - t))\n",
    "\n",
    "        #     ## predict for the patches\n",
    "\n",
    "        dataset = '%(stack)s_%(sec)04d_roi1' % {'stack': stack, 'sec': sec}\n",
    "\n",
    "        img_filenames = sorted(os.listdir(patches_dir))\n",
    "\n",
    "        true_labels = -1 * np.ones((99999,), np.int)\n",
    "        if stack_has_annotation:\n",
    "            if sec in indices_allLandmarks_allSections:\n",
    "                for l in indices_allLandmarks_allSections[sec].dropna().keys():\n",
    "                    if l == 'bg': continue\n",
    "                    if l.endswith('surround'):\n",
    "                        true_labels[indices_allLandmarks_allSections[sec][l]] = 0\n",
    "                    else:\n",
    "                        true_labels[indices_allLandmarks_allSections[sec][l]] = label_dict[l]\n",
    "\n",
    "        with open(iterators_dir + '/%(dataset)s_test.lst' % {'dataset': dataset}, 'w') as lst_file:\n",
    "            for index, img_filename in enumerate(img_filenames):\n",
    "                grid_index = int(img_filename[:-4].split('_')[-1])\n",
    "                lst_file.write('%s\\t%d\\t%s\\n'%(index, true_labels[grid_index], img_filename))\n",
    "\n",
    "        t = time.time()\n",
    "\n",
    "        cmd_gen_iterator = os.environ['MXNET_DIR']+'/bin/im2rec %(iterators_dir)s/%(dataset)s_test.lst \\\n",
    "        %(data_dir)s/ %(iterators_dir)s/%(dataset)s_test.rec' % \\\n",
    "                  {'dataset': dataset, 'data_dir': patches_dir, 'iterators_dir': iterators_dir}\n",
    "        # note: the / after data_dir is necessary\n",
    "\n",
    "#         os.system(cmd_gen_iterator)\n",
    "\n",
    "        sys.stderr.write('generating iterators: %.2f seconds\\n' % (time.time() - t))\n",
    "\n",
    "        # feed the network\n",
    "        batch_size = 256\n",
    "\n",
    "        t = time.time()\n",
    "        \n",
    "        test_iter = mx.io.ImageRecordIter(\n",
    "            path_imgrec = iterators_dir + '/%(dataset)s_test.rec' % {'dataset': dataset},\n",
    "            batch_size = batch_size,\n",
    "            data_shape = (3, 224, 224),\n",
    "            mean_img = os.path.join(model_dir, 'mean_224.nd'),\n",
    "        )\n",
    "\n",
    "        sys.stderr.write('load iterators: %.2f seconds\\n' % (time.time() - t))\n",
    "\n",
    "        \n",
    "        t = time.time()\n",
    "        probs = model.predict(test_iter)\n",
    "        np.save(predictions_dir + '/%(dataset)s_predictions.npy'% {'dataset': dataset}, probs)\n",
    "        # probs = np.load(predictions_dir + '/%(dataset)s_predictions.npy'% {'dataset': dataset})\n",
    "        sys.stderr.write('predict: %.2f seconds\\n' % (time.time() - t))\n",
    "\n",
    "        break\n",
    "        \n",
    "        ## interpolate\n",
    "\n",
    "        interpolation_xmin, interpolation_ymin = sample_locations_roi.min(axis=0)\n",
    "        interpolation_xmax, interpolation_ymax = sample_locations_roi.max(axis=0)\n",
    "        interpolation_w = interpolation_xmax - interpolation_xmin + 1\n",
    "        interpolation_h = interpolation_ymax - interpolation_ymin + 1\n",
    "\n",
    "        ##### sample_locations_roi + scores to dense_score_map #####\n",
    "\n",
    "        shrink_factor = 4\n",
    "\n",
    "        sample_locations_unique_xs = np.unique(sample_locations_roi[:,0])\n",
    "        sample_locations_unique_ys = np.unique(sample_locations_roi[:,1])\n",
    "\n",
    "        n_sample_x = sample_locations_unique_xs.size\n",
    "        n_sample_y = sample_locations_unique_ys.size\n",
    "\n",
    "        index_x = dict([(j,i) for i,j in enumerate(sample_locations_unique_xs)])\n",
    "        index_y = dict([(j,i) for i,j in enumerate(sample_locations_unique_ys)])\n",
    "        sample_location_indices = np.asarray([(index_x[x], index_y[y]) for x, y in sample_locations_roi])\n",
    "\n",
    "        sample_locations_interpolatedArea_ys_matrix, \\\n",
    "        sample_locations_interpolatedArea_xs_matrix = np.meshgrid(range(interpolation_ymin/shrink_factor, \n",
    "                                                                        interpolation_ymax/shrink_factor), \n",
    "                                                                  range(interpolation_xmin/shrink_factor, \n",
    "                                                                        interpolation_xmax/shrink_factor), \n",
    "                                                                  indexing='ij')\n",
    "\n",
    "\n",
    "        def generate_score_map(l):\n",
    "\n",
    "            label = labels[(l+1)%len(labels)]\n",
    "            if label == 'BackG':\n",
    "                return\n",
    "\n",
    "            score_matrix = np.zeros((n_sample_x, n_sample_y))\n",
    "            score_matrix[sample_location_indices[:,0], sample_location_indices[:,1]] = probs[:,l]\n",
    "\n",
    "            spline = RectBivariateSpline(sample_locations_unique_xs/shrink_factor, \n",
    "                                         sample_locations_unique_ys/shrink_factor, \n",
    "                                         score_matrix, \n",
    "                                         bbox=[interpolation_xmin/shrink_factor, \n",
    "                                               interpolation_xmax/shrink_factor, \n",
    "                                               interpolation_ymin/shrink_factor, \n",
    "                                               interpolation_ymax/shrink_factor])\n",
    "\n",
    "            dense_score_map = spline.ev(sample_locations_interpolatedArea_xs_matrix, \n",
    "                                        sample_locations_interpolatedArea_ys_matrix)\n",
    "\n",
    "            dense_score_map = resize(dense_score_map, (interpolation_h, interpolation_w))\n",
    "\n",
    "\n",
    "            dense_score_map[dense_score_map < 1e-2] = 0\n",
    "            dense_score_map_lossless = np.pad(dense_score_map, ((interpolation_ymin, h-interpolation_ymax-1), \n",
    "                                                  (interpolation_xmin, w-interpolation_xmax-1)),\n",
    "                                              mode='constant', constant_values=0)\n",
    "            \n",
    "            if np.count_nonzero(score_map[::8, ::8] > .1) < 1e3:\n",
    "                sys.stderr.write('No %s is detected on section %d\\n' % (label, sec))\n",
    "            \n",
    "#             bp.pack_ndarray_file(dense_score_map_lossless, \n",
    "#                                    os.path.join(scoremaps_dir, '%(dataset)s_denseScoreMapLossless_%(label)s.bp' % \\\n",
    "#                                                 {'dataset': dataset, 'label': label}))\n",
    "\n",
    "\n",
    "        t = time.time()\n",
    "\n",
    "        n_labels = probs.shape[1]\n",
    "\n",
    "        _ = Parallel(n_jobs=12)(delayed(generate_score_map)(l) for l in range(n_labels))\n",
    "\n",
    "        sys.stderr.write('interpolate: %.2f seconds\\n' % (time.time() - t))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
