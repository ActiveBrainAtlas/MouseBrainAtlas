{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting environment for Precision WorkStation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No vtk\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from multiprocess import Pool\n",
    "\n",
    "sys.path.append(os.path.join(os.environ['REPO_DIR'], 'utilities'))\n",
    "from utilities2015 import *\n",
    "from metadata import *\n",
    "from data_manager import *\n",
    "from learning_utilities import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/mxnet/module/base_module.py:53: UserWarning: \u001b[91mYou created Module with Module(..., label_names=['softmax_label']) but input with name 'softmax_label' is not found in symbol.list_arguments(). Did you mean one of:\n",
      "\tdata\u001b[0m\n",
      "  warnings.warn(msg)\n",
      "/usr/local/lib/python2.7/dist-packages/mxnet/module/base_module.py:65: UserWarning: Data provided by label_shapes don't match names specified by label_names ([] vs. ['softmax_label'])\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "model_dir_name = 'inception-bn-blue'\n",
    "model_name = 'inception-bn-blue'\n",
    "model, mean_img = load_mxnet_model(model_dir_name=model_dir_name, model_name=model_name, \n",
    "                                   num_gpus=1, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from learning_utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "locate patches: 0.04 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf \"/data/CSHL_patch_features/inception-bn-blue/CHATM2/CHATM2_prep2_none_win7/CHATM2_slide36_2018_01_22-S3_prep2_none_win7_inception-bn-blue_features.bp\" && mkdir -p \"/data/CSHL_patch_features/inception-bn-blue/CHATM2/CHATM2_prep2_none_win7\"\n",
      "0\n",
      "aws s3 cp \"s3://mousebrainatlas-data/CSHL_patch_features/inception-bn-blue/CHATM2/CHATM2_prep2_none_win7/CHATM2_slide36_2018_01_22-S3_prep2_none_win7_inception-bn-blue_features.bp\" \"/data/CSHL_patch_features/inception-bn-blue/CHATM2/CHATM2_prep2_none_win7/CHATM2_slide36_2018_01_22-S3_prep2_none_win7_inception-bn-blue_features.bp\"\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/data/CSHL_patch_features/inception-bn-blue/CHATM2/CHATM2_prep2_none_win7/CHATM2_slide36_2018_01_22-S3_prep2_none_win7_inception-bn-blue_features.bp'\n",
      "No pre-computed features found... computing from scratch.\n",
      "Not using image_cache.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/CSHL_data_processed/CHATM2/CHATM2_prep2_raw_NtbNormalizedAdaptiveInvertedGamma/CHATM2_slide36_2018_01_22-S3_prep2_raw_NtbNormalizedAdaptiveInvertedGamma.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load image: 0.67 seconds.\n",
      "Rescale image from 317 to 224: 1.30 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10492, 7598)\n",
      "[[  177   177]\n",
      " [  177   242]\n",
      " [  177   307]\n",
      " ...\n",
      " [15714  8693]\n",
      " [15714  8758]\n",
      " [15714  8823]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Crop patches: 0.80 seconds.\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-2f501d76e94c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m                                  \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mattach_timestamp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         version='NtbNormalizedAdaptiveInvertedGamma')\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;31m#         break\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yuncong/Brain/utilities/learning_utilities.py\u001b[0m in \u001b[0;36mcompute_and_save_features_one_section\u001b[0;34m(scheme, win_id, stack, prep_id, locations_roi, bbox, sec, fn, method, model, mean_img, model_name, batch_size, attach_timestamp, version)\u001b[0m\n\u001b[1;32m   3004\u001b[0m                                           \u001b[0mstack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocations_to_compute\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3005\u001b[0m                                           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_img\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmean_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3006\u001b[0;31m                                                  version=version)\n\u001b[0m\u001b[1;32m   3007\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Compute features at one section, multiple locations: %.2f seconds\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yuncong/Brain/utilities/learning_utilities.py\u001b[0m in \u001b[0;36mcompute_features_at_one_section_locations\u001b[0;34m(scheme, win_id, stack, section, locations, method, model, mean_img, batch_size, version)\u001b[0m\n\u001b[1;32m   3043\u001b[0m                                                    \u001b[0moutput_patch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3044\u001b[0m                                                    \u001b[0mnormalization_scheme\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheme\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3045\u001b[0;31m                                                   version=version)\n\u001b[0m\u001b[1;32m   3046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3047\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Extract patches: %.2f seconds\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yuncong/Brain/utilities/learning_utilities.py\u001b[0m in \u001b[0;36mextract_patches_given_locations\u001b[0;34m(patch_size, locs, img, stack, sec, fn, version, prep_id, normalization_scheme, is_nissl, output_patch_size)\u001b[0m\n\u001b[1;32m    869\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Crop patches: %.2f seconds.\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moutput_patch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_patch_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpatches\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnormalization_scheme\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'normalize_mu_region_sigma_wholeImage_(-1,9)'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# for stack in ['MD661', 'MD662']:\n",
    "# for stack in ['MD585', 'MD589', 'MD594']:\n",
    "for stack in ['CHATM2']:\n",
    "#     for sec in metadata_cache['valid_sections'][stack]:\n",
    "    for sec in [108]:\n",
    "#         if sec < 253:\n",
    "#             continue\n",
    "\n",
    "    #     for structure in clfs.keys():\n",
    "    #     for structure in ['DC', '5N', '3N', 'Pn', '10N', 'LC', '7N', 'Amb', '12N', 'RMC', 'Sp5O', 'Sp5I', 'Sp5C', 'VCP', 'AP', 'PBG', 'LRt', 'IC', 'VLL', '4N', 'SNC', '6N', 'SNR', 'SC', 'RtTg']:\n",
    "\n",
    "        compute_and_save_features_one_section(\n",
    "#                                 scheme='normalize_mu_region_sigma_wholeImage_(-1,5)', \n",
    "                                    scheme='none', \n",
    "    #                             bbox=(11217, 16886, 13859, 18404),\n",
    "#                                 method='glcm',\n",
    "                                method='cnn',\n",
    "                                win_id=7, prep_id=2,\n",
    "                                stack=stack, sec=sec,\n",
    "                                model=model, model_name=model_name,\n",
    "                                 mean_img=mean_img, \n",
    "                                 batch_size=batch_size, \n",
    "            attach_timestamp=False,\n",
    "        version='NtbNormalizedAdaptiveInvertedGamma')\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack = 'CHATM3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database or disk is full',)).History will not be written to the database.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'bbox' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-954e4fdb5851>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mbbox\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mroi_xmin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mroi_ymin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mroi_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroi_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image_shape'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bbox' is not defined"
     ]
    }
   ],
   "source": [
    "if bbox is None:\n",
    "    roi_xmin = 0\n",
    "    roi_ymin = 0\n",
    "    roi_w, roi_h = metadata_cache['image_shape'][stack]\n",
    "else:\n",
    "    roi_xmin, roi_xmax, roi_ymin, roi_ymax = bbox\n",
    "    roi_w = roi_xmax + 1 - roi_xmin\n",
    "    roi_h = roi_ymax + 1 - roi_ymin\n",
    "\n",
    "if fn is None:\n",
    "    fn = metadata_cache['sections_to_filenames'][stack][sec]\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "t = time.time()\n",
    "mask_tb = DataManager.load_thumbnail_mask_v3(stack=stack, prep_id=prep_id, fn=fn)\n",
    "grid_spec = win_id_to_gridspec(win_id=win_id, stack=stack)\n",
    "locations_roi = locate_patches_v2(grid_spec=grid_spec, mask_tb=mask_tb,\n",
    "                                bbox_lossless=(roi_xmin, roi_ymin, roi_w, roi_h),\n",
    "                               return_locations=True)\n",
    "sys.stderr.write('locate patches: %.2f seconds\\n' % (time.time() - t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_patches = extract_patches_given_locations(stack='CHATM3', sec=100,\n",
    "                                               locs=locations,\n",
    "                                               patch_size=patch_size_px,\n",
    "                                               output_patch_size=224,\n",
    "                                               normalization_scheme=scheme,\n",
    "                                              version=version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
