{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/IPython/html.py:14: ShimWarning: The `IPython.html` package has been deprecated. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.environ['REPO_DIR'] + '/utilities')\n",
    "from utilities2015 import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import mxnet as mx\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patches_rootdir = '/home/yuncong/CSHL_data_patches/'\n",
    "model_dir = '/home/yuncong/mxnet_models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = ['BackG', '5N', '7n', '7N', '12N', 'Pn', 'VLL', \n",
    "          '6N', 'Amb', 'R', 'Tz', 'RtTg', 'LRt', 'LC', 'AP', 'sp5']\n",
    "\n",
    "label_dict = dict([(l,i) for i, l in enumerate(labels)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_img = mx.nd.load(os.path.join(model_dir, 'mean_224.nd'))['mean_img'].asnumpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "progress_bar = FloatProgress(min=0, max=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5N\n",
      "121 samples\n",
      "100 used samples\n",
      "5N_surround\n",
      "612 samples\n",
      "100 used samples\n",
      "7n\n",
      "48 samples\n",
      "48 used samples\n",
      "7n_surround\n",
      "515 samples\n",
      "100 used samples\n",
      "VLL\n",
      "83 samples\n",
      "83 used samples\n",
      "VLL_surround\n",
      "535 samples\n",
      "100 used samples\n"
     ]
    }
   ],
   "source": [
    "patches_allClasses = defaultdict(list)\n",
    "\n",
    "for stack in ['MD589']:\n",
    "\n",
    "    dm = DataManager(stack=stack)\n",
    "    stack_has_annotation = True\n",
    "\n",
    "    if stack_has_annotation:\n",
    "        table_filepath = os.path.join(patches_rootdir, '%(stack)s_indices_allLandmarks_allSections.h5'%{'stack':stack})\n",
    "        indices_allLandmarks_allSections = pd.read_hdf(table_filepath, 'indices_allLandmarks_allSections')\n",
    "        grid_parameters = pd.read_hdf(table_filepath, 'grid_parameters')\n",
    "        \n",
    "    patch_size, stride, w, h = grid_parameters.tolist()\n",
    "    half_size = patch_size/2\n",
    "    ys, xs = np.meshgrid(np.arange(half_size, h-half_size, stride), np.arange(half_size, w-half_size, stride),\n",
    "                     indexing='xy')\n",
    "    sample_locations = np.c_[xs.flat, ys.flat]\n",
    "        \n",
    "    first_bs_sec, last_bs_sec = section_range_lookup[stack]\n",
    "    first_detect_sec, last_detect_sec = detect_bbox_range_lookup[stack]\n",
    "\n",
    "    progress_bar.min = first_detect_sec\n",
    "    progress_bar.max = last_detect_sec\n",
    "    display(progress_bar)\n",
    "    \n",
    "    for sec in range(first_detect_sec, last_detect_sec+1):\n",
    "#     for sec in range(first_detect_sec, first_detect_sec+10):\n",
    "#     for sec in range(first_detect_sec, first_detect_sec+1):\n",
    "        \n",
    "        if sec not in indices_allLandmarks_allSections.columns:\n",
    "            continue\n",
    "\n",
    "        progress_bar.value = sec\n",
    "#         print sec\n",
    "\n",
    "        ## define grid, generate patches\n",
    "\n",
    "        dm.set_slice(sec)\n",
    "        dm._load_image(['rgb-jpg'])\n",
    "\n",
    "        q = indices_allLandmarks_allSections[sec].dropna()\n",
    "        if len(q.index) == 0:\n",
    "            continue\n",
    "\n",
    "        for label in q.index:\n",
    "            if label == 'bg':\n",
    "                continue\n",
    "\n",
    "            print label\n",
    "            indices_roi = q[label]\n",
    "    \n",
    "            n2 = len(indices_roi)\n",
    "            print n2, 'samples'\n",
    "\n",
    "            num_sample_each_polygon = 100\n",
    "            indices_roi = np.random.choice(indices_roi, min(num_sample_each_polygon, n2), replace=False)\n",
    "\n",
    "            n = len(indices_roi)\n",
    "            print n, 'used samples'\n",
    "\n",
    "            sample_locations_roi = sample_locations[indices_roi]\n",
    "\n",
    "            patches2 = np.asarray([dm.image_rgb_jpg[y-half_size:y+half_size, x-half_size:x+half_size]\n",
    "                                  for x, y in sample_locations_roi])\n",
    "\n",
    "            patches = np.rollaxis(patches2, 3, 1)\n",
    "            patches_allClasses[label].append(patches - mean_img)\n",
    "\n",
    "            del patches, patches2, sample_locations_roi\n",
    "\n",
    "    del sample_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_features_dir = '/home/yuncong/CSHL_patch_features/train'\n",
    "if not os.path.exists(training_features_dir):\n",
    "    os.makedirs(training_features_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for label, patches in patches_allClasses_arr.iteritems():\n",
    "\n",
    "for label, patches1 in patches_allClasses.iteritems():\n",
    "    \n",
    "    patches = np.concatenate(patches1)\n",
    "\n",
    "    n = len(patches)\n",
    "    \n",
    "    batch_size = 512 # increasing to 892 does not save any time\n",
    "\n",
    "    if n < batch_size:\n",
    "        sys.stderr.write('data size smaller than batch size: %s\\n' % label)\n",
    "        continue\n",
    "    \n",
    "    train_iter = mx.io.NDArrayIter(\n",
    "        patches, \n",
    "        np.zeros((n, ), np.int),\n",
    "        batch_size = batch_size,\n",
    "        shuffle=False\n",
    "    )\n",
    "    #         sys.stderr.write('load iterator: %.2f seconds\\n' % (time.time() - t))\n",
    "\n",
    "    t = time.time()\n",
    "\n",
    "    features = model.predict(train_iter)\n",
    "\n",
    "    bp.pack_ndarray_file(features, training_features_dir + '/%(stack)s_%(label)s_features.bp'% {'stack': stack,\n",
    "                                                                                               'label': label})\n",
    "\n",
    "    sys.stderr.write('predict: %.2f seconds\\n' % (time.time() - t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name = 'experiment0317'\n",
    "model_iteration = 6\n",
    "\n",
    "model = mx.model.FeedForward.load(os.path.join(model_dir, model_name), model_iteration, ctx=mx.gpu())\n",
    "\n",
    "# model.arg_params['fullc_bias'].asnumpy()\n",
    "\n",
    "# fc_output = model.symbol.get_internals()['fc_output']\n",
    "flatten_output = model.symbol.get_internals()['flatten_output']\n",
    "# fc_output = model.symbol.get_internals()['fullc_output']\n",
    "# sm_output = model.symbol.get_internals()['softmax_output']\n",
    "# grouped_output = mx.symbol.Group([flatten_output, sm_output])\n",
    "\n",
    "model = mx.model.FeedForward(ctx=mx.gpu(), symbol=flatten_output, num_epoch=model_iteration,\n",
    "                            arg_params=model.arg_params, aux_params=model.aux_params,\n",
    "                            allow_extra_params=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for label in ['6N', '6N_surround']:\n",
    "\n",
    "    patches1 = patches_allClasses[label]\n",
    "\n",
    "    patches = np.concatenate(patches1)\n",
    "\n",
    "    n = len(patches)\n",
    "\n",
    "    batch_size = 128 # increasing to 892 does not save any time\n",
    "\n",
    "    train_iter = mx.io.NDArrayIter(\n",
    "        patches, \n",
    "        np.zeros((n, ), np.int),\n",
    "        batch_size = batch_size,\n",
    "        shuffle=False\n",
    "    )\n",
    "    #         sys.stderr.write('load iterator: %.2f seconds\\n' % (time.time() - t))\n",
    "\n",
    "    t = time.time()\n",
    "\n",
    "    features = model.predict(train_iter)\n",
    "\n",
    "    bp.pack_ndarray_file(features, training_features_dir + '/%(stack)s_%(label)s_features.bp'% {'stack': stack,\n",
    "                                                                                               'label': label})\n",
    "\n",
    "    sys.stderr.write('predict: %.2f seconds\\n' % (time.time() - t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[(label, len(patches)) for label, patches in patches_allClasses_arr.iteritems()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
