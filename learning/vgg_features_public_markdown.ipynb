{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG features experiment\n",
    "\n",
    "This notebook reports an classification experiment using the features extracted by the [VGG net](http://www.robots.ox.ac.uk/~vgg/research/very_deep/]). The network takes 224-by-224 patches and outputs 4906-dimensional feature vectors. \n",
    "\n",
    "Based on the manually drawn contours of structures on images of half a brain, we collected patches for nine landmarks as the training set:\n",
    "\n",
    "label| #patches\n",
    "---|---|\n",
    "Gr | 36\n",
    "7N | 646\n",
    "SuVe | 84\n",
    "12N |161\n",
    "LVe |424\n",
    "5N | 312\n",
    "7n | 121\n",
    "Pn | 1940\n",
    "VLL | 247\n",
    "\n",
    "The feature extractor is implemented with [mxnet](https://github.com/dmlc/mxnet). On Jiaxu's 4GB-memory GPU, the extraction for all training patches takes 2 minutes. Another timing experiment shows using the 2GB-memory GPU on my Macbook Pro is more than 15 times faster than using the CPUs on Gordon.\n",
    "\n",
    "\n",
    "Similar to this paper, the feature vectors of all patches in a single class are pooled, by taking the 3-norm of each feature. This figure shows the pooled feature vector for each class:\n",
    "\n",
    "![caption](../public/figures/pooled_features_9class.jpg)\n",
    "\n",
    "Now we focus on the classification task for a pair of nearby landmarks: 12N vs Gr. To reduce the dimensionality of features, as well as to increase the specificity of features to our own data, we keep only the 100 features that are most different between the pooled feature vectors of 12N and Gr. A linear SVM is trained to separate the two classes.\n",
    "\n",
    "The figure below shows the effect of this classifier on an unseen image. The magenta and cyan contours are the manually drawn contours for 12N and Gr respectively. Green circles are where the patches are predicted to be 12N and the red circles are those predicted to be Gr.\n",
    "\n",
    "When the threshold is 0:\n",
    "![caption](../public/figures/labelmap_score0.00.jpg)\n",
    "\n",
    "Increase the threshold to 1.1\n",
    "![caption](../public/figures/labelmap_score1.10.jpg)\n",
    "\n",
    "This of course is a very ad-hoc experiment. It would make more sense if the classifier is trained to separate 12N from all other textures in its surrounding. Nonetheless, this demonstrates the usefulness of features extracted by the VGG net."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a range of possibilities for improving the classifier, for example:\n",
    "- a more principled way of choosing which textures to classify. One possibility is to train binary classifier for a landmark vs. all other textures within a certain radius of its extent.\n",
    "- a more effective way to reduce the dimensionality of neural network features. For example, using boosting to select top features.\n",
    "- fine-tune the VGG network against our labeled data.\n",
    "\n",
    "While these are promising directions, I think the more important question is, **how to convert classifier results on patches into smooth contours that fit landmark boundaries well**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
