{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.environ['REPO_DIR'] + '/utilities')\n",
    "from utilities2015 import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import mxnet as mx\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# labels =  ['BackG', '5N', '7n', '7N', '12N', 'Gr', 'LVe', 'Pn', 'SuVe', 'VLL']\n",
    "\n",
    "labels = ['BackG', '5N', '7n', '7N', '12N', 'Pn', 'VLL', \n",
    "          '6N', 'Amb', 'R', 'Tz', 'RtTg', 'LRt', 'LC', 'AP', 'sp5']\n",
    "\n",
    "label_dict = dict([(l,i) for i, l in enumerate(labels)])\n",
    "\n",
    "# label_dict = dict([(l,i) for i, l in enumerate(labels)] + \\\n",
    "#                   zip(other_labels, range(len(labels), len(labels)+len(other_labels))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patches_rootdir = '/home/yuncong/CSHL_data_patches/'\n",
    "model_dir = '/home/yuncong/mxnet_models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model_name='Inception_BN'\n",
    "# model_iteration = 39\n",
    "# init_model = mx.model.FeedForward.load(os.path.join(model_dir, model_name), \n",
    "#                                      model_iteration, \n",
    "#                                      ctx=mx.gpu(),\n",
    "#                                     numpy_batch_size=batch_size)\n",
    "\n",
    "# arg_params = init_model.arg_params.copy()\n",
    "# arg_params.pop('fc_bias');\n",
    "# arg_params.pop('fc_weight');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name='inception-stage1'\n",
    "model_iteration = 10\n",
    "init_model = mx.model.FeedForward.load(os.path.join(model_dir, model_name), \n",
    "                                     model_iteration, \n",
    "                                     ctx=mx.gpu(),\n",
    "                                    numpy_batch_size=batch_size)\n",
    "\n",
    "\n",
    "arg_params = init_model.arg_params.copy()\n",
    "arg_params.pop('fullc_bias');\n",
    "arg_params.pop('fullc_weight');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_class = len(labels)\n",
    "internals = init_model.symbol.get_internals()\n",
    "flatten_output = internals['flatten_output']\n",
    "fc = mx.symbol.FullyConnected(data=flatten_output, name='fullc', num_hidden=n_class)\n",
    "softmax = mx.symbol.SoftmaxOutput(data=fc, name='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_img = mx.nd.load(os.path.join(model_dir, 'mean_224.nd'))['mean_img'].asnumpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.html.widgets import FloatProgress\n",
    "from IPython.display import display\n",
    "\n",
    "progress_bar = FloatProgress(min=0, max=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patches_allClasses = []\n",
    "patchLabels_allClasses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for stack in ['MD589']:\n",
    "\n",
    "    dm = DataManager(stack=stack)\n",
    "    stack_has_annotation = True\n",
    "\n",
    "    if stack_has_annotation:\n",
    "        table_filepath = os.path.join(patches_rootdir, '%(stack)s_indices_allLandmarks_allSections.h5'%{'stack':stack})\n",
    "        indices_allLandmarks_allSections = pd.read_hdf(table_filepath, 'indices_allLandmarks_allSections')\n",
    "        grid_parameters = pd.read_hdf(table_filepath, 'grid_parameters')\n",
    "\n",
    "    first_bs_sec, last_bs_sec = section_range_lookup[stack]\n",
    "    first_detect_sec, last_detect_sec = detect_bbox_range_lookup[stack]\n",
    "\n",
    "    progress_bar.min = first_detect_sec\n",
    "    progress_bar.max = last_detect_sec\n",
    "    display(progress_bar)\n",
    "    \n",
    "    for sec in range(first_detect_sec, last_detect_sec+1):\n",
    "#     for sec in range(first_detect_sec, first_detect_sec+10):\n",
    "#     for sec in range(first_detect_sec, first_detect_sec+1):\n",
    "        \n",
    "        if sec not in indices_allLandmarks_allSections.columns:\n",
    "            continue\n",
    "\n",
    "        progress_bar.value = sec\n",
    "#         print sec\n",
    "\n",
    "        ## define grid, generate patches\n",
    "\n",
    "    #     t = time.time()\n",
    "        dm.set_slice(sec)\n",
    "        dm._load_image(['rgb-jpg'])\n",
    "\n",
    "        patch_size, stride, w, h = grid_parameters.tolist()\n",
    "        half_size = patch_size/2\n",
    "\n",
    "        ys, xs = np.meshgrid(np.arange(half_size, h-half_size, stride), np.arange(half_size, w-half_size, stride),\n",
    "                         indexing='xy')\n",
    "\n",
    "        sample_locations = np.c_[xs.flat, ys.flat]\n",
    "\n",
    "\n",
    "        q = indices_allLandmarks_allSections[sec].dropna()\n",
    "        if len(q.index) == 0:\n",
    "            continue\n",
    "\n",
    "        for label_ind, label in enumerate(labels):\n",
    "\n",
    "            print label\n",
    "\n",
    "            if label == 'BackG':\n",
    "                w = [q[l] for l in q.index if l.endswith('surround')]\n",
    "                if len(w) == 0:\n",
    "                    continue\n",
    "                else:\n",
    "                    indices_roi = np.concatenate(w)\n",
    "            else:\n",
    "                if label in q.index:\n",
    "                    indices_roi = q[label]\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "            n2 = len(indices_roi)\n",
    "            print n2, 'samples'\n",
    "\n",
    "            num_sample_each_polygon = 30\n",
    "            indices_roi = np.random.choice(indices_roi, min(num_sample_each_polygon, n2), replace=False)\n",
    "\n",
    "            n = len(indices_roi)\n",
    "            print n, 'used samples'\n",
    "\n",
    "            sample_locations_roi = sample_locations[indices_roi]\n",
    "\n",
    "            patches2 = np.asarray([dm.image_rgb_jpg[y-half_size:y+half_size, x-half_size:x+half_size]\n",
    "                                  for x, y in sample_locations_roi])\n",
    "\n",
    "            patches = np.rollaxis(patches2, 3, 1)\n",
    "            patches = patches - mean_img\n",
    "\n",
    "            patches_allClasses.append(patches.copy())\n",
    "\n",
    "            patch_labels = label_ind * np.ones((n, ), np.int)\n",
    "            patchLabels_allClasses.append(patch_labels)\n",
    "\n",
    "            del patches, patches2, sample_locations_roi\n",
    "\n",
    "        del sample_locations\n",
    "\n",
    "    #     break\n",
    "    #     sys.stderr.write('generating patches: %.2f seconds\\n' % (time.time() - t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patches_allClasses_arr = np.concatenate(patches_allClasses)\n",
    "patchLabels_allClasses_arr = np.concatenate(patchLabels_allClasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(patchLabels_allClasses_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patches_allClasses_eval = []\n",
    "patchLabels_allClasses_eval = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for stack in ['MD594']:\n",
    "\n",
    "    dm = DataManager(stack=stack)\n",
    "    stack_has_annotation = True\n",
    "\n",
    "    if stack_has_annotation:\n",
    "        table_filepath = os.path.join(patches_rootdir, '%(stack)s_indices_allLandmarks_allSections.h5'%{'stack':stack})\n",
    "        indices_allLandmarks_allSections = pd.read_hdf(table_filepath, 'indices_allLandmarks_allSections')\n",
    "        grid_parameters = pd.read_hdf(table_filepath, 'grid_parameters')\n",
    "\n",
    "    first_bs_sec, last_bs_sec = section_range_lookup[stack]\n",
    "    first_detect_sec, last_detect_sec = detect_bbox_range_lookup[stack]\n",
    "\n",
    "    progress_bar.min = first_detect_sec\n",
    "    progress_bar.max = last_detect_sec\n",
    "    display(progress_bar)\n",
    "    \n",
    "    for sec in range(first_detect_sec, last_detect_sec+1):\n",
    "        \n",
    "        if sec not in indices_allLandmarks_allSections.columns:\n",
    "            continue\n",
    "\n",
    "        progress_bar.value = sec\n",
    "#         print sec\n",
    "\n",
    "        ## define grid, generate patches\n",
    "\n",
    "    #     t = time.time()\n",
    "        dm.set_slice(sec)\n",
    "        dm._load_image(['rgb-jpg'])\n",
    "\n",
    "        patch_size, stride, w, h = grid_parameters.tolist()\n",
    "        half_size = patch_size/2\n",
    "\n",
    "        ys, xs = np.meshgrid(np.arange(half_size, h-half_size, stride), np.arange(half_size, w-half_size, stride),\n",
    "                         indexing='xy')\n",
    "\n",
    "        sample_locations = np.c_[xs.flat, ys.flat]\n",
    "\n",
    "\n",
    "        q = indices_allLandmarks_allSections[sec].dropna()\n",
    "        if len(q.index) == 0:\n",
    "            continue\n",
    "\n",
    "        for label_ind, label in enumerate(labels):\n",
    "\n",
    "            print label\n",
    "\n",
    "            if label == 'BackG':\n",
    "                w = [q[l] for l in q.index if l.endswith('surround')]\n",
    "                if len(w) == 0:\n",
    "                    continue\n",
    "                else:\n",
    "                    indices_roi = np.concatenate(w)\n",
    "            else:\n",
    "                if label in q.index:\n",
    "                    indices_roi = q[label]\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "            n2 = len(indices_roi)\n",
    "            print n2, 'samples'\n",
    "\n",
    "            num_sample_each_polygon = 30\n",
    "            indices_roi = np.random.choice(indices_roi, min(num_sample_each_polygon, n2), replace=False)\n",
    "\n",
    "            n = len(indices_roi)\n",
    "            print n, 'used samples'\n",
    "\n",
    "            sample_locations_roi = sample_locations[indices_roi]\n",
    "\n",
    "            patches2 = np.asarray([dm.image_rgb_jpg[y-half_size:y+half_size, x-half_size:x+half_size]\n",
    "                                  for x, y in sample_locations_roi])\n",
    "\n",
    "            patches = np.rollaxis(patches2, 3, 1)\n",
    "            patches = patches - mean_img\n",
    "\n",
    "            patches_allClasses_eval.append(patches.copy())\n",
    "\n",
    "            patch_labels = label_ind * np.ones((n, ), np.int)\n",
    "            patchLabels_allClasses_eval.append(patch_labels)\n",
    "\n",
    "            del patches, patches2, sample_locations_roi\n",
    "\n",
    "        del sample_locations\n",
    "\n",
    "    #     break\n",
    "    #     sys.stderr.write('generating patches: %.2f seconds\\n' % (time.time() - t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(patches_allClasses_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patches_allClasses_eval_arr = np.concatenate(patches_allClasses_eval)\n",
    "patchLabels_allClasses_eval_arr = np.concatenate(patchLabels_allClasses_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_epoch = 10\n",
    "l_rate = 0.001\n",
    "# checkpoint_prefix = os.path.join(model_dir, 'experiment0227')\n",
    "checkpoint_prefix = os.path.join(model_dir, 'experiment0317')\n",
    "\n",
    "opt = mx.optimizer.SGD(learning_rate=l_rate)\n",
    "\n",
    "net = mx.model.FeedForward(ctx=mx.gpu(), \n",
    "#                            symbol=init_model.symbol, \n",
    "                           symbol=softmax, \n",
    "                           num_epoch=n_epoch, optimizer=opt,\n",
    "                           arg_params = arg_params, \n",
    "                           aux_params = init_model.aux_params,\n",
    "                           allow_extra_params = True,\n",
    "                           numpy_batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_iter = mx.io.NDArrayIter(\n",
    "    patches_allClasses_arr, \n",
    "    patchLabels_allClasses_arr,\n",
    "    batch_size = batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# eval_iter = mx.io.NDArrayIter(\n",
    "#     patches_allClasses_eval_arr, \n",
    "#     patchLabels_allClasses_eval_arr,\n",
    "#     batch_size = batch_size,\n",
    "#     shuffle=True\n",
    "# )\n",
    "\n",
    "t = time.time()\n",
    "\n",
    "# net.fit(train_iter, eval_data=eval_iter,\n",
    "#         batch_end_callback=mx.callback.Speedometer(batch_size, 30),\n",
    "#         epoch_end_callback=mx.callback.do_checkpoint(checkpoint_prefix))\n",
    "\n",
    "net.fit(train_iter,\n",
    "        batch_end_callback=mx.callback.Speedometer(batch_size, 30),\n",
    "        epoch_end_callback=mx.callback.do_checkpoint(checkpoint_prefix))\n",
    "\n",
    "net.save(checkpoint_prefix)\n",
    "\n",
    "print time.time() - t\n",
    "\n",
    "# 100 samples/sec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "q = np.where(patchLabels_allClasses == label_dict['7N'])[0]\n",
    "\n",
    "for p in patches_allClasses[q]:\n",
    "    plt.imshow(np.rollaxis(p + mean_img, 0, 3).astype(np.uint8));\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
