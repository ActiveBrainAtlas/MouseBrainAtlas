{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.environ['REPO_DIR'], 'utilities'))\n",
    "from utilities2015 import *\n",
    "\n",
    "sys.path.append('/oasis/projects/nsf/csd181/yuncong/opencv-2.4.9/release/lib/python2.7/site-packages')\n",
    "import cv2\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting environment for Gordon\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/oasis/projects/nsf/csd181/yuncong/virtualenv-1.9.1/yuncongve/lib/python2.7/site-packages/skimage/filter/__init__.py:6: skimage_deprecation: The `skimage.filter` module has been renamed to `skimage.filters`.  This placeholder module will be removed in v0.13.\n",
      "  warn(skimage_deprecation('The `skimage.filter` module has been renamed '\n"
     ]
    }
   ],
   "source": [
    "from skimage.filters.rank import entropy\n",
    "from skimage.morphology import remove_small_objects, disk\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.io import imread, imsave\n",
    "from skimage import img_as_float\n",
    "\n",
    "from sklearn import mixture\n",
    "\n",
    "from skimage.measure import find_contours\n",
    "from annotation_utilities import *\n",
    "from skimage.segmentation import active_contour\n",
    "from skimage.filters import gaussian\n",
    "from skimage.filter import threshold_adaptive, canny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def generate_mask(img):\n",
    "\n",
    "#     h, w = img.shape\n",
    "    \n",
    "#     e = entropy(img, disk(5))\n",
    "    \n",
    "#     clf = mixture.GMM(n_components=2, covariance_type='full')\n",
    "#     clf.fit(np.atleast_2d(e[e > 0.1]).T)\n",
    "\n",
    "#     means = np.squeeze(clf.means_)\n",
    "\n",
    "#     order = np.argsort(means)\n",
    "#     means = means[order]\n",
    "\n",
    "#     covars =np.squeeze(clf.covars_)\n",
    "#     covars = covars[order]\n",
    "\n",
    "#     weights = clf.weights_\n",
    "#     weights = weights[order]\n",
    "\n",
    "#     counts, bins = np.histogram(e.flat, bins=100, density=True);\n",
    "\n",
    "#     gs = np.array([w * 1./np.sqrt(2*np.pi*c) * np.exp(-(bins-m)**2/(2*c)) for m, c, w in zip(means, covars, weights)])\n",
    "\n",
    "#     thresh = bins[np.where(gs[-1] - gs[-2] < 0)[0][-1]]\n",
    "\n",
    "#     v = e > thresh\n",
    "\n",
    "#     l = label(v, background=0)\n",
    "#     mask = l == np.argmax([p.area for p in regionprops(l+1)])\n",
    "    \n",
    "#     mask = ~remove_small_objects(~mask, min_size=10000, connectivity=8)\n",
    "    \n",
    "#     l = label(v)\n",
    "#     l[v > 0] = -1\n",
    "#     props = regionprops(l)\n",
    "    \n",
    "#     border_holes = np.where([np.any(p.coords[:,0] == 0) or np.any(p.coords[:,1] == 0) \\\n",
    "#                              or np.any(p.coords[:,0] == h-1) or np.any(p.coords[:,1] == w-1) \n",
    "#                              for p in props])[0]\n",
    "\n",
    "#     for i in border_holes:\n",
    "#         c = props[i].coords\n",
    "#         mask[c[:,0], c[:,1]] = 0\n",
    "    \n",
    "#     return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_mask(fn):\n",
    "\n",
    "    img_rgb = imread(os.path.join(input_dir, fn + '.tif'))\n",
    "    img = rgb2gray(img_rgb)\n",
    "\n",
    "    entropy_mask = generate_entropy_mask(img)\n",
    "\n",
    "    init_contours = [yxs[:,::-1] for yxs in find_contours(entropy_mask, .5)]\n",
    "    assert len(init_contours) > 0, 'No contour is detected from entropy mask %s' % fn\n",
    "\n",
    "    img_adap = threshold_adaptive(img, 51)\n",
    "    img_adap[~entropy_mask] = 1\n",
    "\n",
    "    init_cnt = init_contours[0]\n",
    "    snake = active_contour(img_adap, init_cnt,\n",
    "                           alpha=1., beta=10., gamma=0.01,\n",
    "                           w_line=0., w_edge=1.,\n",
    "                           max_iterations=100)\n",
    "\n",
    "    bg = np.zeros(img.shape[:2], bool)\n",
    "    xys = points_inside_contour(snake.astype(np.int))\n",
    "    bg[xys[:,1], xys[:,0]] = 1\n",
    "\n",
    "    final_mask = bg & entropy_mask\n",
    "\n",
    "    return final_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack = 'MD585'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stack_masks_dir = create_if_not_exists('/home/yuncong/CSHL_data_processed/%(stack)s/%(stack)s_mask_unsorted' % dict(stack=stack))\n",
    "\n",
    "all_images = glob('/home/yuncong/CSHL_data/%(stack)s/*.tif' % dict(stack=stack))\n",
    "\n",
    "bar = show_progress_bar(1, len(all_images))\n",
    "\n",
    "for i, fn in enumerate(all_images):\n",
    "    \n",
    "    bar.value = i\n",
    "    \n",
    "    img_rgb = imread(fn)    \n",
    "    img = rgb2gray(img_rgb)\n",
    "\n",
    "    entropy_mask = generate_mask(img)\n",
    "\n",
    "    init_contours = [yxs[:,::-1] for yxs in find_contours(entropy_mask, .5)]\n",
    "\n",
    "    img_adap = threshold_adaptive(img, 51)\n",
    "    img_adap[~entropy_mask] = 1\n",
    "\n",
    "    init_cnt = init_contours[0]\n",
    "\n",
    "#     t = time.time()\n",
    "\n",
    "    # alpha: length\n",
    "    # beta: second order\n",
    "\n",
    "    snake = active_contour(img_adap, init_cnt, \n",
    "                           alpha=1., beta=10., gamma=0.01, \n",
    "                           w_line=0., w_edge=1., \n",
    "                           max_iterations=100)\n",
    "    #                        convergence=.01)\n",
    "\n",
    "#     print time.time() - t\n",
    "\n",
    "    bg = np.zeros(img.shape[:2], bool)\n",
    "    xys = points_inside_contour(snake.astype(np.int))\n",
    "    bg[xys[:,1], xys[:,0]] = 1\n",
    "\n",
    "    \n",
    "    final_mask = bg & entropy_mask\n",
    "    \n",
    "#     final_contours = find_contours(final_mask, .5)\n",
    "#     if len(final_contours) == 0:\n",
    "#         sys.stderr.write('%d contour error.\\n' % s)\n",
    "#         continue\n",
    "    \n",
    "#     final_cnt = final_contours[0][:,::-1]\n",
    "    \n",
    "    mask_fn = os.path.join(stack_masks_dir, '%(fn)s_mask.png' % dict(fn=os.path.splitext(os.path.basename(fn))[0]))\n",
    "    imsave(mask_fn, img_as_ubyte(final_mask))\n",
    "        \n",
    "#     fig = plt.figure(figsize=(30, 30));\n",
    "#     plt.imshow(img_adap, cmap=plt.cm.gray)\n",
    "#     plt.plot(init_cnt[:, 0], init_cnt[:, 1], '--r', lw=3)\n",
    "#     plt.plot(snake[:, 0], snake[:, 1], '-g', lw=3)\n",
    "#     plt.plot(final_cnt[:, 0], final_cnt[:, 1], '-b', lw=3)\n",
    "#     plt.title(s)\n",
    "#     plt.show()\n",
    "\n",
    "#     img_rgb_lossless = imread('/home/yuncong/CSHL_data_processed/MD603/MD603_lossless_sorted_aligned_cropped_compressed/MD603_%04d_lossless_aligned_cropped_compressed.jpg' % s)\n",
    "#     contour_lossless = final_cnt * 32\n",
    "#     contour_lossless_cropped = np.c_[contour_lossless[:, 0]-xmin*32, contour_lossless[:, 1]-ymin*32].astype(np.int)\n",
    "#     img2 = img_rgb_lossless.copy()\n",
    "#     for x, y in contour_lossless_cropped:\n",
    "#         cv2.circle(img2, (x,y), 10, (255,0,0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/home/yuncong/CSHL_data_processed/%(stack)s/%(stack)s_sorted_filenames.txt'%dict(stack=stack), 'r') as f:\n",
    "    fn_idx_tuples = [line.strip().split() for line in f.readlines()]\n",
    "    filename_to_section = {fn: int(idx) for fn, idx in fn_idx_tuples}\n",
    "    \n",
    "import cPickle as pickle\n",
    "Ts = pickle.load(open('/home/yuncong/CSHL_data_processed/%(stack)s/%(stack)s_elastix_output/%(stack)s_transformsTo_anchor.pkl' % dict(stack=stack), 'r'))\n",
    "\n",
    "Ts_inv = {}\n",
    "for fn, T0 in Ts.iteritems():\n",
    "    T = T0.copy()\n",
    "    T[:2, 2] = T[:2, 2]\n",
    "    Tinv = np.linalg.inv(T)\n",
    "    Ts_inv[fn] = Tinv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, stack, stack+'_anchor.txt'), 'r') as f:\n",
    "    anchor_fn = str(f.readline().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack_masks_aligned_dir = create_if_not_exists('/home/yuncong/CSHL_data_processed/%(stack)s/%(stack)s_mask_unsorted_alignedTo_%(anchor_fn)s' %\\\n",
    "                        dict(stack=stack, anchor_fn=anchor_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for fn, sec in filename_to_section.iteritems():\n",
    "    \n",
    "    T = Ts_inv[fn]\n",
    "    \n",
    "    d = {'sx':T[0,0],\n",
    "     'sy':T[1,1],\n",
    "     'rx':T[1,0],\n",
    "     'ry':T[0,1],\n",
    "     'tx':T[0,2],\n",
    "     'ty':T[1,2],\n",
    "     'input_fn': os.path.join(stack_masks_dir, fn + '_mask.png'),\n",
    "     'output_fn': os.path.join(stack_masks_aligned_dir, fn + 'mask_aligned.png'),\n",
    "     'x': '+' + str(x * scale_factor) if int(x)>=0 else str(x * scale_factor),\n",
    "     'y': '+' + str(y * scale_factor) if int(y)>=0 else str(y * scale_factor),\n",
    "     'w': str(w * scale_factor),\n",
    "     'h': str(h * scale_factor),\n",
    "    }\n",
    "\n",
    "    os.system(\"convert %(input_fn)s -virtual-pixel background +distort AffineProjection '%(sx)f,%(rx)f,%(ry)f,%(sy)f,%(tx)f,%(ty)f' -crop %(w)sx%(h)s%(x)s%(y)s\\! -flatten -compress lzw %(output_fn)s\"%d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
