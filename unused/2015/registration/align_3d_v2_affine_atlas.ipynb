{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Aligns a score volume with an annotation volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.environ['REPO_DIR'] + '/utilities')\n",
    "from utilities2015 import *\n",
    "from registration_utilities import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import time\n",
    "\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "volume_dir = '/oasis/projects/nsf/csd395/yuncong/CSHL_volumes/'\n",
    "\n",
    "atlasAlignOptLogs_dir = create_if_not_exists('/oasis/projects/nsf/csd395/yuncong/CSHL_atlasAlignOptLogs_atlas')\n",
    "atlasAlignParams_dir = create_if_not_exists('/oasis/projects/nsf/csd395/yuncong/CSHL_atlasAlignParams_atlas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "volume_landmark_names_unsided = ['12N', '5N', '6N', '7N', '7n', 'AP', 'Amb', 'LC',\n",
    "                                 'LRt', 'Pn', 'R', 'RtTg', 'Tz', 'VLL', 'sp5']\n",
    "linear_landmark_names_unsided = ['outerContour']\n",
    "\n",
    "labels_unsided = volume_landmark_names_unsided + linear_landmark_names_unsided\n",
    "labels_unsided_indices = dict((j, i+1) for i, j in enumerate(labels_unsided))  # BackG always 0\n",
    "\n",
    "labelMap_unsidedToSided = {'12N': ['12N'],\n",
    "                            '5N': ['5N_L', '5N_R'],\n",
    "                            '6N': ['6N_L', '6N_R'],\n",
    "                            '7N': ['7N_L', '7N_R'],\n",
    "                            '7n': ['7n_L', '7n_R'],\n",
    "                            'AP': ['AP'],\n",
    "                            'Amb': ['Amb_L', 'Amb_R'],\n",
    "                            'LC': ['LC_L', 'LC_R'],\n",
    "                            'LRt': ['LRt_L', 'LRt_R'],\n",
    "                            'Pn': ['Pn_L', 'Pn_R'],\n",
    "                            'R': ['R_L', 'R_R'],\n",
    "                            'RtTg': ['RtTg'],\n",
    "                            'Tz': ['Tz_L', 'Tz_R'],\n",
    "                            'VLL': ['VLL_L', 'VLL_R'],\n",
    "                            'sp5': ['sp5'],\n",
    "                           'outerContour': ['outerContour']}\n",
    "\n",
    "labelMap_sidedToUnsided = {n: nu for nu, ns in labelMap_unsidedToSided.iteritems() for n in ns}\n",
    "\n",
    "from itertools import chain\n",
    "labels_sided = list(chain(*(labelMap_unsidedToSided[name_u] for name_u in labels_unsided)))\n",
    "labels_sided_indices = dict((j, i+1) for i, j in enumerate(labels_sided)) # BackG always 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 303.   200.5  265.5]\n"
     ]
    }
   ],
   "source": [
    "# atlas_volume = bp.unpack_ndarray_file(os.path.join(volume_dir, 'MD589/volume_MD589_annotation_withOuterContour.bp'))\n",
    "atlas_volume = bp.unpack_ndarray_file(volume_dir + '/atlasVolume_icp.bp')\n",
    "\n",
    "atlas_ydim, atlas_xdim, atlas_zdim = atlas_volume.shape\n",
    "atlas_centroid = np.array([.5*atlas_xdim, .5*atlas_ydim, .5*atlas_zdim])\n",
    "print atlas_centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "available_labels_sided = [labels_sided[i-1] for i in np.unique(atlas_volume) if i > 0]\n",
    "available_labels_unsided = set([labelMap_sidedToUnsided[name] for name in available_labels_sided ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load atlas: 2.126436 seconds\n"
     ]
    }
   ],
   "source": [
    "def parallel_where(name, num_samples=None):\n",
    "    \n",
    "    w = np.where(atlas_volume == labels_sided_indices[name])\n",
    "    \n",
    "    if num_samples is not None:\n",
    "        n = len(w[0])\n",
    "        sample_indices = np.random.choice(range(n), min(num_samples, n), replace=False)\n",
    "        return np.c_[w[1][sample_indices].astype(np.int16), \n",
    "                     w[0][sample_indices].astype(np.int16), \n",
    "                     w[2][sample_indices].astype(np.int16)]\n",
    "    else:\n",
    "        return np.c_[w[1].astype(np.int16), w[0].astype(np.int16), w[2].astype(np.int16)]\n",
    "\n",
    "t = time.time()\n",
    "\n",
    "atlas_nzs = Parallel(n_jobs=16)(delayed(parallel_where)(name_s, num_samples=int(1e5)) for name_s in available_labels_sided)\n",
    "atlas_nzs = dict(zip(available_labels_sided, atlas_nzs))\n",
    "\n",
    "sys.stderr.write('load atlas: %f seconds\\n' % (time.time() - t)) #~ 7s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pts_centered = {name: (np.concatenate([atlas_nzs[n] for n in labelMap_unsidedToSided[name]]) - atlas_centroid).astype(np.int16) \n",
    "                         for name in available_labels_unsided}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# label_weights = {name: 0 if name == 'outerContour' else 1. for name in labels_unsided[1:]}\n",
    "label_weights = {name: .1 if name == 'outerContour' else 1. for name in available_labels_unsided}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_score_and_gradient(T):\n",
    "    global pts_centered\n",
    "    \n",
    "    score = 0\n",
    "    dMdA = np.zeros((12,))\n",
    "    \n",
    "    for name in available_labels_unsided:\n",
    "#         t1 = time.time()\n",
    "    \n",
    "        pts_prime = transform_points(T, pts_centered=pts_centered[name], c_prime=test_centroid)\n",
    "        \n",
    "        xs_prime, ys_prime, zs_prime = pts_prime.T.astype(np.int16)\n",
    "\n",
    "        valid = (xs_prime >= 0) & (ys_prime >= 0) & (zs_prime >= 0) & \\\n",
    "                (xs_prime < test_xdim) & (ys_prime < test_ydim) & (zs_prime < test_zdim)\n",
    "                   \n",
    "        if np.count_nonzero(valid) > 0:\n",
    "\n",
    "            xs_prime_valid = xs_prime[valid]\n",
    "            ys_prime_valid = ys_prime[valid]\n",
    "            zs_prime_valid = zs_prime[valid]\n",
    "            \n",
    "            voxel_probs_valid = volume2_allLabels[name][ys_prime_valid, xs_prime_valid, zs_prime_valid] / 1e4\n",
    "\n",
    "            score += label_weights[name] * voxel_probs_valid.sum()\n",
    "            \n",
    "            Sx = dSdxyz[name][0, ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "            Sy = dSdxyz[name][1, ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "            Sz = dSdxyz[name][2, ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "            \n",
    "            dxs, dys, dzs = pts_centered[name][valid].T\n",
    "\n",
    "            q = np.c_[Sx*dxs, Sx*dys, Sx*dzs, Sx, \n",
    "                          Sy*dxs, Sy*dys, Sy*dzs, Sy,\n",
    "                          Sz*dxs, Sz*dys, Sz*dzs, Sz]        \n",
    "            \n",
    "            dMdA += label_weights[name] * q.sum(axis=0)\n",
    "            \n",
    "            del voxel_probs_valid, q, Sx, Sy, Sz, dxs, dys, dzs, xs_prime_valid, ys_prime_valid, zs_prime_valid\n",
    "        \n",
    "#         sys.stderr.write('########### %s: %f seconds\\n' % (labels[l], time.time() - t1))\n",
    "        \n",
    "        del valid, xs_prime, ys_prime, zs_prime, pts_prime\n",
    "        \n",
    "    return score, dMdA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_score(T):\n",
    "    \n",
    "    score = 0\n",
    "    for name in available_labels_unsided:\n",
    "        \n",
    "        pts_prime = transform_points(T, pts_centered=pts_centered[name], c_prime=test_centroid)\n",
    "    \n",
    "        xs_prime, ys_prime, zs_prime = pts_prime.T.astype(np.int16)\n",
    "        \n",
    "        valid = (xs_prime >= 0) & (ys_prime >= 0) & (zs_prime >= 0) & \\\n",
    "            (xs_prime < test_xdim) & (ys_prime < test_ydim) & (zs_prime < test_zdim)\n",
    "            \n",
    "        voxel_probs_valid = volume2_allLabels[name][ys_prime[valid], xs_prime[valid], zs_prime[valid]] / 1e4\n",
    "\n",
    "        score += label_weights[name] * voxel_probs_valid.sum()\n",
    "                \n",
    "        del voxel_probs_valid, valid, xs_prime, ys_prime, zs_prime, pts_prime\n",
    "                \n",
    "    return score\n",
    "\n",
    "def compute_score_gradient(T):\n",
    "\n",
    "    dMdA = np.zeros((12,))\n",
    "\n",
    "    for name in available_labels_unsided:\n",
    "#       \n",
    "        pts_prime = transform_points(T, pts_centered=pts_centered[name], c_prime=test_centroid)\n",
    "\n",
    "        xs_prime, ys_prime, zs_prime = pts_prime.T.astype(np.int16)\n",
    "\n",
    "        valid = (xs_prime >= 0) & (ys_prime >= 0) & (zs_prime >= 0) & \\\n",
    "            (xs_prime < test_xdim) & (ys_prime < test_ydim) & (zs_prime < test_zdim)\n",
    "            \n",
    "        if np.count_nonzero(valid) > 0:\n",
    "            \n",
    "            xs_prime_valid = xs_prime[valid]\n",
    "            ys_prime_valid = ys_prime[valid]\n",
    "            zs_prime_valid = zs_prime[valid]\n",
    "            \n",
    "            Sx = dSdxyz[name][0, ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "            Sy = dSdxyz[name][1, ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "            Sz = dSdxyz[name][2, ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "               \n",
    "            dxs, dys, dzs = pts_centered[name][valid].T\n",
    "                        \n",
    "            dMdA += label_weights[name] * np.c_[Sx*dxs, Sx*dys, Sx*dzs, Sx, \n",
    "                          Sy*dxs, Sy*dys, Sy*dzs, Sy,\n",
    "                          Sz*dxs, Sz*dys, Sz*dzs, Sz].sum(axis=0)\n",
    "            \n",
    "    return dMdA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load score volumes: 24.233466 seconds\n",
      "load gradient RtTg: 6.154358 seconds\n",
      "load gradient VLL: 5.929505 seconds\n",
      "load gradient Tz: 5.167452 seconds\n",
      "load gradient LC: 5.658573 seconds\n",
      "load gradient 7N: 5.377985 seconds\n",
      "load gradient Amb: 6.036815 seconds\n",
      "load gradient 6N: 7.947687 seconds\n",
      "load gradient AP: 10.084135 seconds\n",
      "load gradient 5N: 49.767496 seconds\n",
      "load gradient 12N: 23.159469 seconds\n",
      "load gradient 7n: 9.931210 seconds\n",
      "load gradient R: 11.666422 seconds\n",
      "load gradient Pn: 15.546721 seconds\n",
      "load gradient LRt: 23.731736 seconds\n",
      "overall: 186.165626 seconds\n",
      "INFO:__main__:grid search iteration 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_xdim, test_ydim, test_zdim: 838 460 454\n",
      "test_centroid: [ 419.  230.  227.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "grid search: 27.077732 seconds\n",
      "INFO:__main__:0.000000 45.404541\n",
      "INFO:__main__:-112.999507 30.282102 -9.577975\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:grid search iteration 1\n",
      "grid search: 21.173573 seconds\n",
      "INFO:__main__:45.404541 50.026577\n",
      "INFO:__main__:-103.491287 45.186247 -16.865309\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:grid search iteration 2\n",
      "grid search: 16.616323 seconds\n",
      "INFO:__main__:50.026577 54.384628\n",
      "INFO:__main__:-92.199966 47.764104 -1.885321\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:grid search iteration 3\n",
      "grid search: 12.901900 seconds\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:grid search iteration 4\n",
      "grid search: 9.793818 seconds\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 0\n",
      "INFO:__main__:score: 54.384628\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 1\n",
      "INFO:__main__:score: 33.577263\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 2\n",
      "INFO:__main__:score: 53.029156\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 3\n",
      "INFO:__main__:score: 58.282015\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 4\n",
      "INFO:__main__:score: 64.647676\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 5\n",
      "INFO:__main__:score: 79.279698\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 6\n",
      "INFO:__main__:score: 81.933414\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 7\n",
      "INFO:__main__:score: 79.601028\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 8\n",
      "INFO:__main__:score: 79.093964\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 9\n",
      "INFO:__main__:score: 79.965405\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 10\n",
      "INFO:__main__:score: 80.436607\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 11\n",
      "INFO:__main__:score: 83.157417\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 12\n",
      "INFO:__main__:score: 82.586597\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 13\n",
      "INFO:__main__:score: 84.138378\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 14\n",
      "INFO:__main__:score: 83.463303\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 15\n",
      "INFO:__main__:score: 84.547287\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 16\n",
      "INFO:__main__:score: 84.096886\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 17\n",
      "INFO:__main__:score: 84.923771\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 18\n",
      "INFO:__main__:score: 84.491108\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 19\n",
      "INFO:__main__:score: 85.072334\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 20\n",
      "INFO:__main__:score: 84.773273\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 21\n",
      "INFO:__main__:score: 85.175854\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 22\n",
      "INFO:__main__:score: 84.934414\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 23\n",
      "INFO:__main__:score: 85.267624\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 24\n",
      "INFO:__main__:score: 85.071083\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 25\n",
      "INFO:__main__:score: 85.381969\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 26\n",
      "INFO:__main__:score: 85.229424\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 27\n",
      "INFO:__main__:score: 85.467960\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 28\n",
      "INFO:__main__:score: 85.284203\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 29\n",
      "INFO:__main__:score: 85.530403\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 30\n",
      "INFO:__main__:score: 85.412254\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 31\n",
      "INFO:__main__:score: 85.589142\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 32\n",
      "INFO:__main__:score: 85.507912\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 33\n",
      "INFO:__main__:score: 85.636036\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 34\n",
      "INFO:__main__:score: 85.546963\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 35\n",
      "INFO:__main__:score: 85.644852\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 36\n",
      "INFO:__main__:score: 85.549812\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 37\n",
      "INFO:__main__:score: 85.685959\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 38\n",
      "INFO:__main__:score: 85.586857\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 39\n",
      "INFO:__main__:score: 85.703724\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 40\n",
      "INFO:__main__:score: 85.644394\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 41\n",
      "INFO:__main__:score: 85.694962\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 42\n",
      "INFO:__main__:score: 85.594578\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 43\n",
      "INFO:__main__:score: 85.712677\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 44\n",
      "INFO:__main__:score: 85.620964\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 45\n",
      "INFO:__main__:score: 85.717682\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 46\n",
      "INFO:__main__:score: 85.595592\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 47\n",
      "INFO:__main__:score: 85.722622\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 48\n",
      "INFO:__main__:score: 85.633575\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 49\n",
      "INFO:__main__:score: 85.705086\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 50\n",
      "INFO:__main__:score: 85.610912\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 51\n",
      "INFO:__main__:score: 85.718845\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 52\n",
      "INFO:__main__:score: 85.600964\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 53\n",
      "INFO:__main__:score: 85.684681\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 54\n",
      "INFO:__main__:score: 85.638084\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 55\n",
      "INFO:__main__:score: 85.681778\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 56\n",
      "INFO:__main__:score: 85.700558\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 57\n",
      "INFO:__main__:score: 85.714046\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 58\n",
      "INFO:__main__:score: 85.693748\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 59\n",
      "INFO:__main__:score: 85.767601\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 60\n",
      "INFO:__main__:score: 85.703579\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 61\n",
      "INFO:__main__:score: 85.761814\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 62\n",
      "INFO:__main__:score: 85.752453\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 63\n",
      "INFO:__main__:score: 85.753864\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 64\n",
      "INFO:__main__:score: 85.732117\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 65\n",
      "INFO:__main__:score: 85.815228\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 66\n",
      "INFO:__main__:score: 85.784733\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 67\n",
      "INFO:__main__:score: 85.825176\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 68\n",
      "INFO:__main__:score: 85.725296\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 69\n",
      "INFO:__main__:score: 85.821068\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 70\n",
      "INFO:__main__:score: 85.785751\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 71\n",
      "INFO:__main__:score: 85.818321\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 72\n",
      "INFO:__main__:score: 85.745834\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 73\n",
      "INFO:__main__:score: 85.809383\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 74\n",
      "INFO:__main__:score: 85.803444\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 75\n",
      "INFO:__main__:score: 85.826008\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 76\n",
      "INFO:__main__:score: 85.749802\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 77\n",
      "INFO:__main__:score: 85.835781\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 78\n",
      "INFO:__main__:score: 85.813263\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 79\n",
      "INFO:__main__:score: 85.859180\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 80\n",
      "INFO:__main__:score: 85.770329\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 81\n",
      "INFO:__main__:score: 85.833763\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 82\n",
      "INFO:__main__:score: 85.800552\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 83\n",
      "INFO:__main__:score: 85.845512\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 84\n",
      "INFO:__main__:score: 85.755768\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 85\n",
      "INFO:__main__:score: 85.861126\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 86\n",
      "INFO:__main__:score: 85.797760\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 87\n",
      "INFO:__main__:score: 85.854340\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 88\n",
      "INFO:__main__:score: 85.741184\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 89\n",
      "INFO:__main__:score: 85.831757\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 90\n",
      "INFO:__main__:score: 85.808472\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 91\n",
      "INFO:__main__:score: 85.861149\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 92\n",
      "INFO:__main__:score: 85.796803\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 93\n",
      "INFO:__main__:score: 85.847446\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 94\n",
      "INFO:__main__:score: 85.744125\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 95\n",
      "INFO:__main__:score: 85.852283\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 96\n",
      "INFO:__main__:score: 85.781193\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 97\n",
      "INFO:__main__:score: 85.839584\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 98\n",
      "INFO:__main__:score: 85.745121\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 99\n",
      "INFO:__main__:score: 85.840588\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 100\n",
      "INFO:__main__:score: 85.779247\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 101\n",
      "INFO:__main__:score: 85.833748\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 102\n",
      "INFO:__main__:score: 85.767570\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 103\n",
      "INFO:__main__:score: 85.859104\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 104\n",
      "INFO:__main__:score: 85.739399\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 105\n",
      "INFO:__main__:score: 85.856182\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 106\n",
      "INFO:__main__:score: 85.761818\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 107\n",
      "INFO:__main__:score: 85.856190\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 108\n",
      "INFO:__main__:score: 85.784176\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 109\n",
      "INFO:__main__:score: 85.871811\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 110\n",
      "INFO:__main__:score: 85.770519\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 111\n",
      "INFO:__main__:score: 85.861023\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 112\n",
      "INFO:__main__:score: 85.791039\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 113\n",
      "INFO:__main__:score: 85.863060\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 114\n",
      "INFO:__main__:score: 85.803745\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 115\n",
      "INFO:__main__:score: 85.859074\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 116\n",
      "INFO:__main__:score: 85.796879\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 117\n",
      "INFO:__main__:score: 85.868908\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 118\n",
      "INFO:__main__:score: 85.802757\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 119\n",
      "INFO:__main__:score: 85.854229\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 120\n",
      "INFO:__main__:score: 85.795895\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 121\n",
      "INFO:__main__:score: 85.875729\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 122\n",
      "INFO:__main__:score: 85.801781\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 123\n",
      "INFO:__main__:score: 85.862064\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 124\n",
      "INFO:__main__:score: 85.816391\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 125\n",
      "INFO:__main__:score: 85.861088\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 126\n",
      "INFO:__main__:score: 85.834965\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 127\n",
      "INFO:__main__:score: 85.854256\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 128\n",
      "INFO:__main__:score: 85.839863\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 129\n",
      "INFO:__main__:score: 85.876671\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 130\n",
      "INFO:__main__:score: 85.808685\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 131\n",
      "INFO:__main__:score: 85.861057\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 132\n",
      "INFO:__main__:score: 85.838898\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 133\n",
      "INFO:__main__:score: 85.871834\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:iteration 134\n",
      "INFO:__main__:score: 85.824219\n",
      "INFO:__main__:\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEKCAYAAADpfBXhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x28ce150>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For all stacks\n",
    "\n",
    "# for stack in ['MD594', 'MD593', 'MD585', 'MD592', 'MD590', 'MD591', 'MD595', 'MD598', 'MD602']:\n",
    "for stack in ['MD589']:\n",
    "    # will do for MD589, MD603 later\n",
    "    \n",
    "    ################# Load Test Volume ######################\n",
    "\n",
    "    t = time.time()\n",
    "\n",
    "    volume2_allLabels = {}\n",
    "\n",
    "    for name in available_labels_unsided:\n",
    "\n",
    "        if name == 'BackG':\n",
    "            continue\n",
    "\n",
    "        volume2_roi = bp.unpack_ndarray_file(os.path.join(volume_dir, '%(stack)s/%(stack)s_scoreVolume_%(label)s.bp' % \\\n",
    "                                                          {'stack': stack, 'label': name})).astype(np.float16)\n",
    "        volume2_allLabels[name] = volume2_roi\n",
    "        del volume2_roi\n",
    "\n",
    "    test_ydim, test_xdim, test_zdim = volume2_allLabels.values()[0].shape\n",
    "    test_centroid = np.r_[.5*test_xdim, .5*test_ydim, .5*test_zdim]\n",
    "\n",
    "    print 'test_xdim, test_ydim, test_zdim:', test_xdim, test_ydim, test_zdim\n",
    "    print 'test_centroid:', test_centroid\n",
    "\n",
    "    sys.stderr.write('load score volumes: %f seconds\\n' % (time.time() - t))\n",
    "\n",
    "    ###################### Load Gradient #####################\n",
    "\n",
    "    dSdxyz = {name: np.empty((3, test_ydim, test_xdim, test_zdim), dtype=np.float16) for name in available_labels_unsided}\n",
    "\n",
    "    t1 = time.time()\n",
    "\n",
    "    for name in available_labels_unsided:\n",
    "\n",
    "        if name == 'BackG':\n",
    "            continue\n",
    "\n",
    "        t = time.time()\n",
    "\n",
    "        dSdxyz[name][0] = bp.unpack_ndarray_file(volume_dir + '/%(stack)s/%(stack)s_scoreVolume_%(label)s_gx.bp' % {'stack':stack, 'label':name})\n",
    "        dSdxyz[name][1] = bp.unpack_ndarray_file(volume_dir + '/%(stack)s/%(stack)s_scoreVolume_%(label)s_gy.bp' % {'stack':stack, 'label':name})\n",
    "        dSdxyz[name][2] = bp.unpack_ndarray_file(volume_dir + '/%(stack)s/%(stack)s_scoreVolume_%(label)s_gz.bp' % {'stack':stack, 'label':name})\n",
    "\n",
    "        sys.stderr.write('load gradient %s: %f seconds\\n' % (name, time.time() - t)) # ~6s\n",
    "\n",
    "    sys.stderr.write('overall: %f seconds\\n' % (time.time() - t1)) # ~100s\n",
    "    \n",
    "    handler = logging.FileHandler(atlasAlignOptLogs_dir + '/%(stack)s_atlasAlignOpt.log' % {'stack': stack})\n",
    "    handler.setLevel(logging.INFO)\n",
    "    logger.addHandler(handler)\n",
    "\n",
    "    ################# Random Grid Search ######################\n",
    "\n",
    "    grid_search_iteration_number = 5\n",
    "    # grid_search_iteration_number = 1\n",
    "\n",
    "    params_best_upToNow = (0, 0, 0)\n",
    "    score_best_upToNow = 0\n",
    "\n",
    "    init_n = 1000\n",
    "\n",
    "    for iteration in range(grid_search_iteration_number):\n",
    "\n",
    "        logger.info('grid search iteration %d', iteration)\n",
    "\n",
    "        init_tx, init_ty, init_tz  = params_best_upToNow\n",
    "\n",
    "        n = int(init_n*np.exp(-iteration/3.))\n",
    "\n",
    "        sigma_tx = 300*np.exp(-iteration/3.)\n",
    "        sigma_ty = 300*np.exp(-iteration/3.)\n",
    "        sigma_tz = 100*np.exp(-iteration/3.)\n",
    "\n",
    "        tx_grid = init_tx + sigma_tx * (2 * np.random.random(n) - 1)\n",
    "        ty_grid = init_ty + sigma_ty * (2 * np.random.random(n) - 1)\n",
    "        tz_grid = init_tz + sigma_tz * (2 * np.random.random(n) - 1)\n",
    "\n",
    "        samples = np.c_[tx_grid, ty_grid, tz_grid]\n",
    "\n",
    "        import time\n",
    "\n",
    "        t = time.time()\n",
    "        # num jobs * memory each job\n",
    "\n",
    "        scores = Parallel(n_jobs=8)(delayed(compute_score)(np.r_[1, 0, 0, tx, 0, 1, 0, ty, 0, 0, 1, tz])\n",
    "                                    for tx, ty, tz in samples)\n",
    "\n",
    "    #     scores = []\n",
    "    #     for tx, ty, tz in samples:\n",
    "    #         scores.append(compute_score([1, 0, 0, tx, 0, 1, 0, ty, 0, 0, 1, tz]))\n",
    "\n",
    "        sys.stderr.write('grid search: %f seconds\\n' % (time.time() - t)) # ~23s\n",
    "\n",
    "        score_best = np.max(scores)\n",
    "\n",
    "        tx_best, ty_best, tz_best = samples[np.argmax(scores)]\n",
    "\n",
    "        if score_best > score_best_upToNow:\n",
    "            logger.info('%f %f', score_best_upToNow, score_best)\n",
    "\n",
    "            score_best_upToNow = score_best\n",
    "            params_best_upToNow = tx_best, ty_best, tz_best\n",
    "\n",
    "            logger.info('%f %f %f', tx_best, ty_best, tz_best)\n",
    "\n",
    "        logger.info('\\n')\n",
    "        \n",
    "    ################# Gradient Descent ######################\n",
    "\n",
    "    lr1, lr2 = (10., 1e-1)\n",
    "    # lr1, lr2 = (1., 1e-3)\n",
    "\n",
    "    # auto_corr = .95\n",
    "\n",
    "    max_iter_num = 1000\n",
    "    fudge_factor = 1e-6 #for numerical stability\n",
    "    dMdA_historical = np.zeros((12,))\n",
    "\n",
    "    tx_best, ty_best, tz_best = params_best_upToNow\n",
    "    T_best = np.r_[1,0,0, tx_best, 0,1,0, ty_best, 0,0,1, tz_best]\n",
    "\n",
    "    lr = np.r_[lr2, lr2, lr2, lr1, lr2, lr2, lr2, lr1, lr2, lr2, lr2, lr1]\n",
    "\n",
    "    score_best = 0\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    for iteration in range(max_iter_num):\n",
    "\n",
    "        logger.info('iteration %d', iteration)\n",
    "\n",
    "    #     t = time.time()\n",
    "        s, dMdA = compute_score_and_gradient(T_best)\n",
    "    #     sys.stderr.write('compute_score_and_gradient: %f seconds\\n' % (time.time() - t)) #~ 2s/iteration or ~.5s: 1e5 samples per landmark\n",
    "\n",
    "        dMdA_historical += dMdA**2\n",
    "    #     dMdA_historical = auto_corr * dMdA_historical + (1-auto_corr) * dMdA**2\n",
    "\n",
    "        dMdA_adjusted = dMdA / (fudge_factor + np.sqrt(dMdA_historical))\n",
    "\n",
    "        T_best += lr*dMdA_adjusted\n",
    "\n",
    "    #         logger.info('A: ' + ' '.join(['%f']*12) % tuple(A_best))\n",
    "    #         logger.info('dMdA adjusted: ' + ' '.join(['%f']*12) % tuple(dMdA_adjusted))\n",
    "\n",
    "        logger.info('score: %f', s)\n",
    "        scores.append(s)\n",
    "\n",
    "        logger.info('\\n')\n",
    "\n",
    "        history_len = 50\n",
    "        if iteration > 100:\n",
    "            if np.abs(np.mean(scores[iteration-history_len:iteration]) - \\\n",
    "                      np.mean(scores[iteration-2*history_len:iteration-history_len])) < 1e-1:\n",
    "                break\n",
    "\n",
    "        if s > score_best:\n",
    "    #             logger.info('Current best')\n",
    "            best_gradient_descent_params = T_best\n",
    "            score_best = s\n",
    "\n",
    "    plt.title('%s' % stack);\n",
    "    plt.plot(scores);\n",
    "    plt.show();\n",
    "    \n",
    "    del volume2_allLabels, dSdxyz\n",
    "    \n",
    "    ################# Save results ###############\n",
    "    \n",
    "    np.save(atlasAlignOptLogs_dir + '/%(stack)s_scoreEvolutions.npy' % {'stack':stack}, scores)\n",
    "    \n",
    "    create_if_not_exists(os.path.join(atlasAlignParams_dir + '/' + stack))\n",
    "    with open(os.path.join(atlasAlignParams_dir, '%(stack)s/%(stack)s_3dAlignParams.txt' % {'stack':stack}), 'w') as f:\n",
    "\n",
    "        f.writelines(' '.join(['%f']*len(best_gradient_descent_params)) % tuple(best_gradient_descent_params) + '\\n')\n",
    "        f.write((' '.join(['%d']*3)+'\\n') % tuple([atlas_xdim, atlas_ydim, atlas_zdim]))\n",
    "        f.write((' '.join(['%.1f']*3)+'\\n') % tuple(atlas_centroid))    \n",
    "        f.write((' '.join(['%d']*3)+'\\n') % tuple([test_xdim, test_ydim, test_zdim]))\n",
    "        f.write((' '.join(['%.1f']*3)+'\\n') % tuple(test_centroid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# single stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack = 'MD585'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "################# Load Test Volume ######################\n",
    "\n",
    "t = time.time()\n",
    "\n",
    "volume2_allLabels = {}\n",
    "\n",
    "for name in available_labels_unsided:\n",
    "\n",
    "    if name == 'BackG':\n",
    "        continue\n",
    "\n",
    "    volume2_roi = bp.unpack_ndarray_file(os.path.join(volume_dir, '%(stack)s/%(stack)s_scoreVolume_%(label)s.bp' % \\\n",
    "                                                      {'stack': stack, 'label': name})).astype(np.float16)\n",
    "    volume2_allLabels[name] = volume2_roi\n",
    "    del volume2_roi\n",
    "\n",
    "test_ydim, test_xdim, test_zdim = volume2_allLabels.values()[0].shape\n",
    "test_centroid = np.r_[.5*test_xdim, .5*test_ydim, .5*test_zdim]\n",
    "\n",
    "print 'test_xdim, test_ydim, test_zdim:', test_xdim, test_ydim, test_zdim\n",
    "print 'test_centroid:', test_centroid\n",
    "\n",
    "# test_xdim = volume_xmax - volume_xmin + 1\n",
    "# test_ydim = volume_ymax - volume_ymin + 1\n",
    "# test_zdim = volume_zmax - volume_zmin + 1\n",
    "\n",
    "sys.stderr.write('load score volumes: %f seconds\\n' % (time.time() - t))\n",
    "\n",
    "###################### Load Gradient #####################\n",
    "\n",
    "dSdxyz = {name: np.empty((3, test_ydim, test_xdim, test_zdim), dtype=np.float16) for name in available_labels_unsided}\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "for name in available_labels_unsided:\n",
    "\n",
    "    if name == 'BackG':\n",
    "        continue\n",
    "\n",
    "    t = time.time()\n",
    "\n",
    "    dSdxyz[name][0] = bp.unpack_ndarray_file(volume_dir + '/%(stack)s/%(stack)s_scoreVolume_%(label)s_gx.bp' % {'stack':stack, 'label':name})\n",
    "    dSdxyz[name][1] = bp.unpack_ndarray_file(volume_dir + '/%(stack)s/%(stack)s_scoreVolume_%(label)s_gy.bp' % {'stack':stack, 'label':name})\n",
    "    dSdxyz[name][2] = bp.unpack_ndarray_file(volume_dir + '/%(stack)s/%(stack)s_scoreVolume_%(label)s_gz.bp' % {'stack':stack, 'label':name})\n",
    "\n",
    "    sys.stderr.write('load gradient %s: %f seconds\\n' % (name, time.time() - t)) # ~6s\n",
    "\n",
    "sys.stderr.write('overall: %f seconds\\n' % (time.time() - t1)) # ~100s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "handler = logging.FileHandler(atlasAlignOptLogs_dir + '/%(stack)s_atlasAlignOpt.log' % {'stack': stack})\n",
    "handler.setLevel(logging.INFO)\n",
    "logger.addHandler(handler)\n",
    "\n",
    "################# Random Grid Search ######################\n",
    "\n",
    "grid_search_iteration_number = 5\n",
    "# grid_search_iteration_number = 1\n",
    "\n",
    "params_best_upToNow = (0, 0, 0)\n",
    "score_best_upToNow = 0\n",
    "\n",
    "init_n = 1000\n",
    "\n",
    "for iteration in range(grid_search_iteration_number):\n",
    "\n",
    "    logger.info('grid search iteration %d', iteration)\n",
    "\n",
    "    init_tx/home/yuncong/Brain/registration/README.md, init_ty, init_tz  = params_best_upToNow\n",
    "\n",
    "    n = int(init_n*np.exp(-iteration/3.))\n",
    "\n",
    "    sigma_tx = 300*np.exp(-iteration/3.)\n",
    "    sigma_ty = 300*np.exp(-iteration/3.)\n",
    "    sigma_tz = 100*np.exp(-iteration/3.)\n",
    "\n",
    "    tx_grid = init_tx + sigma_tx * (2 * np.random.random(n) - 1)\n",
    "    ty_grid = init_ty + sigma_ty * (2 * np.random.random(n) - 1)\n",
    "    tz_grid = init_tz + sigma_tz * (2 * np.random.random(n) - 1)\n",
    "\n",
    "    samples = np.c_[tx_grid, ty_grid, tz_grid]\n",
    "\n",
    "    import time\n",
    "\n",
    "    t = time.time()\n",
    "    # num jobs * memory each job\n",
    "    \n",
    "    scores = Parallel(n_jobs=8)(delayed(compute_score)(np.r_[1, 0, 0, tx, 0, 1, 0, ty, 0, 0, 1, tz])\n",
    "                                for tx, ty, tz in samples)\n",
    "\n",
    "#     scores = []\n",
    "#     for tx, ty, tz in samples:\n",
    "#         scores.append(compute_score([1, 0, 0, tx, 0, 1, 0, ty, 0, 0, 1, tz]))\n",
    "                                \n",
    "    sys.stderr.write('grid search: %f seconds\\n' % (time.time() - t)) # ~23s\n",
    "    \n",
    "    score_best = np.max(scores)\n",
    "\n",
    "    tx_best, ty_best, tz_best = samples[np.argmax(scores)]\n",
    "\n",
    "    if score_best > score_best_upToNow:\n",
    "        logger.info('%f %f', score_best_upToNow, score_best)\n",
    "\n",
    "        score_best_upToNow = score_best\n",
    "        params_best_upToNow = tx_best, ty_best, tz_best\n",
    "\n",
    "        logger.info('%f %f %f', tx_best, ty_best, tz_best)\n",
    "    \n",
    "    logger.info('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "################# Gradient Descent ######################\n",
    "\n",
    "lr1, lr2 = (10., 1e-1)\n",
    "# lr1, lr2 = (1., 1e-3)\n",
    "\n",
    "# auto_corr = .95\n",
    "\n",
    "max_iter_num = 1000\n",
    "fudge_factor = 1e-6 #for numerical stability\n",
    "dMdA_historical = np.zeros((12,))\n",
    "\n",
    "tx_best, ty_best, tz_best = params_best_upToNow\n",
    "T_best = np.r_[1,0,0, tx_best, 0,1,0, ty_best, 0,0,1, tz_best]\n",
    "\n",
    "lr = np.r_[lr2, lr2, lr2, lr1, lr2, lr2, lr2, lr1, lr2, lr2, lr2, lr1]\n",
    "\n",
    "score_best = 0\n",
    "\n",
    "scores = []\n",
    "\n",
    "for iteration in range(max_iter_num):\n",
    "\n",
    "    logger.info('iteration %d', iteration)\n",
    "\n",
    "#     t = time.time()\n",
    "    s, dMdA = compute_score_and_gradient(T_best)\n",
    "#     sys.stderr.write('compute_score_and_gradient: %f seconds\\n' % (time.time() - t)) #~ 2s/iteration or ~.5s: 1e5 samples per landmark\n",
    "\n",
    "    dMdA_historical += dMdA**2\n",
    "#     dMdA_historical = auto_corr * dMdA_historical + (1-auto_corr) * dMdA**2\n",
    "\n",
    "    dMdA_adjusted = dMdA / (fudge_factor + np.sqrt(dMdA_historical))\n",
    "\n",
    "    T_best += lr*dMdA_adjusted\n",
    "\n",
    "#         logger.info('A: ' + ' '.join(['%f']*12) % tuple(A_best))\n",
    "#         logger.info('dMdA adjusted: ' + ' '.join(['%f']*12) % tuple(dMdA_adjusted))\n",
    "\n",
    "    logger.info('score: %f', s)\n",
    "    scores.append(s)\n",
    "\n",
    "    logger.info('\\n')\n",
    "\n",
    "    history_len = 50\n",
    "    if iteration > 100:\n",
    "        if np.abs(np.mean(scores[iteration-history_len:iteration]) - \\\n",
    "                  np.mean(scores[iteration-2*history_len:iteration-history_len])) < 1e-1:\n",
    "            break\n",
    "\n",
    "    if s > score_best:\n",
    "#             logger.info('Current best')\n",
    "        best_gradient_descent_params = T_best\n",
    "        score_best = s\n",
    "\n",
    "plt.plot(scores);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(atlasAlignOptLogs_dir + '/%(stack)s_scoreEvolutions.npy' % {'stack':stack}, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(atlasAlignParams_dir, '%(stack)s/%(stack)s_3dAlignParams.txt' % {'stack':stack}), 'w') as f:\n",
    "\n",
    "    f.writelines(' '.join(['%f']*len(best_gradient_descent_params)) % tuple(best_gradient_descent_params) + '\\n')\n",
    "    f.write((' '.join(['%d']*3)+'\\n') % tuple([atlas_xdim, atlas_ydim, atlas_zdim]))\n",
    "    f.write((' '.join(['%.1f']*3)+'\\n') % tuple(atlas_centroid))    \n",
    "    f.write((' '.join(['%d']*3)+'\\n') % tuple([test_xdim, test_ydim, test_zdim]))\n",
    "    f.write((' '.join(['%.1f']*3)+'\\n') % tuple(test_centroid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
