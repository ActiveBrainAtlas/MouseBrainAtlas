{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Aligns a score volume with an annotation volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.environ['REPO_DIR'] + '/utilities')\n",
    "from utilities2015 import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import time\n",
    "\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = ['BackG', '5N', '7n', '7N', '12N', 'Pn', 'VLL', \n",
    "          '6N', 'Amb', 'R', 'Tz', 'RtTg', 'LRt', 'LC', 'AP', 'sp5']\n",
    "\n",
    "n_labels = len(labels)\n",
    "\n",
    "labels_index = dict((j, i) for i, j in enumerate(labels))\n",
    "\n",
    "labels_from_surround = dict( (l+'_surround', l) for l in labels[1:])\n",
    "\n",
    "labels_surroundIncluded_list = labels[1:] + [l+'_surround' for l in labels[1:]]\n",
    "labels_surroundIncluded = set(labels_surroundIncluded_list)\n",
    "\n",
    "labels_surroundIncluded_index = dict((j, i) for i, j in enumerate(labels_surroundIncluded_list))\n",
    "\n",
    "# colors = np.random.randint(0, 255, (len(labels_index), 3))\n",
    "\n",
    "colors = np.loadtxt(os.environ['REPO_DIR'] + '/visualization/100colors.txt')\n",
    "colors[labels_index['BackG']] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "volume_dir = '/oasis/projects/nsf/csd395/yuncong/CSHL_volumes/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "volume1 = bp.unpack_ndarray_file(os.path.join(volume_dir, 'volume_MD589_annotation.bp'))\n",
    "atlas_ydim, atlas_xdim, atlas_zdim = volume1.shape\n",
    "print atlas_xdim, atlas_ydim, atlas_zdim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parallel_where(l):\n",
    "    w = np.where(volume1 == l)\n",
    "    return [w[1], w[0], w[2]]\n",
    "\n",
    "t = time.time()\n",
    "\n",
    "atlas_nzs = Parallel(n_jobs=16)(delayed(parallel_where)(l) for l in range(1, n_labels))\n",
    "\n",
    "print time.time() - t, 'seconds'\n",
    "\n",
    "atlas_xmin, atlas_ymin, atlas_zmin = np.min([np.min(atlas_nzs[l-1], axis=1) for l in range(1, n_labels)], axis=0)\n",
    "atlas_xmax, atlas_ymax, atlas_zmax = np.max([np.max(atlas_nzs[l-1], axis=1) for l in range(1, n_labels)], axis=0)\n",
    "print atlas_xmin, atlas_xmax, atlas_ymin, atlas_ymax, atlas_zmin, atlas_zmax\n",
    "\n",
    "atlas_centroid = np.array([.5*atlas_xmin+.5*atlas_xmax, .5*atlas_ymin+.5*atlas_ymax, .5*atlas_zmin+.5*atlas_zmax])\n",
    "print atlas_centroid\n",
    "\n",
    "atlas_cx, atlas_cy, atlas_cz = atlas_centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "downsample_factor = 16\n",
    "\n",
    "section_thickness = 20 # in um\n",
    "xy_pixel_distance_lossless = 0.46\n",
    "xy_pixel_distance_tb = xy_pixel_distance_lossless * 32 # in um, thumbnail\n",
    "# factor = section_thickness/xy_pixel_distance_lossless\n",
    "\n",
    "xy_pixel_distance_downsampled = xy_pixel_distance_lossless * downsample_factor\n",
    "z_xy_ratio_downsampled = section_thickness / xy_pixel_distance_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "atlasAlignOptLogs_dir = '/oasis/projects/nsf/csd395/yuncong/CSHL_atlasAlignOptLogs'\n",
    "if not os.path.exists(atlasAlignOptLogs_dir):\n",
    "    os.makedirs(atlasAlignOptLogs_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "atlasAlignParams_dir = '/oasis/projects/nsf/csd395/yuncong/CSHL_atlasAlignParams'\n",
    "if not os.path.exists(atlasAlignParams_dir):\n",
    "    os.makedirs(atlasAlignParams_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "annotationsViz_rootdir = '/oasis/projects/nsf/csd395/yuncong/CSHL_annotaionsPojectedViz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "volume2_allLabels = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds = []\n",
    "for l in range(1, n_labels):\n",
    "    ds.append(np.array(atlas_nzs[l-1]) - atlas_centroid[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_score_and_gradient(T):\n",
    "    global ds\n",
    "    \n",
    "    Tm = T.reshape((3,4))\n",
    "    tx, ty, tz = Tm[:, 3]\n",
    "    A = Tm[:, :3]\n",
    "\n",
    "    score = 0\n",
    "    dMdA = np.zeros((12,))\n",
    "    \n",
    "    for l in range(1, n_labels):\n",
    "#         t1 = time.time()\n",
    "    \n",
    "        xs_prime, ys_prime, zs_prime = (np.dot(A, ds[l-1]) + \\\n",
    "                                    np.asarray([tx + test_cx, \n",
    "                                                ty + test_cy, \n",
    "                                                tz + test_cz])[:,np.newaxis]).astype(np.int)\n",
    "\n",
    "        valid = (xs_prime >= 0) & (ys_prime >= 0) & (zs_prime >= 0) & \\\n",
    "                (xs_prime < test_xdim) & (ys_prime < test_ydim) & (zs_prime < test_zdim)\n",
    "                   \n",
    "        if np.count_nonzero(valid) > 0:\n",
    "\n",
    "            xs_prime_valid = xs_prime[valid]\n",
    "            ys_prime_valid = ys_prime[valid]\n",
    "            zs_prime_valid = zs_prime[valid]\n",
    "            \n",
    "            voxel_probs_valid = volume2_allLabels[l-1][ys_prime_valid, xs_prime_valid, zs_prime_valid] / 1e4\n",
    "\n",
    "            score += voxel_probs_valid.sum()\n",
    "            \n",
    "            Sx = dSdxyz[l-1][0][ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "            Sy = dSdxyz[l-1][1][ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "            Sz = dSdxyz[l-1][2][ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "            \n",
    "            dxs, dys, dzs = ds[l-1][:, valid]\n",
    "\n",
    "#             dMdA += np.c_[Sx*dxs, Sx*dys, Sx*dzs, Sx, \n",
    "#                           Sy*dxs, Sy*dys, Sy*dzs, Sy,\n",
    "#                           Sz*dxs, Sz*dys, Sz*dzs, Sz].sum(axis=0)\n",
    "            \n",
    "            q = np.c_[Sx*dxs, Sx*dys, Sx*dzs, Sx, \n",
    "                          Sy*dxs, Sy*dys, Sy*dzs, Sy,\n",
    "                          Sz*dxs, Sz*dys, Sz*dzs, Sz]        \n",
    "            \n",
    "            dMdA += q.sum(axis=0)\n",
    "            \n",
    "            del voxel_probs_valid, q, Sx, Sy, Sz, dxs, dys, dzs, xs_prime_valid, ys_prime_valid, zs_prime_valid\n",
    "        \n",
    "#         sys.stderr.write('########### %s: %f seconds\\n' % (labels[l], time.time() - t1))\n",
    "        \n",
    "        del valid, xs_prime, ys_prime, zs_prime\n",
    "        \n",
    "    return score, dMdA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_score_and_gradient_and_hessian(T):\n",
    "    global ds\n",
    "    \n",
    "    Tm = T.reshape((3,4))\n",
    "    tx, ty, tz = Tm[:, 3]\n",
    "    A = Tm[:, :3]\n",
    "\n",
    "    score = 0\n",
    "    dMdA = np.zeros((12,))\n",
    "    d2MdT2 = np.zeros((12, 12))\n",
    "    \n",
    "#     for l in range(1, n_labels):\n",
    "    for l in range(1, 5):\n",
    "#         t1 = time.time()\n",
    "    \n",
    "        xs_prime, ys_prime, zs_prime = (np.dot(A, ds[l-1]) + \\\n",
    "                                    np.asarray([tx + test_cx, \n",
    "                                                ty + test_cy, \n",
    "                                                tz + test_cz])[:,np.newaxis]).astype(np.int)\n",
    "\n",
    "        valid = (xs_prime >= 0) & (ys_prime >= 0) & (zs_prime >= 0) & \\\n",
    "                (xs_prime < test_xdim) & (ys_prime < test_ydim) & (zs_prime < test_zdim)\n",
    "                   \n",
    "        if np.count_nonzero(valid) > 0:\n",
    "\n",
    "            xs_prime_valid = xs_prime[valid]\n",
    "            ys_prime_valid = ys_prime[valid]\n",
    "            zs_prime_valid = zs_prime[valid]\n",
    "            \n",
    "            voxel_probs_valid = volume2_allLabels[l-1][ys_prime_valid, xs_prime_valid, zs_prime_valid] / 1e4\n",
    "\n",
    "            score += voxel_probs_valid.sum()\n",
    "            \n",
    "            Sx = dSdxyz[l-1][0][ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "            Sy = dSdxyz[l-1][1][ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "            Sz = dSdxyz[l-1][2][ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "            \n",
    "            dxs, dys, dzs = ds[l-1][:, valid]\n",
    "\n",
    "#             dMdA += np.c_[Sx*dxs, Sx*dys, Sx*dzs, Sx, \n",
    "#                           Sy*dxs, Sy*dys, Sy*dzs, Sy,\n",
    "#                           Sz*dxs, Sz*dys, Sz*dzs, Sz].sum(axis=0)\n",
    "            \n",
    "            q = np.c_[Sx*dxs, Sx*dys, Sx*dzs, Sx, \n",
    "                          Sy*dxs, Sy*dys, Sy*dzs, Sy,\n",
    "                          Sz*dxs, Sz*dys, Sz*dzs, Sz]        \n",
    "            \n",
    "            dMdA += q.sum(axis=0)\n",
    "            \n",
    "            \n",
    "            Sxx_full, Sxy_full, Sxz_full, Syx_full, Syy_full, Syz_full, Szx_full, Szy_full, Szz_full = d2Sdxyz2[l-1]\n",
    "            Sxx = Sxx_full[ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "            Sxy = Sxy_full[ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "            Sxz = Sxz_full[ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "            Syx = Syx_full[ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "            Syy = Syy_full[ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "            Syz = Syz_full[ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "            Szx = Szx_full[ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "            Szy = Szy_full[ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "            Szz = Szz_full[ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "            \n",
    "            rx = np.c_[Sxx*dxs, Sxx*dys, Sxx*dzs, Sxx, Sxy*dxs, Sxy*dys, Sxy*dzs, Sxy, Sxz*dxs, Sxz*dys, Sxz*dzs, Sxz]\n",
    "            ry = np.c_[Syx*dxs, Syx*dys, Syx*dzs, Syx, Syy*dxs, Syy*dys, Syy*dzs, Syy, Syz*dxs, Syz*dys, Syz*dzs, Syz]\n",
    "            rz = np.c_[Szx*dxs, Szx*dys, Szx*dzs, Szx, Szy*dxs, Szy*dys, Szy*dzs, Szy, Szz*dxs, Szz*dys, Szz*dzs, Szz]\n",
    "            r1 = (rx*dxs[:,None]).sum(axis=0)\n",
    "            r2 = (rx*dys[:,None]).sum(axis=0)\n",
    "            r3 = (rx*dzs[:,None]).sum(axis=0)\n",
    "            r4 = rx.sum(axis=0)\n",
    "            r5 = (ry*dxs[:,None]).sum(axis=0)\n",
    "            r6 = (ry*dys[:,None]).sum(axis=0)\n",
    "            r7 = (ry*dzs[:,None]).sum(axis=0)\n",
    "            r8 = ry.sum(axis=0)\n",
    "            r9 = (rz*dxs[:,None]).sum(axis=0)\n",
    "            r10 = (rz*dys[:,None]).sum(axis=0)\n",
    "            r11 = (rz*dzs[:,None]).sum(axis=0)\n",
    "            r12 = rz.sum(axis=0)\n",
    "        \n",
    "            d2MdT2 += np.vstack([r1, r2, r3, r4, r5, r6, r7, r8, r9, r10, r11, r12])\n",
    "            \n",
    "            del voxel_probs_valid, q, Sx, Sy, Sz, dxs, dys, dzs, xs_prime_valid, ys_prime_valid, zs_prime_valid\n",
    "            del Sxx_full, Sxy_full, Sxz_full, Syx_full, Syy_full, Syz_full, Szx_full, Szy_full, Szz_full\n",
    "        \n",
    "#         sys.stderr.write('########### %s: %f seconds\\n' % (labels[l], time.time() - t1))\n",
    "        \n",
    "        del valid, xs_prime, ys_prime, zs_prime\n",
    "        \n",
    "    return score, dMdA, d2MdT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_score_minus(T):\n",
    "    return -compute_score(T)\n",
    "\n",
    "def compute_score_gradient_minus(T):\n",
    "    return -compute_score_gradient(T)\n",
    "\n",
    "def compute_score_hessian_minus(T):\n",
    "    return -compute_score_hessian(T)\n",
    "\n",
    "def compute_score_and_gradient_minus(T):\n",
    "    s, g = compute_score_and_gradient(T)\n",
    "    return -s, -g\n",
    "\n",
    "def compute_score_and_gradient_and_hessian_minus(T):\n",
    "    s, g, h = compute_score_and_gradient_and_hessian(T)\n",
    "    return -s, -g, -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_score(T):\n",
    "    \n",
    "    Tm = np.reshape(T, (3,4))\n",
    "    tx, ty, tz = Tm[:, 3]\n",
    "    A = Tm[:, :3]\n",
    "  \n",
    "    score = 0\n",
    "#     for l in range(1, n_labels):\n",
    "    for l in range(1, 5):\n",
    "        \n",
    "        xs_prime, ys_prime, zs_prime = (np.dot(A, ds[l-1]) + \\\n",
    "                                    np.asarray([tx + test_cx, \n",
    "                                                ty + test_cy, \n",
    "                                                tz + test_cz])[:,np.newaxis]).astype(np.int)\n",
    "        valid = (xs_prime >= 0) & (ys_prime >= 0) & (zs_prime >= 0) & \\\n",
    "            (xs_prime < test_xdim) & (ys_prime < test_ydim) & (zs_prime < test_zdim)\n",
    "        voxel_probs_valid = volume2_allLabels[l-1][ys_prime[valid], xs_prime[valid], zs_prime[valid]] / 1e4\n",
    "\n",
    "        score += voxel_probs_valid.sum()\n",
    "                \n",
    "    del voxel_probs_valid, valid, xs_prime, ys_prime, zs_prime\n",
    "                \n",
    "    return score\n",
    "\n",
    "def compute_score_gradient(T):\n",
    "\n",
    "    Tm = np.reshape(T, (3,4))\n",
    "    tx, ty, tz = Tm[:, 3]\n",
    "    A = Tm[:, :3]\n",
    "\n",
    "    dMdA = np.zeros((12,))\n",
    "\n",
    "    for l in range(1, n_labels):    \n",
    "#     for l in [1]:\n",
    "\n",
    "        xs_prime, ys_prime, zs_prime = (np.dot(A, ds[l-1]) + \\\n",
    "                                        np.asarray([tx + test_cx, \n",
    "                                                    ty + test_cy, \n",
    "                                                    tz + test_cz])[:,np.newaxis]).astype(np.int)\n",
    "\n",
    "        valid = (xs_prime >= 0) & (ys_prime >= 0) & (zs_prime >= 0) & \\\n",
    "            (xs_prime < test_xdim) & (ys_prime < test_ydim) & (zs_prime < test_zdim)\n",
    "            \n",
    "        if np.count_nonzero(valid) > 0:\n",
    "            \n",
    "            xs_prime_valid = xs_prime[valid]\n",
    "            ys_prime_valid = ys_prime[valid]\n",
    "            zs_prime_valid = zs_prime[valid]\n",
    "            \n",
    "            Sx = dSdxyz[l-1][0][ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "            Sy = dSdxyz[l-1][1][ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "            Sz = dSdxyz[l-1][2][ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "               \n",
    "            dxs, dys, dzs = ds[l-1][:, valid]\n",
    "            dMdA += np.c_[Sx*dxs, Sx*dys, Sx*dzs, Sx, \n",
    "                          Sy*dxs, Sy*dys, Sy*dzs, Sy,\n",
    "                          Sz*dxs, Sz*dys, Sz*dzs, Sz].sum(axis=0)\n",
    "            \n",
    "    return dMdA\n",
    "\n",
    "\n",
    "def compute_score_hessian(T):\n",
    "    \n",
    "    Tm = np.reshape(T, (3,4))\n",
    "    tx, ty, tz = Tm[:, 3]\n",
    "    A = Tm[:, :3]\n",
    "\n",
    "    d2MdT2 = np.zeros((12, 12))\n",
    "    \n",
    "    for l in range(1, n_labels):\n",
    "\n",
    "        xs_prime, ys_prime, zs_prime = (np.dot(A, ds[l-1]) + \\\n",
    "                                        np.asarray([tx + test_cx, \n",
    "                                                    ty + test_cy, \n",
    "                                                    tz + test_cz])[:,np.newaxis]).astype(np.int)\n",
    "\n",
    "        valid = (xs_prime >= 0) & (ys_prime >= 0) & (zs_prime >= 0) & \\\n",
    "            (xs_prime < test_xdim) & (ys_prime < test_ydim) & (zs_prime < test_zdim)\n",
    "\n",
    "        if np.count_nonzero(valid) > 0:\n",
    "\n",
    "            xs_prime_valid = xs_prime[valid]\n",
    "            ys_prime_valid = ys_prime[valid]\n",
    "            zs_prime_valid = zs_prime[valid]\n",
    "            \n",
    "            dxs, dys, dzs = ds[l-1][:, valid]\n",
    "\n",
    "            Sxx_full, Sxy_full, Sxz_full, Syx_full, Syy_full, Syz_full, Szx_full, Szy_full, Szz_full = d2Sdxyz2[l-1]\n",
    "            Sxx = Sxx_full[ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "            Sxy = Sxy_full[ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "            Sxz = Sxz_full[ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "            Syx = Syx_full[ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "            Syy = Syy_full[ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "            Syz = Syz_full[ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "            Szx = Szx_full[ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "            Szy = Szy_full[ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "            Szz = Szz_full[ys_prime_valid, xs_prime_valid, zs_prime_valid]\n",
    "\n",
    "            rx = np.c_[Sxx*dxs, Sxx*dys, Sxx*dzs, Sxx, Sxy*dxs, Sxy*dys, Sxy*dzs, Sxy, Sxz*dxs, Sxz*dys, Sxz*dzs, Sxz]\n",
    "            ry = np.c_[Syx*dxs, Syx*dys, Syx*dzs, Syx, Syy*dxs, Syy*dys, Syy*dzs, Syy, Syz*dxs, Syz*dys, Syz*dzs, Syz]\n",
    "            rz = np.c_[Szx*dxs, Szx*dys, Szx*dzs, Szx, Szy*dxs, Szy*dys, Szy*dzs, Szy, Szz*dxs, Szz*dys, Szz*dzs, Szz]\n",
    "            r1 = (rx*dxs[:,None]).sum(axis=0)\n",
    "            r2 = (rx*dys[:,None]).sum(axis=0)\n",
    "            r3 = (rx*dzs[:,None]).sum(axis=0)\n",
    "            r4 = rx.sum(axis=0)\n",
    "            r5 = (ry*dxs[:,None]).sum(axis=0)\n",
    "            r6 = (ry*dys[:,None]).sum(axis=0)\n",
    "            r7 = (ry*dzs[:,None]).sum(axis=0)\n",
    "            r8 = ry.sum(axis=0)\n",
    "            r9 = (rz*dxs[:,None]).sum(axis=0)\n",
    "            r10 = (rz*dys[:,None]).sum(axis=0)\n",
    "            r11 = (rz*dzs[:,None]).sum(axis=0)\n",
    "            r12 = rz.sum(axis=0)\n",
    "            \n",
    "            d2MdT2_l = np.vstack([r1, r2, r3, r4, r5, r6, r7, r8, r9, r10, r11, r12])\n",
    "    \n",
    "        d2MdT2 += d2MdT2_l\n",
    "    \n",
    "    return d2MdT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stack = 'MD594'\n",
    "\n",
    "section_bs_begin, section_bs_end = section_range_lookup[stack]\n",
    "print section_bs_begin, section_bs_end\n",
    "\n",
    "(volume_xmin, volume_xmax, volume_ymin, volume_ymax, volume_zmin, volume_zmax) = \\\n",
    "np.loadtxt(os.path.join(volume_dir, 'volume_%(stack)s_scoreMap_limits.txt' % {'stack': stack}), dtype=np.int)\n",
    "\n",
    "map_z_to_section = {}\n",
    "for s in range(section_bs_begin, section_bs_end+1):\n",
    "    for z in range(int(z_xy_ratio_downsampled*s) - volume_zmin, int(z_xy_ratio_downsampled*(s+1)) - volume_zmin + 1):\n",
    "        map_z_to_section[z] = s\n",
    "\n",
    "global volume2_allLabels\n",
    "volume2_allLabels = []\n",
    "\n",
    "for l in labels[1:]:\n",
    "    \n",
    "    volume2 = bp.unpack_ndarray_file(os.path.join(volume_dir, 'volume_%(stack)s_scoreMap_%(label)s.bp' % \\\n",
    "                                                  {'stack': stack, 'label': l}))\n",
    "\n",
    "    volume2_cropped = volume2[volume_ymin:volume_ymax+1, volume_xmin:volume_xmax+1]\n",
    "    # copy is important, because then you can delete the large array\n",
    "\n",
    "    volume2_allLabels.append(volume2_cropped.copy())\n",
    "\n",
    "    del volume2, volume2_cropped\n",
    "\n",
    "\n",
    "test_ydim, test_xdim, test_zdim = volume2_allLabels[0].shape\n",
    "test_centroid = (.5*test_xdim, .5*test_ydim, .5*test_ydim)\n",
    "test_cx, test_cy, test_cz = test_centroid\n",
    "\n",
    "print test_xdim, test_ydim, test_zdim\n",
    "print test_centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_search_iteration_number = 1\n",
    "\n",
    "params_best_upToNow = (0, 0, 0)\n",
    "score_best_upToNow = 0\n",
    "\n",
    "for iteration in range(grid_search_iteration_number):\n",
    "\n",
    "    logger.info('grid search iteration %d', iteration)\n",
    "\n",
    "    init_tx, init_ty, init_tz  = params_best_upToNow\n",
    "\n",
    "    n = int(1000*np.exp(-iteration/3.))\n",
    "\n",
    "    sigma_tx = 300*np.exp(-iteration/3.)\n",
    "    sigma_ty = 300*np.exp(-iteration/3.)\n",
    "    sigma_tz = 100*np.exp(-iteration/3.)\n",
    "\n",
    "    tx_grid = init_tx + sigma_tx * (2 * np.random.random(n) - 1)\n",
    "    ty_grid = init_ty + sigma_ty * (2 * np.random.random(n) - 1)\n",
    "    tz_grid = init_tz + sigma_tz * (2 * np.random.random(n) - 1)\n",
    "\n",
    "    samples = np.c_[tx_grid, ty_grid, tz_grid]\n",
    "\n",
    "    import time\n",
    "    t = time.time()\n",
    "\n",
    "    scores = Parallel(n_jobs=16)(delayed(compute_score)([1, 0, 0, tx, 0, 1, 0, ty, 0, 0, 1, tz]) \n",
    "                                 for tx, ty, tz in samples)\n",
    "\n",
    "#     scores = [compute_score([1, 0, 0, tx, 0, 1, 0, ty, 0, 0, 1, tz]) for tx, ty, tz in samples]\n",
    "\n",
    "    print time.time() - t, 'seconds'\n",
    "\n",
    "    score_best = np.max(scores)\n",
    "\n",
    "    tx_best, ty_best, tz_best = samples[np.argmax(scores)]\n",
    "\n",
    "    if score_best > score_best_upToNow:\n",
    "        logger.info('%f %f', score_best_upToNow, score_best)\n",
    "\n",
    "        score_best_upToNow = score_best\n",
    "        params_best_upToNow = tx_best, ty_best, tz_best\n",
    "\n",
    "        logger.info('%f %f %f', tx_best, ty_best, tz_best)\n",
    "        logger.info('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def parallel_where(l):\n",
    "#     w = np.where(volume2_allLabels[l-1] > .5)\n",
    "#     return [w[1], w[0], w[2]]\n",
    "\n",
    "# t = time.time()\n",
    "\n",
    "# test_nzs = Parallel(n_jobs=16)(delayed(parallel_where)(l) for l in range(1, n_labels))\n",
    "\n",
    "# print time.time() - t, 'seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10));\n",
    "plt.imshow(volume2_allLabels[1][..., 0], vmin=0, vmax=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dSdxyz = []\n",
    "\n",
    "# for l in range(1, n_labels):\n",
    "for l in range(1, 5):\n",
    "    \n",
    "    print labels[l]\n",
    "    \n",
    "    t = time.time()\n",
    "    \n",
    "#     gx, gy, gz = Parallel(n_jobs=3)(delayed(load_hdf)(volume_dir + '/volume_%(stack)s_scoreMap_%(lab)s_%(g)s.hdf' % \\\n",
    "#                                          {'stack': stack, 'lab': labels[l], 'g': g} )\n",
    "#                                     for g in ['gx', 'gy', 'gz'])\n",
    "\n",
    "    gx = load_hdf(volume_dir + '/volume_%(stack)s_scoreMap_%(lab)s_gx.hdf' % {'stack': stack, 'lab': labels[l]})\n",
    "    gy = load_hdf(volume_dir + '/volume_%(stack)s_scoreMap_%(lab)s_gy.hdf' % {'stack': stack, 'lab': labels[l]})\n",
    "    gz = load_hdf(volume_dir + '/volume_%(stack)s_scoreMap_%(lab)s_gz.hdf' % {'stack': stack, 'lab': labels[l]})\n",
    "    \n",
    "    print time.time() - t\n",
    "    \n",
    "    dSdxyz.append([gx, gy, gz])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d2Sdxyz2 = []\n",
    "\n",
    "# for l in range(1, n_labels):\n",
    "for l in range(1, 5):\n",
    "    \n",
    "    print labels[l]\n",
    "    \n",
    "    t = time.time()\n",
    "    \n",
    "    gxx = load_hdf(volume_dir + '/volume_%(stack)s_scoreMap_%(lab)s_gxx.hdf' % {'stack': stack, 'lab': labels[l]})\n",
    "    gxy = load_hdf(volume_dir + '/volume_%(stack)s_scoreMap_%(lab)s_gxy.hdf' % {'stack': stack, 'lab': labels[l]})\n",
    "    gxz = load_hdf(volume_dir + '/volume_%(stack)s_scoreMap_%(lab)s_gxz.hdf' % {'stack': stack, 'lab': labels[l]})\n",
    "    gyx = load_hdf(volume_dir + '/volume_%(stack)s_scoreMap_%(lab)s_gyx.hdf' % {'stack': stack, 'lab': labels[l]})\n",
    "    gyy = load_hdf(volume_dir + '/volume_%(stack)s_scoreMap_%(lab)s_gyy.hdf' % {'stack': stack, 'lab': labels[l]})\n",
    "    gyz = load_hdf(volume_dir + '/volume_%(stack)s_scoreMap_%(lab)s_gyz.hdf' % {'stack': stack, 'lab': labels[l]})\n",
    "    gzx = load_hdf(volume_dir + '/volume_%(stack)s_scoreMap_%(lab)s_gzx.hdf' % {'stack': stack, 'lab': labels[l]})\n",
    "    gzy = load_hdf(volume_dir + '/volume_%(stack)s_scoreMap_%(lab)s_gzy.hdf' % {'stack': stack, 'lab': labels[l]})\n",
    "    gzz = load_hdf(volume_dir + '/volume_%(stack)s_scoreMap_%(lab)s_gzz.hdf' % {'stack': stack, 'lab': labels[l]})\n",
    "    \n",
    "    print time.time() - t\n",
    "    \n",
    "    d2Sdxyz2.append([gxx, gxy, gxz, gyx, gyy, gyz, gzx, gzy, gzz])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import fmin_bfgs, fmin_ncg, fmin_l_bfgs_b, fmin_cg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import collections, functools\n",
    "\n",
    "# def func_wrapper(f, cache_size=10):\n",
    "#     evals = {}\n",
    "#     last_points = collections.deque()\n",
    "\n",
    "#     def get(pt, which):\n",
    "#         s = pt.tostring() # get binary string of numpy array, to make it hashable\n",
    "#         if s not in evals:\n",
    "#             evals[s] = f(pt)\n",
    "#             last_points.append(s)\n",
    "#             if len(last_points) >= cache_size:\n",
    "#                 del evals[last_points.popleft()]\n",
    "#         return evals[s][which]\n",
    "\n",
    "#     return functools.partial(get, which=0), functools.partial(get, which=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections, functools\n",
    "\n",
    "def func_wrapper(f, cache_size=10):\n",
    "    evals = {}\n",
    "    last_points = collections.deque()\n",
    "\n",
    "    def get(pt, which):\n",
    "        s = pt.tostring() # get binary string of numpy array, to make it hashable\n",
    "        if s not in evals:\n",
    "            evals[s] = f(pt)\n",
    "            last_points.append(s)\n",
    "            if len(last_points) >= cache_size:\n",
    "                del evals[last_points.popleft()]\n",
    "        return evals[s][which]\n",
    "\n",
    "    return functools.partial(get, which=0), functools.partial(get, which=1), functools.partial(get, which=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tx_best, ty_best, tz_best = params_best_upToNow\n",
    "T_best = np.r_[1,0,0, tx_best, 0,1,0, ty_best, 0,0,1, tz_best]\n",
    "\n",
    "t = time.time()\n",
    "\n",
    "# f_, fprime = func_wrapper(compute_score_and_gradient_minus)\n",
    "\n",
    "f_, fprime, fhess = func_wrapper(compute_score_and_gradient_and_hessian_minus)\n",
    "\n",
    "# res = fmin_ncg(f=f_, x0=T_best, fprime=fprime, fhess=fhess, maxiter=100, epsilon=1e-3, full_output=True)\n",
    "# res = fmin_ncg(f=compute_score_minus, x0=T_best, fprime=compute_score_gradient_minus, maxiter=10, epsilon=1e-2)\n",
    "\n",
    "res = fmin_cg(f=f_, x0=T_best, fprime=fprime, maxiter=10)\n",
    "\n",
    "# res = fmin_bfgs(f=f_, x0=T_best, fprime=fprime, maxiter=10)\n",
    "\n",
    "# res = fmin_l_bfgs_b(func=compute_score_minus, x0=T_best, maxiter=10, approx_grad=True)\n",
    "\n",
    "sys.stderr.write('optimize: %f seconds\\n' % (time.time() - t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tx_best, ty_best, tz_best = params_best_upToNow\n",
    "T_best = np.r_[1,0,0, tx_best, 0,1,0, ty_best, 0,0,1, tz_best]\n",
    "\n",
    "lr1, lr2 = (10., 1e-3)\n",
    "max_iter_num = 5000\n",
    "\n",
    "fudge_factor = 1e-6 #for numerical stability\n",
    "\n",
    "dMdA_historical = np.zeros((12,))\n",
    "\n",
    "lr = np.array([lr2, lr2, lr2, lr1, lr2, lr2, lr2, lr1, lr2, lr2, lr2, lr1])\n",
    "\n",
    "score_best = 0\n",
    "\n",
    "scores = []\n",
    "\n",
    "for iteration in range(max_iter_num):\n",
    "    \n",
    "    logger.info('iteration %d\\n', iteration)\n",
    "    \n",
    "    t = time.time()\n",
    "    \n",
    "    s, dMdA = compute_score_and_gradient(T_best)\n",
    "#     s, dMdA = compute_score_and_gradient_parallel(T_best)\n",
    "\n",
    "#     sys.stderr.write('###### compute_score_and_gradient: %f seconds\\n' % (time.time() - t))\n",
    "#     sys.stderr.write('###### s: %f\\n' % s)\n",
    "\n",
    "    dMdA_historical += dMdA**2\n",
    "    dMdA_adjusted = dMdA / (fudge_factor + np.sqrt(dMdA_historical))\n",
    "    \n",
    "    T_best += lr*dMdA_adjusted\n",
    "\n",
    "#     logger.info('A: ' + ' '.join(['%f']*12) % tuple(T_best))\n",
    "#     logger.info('dMdA adjusted: ' + ' '.join(['%f']*12) % tuple(dMdA_adjusted))\n",
    "\n",
    "    logger.info('score: %f', s)\n",
    "    scores.append(s)\n",
    "\n",
    "    logger.info('\\n')\n",
    "\n",
    "    history_len = 50\n",
    "    if iteration > 200:\n",
    "        if np.abs(np.mean(scores[iteration-history_len:iteration]) - \\\n",
    "                  np.mean(scores[iteration-2*history_len:iteration-history_len])) < 1e-2:\n",
    "            break\n",
    "\n",
    "    if s > score_best:\n",
    "#         logger.info('Current best')\n",
    "        best_gradient_descent_params = T_best\n",
    "        score_best = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
